{
  "doc_type": "scientific paper",
  "title": "Marie-Anick Specificity of Affective Response Depends on Trigger Identification",
  "authors": [
    "Savard"
  ],
  "year": null,
  "journal": "Neuroscience | www.frontiersin.org 1 May 2022 | Volume 16 | Article 879583Editedby:",
  "doi": "10.3389/fnins.2022.879583",
  "abstract": null,
  "keywords": [
    "misophonia",
    "auditory cognition",
    "emotion regulati on",
    "anxiety",
    "anger",
    "mental health",
    "sound sensitivity"
  ],
  "research_topics": [
    "misophonia",
    "auditory cognition",
    "emotion regulati on",
    "anxiety",
    "anger",
    "mental health",
    "sound sensitivity"
  ],
  "created_at": "2025-05-05T02:48:55.868041Z",
  "source_pdf": "documents/research/Global/Savard Marie-Anick Specificity of Affective Response Depends on Trigger Identification.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "ORIGINAL RESEARCH\npublished: 26 May 2022\ndoi: 10.3389/fnins.2022.879583\nFrontiers in Neuroscience | www.frontiersin.org 1 May 2022 | Volume 16 | Article 879583Editedby:\nM.ZacharyRosenthal,\nDukeUniversity,UnitedStates\nReviewedby:\nMercedeErfanian,\nUniversityCollegeLondon,\nUnitedKingdom\nAndradaNeacsiu,\nDukeUniversity,UnitedStates\nLauraDixon,\nUniversityofMississippi,\nUnitedStates\n*Correspondence:\nMarie-AnickSavard\nmarieanick.savard@concordia.ca\n†ORCID:\nMarie-AnickSavard\norcid.org/0000-0001-9332-9806\nAnastasiaG.Sares\norcid.org/0000-0002-1440-2639\nEmilyB.J.Coffey\norcid.org/0000-0001-8249-7396\nMickaelL.D.Deroche\norcid.org/0000-0002-8698-2249\nSpecialtysection:\nThisarticlewassubmittedto\nAuditoryCognitiveNeuroscience,\nasectionofthejournal\nFrontiersinNeuroscience\nReceived: 19February2022\nAccepted: 26April2022\nPublished: 26May2022\nCitation:\nSavardM-A,SaresAG,CoffeyEBJ\nandDerocheMLD(2022)Speciﬁcity\nofAffectiveResponsesinMisophonia\nDependsonTriggerIdentiﬁcation.\nFront.Neurosci.16:879583.\ndoi:10.3389/fnins.2022.879583Speciﬁcity of Affective Responses in\nMisophonia Depends on Trigger\nIdentiﬁcation\nMarie-AnickSavard1,2,3*†,AnastasiaG.Sares1,2,3†,EmilyB.J.Coffey1,2,3†and\nMickaelL.D.Deroche1,2,3†\n1DepartmentofPsychology,ConcordiaUniversity,Montreal ,QC,Canada,2LaboratoryforBrain,MusicandSoundResearch\n(BRAMS),Montreal,QC,Canada,3CentreforResearchonBrain,Language,andMusic(CRBLM),M ontreal,QC,Canada\nIndividuals with misophonia, a disorder involving extreme sound sensitivity, report\nsigniﬁcantanger,disgust,andanxietyinresponsetoselec tbutusuallycommonsounds.\nWhile estimates of prevalence within certain populations su ch as college students\nhave approached 20%, it is currently unknown what percentag e of people experience\nmisophonicresponsestosuch“trigger”sounds.Furthermor e,thereislittleunderstanding\nof the fundamental processes involved. In this study, we aim ed to characterize the\ndistribution of misophonic symptoms in a general populatio n, as well as clarify whether\ntheaversiveemotionalresponsestotriggersoundsarepart lycausedbyacousticsalience\nof the sound itself, or by recognition of the sound. Using mul ti-talker babble as masking\nnoise to decrease participants’ ability to identify sounds , we assessed how identiﬁcation\nof common trigger sounds related to subjective emotional re sponses in 300 adults\nwho participated in an online study. Participants were aske d to listen to and identify\nneutral, unpleasant and trigger sounds embedded in differe nt levels of the masking\nnoise (signal-to-noise ratios: −30,−20,−10, 0,+10 dB), and then to evaluate their\nsubjective judgment of the sounds (pleasantness) and emoti onal reactions to them\n(anxiety,anger,anddisgust).Usingparticipants’scores onascalequantifyingmisophonia\nsensitivity, we selected the top and bottom 20% scorers from the distribution to form a\nMost-Misophonic subgroup ( N=66) and Least-Misophonic subgroup ( N=68). Both\ngroups were better at identifying triggers than unpleasant sounds, which themselves\nwereidentiﬁedbetterthanneutralsounds.Bothgroupsalso recognizedtheaversiveness\nof the unpleasant and trigger sounds, yet for the Most-Misop honic group, there was a\ngreater increase in subjective ratings of negative emotion s once the sounds became\nidentiﬁable, especially for trigger sounds. These results highlight the heightened salience\nof trigger sounds, but furthermore suggest that learning an d higher-order evaluation of\nsounds play an important role in misophonia.\nKeywords: misophonia, auditory cognition, emotion regulati on, anxiety, anger, mental health, sound sensitivity\n1. INTRODUCTION\nMisophonia is a disorder ( Swedo et al., 2022 ) involving extreme sensitivity to common sounds\nsuch as eating, smacking lips, or breathing ( Schröder et al., 2013; Jastreboﬀ and Jastreboﬀ, 2014 )\nwhich trigger a strong negative emotional state. The misopho nic response typically involves\nirritability,annoyance,anxiety,disgust,andangerwhen peopleareexposedtotheirtriggersounds"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\n(Rouw and Erfanian, 2018 ). People with misophonia show\nheightened trigger-speciﬁc physiological autonomic respons es,\nexperience a strong desire to escape from the environment\nwhere they hear trigger sounds ( Kumar et al., 2014 ), and can\nsometimes feel a desire to harm those producing the sounds\n(Edelstein et al., 2013 ). As a consequence, they tend to avoid\nsituations where triggers are likely to be encountered (e.g .,\nsocial gatherings, classrooms, family dinners, etc.) ( Schröder\net al., 2013 ). These avoidance behaviors can be detrimental\nto wellbeing, education, and social relationships ( Neal and\nCavanna, 2013; Jager et al., 2020 ), which highlights the need\nto better characterize misophonia, and explore the underlyin g\nmechanisms by which sounds cause such strong reactions in\ncertainpeople.\n1.1. Misophonia in a General Population\nMisophoniawithingeneralpopulationshasonlyrecentlybecome\na focus of scientiﬁc inquiry. Studies in large samples ( N\n>300) estimate that, when assessed with scales speciﬁcally\ndesigned to target misophonia, about 12–20% of people suﬀer\nfrommoderateorseveremisophoniasymptoms,cross-culturally\n(Turkey, United Kingdom, United States, China) ( Wu et al.,\n2014; Zhou et al., 2017; Kılıç et al., 2021; Naylor et al., 202 1).\nModerate and severe symptoms tend to be grouped together,\nand are characterized by the interference that they cause in\ndaily life at work, school, and home. Research on the prevalenc e\nof misophonia labels subjects as having misophonia or not\nbased on cut-oﬀ points; however, it is unknown if those with\nsevere symptoms of misophonia are truly a categorically specia l\npopulation or merely the tail end of a continuum of sound-\nsensitivity symptoms. Adding to this incertitude, there is s till\nlittleknowledgeofhowprevalencemaydiﬀerbetweenbiologica l\nsexes.Althoughsomeresearchsuggeststhatmisophoniaismo re\nprevalent in females, the samples on which these observations\nwere based were primarily comprised of female university\nstudents (67–84% female), which the authors highlight as a\nlimitation to the generalizability of their results ( Wu et al., 2014;\nZhou et al., 2017; Kılıç et al., 2021 ). As such, it is not yet clear\nif the apparent imbalance is caused by sample bias, noting that\nmost studies recruit within psychology departments, or due to\na real diﬀerence in prevalence across sexes. In addition to sex ,\nage is a factor of interest in the study of misophonia, as ﬁndin gs\ntend to point toward younger age being associated with greate r\nratesofmisophonia.Indeed,researchersﬁndahigherproporti on\nof individuals with misophonia in younger samples (mean age\n19.8 inZhou et al., 2017 and 21.4 in Wu et al., 2014 ) than in\nrelatively older and more age-balanced samples. In a study wit h\nparticipants who were more balanced in age (age range of 15–\n88 inKılıç et al., 2021 , mean age of 43.5 years old), researchers\nfoundloweraverageprevalenceofmisophoniaandobservedtha t\nyounger age was related to higher rates of misophonia. Though\nprevalence estimates are inﬂuenced by the measurement tools\nanddegreeofseverityconsideredasacut-oﬀ,itiscleartha tthere\nare a large number of suﬀerers globally. A better understandi ng\nofwhosuﬀersfrommisophoniaisneeded.1.2. Misophonia, a Sound-Speciﬁc or\nPerson-Speciﬁc Disorder?\nTo understand why certain sounds cause such strong reaction s\nin people with misophonia, some researchers turned their\nattention to the nature of trigger sounds. Although they ten d\nto vary between individuals, there are commonalities in the\ncategories of sounds reported as triggers. Speciﬁcally, they\nare often everyday sounds created by other individuals (and\noccasionally animals), and sometimes repetitive environmen tal\nsounds (Schröder et al., 2013, 2017; Kumar et al., 2014 ). One\nstudy found that in a large misophonic sample ( N=575),\nmost participants were triggered by eating sounds (96% of the\nsample), nasal and breathing sounds (85%), repetitive tapping\n(74%), and mouth/throat sounds (60%) ( Jager et al., 2020 ). One\nobservation about the nature of trigger sounds is that they t end\nto share some acoustic properties. Whether they are of organic\n(e.g., eating) or non-organic (e.g., clock ticking) origin, triggers\nstill tend to be pattern-based and repetitive ( Vitoratou et al.,\n2021). In general, sounds that are temporally modulated tend\nto stand out from a noisy background ( Kayser et al., 2005 );\nthis seems particularly exacerbated in some modulation rate s\nresultingina senseofroughness ( Arnaletal.,2019 ),while other\nwork showed an association between ratings of unpleasantnes s\nand temporal modulation (i.e., 1–16 Hz) in naturalistic sound s\n(Kumar et al., 2008 ). Such acoustic qualities make auditory\nstimuli easier to detect, grab the listener’s attention, an d are\nthought to be processed viabottom-up auditory mechanisms\n(Duangudom and Anderson, 2007 ). Given that typical trigger\nsounds seem to share these attention-grabbing properties, it is\npossible that early-attentive processes are somehow involved i n\nmisophonia(anideadiscussedin Schröderetal.,2014 ,discussed\nin Section 4.2). If it is true that misophonic triggers are easi er to\ndetect than other types of sounds, it may be that such bottom-\nup cues are involved in the development of these sounds as\ntriggers. In other words, more acoustically salient stimul i would\nbe more likely to become triggers, because people are better at\ndetectingthem.\nAt higher levels of processing, the meaning of stimuli is\nextracted as we recognize sounds, interpret them, and make\nlinks with previous memories. Another line of research thus\ninvestigates the common observation that individuals’ tri gger\nsounds seem to relate primarily to contextual cues, and only\npartially to physical characteristics of the sounds ( Jastreboﬀ\nand Jastreboﬀ, 2001 ). Evidence from past studies points toward\nthe involvement of higher-level evaluation of sounds in the\nmisophonic response. Such features include the meaning, soci al\ncontext, and interpretation of the sound ( Schröder et al., 2013;\nBruxner, 2016 ), the belief that the sound is a potential threat\nor that exposure to it will be harmful ( Jastreboﬀ and Jastreboﬀ,\n2014), and the inﬂuence of personality traits ( Daniels et al.,\n2020). In addition, a majority of people with misophonia report\nthat their responses are exacerbated if the sounds are produce d\nby certain people, often close friends, coworkers, and family\nmembers; or that their misophonic responses may even be\nisolated to these events ( Edelstein et al., 2013 ). This insight\nabout the importance of the person who produces the sound in\nFrontiers in Neuroscience | www.frontiersin.org 2 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nthe misophonic response supports the involvement of higher-\nlevel cognitive appraisals (i.e., subjective interpretation ) in the\nmisophonicreaction.Furthermore,individualswithmisophon ia\nreport that they may react to a given sound in one setting (such\nas in their home) but not react as strongly to the same sound\nin another setting (such as in the home of a friend) ( Jastreboﬀ\nand Jastreboﬀ, 2014 ). Considering that the sounds share similar\nacoustic properties regardless of who or what produces them,\nit is likely that a person’s appraisal of a sound and context\naround it aﬀect whether a misophonic reaction is produced or\nnot. This involvement of top-down processes has been hinted\nat by self-reports and case studies, and brieﬂy mentioned in\nHansen et al. (2021) , however it has yet to be supported by\nbehavioralassessments.\nWithevidenceforbothbottom-upandtop-downmechanisms\nbeing involved in misophonia, disentangling the factors\ncontributing to the misophonic response and their relative\nimportance in producing said response will lay essential\ngroundwork for devising eﬀective intervention strategies. If\nevidence supports a greater importance of acoustic cues, then\nsolutions should turn toward modifying the acoustic properti es\nof triggers. If evidence supports the importance of higher\norder evaluations of sounds, then solutions must focus on th e\nassociative link with the speciﬁc triggers of each patient and\nimaginewaysinwhichonecouldbreakthoseassociations.\n1.3. Goal of the Present Study\nThe ﬁrst aim of this study was to characterize the distributi on\nof misophonia symptoms in a general population. To do so,\nwe collected responses from an online community sample on\na scale assessing misophonia. We then examined the shape\nof the distribution to determine whether people with severe\nmisophonia symptoms represent a diﬀerent group than those\nwith sub-clinical symptoms (binomial distribution) or if th ey\nare simply the tail-end of a normal distribution of misophonia\nsensitivity. This ﬁrst aim was descriptive in nature. In term s\nof a potential diﬀerence between males and females, we tested\nthe hypothesis that scores on the measure designed to screen\nfor misophonia would diﬀer between sexes. Based on previous\nresearch ( Wu et al., 2014; Zhou et al., 2017; Kılıç et al., 2021 ),\nwe expected that females would score higher than males, thus\nreportingmoremisophoniasymptoms.\nThe second aim of this study was to determine whether\nmisophonia could be partly caused by a reaction to acoustic\nsalience of typical trigger sounds regardless of what the sou nd\nis (bottom-up processing), or if a sound must be consciously\nidentiﬁed as a known trigger in order to cause a misophonic\nresponse (top-down evaluation of sounds). To do this, we\nselected subgroups of most- and least-misophonic participants\nand measured identiﬁcation thresholds (i.e., the point at wh ich\nsoundsfromacategorywereidentiﬁedbyagivenparticipant)o f\nboth groups for diﬀerent categories of sounds (neutral sounds ,\nunpleasant sounds, typical misophonic triggers). To establis h\nif trigger sounds were indeed more acoustically salient (i. e.,\nmore attention-grabbing) than other categories of sounds, we\nasked participants to identify sounds in the presence of maskin g\nnoise with diﬀerent signal-to-noise ratios (SNR). We thenexploredtheroleofsoundidentiﬁcationonsubjectiveemoti onal\nresponses (anger, anxiety, disgust) and perceived pleasantne ss\nof the sounds, by comparing sub-threshold and supra-threshol d\nresponses. This second aim yielded three diﬀerent hypotheses.\nThe ﬁrst hypothesis, related to lower-level properties of trig ger\nsounds, is that as SNR increases (and all sounds become easie r\nto detect), there would be a diﬀerence in identiﬁcation of the\ndiﬀerent sound categories, such that trigger sounds would be\nidentiﬁed more easily than neutral and unpleasant sounds. Th e\nsecond hypothesis, related to individuals’ diﬀering ability to\ndetect trigger sounds, was that the group of people most prone\ntomisophoniawouldhavelowerdetectionthresholdsfortrig ger\nsounds (i.e., they would be able to detect trigger sounds at a\nlower SNR level). A third hypothesis, related to the potential\ninvolvement of higher-order processes in subjective emotio nal\nresponses of most- and least-misophonic individuals, was that\nthe diﬀerences in subjective ratings of trigger sounds would\nonly appear after the sounds are identiﬁed. In other words, at\nan SNR level where sounds are not identiﬁed, both least- and\nmost-misophonic groups would have similar subjective ratings\nof sounds, and at an SNR level where the sounds are identiﬁed,\nresponseswoulddiﬀerbetweengroupsfortriggersounds.\nThisstudywillfurtherourunderstandingofwhosuﬀersfrom\nmisophonia, whether common trigger sounds diﬀer from other\nenvironmentalsoundsintheirsalience,andifthispotentia leﬀect\nof acoustic properties or higher order evaluation of sounds pla y\nimportantrolesinmisophonicresponses.\n2. METHODS\n2.1. Participants\nA total of 300 adults participated in this study (149 males, 151\nfemales; age range: 18–50 years, mean age: 24.6 SD=6.7) and\nwererecruitedonlinethroughProliﬁc(https://www.proliﬁc. co/).\nProliﬁcisanonlineplatformwhichcombinesdecentrecruitm ent\nstandards with reasonable cost, and allows researchers to pre -\nscreen participants based on information provided when the\nparticipants sign up to the platform, which is updated over\ntime (Palan and Schitter, 2018 ). Research comparing Proliﬁc\nto other more widely used platforms (e.g., MTurk) showed\nthat Proliﬁc provides the highest quality data; participants o n\nProliﬁcgenerallydevotemoreattentiontothetasks,comprehe nd\ninstructions better, answer questionnaire items more care fully,\nand behave more honestly than on comparable platforms ( Eyal\netal.,2021 ).\nTo ensure that participants had a level of English ﬂuency\nthat would allow them to understand and take part in the\nstudy, recruitment was only open to residents of predominantl y\nEnglish-speaking countries (65% from Canada/USA, 32%\nfrom the Ireland/UK, 3% from Australia/New-Zealand). The\nparticipants came from 48 diﬀerent countries of origin, with\ngeneralrepresentationasfollows:52%fromNorthAmerica,3 0%\nfrom Europe, 13% from Asia, 2% from Africa, 1% from South\nAmerica,1%fromOceania(1%missingdata).Fromtheresulti ng\nsample, 64% were English monolinguals, 28% were bilinguals,\nand8%wereﬂuentinthreetoﬁvelanguages(includingEnglish ).\nFurthermore, students and non-students were represented in\nFrontiers in Neuroscience | www.frontiersin.org 3 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nour sample (students: 60%, non-students: 40%), in addition to\npeople with diﬀering employment status (full-time: 31%; part-\ntime: 22%; unemployed: 23%; other: 24%). Subgroups were\ndeﬁnedatthedataanalysisstagebasedontotalMisoQuestsco res\n(Siepsiak et al., 2020a ). See Section 3.1 for details regarding the\ngroupingapproach.\nAll participants reported being in good neurological health\nwith normal hearing and were free of any diagnosed language\ndisorder.Giventhatcomorbidityofmisophoniawithpsychiat ric\nsymptoms could contribute to high levels of anxiety or anger,\nwe used the Proliﬁc pre-screeners to exclude all individuals\nwho were taking medication to treat symptoms of depression,\nanxiety, or low mood. This was done to limit the number of\nindividuals experiencing severe psychiatric symptoms in our\nsample.TheexclusioncriteriaalsoincludedadiagnosisofA utism\nSpectrumDisorder(basedonparticipantself-reportonProliﬁc ),\nas this disorder shows considerable overlap with misophonia in\nterms of symptomatology related to sound sensitivity ( Stiegler\nand Davis, 2010 ). As in other crowdsourcing platforms used\nfor behavioral experiments, Proliﬁc provides an approval rate\nfor each participant. All participants who completed our study\nhad an approval rate above 92% ( M=99.3,SD=1.8),\nwhich we considered to be an acceptable range. No other\nexclusion criteria were speciﬁed for this study. All participa nts\ngave informed consent and were compensated with 2.95GBP\n(equivalent to $5CAD) for their time through Proliﬁc. The\nexperimental protocol was approved by Concordia University’s\nHumanResearchEthicsCommittee.\n2.2. Protocol\nParticipants were recruited through Proliﬁc (www.proliﬁc.c o),\nand redirected to an online behavioral platform (Pavlovia,\nhttps://pavlovia.org/) running the experiment designed on\nPsychoPy ( Peirce et al., 2019 ). The entire experiment took on\naverage28mintocomplete.\nBefore proceeding with the task, participants were asked to\ncomplete a questionnaire designed to screen for misophonia\n(see Section 2.4). They were also asked to specify the type of\naudiooutputthattheywereusing(earbuds,headphones,defau lt\ncomputer audio, speakers), and rate the quality of their audio\n(from1=poorto5 =excellent).Notethatallparticipantsrated\ntheiraudioqualityasa3orhigher.\nParticipants were presented with written instructions on how\nto complete the task and completed three practice trials. The\nsounds in the practice trials were presented without masking\nnoise. After each sound, participants rated their subjective\nresponses to the sound presented and identiﬁed it as they would\nin the task. This allowed participants to familiarize themsel ves\nwith the scales for subjective ratings and with the labels fo r\nthe forced-choice identiﬁcation task, which they were prompt ed\nto closely examine. For the ﬁrst two practice trials, they hea rd\nsounds of a Toddler Crying (1st trial) and a Washing Machine\n(2nd trial) for 15 s with a prompt to take this time to adjust\nthe audio to be comfortably loud. In the third practice trial,\nparticipants were informed that the sounds in the study would\nbe considerably shorter (3 s rather than 15) and proceeded to a\ntrial containing a 3-s version of an Eating sound (diﬀerent fr omtheEatingsoundusedinthetask).Feedbackquestionsatthe end\nof the study revealed that all participants found the instruct ions\nclearandhadnoproblemunderstandingthetask.\nThetaskitselfconsistedof75trials,whereneutral,unpleas ant,\nand trigger sounds were embedded in multitalker babble (see\nSection 2.3), with diﬀerent levels of signal-to-noise ratio ( SNR;\n15 sounds ×5 SNR levels). For each trial, participants ﬁrst\nlistened to the stimuli (3 s), then were prompted to rate the\npleasantness of the sound (from 0 =unpleasant to 100 =\npleasant), as well as their subjective anger (from 0 =angry to\n100=neutral), disgust (from 0 =disgusted to 100 =neutral),\nandanxiety(from0 =anxiousto100 =neutral),usingsliderson\na continuous scale. In contrast with appraisal of the sound itse lf,\nthe person-centered metrics were unidirectional with a neut ral\nstate on one end and the negative aﬀect on the other, such that\nnegativetoneutralreactionswerecaptured.Finally,forea chtrial,\nparticipants completed a 15-alternative forced-choice (15-AF C)\ntask, where they were presented with labels describing all th e\npossiblesoundsandwereaskedtoidentifytheonethattheyhad\njust heard. The experimental interface is presented in Figure1.\nThe participants completed all 75 trials in one single block, and\ntheorderofsoundswasfullyrandomizedwithintheblock.\nAfter the experimental portion ended, participants were\nalso asked to describe what they thought the purpose of\nthe experiment was and whether they had noticed anything\nparticular about the sounds (open-ended response). Of the 300\nparticipants, a total of 19 participants provided vague answers\nto both these questions. We visually assessed the data for th ese\nindividuals to check that they had done the task correctly.\nBecausetheyallshowedgoodidentiﬁcationofthesounds(ab ove\n80% identiﬁcation) on trials where the sounds were louder\nthan the babble, we concluded that all participants were likely\nto have been engaged throughout the experiment. Participants\nwere further asked whether they had experienced technical\ndiﬃculties; no participant reported diﬃculties preventing the m\nfromcompletingthetask.\n2.3. Stimuli\nThe neutral, unpleasant, and misophonic trigger sounds used in\nthisstudywereborrowedfrom Kumaretal.(2017) .Thematerials\noriginally comprised 42 sounds (each category consisting of 14\nstimuli) of 15 s in length, from which we selected a subset of 1 5\nsounds (5 from each category). The triggers in this set of sou nds\nare related to orofacial actions (eating, drinking, etc.), which is\nin line with previous assessments of misophonia showing that\norofacial sounds are the most common misophonic triggers.\nIndeed,Jager et al. (2020) found that all participants in their\nlarge (N=575) sample had at least one oral or nasal sound\nas a trigger, and Vitoratou et al. (2021) showed that people\nwith misophonia were more than 40 times more likely than\nthose without misophonia to be triggered by eating sounds, an d\nmore than 20 times more likely to be triggered by loud/unusual\nbreathing sounds. Though we understand that misophonia is\ncharacterized by a wider range of trigger sounds (as shown in\nDaniels et al., 2020 ), we used human-generated sounds related\nto orofacial actions in the present study, given that they are the\nmostcommontriggersamongindividualswithmisophonia.\nFrontiers in Neuroscience | www.frontiersin.org 4 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nFIGURE 1 | (A) Subjective ratings. Participants had unlimited time to rat e the pleasantness of the sound (from unpleasant to pleasant ) and the subjective feelings of\nanger, disgust, and anxiety after hearing the sound. (B)15-alternative forced-choice task. Participants had unli mited time to click on the label corresponding to the\nsound that they just heard.\nBecause the study design involved a total of 75 trials (5\nSNR levels for each of the 15 sounds), we decided to select a\nrepresentative 3 s clip from each, to reduce the length of the\nexperiment and avoid participant fatigue. The ﬁfteen sounds\nwere selected based on pilot testing. Sounds were eliminated\nif they were frequently confused with another sound (e.g.,\nVacuum Cleaner and Hair Dryer), if they had highly similar\nsemantic meaning (e.g., Eating, Chewing, and Crunching), o r\nif they were diﬃcult to identify in their 3-s form (e.g., Kett le\nBoiling, the acoustic properties of which evolved over 15 s). T he\nﬁnal set of sounds comprised: Hair Dryer, Helicopter, Phone\nRinging,Shower,andWashingMachineasneutralsounds;Alar m\nClock,DentistDrill,FemaleScream,MultipleDogsBarking,a nd\nToddlerCryingasunpleasantsounds;Coughing,Sniﬃng,Eati ng,\nPacketRustling,andCutleryastriggersounds.\nMulti-talker babble is often used as a masker for speech\nperception and hearing-in-noise experiments ( Coﬀey et al.,\n2017). It is a type of noise that many listeners encounter on a\nregular basis in everyday life, therefore it has a higher deg ree\nof ecological validity than other types of maskers ( Silbert et al.,\n2014). Because trigger sounds are frequently human-generated\nandheardinsocialcontexts,wealsoadopteditasamasker.\nInthisstudy,weused10-talkedbabble,withdiﬀerentlevels of\nSNR. The levels were chosen via piloting such that, at the lowes t\nlevel, the target sound would be generally indistinguishabl e\namong the babble, whereas at the highest level, the target so und\nwould be very easily detectable from the babble. Thus, the\nchosenlevelswerecoveringmostoftheunderlyingpsychomet ric\nfunctionfromwhichaninﬂectionpointcouldbewell-bracket ed.\nTheresultingSNRlevelswere: −30,−20,−10,0,+10dB.\n2.4. Questionnaires\nTheMisoQuest( Siepsiaketal.,2020a )isa14-itemquestionnaire\ndesigned to screen for misophonia as a disorder in which\na person is “triggered immediately by certain sounds, withanger as a core (but not exclusive) emotion”. The questionnai re\nincludes items assessing diﬀerent aspects of misophonia, from\nbasic phenomenology (e.g., “I ﬁnd some sounds made by the\nhumanbodyunbearable.”),toclinically-relevantquestion sabout\navoidance behavior and daily functioning (e.g., “If I can, I avoid\nmeeting with certain people because of the sounds they make.”).\nForeachitem,participantswererequiredtoanswerona5-point\nLikert-scale (from 1 =completely disagree, to 5 =completely\nagree). Misophonia symptomatology is indicated by summing\nthescorestogether,foramaximumof70points.TheMisoQuest\nwas developed in Polish with an Exploratory Factor Analysis\n(EFA), and showed excellent reliability (Cronbach’s alpha =\n0.955) in a misophonic sample. The English translation was\nprovided by the team who developed the questionnaire, and (to\nthe best of our knowledge) has yet to be validated in an English -\nspeaking sample. The internal consistency (Cronbach’s alpha) of\ntheMisoQuestinoursampleof300participantswasof0.890.\n2.5. Statistical Approach\nThe ﬁrst analysis concerned the prevalence of misophonia-like\nsymptoms in our online community sample. We characterized\nthefourmomentsofthedistributionofMisoQuestscores(mea n,\nstandarddeviation,skewness,andkurtosis),andusedaShapir o–\nWilk test to examine the normality of this distribution. We\nreiteratedthisanalysissplitbysex(maleorfemale),andreg ressed\ntheMisoQuestscoresbychronologicalage.Afurtherexplorat ion\nof sex eﬀects on each item of this questionnaire was conducted\nwith non-parametric t-tests (given the ordinal nature of the DV\nonanitembasis)andcorroboratedbyaBayesianapproach.This\nhelped isolate which aspects of the questionnaire were likely t o\ndepend on sex, and which were not. Finally, the distribution of\nMisoQuestscoreswasdividedinthetopandbottom20%toform\ntwosub-groups:Most-andLeast-Misophonic.Notethatthiswas\na critical step to the rest of the analyses, which focused on t hese\ntwosubgroups.\nFrontiers in Neuroscience | www.frontiersin.org 5 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nThe second analysis concerned the performance in the\nidentiﬁcation of each sound with one of the 15 labels. A\nsigmoidfunctionwasﬁttedtothepercentcorrectscore,aver aged\nfor each category (neutral, unpleasant, and trigger sounds)\nacross the ﬁve SNRs (from −30 to +10 dB). From these ﬁts,\na threshold was extracted at a ﬁxed level of performance of\n60.5% (which corresponds to d’ of 2 in a 15-AFC task). This\nthreshold was then submitted to a mixed analysis of variance\n(ANOVA) with one between-subject factor (most- vs. least-\nmisophonic group) and one within-subject factor (category:\nneutral, unpleasant, trigger). Greenhouse-Geisser correc tions\nwere applied to eﬀects and interactions that violated the\nassumption of sphericity. Post-hocpairwise comparisons further\nexplored the eﬀect of category, correcting the inﬂation of type I\nerrorwithBonferroniadjustments.\nThe third analysis concerned the subjective ratings, colle cted\nfor each of the ﬁve sounds in each of the three categories of\nsound, at each of the ﬁve SNRs (like the performance data).\nThese ratings were ﬁtted with a second-degree polynomial as a\nfunction of SNR. The position of the threshold divided the SNR\nscaleinwindowswheresoundswereorwerenotidentiﬁable.T he\nsubjectiveratingswereaveragedfromtheﬁtsineachofthes etwo\nwindows, providing twovalues (sub-thresholdratingandsupr a-\nthresholdrating).Thegoalofthisthirdanalysiswastodete rmine\nwhether the supra-threshold rating would depart substantiall y\nfromthesub-thresholdrating,speciﬁcallyfortriggersoun dsand\nspeciﬁcally for the most-misophonic group. Thus, these rating s\nwere submitted to a mixed ANOVA with one between-subject\nfactor(group)andtwowithin-subjectfactors(SNRwindow:s ub-\nvs.supra-threshold,andcategory:3levels).Tofurtherexpl orethe\n3-wayinteraction,thechangeinrating(sub-vs.supra-thre shold)\nwas calculated and submitted to a 2-way ANOVA similar to that\ndescribed above (second analysis). With this reduced desig n, the\nsimple eﬀect of group separately for neutral, unpleasant, and\ntriggersoundsenabledustopointatthetypeofsoundthatcoul d\nelicit a particularly aversive experience (induced by the sou nd\nbecoming identiﬁable) in the Most-Misophonic group. Finally,\nnote that this third approach was repeated in four diﬀerent\nversions, for (1) unpleasantness, (2) anger, (3) disgust, an d (4)\nanxiety,andweredescribedasidenticallyaspossible.\n3. RESULTS\n3.1. MisoQuest Scores\nScores on the MisoQuest were normally distributed (minimum:\n14, maximum: 69, M=37.9SD=9.9), as evidenced by a\nShapiro–Wilk test supporting the normality of the distributio n\n(p=0.560) and by indices of skewness (0.114) and kurtosis\n(−0.017) approaching zero. Figure2 shows the distribution of\nscores for the entire sample. Mean scores on the MisoQuest\ndid not diﬀer between males and females [ t(298)= −0.67,p\n=0.506], and both male and female distributions of MisoQuest\nscores were also respectively normal according to the Shapiro –\nWilk test (female: p=0.653; male: p=0.841). In addition, the\nMisoQuest scores did not correlate with age ( r= −0.06,p=\n0.321), which was also true for males and females separately\n(female: p=0.151; male: p=0.984). In other words, the\nFIGURE 2 | Distribution of MisoQuest scores ( N=300). Least-Misophonic\n(LM) and Most-Misophonic (MM) groups represent the top and b ottom 20% of\nthe distribution. Actual scores are plotted below the curve (jittered for better\nvisualization).\ndata suggest that misophonia symptoms are present in people\nregardlessofsexorage,andisbestconceptualizedasacontin uum\nin a symmetric and mesokurtic distribution of sound sensitivi ty.\nThe distributions of MisoQuest scores by sex and by age are\npresentedinAppendixA.\nBased on the proposition that certain types of misophonic\nresponses may be more common in women than in men ( Kılıç\net al., 2021 ), we compared sexes on their responses to individual\nitems of the MisoQuest. For these additional analyses, given\nthe ordinal nature of the data, we used Mann–Whitney U-tests.\nResults of the tests (using a Bayesian approach) on each item\nare provided in Appendix B. We found that females scored\ngenerallyhigheronitem14,whichassessesimpairmentsindai ly\nfunctioning, and also scored higher on three items relating to\nemotional control (item 1, 2, and 5). Of note, the evidence fo r\na sex diﬀerence was especially strong for item 5 (“When I hear\nunpleasant sounds, I start sensing emotions in my body [e.g., I\nsweat, feel pain, feel pressure, my muscles tense]”), which refe rs\nspeciﬁcallytothephysiologicalcomponentofemotions.\nTo compare people with and without severe misophonia\nsymptoms on our diﬀerent measures, we established two groups\nbased on participants’ total scores on the MisoQuest. The\ngroups of Most-Misophonic (MM) and Least-Misophonic (LM)\nincluded respectively the top and bottom 20% scorers on the\nMisoQuest,basedonaprevalenceof20%formoderate-to-severe\nmisophonia symptoms reported in past literature ( Wu et al.,\n2014; Zhou et al., 2017 ). The resulting MM group ( N=66,\n33 females, mean age: 24.0 SD=5.9) included participants\nwith a total score above 45 on the MisoQuest ( M=51.3; SD\n=5.0), and the LM group ( N=68, 32 females, mean age:\n25.1SD=7.6) included participants with total scores below 31\n(M=25.1;SD=4.6).\nThegroupsdidnotshowstatisticallysigniﬁcantdiﬀerencesin\nany of the demographic variables, including age [ t(132)=−0.88,\np=0.382], sex [ χ2(1)=0.12,p=0.733], number of ﬂuent\nlanguages[ χ2(4)=1.09,p=0.895],continentofresidence[ χ2(2)\n=2.69,p=0.261], employment status [ χ2(3)=2.69,p=0.261]\nandstudentstatus[ χ2(1)=0.21,p=0.645].Thetwogroupsalso\ndid not diﬀer in the audio output they used [ χ2(3)=4.91,p=\nFrontiers in Neuroscience | www.frontiersin.org 6 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\n0.179], nor the audio quality they reported [ χ2(2)=4.18,p=\n0.124].Inotherwords,exceptfromMisoQuestscores,thegrou ps\ndidnotdiﬀerfromoneanother.\n3.2. Identiﬁcation Thresholds\nAs expected, performance on the identiﬁcation task averaged\nover the entire sample (300 participants) increased with SNR,\nsuchthatwhensoundsweremoreeasilydetectable,performan ce\nontheidentiﬁcationtaskincreasedtoabout100%identiﬁca tion.\nPercent correctness of sound identiﬁcation on the 15-AFC-\ntask was used to compute a sigmoidal model of psychometric\nfunctions for each category of sound and individual listene r\n(Figure3A ). Although average ﬁt of the models was lower for\ntrigger sounds ( R2\ntrigger=0.912) than for other types of sounds\n(R2\nunpleasant=0.933,R2\nneutral=0.937), all goodness of ﬁt indices\nwereabove0.9,andthemodelﬁtforeachcategorydidnotdiﬀer\nbetweengroups.\nForeachparticipant,anidentiﬁcationthresholdwasextract ed\nfrom the psychometric function of each category of sound. Thi s\nthreshold would represent the SNR level required to attain an\narbitrary criterion of 60.5% performance on the identiﬁcati on\ntask for a given sound category. In other words, for each\nparticipant, the identiﬁcation threshold represented the SNR\nlevelatwhichtheyreliablyidentiﬁedthesounds.\nA 2×3 mixed ANOVA was conducted to assess diﬀerences\nin identiﬁcation thresholds between the LM and MM groups\nfor the three sound categories (neutral, unpleasant, trigge r). The\nassumptionofsphericityamongthethreecategoriesofsoundw as\nnotmet.Inthisanalysis,andforallothersetsofdatathatv iolated\nthis assumption, the degrees of freedom were adjusted with\nGreenhouse-Geisser [here, χ2(2)=18.8,p<0.001, ǫ=0.882].\nThere was a main eﬀect of category [ F(1.8, 232.9) =362.8,p<\n0.001], and post-hoccomparisons (with Bonferroni corrections)\nrevealed that thresholds were lower for triggers than unplea sant\nsounds (by 2.3 dB, p<0.001) which themselves were lower\nthan neutral sounds (by 9.9 dB, p<0.001). However, there was\nno main eﬀect of Group [ F(1, 132)=0.58,p=0.884] nor any\ninteraction of Group and Sound category [ F(1.8, 232.9) =0.3,p=\n0.688].Figure3B illustratestheANOVAresults.\nThe trigger sounds were more salient in general than the\nother categories of sounds, but this was true of all participan ts,\nregardless of whether they were in the LM or MM group.\nThis provides evidence for the ﬁrst hypothesis, that as SNR\nincreases (and all sounds become easier to detect), there wo uld\nbe a diﬀerence in identiﬁcation of the sounds between sound\ncategories,suchthattriggerswillbeidentiﬁedpriortounpl easant\nsounds and certainly prior to (at least 10 dB) neutral sounds. It\nis also evidence against our second hypothesis; individuals m ost\nprone to misophonia are not better at detecting trigger sounds\nthanthosewhoareleastmisophonic.\n3.3. Subjective Ratings Before and After\nIdentiﬁcation\nFollowing a visual assessment of participants’ responses for e ach\ntype of subjective rating as a function of SNR, we observed tha t\nthe ratings for the aversive sound categories seemed to follo w acurvilineartrend.Thereforeweuseda2nd-degreepolynomial to\nﬁt the participant’s mean ratings at each level of SNR, for each\ntypeofratingandeachcategoryofsound( Figure4).\nToassesswhethersubjective ratingsdiﬀeredinsub-thresho ld\nSNRs vs. supra-threshold SNRs, we averaged all points in the\nsubjective ﬁts below and above the threshold to provide only\n2 values per category and per participant. For each type of\nrating, this resulted in a total of six data points per participan t:\n3 categories of sounds (neutral, unpleasant, trigger) ×2\nSNR windows (below recognition threshold, above recogniti on\nthreshold).Ratingsfromtheself-reportscaleswereﬂipped,s uch\nthat high scores indicated a more aversive reaction. Increa ses in\nagivenratingthereforeindicatedelevatedunpleasantness ,anger,\ndisgust,andanxiety.\nFor each type of rating, we conducted a 2 ×2×3 mixed\nANOVA, with the within-subject factors being Sound category\nand SNR window, and the between-subjects factor being Group\n(LM and MM). For each test, the assumption of sphericity\nwas assessed for Sound category and its interactions; when th e\nassumption of sphericity was not met, degrees of freedom were\nadjusted with the Greenhouse-Geisser correction. Statisti cs for\nmaineﬀectsandinteractions(includingeﬀectsizes)arerepor ted\ninTable1. Note that, when re-computing these analyses with\ntype of audio output or quality of audio as a between-subjects\nfactor, we found that the main results were not aﬀected. The\nLM and MM groups did not diﬀer in audio quality or output,\nthe main eﬀect of either of these variables was never signiﬁca nt,\nand they did not interact with the group variable for any type\nofrating.\nIn addition, we reiterated a similar analysis looking at\nthe linear slope with which subjective ratings degraded as a\nfunction of SNR. The results (reported in Appendix C) were\nlargely consistent with those presented here in Section 3.3. This\nadditionalanalysisreﬂectedthediﬀerentialtrendsinhowso unds\nbecame more aversive as they progressively stood out from the\nmultitalkerbabble.\n3.3.1. Unpleasantness\nThe ﬁrst ANOVA revealed a main eﬀect of Sound category\nand of SNR window, but no main eﬀect of Group. All 2- and\n3-way interactions were signiﬁcant (see Table1for statistics).\nPost-hoc comparisons of the 3-way interaction (with Tukey\ncorrection for multiple comparisons) revealed that, for each\nsound category, there was no statistically signiﬁcant group\ndiﬀerence in unpleasantness ratings below threshold (all p>\n0.999), suggesting that the ratings for the two groups did not\nsigniﬁcantlydiﬀerwhentheycouldnotdetectthesounds.\nThe average ﬁt of the second-degree polynomial was lower\nfor neutral sounds ( R2\nneutral=0.656) than for trigger sounds\n(R2\ntrigger=0.800), which was itself lower than for unpleasant\nsounds (R2\nunpleasant=0.870). The goodness of ﬁt did not diﬀer\nbetweengroups.\nTo assess the 3-way interaction, we tested speciﬁcally the\nchange in rating below and above threshold, across the two\ngroups and the three categories (reducing the design to a 2-wa y\nmixed ANOVA). For the LM group, the increase in rating was\nFrontiers in Neuroscience | www.frontiersin.org 7 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nFIGURE 3 | (A) Psychometric functions ( N=300) for the 15-AFC identiﬁcation task. Average percent iden tiﬁcation plotted at each (SNR) level, for each sound\ncategory. Solid lines represent the mean of the ﬁts and shaded areas represent ±1 standard deviation. Dotted lines represent chance level a nd the performance level\nchosen to deﬁne identiﬁcation thresholds of the 15-AFC task. (B)Mean identiﬁcation threshold for each sound category, for th e Least-Misophonic (LM) and\nMost-Misophonic (MM) groups. Error bars represent ±1 standard deviation. Asterisk (*) indicates a statistical ly signiﬁcant difference ( p<0.01), “n.s.” indicates a\nnon-signiﬁcant difference.\nconsiderably stronger for unpleasant and trigger sounds rel ative\nto neutral sounds (by 24.9 and 17.7 points, p<0.001 in both\ncases),buttheincreasewassmallerintriggersthaninunple asant\nsounds(by7.3points, p=0.001).FortheMMgroup,theincrease\nin rating was even stronger for unpleasant and trigger sounds\nthan neutral (by 33.2 and 27.7 points, p<0.001 in both cases)\nand the increase was again smaller for triggers than unpleasa nt\nsounds (by 7.3 points, p=0.050). Results of the Unpleasantness\nratings below and above the identiﬁcation threshold, for ea ch\nsound category and group, are shown in Figure5. These results\nillustrate how both groups recognized the unpleasantness of\nthe trigger and unpleasant sounds, but only when the sounds\nwereidentiﬁed.\nPerhaps most importantly, the simple eﬀect of Group on the\nbelow/above change in rating was signiﬁcant for triggers ( p<\n0.001) and unpleasant sounds ( p=0.006) but not for neutral\nsounds (p=0.760). Trigger sounds were the category of sounds\nwhere the MM group increased their rating considerably more\nthan the LM group (eﬀect size d=0.64), whereas this was true\nto a smaller degree for unpleasant sounds ( d=0.48), and not\ntrue for neutral sounds (i.e., same trend for the two groups). In\notherwords,theincreaseinunpleasantnessratingsforalla versive\nsounds was more extreme for the MM group than for the LM\ngroup,especiallyfortriggersounds.\n3.3.2. Anger\nThere was a main eﬀect of Sound category, SNR window, and\nGroup, on ratings of Anger. Like for Unpleasantness, all 2- and\n3-way interactions were signiﬁcant. Statistics (includin g eﬀectsizes)arereportedin Table1.Post-hoccomparisonsofthe3-way\ninteraction (with Tukey correction for multiple comparisons)\nrevealed that, for each sound category, there was no statisti cally\nsigniﬁcant group diﬀerence in anger ratings below threshold (all\np>0.271),suggestingthattheratingsforthetwogroupsdidnot\nsigniﬁcantlydiﬀerwhentheycouldnotdetectthesounds.\nTheaverageﬁtofthesecond-degreepolynomialwaslowerfor\nneutralsounds( R2\nneutral=0.593)thanforunpleasantandtrigger\nsounds (R2\nunpleasant=0.768,R2\ntrigger=0.767), which themselves\ndidnotdiﬀerfromoneanother.Thegoodnessofﬁtdidnotdiﬀer\nbetweengroups.\nTo assess the 3-way interaction, we again reduced the design\nto a 2-way mixed ANOVA assessing the change in rating below\nand above threshold. For the LM group, the elevated anger was\nconsiderably stronger for unpleasant and trigger sounds rel ative\nto neutral sounds (by 17.97 and 14.65 points, p<0.001 in both\ncases), but it was not signiﬁcantly diﬀerent between trigger s and\nunpleasant sounds. For the MM group, the elevated anger was\nevenstrongerforunpleasantandtriggersoundsthanforneut ral\nsounds (by 26.59 and 29.17 points, p<0.001 in both cases) and\nagain not signiﬁcantly diﬀerent between triggers and unpleas ant\nsounds, as illustrated in Figure5. These results illustrate how\nboth groups felt more anger in response to the unpleasant and\ntriggersoundswhentheywereidentiﬁed.\nThe simple eﬀect of Group on the elevated anger was\nsigniﬁcant for triggers ( p<0.001) and unpleasant sounds ( p=\n0.005), but not for neutral sounds ( p=0.760). Trigger sounds\nwere the category of sounds where the MM group experienced\nelevatedangerconsiderablymorethantheLMgroup( d=0.95),\nFrontiers in Neuroscience | www.frontiersin.org 8 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nFIGURE 4 | Population results ( N=300) for subjective ratings of each sound category. Shaded a reas represent ±1 standard deviation from the mean ﬁt. The aversive\nsounds (blue and red) show a curvilinear trend.\nwhichwasalsotruetoasmallerdegreeforunpleasantsounds( d\n=0.57), but not true for neutral sounds (i.e., same trend arou nd\n0% for the two groups). That is, the increase in anger ratings f or\nall aversive sounds was more extreme for the MM group than\nfor the LM group, a pattern which was especially strong for the\ntriggersounds.\n3.3.3. Disgust\nThere was a main eﬀect of Sound category, SNR window, and\nGroup, on ratings of Disgust. All 2- and 3-way interactions\nwere signiﬁcant. Statistics (including eﬀect sizes) are repo rted\ninTable1.Post-hoccomparisons of the 3-way interaction (with\nTukey correction for multiple comparisons) revealed that, fo r\neach sound category, there was no statistically signiﬁcant group\ndiﬀerence in disgust ratings below threshold (all p>0.143),\nsuggestingthattheratingsforthetwogroupsdidnotsigniﬁc antly\ndiﬀerwhentheycouldnotdetectthesounds.\nThe average ﬁt of the second-degree polynomial was lower\nfor neutral sounds ( R2\nneutral= 0.581) than for unpleasant sounds\n(R2\nunpleasant=0.674),whichwerethemselveslowerthanfortriggersounds ( R2\ntrigger= 0.803). The goodness of ﬁt did not diﬀer\nbetweengroups.\nTo assess the 3-way interaction, we again reduced the design\nto a 2-way mixed ANOVA assessing the change in rating below\nandabovethreshold.FortheLMgroup,theelevateddisgustwa s\nconsiderably stronger for unpleasant and trigger sounds rel ative\nto neutral sounds (by 9.96 and 21.65 points, p<0.001 in both\ncases), and stronger for trigger relative to unpleasant soun ds (by\n11.69,p<0.001). For the MM group, the elevated disgust was\nevenstrongerforunpleasantandtriggersoundsthanforneut ral\nsounds (by 16.89and 32.92points, p<0.001inboth cases),and\nstronger for triggers than unpleasant sounds (by 16.03 points, p\n<0.001), as illustrated in Figure5. These results illustrate how\nboth groups felt more disgust toward the unpleasant and trigge r\nsounds(especiallythetriggersounds)whentheywereidenti ﬁed.\nThe simple eﬀect of Group on the elevated disgust was\nsigniﬁcant for triggers ( p<0.001), but not for unpleasant ( p=\n0.201) or neutral sounds ( p=1.000). Triggers were the category\nof sounds where the MM group experienced elevated disgust\nconsiderably more than the LM group ( d= 0.60), whereas this\nFrontiers in Neuroscience | www.frontiersin.org 9 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic ResponsesTABLE 1 | ANOVA results for emotional ratings before and after recogn ition threshold.\nUnpleasantness Anger Disgust Anxiety\nMauchly’s test of sphericitya\nSound category χ2(2)=12.4,p=0.002, ǫ= 0.917 χ2(2)= 2.8,p= 0.244 χ2(2)= 12.6,p= 0.002, ǫ= 0.916 χ2(2)= 2.5,p= 0.279\nSNR×Sound category χ2(2)= 5.0,p= 0.081 χ2(2)= 3.2,p= 0.200 χ2(2)= 3.3,p= 0.196 χ2(2)= 2.9,p= 0.234\nMain effects\nSound category F(1.84, 242.16) =272.18 F(2, 264)=135.74 F(1.83, 241.83) =151.49 F(2, 264)=201.91\np<0.001, η2=0.110, η2\np=0.673 p<0.001, η2=0.048, η2\np=0.507 p<0.001, η2=0.062, η2\np=0.534 p<0.001, η2=0.076, η2\np=0.605\nSNR F(1, 132)=190.44, F(1, 132)=143.29 F(1, 132)=113.69 F(1, 132)=193.11\np<0.001, η2=0.116, η2\np=0.591 p<0.001, η2=0.068, η2\np=0.521 p<0.001, η2=0.046, η2\np=0.463 p<0.001, η2=0.107, η2\np=0.594\nGroup F(1, 132)=0.15 F(1, 132)=16.86 F(1, 132)=16.06 F(1, 132)=19.95\np=0.702 p<0.001, η2=0.113, η2\np=0.113 p<0.001, η2=0.073, η2\np=0.108 p<0.001, η2=0.074, η2\np=131\n2-way interactions\nSNR×Sound category F(2, 264)=274.5 F(2, 264)=150.44 F(2, 264)=170.25 F(2, 264)=234.79\np<0.001, η2=0.089, η2\np=0.675 p<0.001, η2=0.045, η2\np=0.533 p<0.001, η2=0.057, η2\np=0.563 p<0.001, η2=0.072, η2\np=0.640\nSNR×Group F(1, 132)=6.64 F(1, 132)=17.76 F(1, 132)=8.414 F(1, 132)=17.18\np=0.011, η2=0.004, η2\np=0.048 p<0.001, η2=0.008, η2\np=0.119 p<0.001, η2=0.004, η2\np=0.060 p<0.001, η2=0.010, η2\np=0.115\nSound category ×Group F(1.84, 242.16) =4.95 F(2, 264)=11.36 F(1.83, 241.83) =6.41 F(2, 264)=8.93\np=0.010, η2=0.002, η2\np=0.036 p<0.001, η2=0.004, η2\np=0.079 p<0.003, η2=0.003, η2\np=0.046 p<0.001, η2=0.003, η2\np=0.063\n3-way interaction\nSNR×Sound category ×Group F(2, 264)=8.42 F(2, 264)=12.34 F(2, 264)=7.39 F(2, 264)=8.55\np<0.001, η2=0.003, η2\np=0.060 p<0.001, η2=0.004, η2\np=0.085 p<0.001, η2=0.002, η2\np=0.053 p<0.001, η2=0.003, η2\np=0.061\nEachcolumnrepresentsadifferentrating.Allratingsshowedasimil arpatternofresults.\naGreenhouse-Geissercorrection( ǫ)appliedwhensphericitywasviolated.\nFrontiers in Neuroscience | www.frontiersin.org 10 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nwas not true for unpleasant sounds and for neutral sounds\n(i.e., same trend [10–15% increase] for the two groups). In\nother words, the increase in disgust ratings was more extrem e\nfor the MM group than for the LM group, speciﬁcally for the\ntriggersounds.\n3.3.4. Anxiety\nThere was a main eﬀect of Sound category, SNR window, and\nGroup, on ratings of Anxiety. Like for all other types of rating s,\nall2-and3-wayinteractionsweresigniﬁcant.Statistics( including\neﬀect sizes) are reported in Table1.Post-hoc comparisons\nof the 3-way interaction (with Tukey correction for multiple\ncomparisons) revealed that, for each sound category, there w as\nno statistically signiﬁcant group diﬀerence in anxiety rati ngs\nbelow threshold (all p>0.157), suggesting that the ratings for\nthe two groups did not signiﬁcantly diﬀer when they could not\ndetectthesounds.\nTheaverageﬁtwaslowerforneutralsounds( R2\nneutral=0.606)\nthan for trigger sounds ( R2\ntrigger=0.679), which was itself lower\nthan for unpleasant sounds ( R2\nunpleasant=0.862). The goodness\nofﬁtdidnotdiﬀerbetweengroups.\nTo assess the 3-way interaction, we again reduced the design\nto a 2-way mixed ANOVA assessing the change in rating below\nandabovethreshold.FortheLMgroup,theelevatedanxietywa s\nconsiderably stronger for unpleasant and trigger sounds rel ative\nto neutral sounds (by 29.08 and 6.91 points, p<0.001 and p=\n0.030), but was weaker for trigger than unpleasant sounds (by\n22.17,p<0.001). For the MM group, the elevated anxiety was\nevenstrongerforunpleasantandtriggersoundsthanneutral (by\n38.79 and 19.33 points, p<0.001 in both cases), and stronger\nfor unpleasant than trigger sounds (by 19.46, p<0.001), as\nillustrated in Figure5. These results illustrate how both groups\nfelt more anxiety toward the unpleasant and trigger sounds\n(especiallytheunpleasantsounds)whentheywereidentiﬁed.\nThe simple eﬀect of Group on the elevated anxiety was\nsigniﬁcant for triggers ( p<0.001) and unpleasant sounds ( p=\n0.005), but not neutral sounds ( p= 1.000). Trigger sounds were\nthecategoryofsoundswheretheMMgroupexperiencedelevated\nanxiety considerably more than the LM group ( d= 0.96), which\nwas also true to a smaller degree for unpleasant sounds ( d=\n0.61),andnottrueforneutralsounds(i.e.,sametrendfort hetwo\ngroups). That is to say, the increase in anxiety ratings was mo re\nextremefortheMMgroupthanfortheLMgroupforallaversive\nsounds. Even though the unpleasant sounds generally induced\nmoreanxietyonceidentiﬁed,thispattern(theMMgrouphaving\na stronger increase in anxiety ratings than the LM group) was\nmoreextremeofthetriggerthanunpleasantsounds.\n4. DISCUSSION\n4.1. Distribution of Misophonia Symptoms\nTo characterize the distribution of misophonia symptoms in\na general population, we collected responses from an online\ncommunity sample of 300 participants on the MisoQuest\n(Siepsiak et al., 2020a ). We found that MisoQuest scores were\nnormally distributed ( Figure2), in line with the idea that manypeople without clinically-signiﬁcant symptoms still experience\nnegative emotional and physiological reactions to sounds. So me\nof the sounds that frequently bother people include ﬁngernails\nscratching on a chalkboard, metal scraping glass, and even\nsome typical misophonic triggers such as chewing or sucking\nnoises (Zald and Pardo, 2002; Kumar et al., 2008 ). Previous\nwork found that, when using a misophonia-speciﬁc scale, a\nrelatively large proportion of the population (68%) reported\nexperiencing such sub-clinical misophonia symptoms ( Zhou\net al., 2017 ). In their study, people with sub-clinical symptoms\nwere deﬁned as individuals experiencing misophonia symptoms\nwhich did not cause signiﬁcant distress in daily life. Taken\ntogether with the distribution of MisoQuest scores found in t his\nstudy,itappearsthatmildmisophoniaregularlyoccursinalarg e\nnumber of people. This observation gives weight to the idea\nthat those who experience daily life impairments as a result of\nmisophoniasimplyrepresentthetailendofanormaldistributio n\nofmisophoniasymptoms.\nIn the development of the MisoQuest, a general cut-oﬀ of 61\noutof70pointswasproposedtoscreenformisophonia( Siepsiak\net al., 2020a ), based on the mean score (minus the standard\ndeviation) of participants self-reporting as having misophonia .\nResearchassessingthepsychometricpropertiesoftheMisoQuest ,\nfound that the questionnaire had good speciﬁcity (ability to\ncorrectly classify an individual as not having misophonia), b ut\nhad low sensitivity (ability to correctly classify an indivi dual\nas having misophonia) ( Siepsiak et al., 2020a; Enzler et al.,\n2021). In other words, using the suggested cutoﬀ point for\nthe MisoQuest introduces a risk of false negatives. In our\nonline community sample, which did not consist of people\nrecruited on the basis of having misophonia or other hearing\nsensitivities, only 4 out of 300 participants (less than 2%) scor ed\nabove 61 on the MisoQuest. This result is considerably lower\nthan previous assessments of misophonia’s prevalence (i.e., 12 –\n20%, using semi-structured interviews and other misophonia-\nspeciﬁc questionnaires), and illustrates the lack of speciﬁc ity of\nthe MisoQuest as a whole, which has not yet been validated\nfor use in the general population ( Siepsiak et al., 2020b ). See\nSupplementaryMaterial for a data-driven grouping approach\nwhich attempted to reﬁne this cutoﬀ, an optimization exercise\noutsidethescopeofthispaper.\nAlthough the 61-point MisoQuest cutoﬀ appears to capture\nthe most severe cases of misophonia, our observations suggest\nthat the distribution of symptom severity in the population lie s\nonacontinuum,analogoustosomeotherdisorders(e.g.,Autis m\nSpectrum Disorder). Previous works proposed that misophonia\nrepresents one end of a speciﬁc sound sensitivity spectrum,\nwith on the other end Autonomous Sensory Meridian Response\n(ASMR), a pleasurable tingling sensation in response to trigger\nsounds (Barratt et al., 2017; McErlean and Banissy, 2018; Rouw\nand Erfanian, 2018 ). The MisoQuest was only designed to assess\nnegativeemotions,andthereforecannotreﬂectbothendsof that\nhypothetical ASMR-to-Misophonia continuum. Nonetheless, it\nmaybesuitabletomeasureanindividual’sseverityofsympto ms,\nassimilartoolsareusedforotherdisordersthatvaryconside rably\nin their presentation (e.g., the Autism Quotient in the ﬁeld o f\nautism;Baron-Cohenetal.,2001 ).\nFrontiers in Neuroscience | www.frontiersin.org 11 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nFIGURE 5 | Change in subjective ratings below and above identiﬁcation t hresholds, for each group and sound category. Unpleasantne ss ratings are from 0 (pleasant)\nto 100 (unpleasant), with 50 being a neutral rating. For Ange r, Disgust, and Anxiety, ratings are from 0 (neutral) to 100. Error bars represent ±1 standard deviation.\nMany diﬀerent measures have been developed and used in\npast years—most notably the A-MISO-S ( Schröder et al., 2013 )\nandMisophoniaQuestionnaire(MQ; Wuetal.,2014 )—andkeep\nbeingintroducedinthemisophonialiterature(e.g.,morere cently\nthe Duke Misophonia Questionnaire by Rosenthal et al., 2021 ).\nWe hope that our ﬁndings about how the MisoQuest behaves\nin our online community sample can reveal how this measure\nrelates to other scales assessing misophonia. Given recent\nconsensus from clinical experts on a deﬁnition of misophonia\n(Swedo et al., 2022 ), understanding how these scales behave\nsimilarly or diﬀerently across multiple populations, and how\nthey correlate with behavioral and physiological responses t o\ntrigger sounds, is crucial to the reﬁnement and generalizati on of\nmisophoniascreeningtools.\nIn addition to understanding the prevalence of the disorder\n(how many people suﬀer from misophonia), unequal sampling\nin past research revealed a need for better understanding of\nthe patients’ identity (exactly who suﬀers from misophonia).\nUnbalanced sex ratios have, so far, prevented researchers\nfrom reaching generalizable conclusions on sex diﬀerences. In\nour balanced data set, we found that both male and female\ndistributions of MisoQuest scores were normal, with averages\nnot statistically diﬀerent from one another. In addition, wh en\nlookingatthetopandbottom20%ofthedistributionseparate ly,\nwe found no diﬀerence in the number of males and females in\neachgroup.Thiscontradictspreviousstatementsonthepossib le\nroleofsexinmisophoniasensitivity( Wuetal.,2014;Zhouetal.,\n2017).\nWhile misophonia severity may not diﬀer between sexes\noverall,Kılıç et al. (2021) noted the possibility that certain typesof responses may be more common in women than men. This\nprompted us to assess sex diﬀerences for individual items on\nthe MisoQuest. The one item in particular which stood out as\ninteracting with sex referred to the physiological component\nof emotions. However, this may not be speciﬁc to misophonia:\nmen and women tend to diﬀer in self-reported experiences to\nnegativeemotionalstimuli,withwomenreportinghigheraro usal\nand negative valence ( Šolcová and La ˇcev, 2017 ). Yet, these self-\nreports do not correlate with physiological measures of facial\nelectromyography(muscleactivity)andskinconductance,w hich\nŠolcová and La ˇcev (2017) proposed to result from stereotypes\nand emotional beliefs. Future research on misophonia should\ninclude physiological metrics to adjudicate on a possible sex -\ninduced diﬀerence in physiology when attending to sounds that\nare known to aﬀect emotions. Further, if this diﬀerence does not\nappear in physiological measures but is present in self reports,\nfuture work should attempt to reﬁne questionnaires or possibl y\nweighitemsdiﬀerentlybasedonsex.\nIn this study, total MisoQuest score did not correlate with\nage, which contrasts with Kılıç et al. (2021) ’s ﬁnding that\nyounger individuals were more likely to have misophonia. One\nexplanation for this discrepancy is likely about characterist ics\nof the sample, as younger (less age-balanced) samples do not\ngenerally exhibit an eﬀect of age on misophonia (no age\neﬀect found in undergraduate samples for Wu et al., 2014;\nZhou et al., 2017 ). Despite our eﬀorts to obtain a sample\nrepresentative of a general population, by opening the study\nto all ages, our participants consisted mostly (80%) of adults\nbetween 18 and 29 years-old. Note however that there could be\nindividual trajectories of symptoms improving and worsening\nFrontiers in Neuroscience | www.frontiersin.org 12 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nover time. Early in misophonia research, Edelstein et al. (2013)\nobservedthatwhile5oftheir11participantsreportedsymptoms\nworsening over time, the same number of people reported\nsymptomsstayingthesameorimproving,astheyhadlearnedto\nbettercopewiththem.Iftherearecounteractingtrendssuch that\nhalf of individuals with misophonia improve and the other half\nworsen, this may be seen as a null eﬀect in population results.\nWe therefore do not rule out an eﬀect of age in misophonia,\neventhoughourresultsdonotsupportitatthepopulationlevel.\nFuture work could clarify how the evolution of symptoms over\nthelifespanandthusadjudicateontheprevalenceofmisophoni a\nacrossdiﬀerentagegroups.\nOf note, although our results can be considered somewhat\nmore generalizable than past studies done with samples\nconsisting of undergraduate students, our sample may not be\nrepresentative of all populations. As outlined in the review by\nChandler and Shapiro (2016) , there are diﬀerences between the\ngeneral population and online convenience samples. Though\ntheir review focused on the crowdsourcing platform MTurk,\nwhich is suggested to provide data of a lesser quality than\nProliﬁc (Eyal et al., 2021 ), some of the considerations brought\nup byChandler and Shapiro (2016) do apply to our sample.\nFor example, in addition to online samples being of younger\nage than the general population, the review outlines how some\ngroups are often over- and under-represented in such samples.\nOur sample is somewhat more diverse than in past research,\nconsideringthatparticipantscamefromavarietyofcountrie sof\norigin (though currently residing in English-speaking coun tries)\nand had diﬀering employment and student status. However,\nthe present context of an online community sample should be\nconsidered when generalizing observations to the population a t\nlarge, particularly as we did not obtain information regardi ng\nethnicity nor socioeconomic-status. In addition, the scre ening\nquestions available in the online platform did not allow for t he\nspeciﬁc exclusion of participants with a diagnosis of anxiety\nor depression. As we were concerned that the available more\ngeneral mental health questions would screen out individua ls\nwithmisophonia,ourpopulationofinterest,weusedascreenin g\nquestion concerning use of medication to treat symptoms of\ndepression,anxiety,orlowmood.Becausepsychiatricsymptom s\nareoftenco-morbidwithmisophonia( RouwandErfanian,2018;\nErfanian et al., 2019 ), it is possible that some of the reported\nmisophonia symptoms or high ratings of anger and anxiety\nin the most-misophonic group could be partially explained by\nco-morbidaﬀectivedisorders.\n4.2. Misophonia, a Sound-Speciﬁc or\nPerson-Speciﬁc Disorder?\nAs highlighted in McGeoch and Rouw (2020) , the often highly\nspeciﬁc nature of trigger sounds (i.e., repetitive, low frequ ency,\netc.) points to the involvement of bottom-up mechanisms,\nwhile the complex behavioral and emotional responses suggest\ninvolvementofhigher-level(top-down)processes.Here,weu sed\na masking paradigm to explore the nature of top-down and\nbottom-upprocessing,andhowtheyinteractinmisophonia.When assessing identiﬁcation thresholds for diﬀerent sound\ncategories, we found that trigger sounds were better identi ﬁed\nthan unpleasant and neutral sounds. This observation provide s\nevidence for our ﬁrst hypothesis, about a diﬀerence in the\nacousticsalienceofdiﬀerentsoundcategories,andindicat esthat\ntrigger sounds are generally easier to detect than other types\nof sounds. With the small number of stimuli in our study (5\nexamples of triggers), this ﬁnding is diﬃcult to generalize. The\nsounds chosen for this study aimed at covering the most typica l\ntrigger sounds, which are usually orofacial (i.e., produced by\nthe mouth and face) in nature ( Jager et al., 2020 ). There are,\nhowever, many diﬀerent types of trigger sounds and so, future\nendeavorsmaycontinueexploringtheideathatcommontrigge rs\nhave distinctive acoustic properties that set them apart from\notherenvironmentalsounds.Alimitationofourstudy(alth ough\nwe found no eﬀect of this in our sample) involved participants\npotentially having diﬀerent audio devices perhaps involving\nsound quality diﬀerences. Future assessments of misophonia\ntaking place on online platforms could aim at standardizing the\ntype of listening device, perhaps through the use of screening\ntools for headphone-users (e.g., Milne et al., 2021 ); however,\nfor use with rich, naturalistic stimuli such as those used in t his\nstudy, minor spectral diﬀerences caused by output device are\nless likely to have an eﬀect than overall diﬀerences in sound\nlevel. A more fruitful approach might be to complement online\nstudies with relatively large sample sizes yet somewhat loos er\nexperimentalcontrolsuchasthisonewithsmaller,highlyfo cused\nandcontrolledstudiesinthelaboratoryenvironment.\nContrary to what we had hypothesized, the least- and most-\nmisophonic participants did not diﬀer in their ability to detect\ntrigger sounds, suggesting that bottom-up processes (e.g., those\nengaged in the salience of certain sounds) may in fact be\nrelatively independent of misophonia. Overall, this is eviden ce\nagainst our second hypothesis. Early misophonia research had\npreviously shown some evidence for diﬀerences between people\nwith and without misophonia in low level auditory informatio n\nprocessing ( Schröder et al., 2014 ) on auditory event-related\npotentials (ERPs). During an oddball task using pure tones, the\nauthors observed a diminished N1 component to oddball tones\nin misophonia patients. One of the reasons suggested for this\nﬁnding was a potential basic impairment in auditory processing\nat a low level, given that the N1 peak is linked to early attenti on\nto auditory stimuli ( Näätänen, 1992; Rinne et al., 2006 ). If\nindividualswhoaremostandleastpronetomisophoniadodiﬀer\nin such basic auditory processes, then this is not reﬂected in our\nbehavioral data, for any type of sound. Our result, paired with\nthe observation that the misophonic reaction is not associate d\nwith absolute hearing threshold or hearing impairments in\ngeneral ( Tyler et al., 2014; Jastreboﬀ and Jastreboﬀ, 2015 ),\noﬀers evidence against misophonia being driven by abnormal\nbottom-up auditory processes. This interpretation is largely\nconsistent with the work of Kumar et al. (2021) , who found\ninvolvement of the anterior insula in misophonia, known to be\nessential to top-down control of action mirroring. Yet, caut ion\nshould be exerted before completely negating the involvemen t\nof (abnormal) bottom-up processes (certain acoustic properti es\nof triggers might elicit a form of pain or aversion, see e.g.,\nFrontiers in Neuroscience | www.frontiersin.org 13 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nArnal et al., 2019 ). Nevertheless, our conclusions about bottom-\nup auditory processes emphasize a departure from hyperacusis\n(i.e., pain in response to environmental sounds, especially lo ud\nsounds), even though it tends to be comorbid with misophonia\n(Jastreboﬀ and Jastreboﬀ, 2014 ). In hyperacusis, the discomfort\nis driven by abnormal responses to the sounds’ characteristi cs\nwhile the meaning of the sound is irrelevant ( Jastreboﬀ and\nHazell, 2008 ); it therefore contrasts with misophonia, in which\nthe sounds’ physical characteristics do not appear to be the\nmain component of the response. Of note, the present study\ndid not assess hyperacusis, and as such it is unknown to what\nextent it might have impacted our results. Still, our observa tions\nmay indicate that treatment options used in disorders such as\nhyperacusis would be less eﬀective for misophonia, and that\nmisophonia may respond better to other approaches such as\nregularcounseling( JastreboﬀandJastreboﬀ,2014 ).\nCertain sounds are more aversive than others; this is true\nregardless of whether a person has misophonia or not. Often,\naversivereactionstosoundsdependontheirphysicalpropertie s;\nfor example, generally aversive sounds are loud, rough, and\nhave strong representation of high frequencies ( Halpern et al.,\n1986). However, certain reactions to aversive sounds are based\non emotional connections with the sound ( Reuter et al., 2014 ),\nand thus involve learned associations (top-down processes).\nIn this study, we found that external evaluations of the\nsounds (unpleasantness) and internal evaluations of emotio ns\n(anger, disgust, anxiety) largely paralleled each other, an d\nboth appeared only after the sounds were recognized. This\nparallel suggests that there is a common process to both sound\nappraisal and personal experience that depends on higher-level\ncognitive processes. The diﬀerence in ratings observed betwe en\ngroups, on trials where the sounds could be identiﬁed, thus\nrelates to a higher-level evaluation of the sounds, which is\nevidence for our third hypothesis. These observations about\nthe involvement of top-down processes are in line with recent\nﬁndings by Hansen et al. (2021) who showed, using self-\nreport data, that knowledge of the sound identity contribute s\nto the discomfort experienced by people with misophonia.\nUsing a similar design (participants identiﬁed sounds and\nprovided aversiveness ratings), they showed that participant s\nwho correctly identiﬁed oral-nasal sounds rated them as mor e\nunpleasant and evoking more discomfort than those who could\nnotidentifythem.\nIn our study, on trials where the sounds were identiﬁed,\nthe most-misophonic group experienced a stronger increase\nin aversiveness ratings than the least-misophonic group. Thi s\nwas true to some degree of unpleasant sounds, but it was\nexacerbated for trigger sounds. For example, the elevated\nanger and anxiety induced by recognizable trigger sounds wa s\nalmost 3 times larger for MM than LM individuals. Expressed\ndiﬀerently, all participants experienced some discomfort, but\nparticipants with higher misophonia symptoms were bothered\nto a more extreme degree, and with speciﬁcity with regard to\ntriggers as opposed to other unpleasant sounds. This ﬁnding of\nexaggerated responses in the MM group when the sounds are\nidentiﬁed provides once again evidence for a strong cognitiv e\ncomponent in the nature of the misophonic response; theremustbesomethingaboutthemeaningofthesoundthattrigger s\nthe response. Diﬀerences at higher-level processing between\nthose with and without misophonia are evident from studies\nusing functional brain imaging ( Kumar et al., 2017; Schröder\net al., 2019 ). When listening to trigger sounds, participants with\nmisophonia showed abnormal functional connectivity betwee n\ntheanteriorinsularcortex,criticalinperceptionofintero ceptive\nsignals (i.e., signals originating from inside the body) an d the\ndefault mode network, which includes regions responsible fo r\nemotion processing and attending to behaviorally-relevant\nstimuli. Such diﬀerences in brain networks between people with\nand without misophonia support the idea that memories and\ncontextualassociationsarestronglytiedtotheaversivee motions\nexperienced in response to triggers. Together, ﬁndings about\ntop-down processing in misophonia call for more behavioral\nexperiments manipulating top-down processes (perhaps\nmanipulating the focus of attention, or instead, the presence of\ndistracting tasks or stimuli) while observing neural correl ates to\ndiﬀerentsoundcategories.\nHere, we provided additional evidence for the idea that\ncognitive processes, speciﬁcally learned associations with\nidentiﬁable triggers, are involved in misophonia. Treatment\noptions could therefore focus on breaking the associative\nlink with speciﬁc triggers. Such treatment options, aimed at\ntreating the cognitive element of the misophonic response,\nhave been anecdotally successful. Although this is often li mited\nto case-studies, cognitive-behavioral therapy (CBT) seems to\nbe eﬀective in reducing misophonia symptoms ( Bernstein\net al., 2013; McGuire et al., 2015 ) and managing levels of\nanger when exposed to triggers ( Roushani and Honarmand,\n2021). Perhaps more convincingly, Schröder et al. (2017)\nshowed that 48% of patients ( N=90) reported a reduction of\nmisophonia symptoms following CBT, whereas the waiting-\nlist control group showed no reduction of misophonia.\nThese results were observed after 3 months of treatment\n(short-term) and maintained a year later (long-term). The\npresent results, emphasizing a person-centered disorder with\na high speciﬁcity to certain triggers (not so much other\nunpleasant sounds) that need to be presented at a suﬃciently\nlarge SNR to be recognizable, are in full support of such\ntreatmentoptions.\nTo summarize, in a study involving 300 adults sampled from\nan online community, two sub-groups of participants were\nformed on the basis of their self reports in a questionnaire\ndesigned for misophonia symptom assessment: a least-\nmisophonic group, largely immune to the impact of sound\non their life and wellbeing, and a most-misophonic group that\nexhibited heightened sensitivity to sound. They all listen ed to\nthree categories of sounds: neutral sounds, unpleasant soun ds\n(typicallyaversive),andsoundstypicallytriggeringtoind ividuals\nwith misophonia (often orofacially-generated). These sound s,\nembedded in a multi-talker babble, were presented at diﬀerent\nsignal-to-noise ratios from very faint in the background (a nd\nthus barely identiﬁable) to perceptually salient (and thus\nclearly identiﬁable). Triggers were found to be recognized\nat a lower SNR than unpleasant sounds and neutral sounds,\nbut this pattern was common in both the least-misophonic\nFrontiers in Neuroscience | www.frontiersin.org 14 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nand most-misophonic groups. Listeners also rated each sound\n(identiﬁed or not) on four scales: unpleasantness, anger, di sgust,\nand anxiety. As SNR increased, unpleasant and trigger sounds\nbecame more aversive (as expected), but this change was\nmore pronounced for triggers than unpleasant sounds, and\nexacerbated in MM compared to LM individuals. These results\ndemonstrate that the heightened sensitivity of individuals most\nprone to misophonia does not generalize to sound overall\n(neutral sounds or sub-threshold unpleasant/trigger sound s).\nIn fact, it does not provide any detection or discrimination\nadvantage,andrelatesto(conscious)appraisalaswellasint ernal\nexperience of certain triggers, provided that they are suﬃcie ntly\nsalient. This pattern of ﬁndings strongly supports a role for\nhigher-order processes related to sound identity (and likel y its\nassociations with the people generating them, contexts, and\nsoon).\n5. CONCLUSION\nMisophonia is increasingly recognized as a problem that can\nsigniﬁcantly aﬀect the wellbeing, education, and careers of\nsuﬀerers. To devise eﬀective mitigation strategies and eﬀecti ve\ntreatments,wemustbetterunderstanditsprevalence,cause s,and\nphysiologicalbasis.Thisstudyaddsseveralpiecesofinform ation\nto our knowledge of misophonia. Overall symptom severity was\nfound in a continuum, and was approximately equal in males\nand females. Although females rated some questionnaire ite ms\nconcerning subjective experiences of physiological response s\nhigher, previous work showed that while males and females\nmight self-report their emotional experiences diﬀerently, the ir\nphysiological responses to negative emotional stimuli do not\ngenerally diﬀer ( Šolcová and La ˇcev, 2017 ). These observations\nsuggests that the biological basis of misophonia is not stron gly\nsex-related, and so eventual treatments might be predicted t o\nwork equally well for both males and females. In addition,\nwe demonstrate that while people detect negative and trigger\nsounds better than neutral sounds in noise, suggesting that\nthose sounds are more salient, people with stronger misophonia\nsymptoms did not show an additional degree of sensitivity\nfor detecting sounds. Conversely, once they were able to\nidentify the aversive sounds, they had a stronger increase\nof negative emotional reactions to them, particularly for th e\ntrigger sounds. Together, these results further emphasize t hat\nconsciouslylinkingsoundstopastexperienceplaysanimportan t\nroleinmisophonia.\nAs described above, the present study has several limitation s,\noneofwhichbeingthatthequestionnaireused(MisoQuest)wa s\nvalidatedinaPolish-speakingpopulation( Siepsiaketal.,2020a ).\nWhile the original authors provided an English translation, and\nthe questionnaire (in English and translated in French) was\nrecently used in a French sample ( Enzler et al., 2021 ), it has\nnot yet been validated in an English-speaking population. To\nour knowledge, this is the ﬁrst study that is using the Englis h\ntranslation of the questionnaire on English-speakers. In ou r\nsample, there was a relatively low proportion of participants\nwho reached the recommended screening score for severemisophonia in our sample, with only 4 participants scoring\nabove 61. This small number is diﬃcult to interpret; because w e\nexcludedindividualswhoweretakingpsychotropicmedication s,\nour distribution may reﬂect the removal of some more severe\ncases. This exclusion may reduce the generalizability of ou r\nﬁnding to more complex psychiatric patients. However, it\ndid allow us to focus on misophonia symptoms in people\nwhose physiology is not being modulated by pharmaceutics,\nand to highlight the continuous nature of misophonia severity\nin a sample more representative of a general population.\nGiven these limitations, we support the proposition by Enzler\net al. (2021) that the MisoQuest should be used with other\nmeasures of misophonia, to determine potential cut-oﬀs for\nmild, moderate, and severe symptoms, and to determine the\nconvergent validity of the MisoQuest with other misophonia\nassessment tools. As regards our experimental design, we cho se\nto use an existing set of stimuli that focuses on orofacial\ntrigger sounds and was used in previous research ( Kumar\net al., 2017, 2021 ). Misophonic trigger sounds are not all\norofacially generated (the importance of other sources is\nhighlighted in Hansen et al., 2021 ), although most people\nwith misophonia do have at least one orofacially generated\ntrigger sound ( Jager et al., 2020 ). While a reasonable starting\npoint for fundamental research, an exclusive focus on orofaci al\nsounds across studies could lead to an incomplete mechanisti c\nunderstanding of misophonia. Therefore, work is needed to\ncharacterize the full range of misophonic trigger sounds\nand produce a wider selection of high-quality stimuli for\nfurther study. In addition, although previous research has\nfound similar experiences with misophonia in diﬀerent cultures\n(Zhou et al., 2017 ), the lack of information on ethnicity and\nsocioeconomic-status in our sample should be considered when\ngeneralizing our results. Finally, the online study design t rades\noﬀ the precise experimental control over listening contexts\nand sound quality that are possible in the laboratory with the\nadvantages of being able to recruit a larger sample with an\neven representation of males and females. While the design\nappeared to be appropriate for the current questions, which\nconcern perception and recognition of sounds in noise, some\nresearch questions such as those requiring ﬁne characteriz ation\nofindividuals’psychiatricproﬁlesandperceptualabilitiesre quire\nanin-persondesign.\nOur main goal was to explore one aspect of misophonia:\nits relation to identiﬁcation and memory. Further work is\nunderway to explore physiological markers of these aversive\nresponses, and manipulate listeners’ attention to emphasize o r\ndeemphasize these sounds’ salience. These next studies will be\nable to inform shorter-term attention-based coping strateg ies\nfor people living with misophonia. However, attention-based\nstrategies are likely to be eﬀortful and tiring to the user and\nmay represent only a partial solution. More work will be needed\nto clarify the etiology of misophonia and its evolution across\nthe lifespan, to distinguish preexisting anatomical diﬀerence s\nthat might predispose people to misophonia from the eﬀects\nof experience ( Kumar et al., 2021 ), and perhaps to use our\nknowledge of neuroplasticity within the auditory and motor\nsystems to induce meaningful long-term changes in how people\nFrontiers in Neuroscience | www.frontiersin.org 15 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nwith misphonia process sound (e.g., Herholz and Zatorre,\n2012).\nDATA AVAILABILITY STATEMENT\nThe original contributions presented in the study are publicl y\navailable.Thisdatacanbefoundhere:https://osf.io/39dz b/.\nETHICS STATEMENT\nThe studies involving human participants were reviewed and\napprovedbyResearchEthicsUnit(OﬃceofResearch)Concordia\nUniversity. The patients/participants provided their written\ninformedconsenttoparticipateinthisstudy.\nAUTHOR CONTRIBUTIONS\nM-AS,AS,MD,andECconceivedanddesignedtheexperiment.\nM-ASandMDselectedandeditedstimuli.MDandAScodedthe\nexperiment.M-AS,MD,andECanalyzedthedata.M-ASdrafted\nthemanuscript.Allauthorsreviewedandeditedthedraftsof themanuscript. All authors contributed to the article and approve d\nthesubmittedversion.\nFUNDING\nThis research was supported by the Misophonia Research\nFund and REAM foundation, and the Natural Sciences and\nEngineering Research Council of Canada (NSERC) award\ntoM-AS.\nACKNOWLEDGMENTS\nTheauthorsthankSukhbinderKumarforsharingstimuli,asw ell\nas the Misophonia Research Fund and REAM Foundation for\nsupportingourwork.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.338 9/fnins.\n2022.879583/full#supplementary-material\nREFERENCES\nArnal, L. H., Kleinschmidt, A., Spinelli, L., Giraud, A.-L., and Mégev and, P.\n(2019). The rough sound of salience enhances aversion through n eural\nsynchronisation. Nat.Commun. 10,1–12.doi:10.1038/s41467-019-11626-7\nBaron-Cohen, S., Wheelwright, S., Skinner, R., Martin, J., and C lubley, E. (2001).\nTheAutism-SpectrumQuotient(AQ):evidencefromaspergersyndro me/high-\nfunctioningautism,malesandfemales,scientistsandmathematici ans.J.Autism\nDev.Disord. 31,5–17.doi:10.1023/A:1005653411471\nBarratt, E. L., Spence, C., and Davis, N. J. (2017). Sensory determi nants of the\nautonomous sensory meridian response (ASMR): understanding the t riggers.\nPeerJ5,e3846.doi:10.7717/peerj.3846\nBernstein,R.E.,Angell,K.L.,andDehle,C.M.(2013).Abriefcou rseofcognitive\nbehavioural therapy for the treatment of misophonia: a case example. Cogn.\nBehav.Ther. 6,e10.doi:10.1017/S1754470X13000172\nBruxner, G. (2016). “Mastication rage”: a review of misophonia–a n under-\nrecognised symptom of psychiatric relevance? Austral. Psychiatry 24, 195–197.\ndoi:10.1177/1039856215613010\nChandler, J. and Shapiro, D. (2016). Conducting clinical researc h using\ncrowdsourced convenience samples. Annu. Rev. Clin. Psychol. 12, 53–81.\ndoi:10.1146/annurev-clinpsy-021815-093623\nCoﬀey,E.B.,Mogilever,N.B.,andZatorre,R.J.(2017).Speech- in-noiseperception\ninmusicians:areview. Hear.Res. 352,49–69.doi:10.1016/j.heares.2017.02.006\nDaniels, E. C., Rodriguez, A., and Zabelina, D. L. (2020). Severi ty of\nmisophonia symptoms is associated with worse cognitive control\nwhen exposed to misophonia trigger sounds. PLoS ONE 15, e0227118.\ndoi:10.1371/journal.pone.0227118\nDuangudom, V., and Anderson, D. V. (2007). “Using auditory sali ency to\nunderstand complex auditory scenes,”in 2007 15th European SignalProcessing\nConference (Poznan:IEEE),1206–1210.\nEdelstein,M.,Brang,D.,Rouw,R.,andRamachandran,V.S.(2013 ).Misophonia:\nphysiologicalinvestigationsandcasedescriptions. Front.Hum.Neurosci. 7,296.\ndoi:10.3389/fnhum.2013.00296\nEnzler, F., Loriot, C., Fournier, P., and Noreña, A. J. (2021). A\npsychoacoustic test for misophonia assessment. Sci. Rep. 11, 1–14.\ndoi:10.1038/s41598-021-90355-8\nErfanian,M.,Kartsonaki,C.,andKeshavarz,A.(2019).Misoph oniaandcomorbid\npsychiatric symptoms: a preliminary study of clinical ﬁndings. Nordic J.\nPsychiatry 73,219–228.doi:10.1080/08039488.2019.1609086Eyal, P., David, R., Andrew, G., Zak, E., and Ekaterina, D. (2021 ). Data quality of\nplatforms and panels for online behavioral research. Behav. Res. Methods . 53,\n1–20.doi:10.3758/s13428-021-01694-3\nHalpern, D. L., Blake, R., and Hillenbrand, J. (1986). Psychoacousti cs of a chilling\nsound.Percept.Psychophys. 39,77–80.doi:10.3758/BF03211488\nHansen,H.A.,Leber,A.B.,andSaygin,Z.M.(2021).Whatsoun dsourcestrigger\nmisophonia? Not just chewing and breathing. J. Clin. Psychol. 77, 2609–2625.\ndoi:10.1002/jclp.23196\nHerholz, S. C., and Zatorre, R. J. (2012). Musical training as a frame work\nfor brain plasticity: behavior, function, and structure. Neuron76, 486–502.\ndoi:10.1016/j.neuron.2012.10.011\nJager, I., de Koning, P., Bost, T., Denys, D., and Vulink, N. (2 020). Misophonia:\nphenomenology, comorbidity and demographics in a large sample. PLoS ONE\n15,e0231390.doi:10.1371/journal.pone.0231390\nJastreboﬀ, M. M., and Jastreboﬀ, P. J. (2001). Components of decre ased sound\ntolerance:hyperacusis,misophonia,phonophobia. ITHSNewsLett. 2,1–5.\nJastreboﬀ,P.J.,andHazell,J.W.(2008). TinnitusRetrainingTherapy:Implementing\ntheNeurophysiologicalModel .NewYork,NY:CambridgeUniversityPress.\nJastreboﬀ, P. J., and Jastreboﬀ, M. M. (2014). Treatments for dec reased\nsound tolerance (hyperacusis and misophonia). Semin. Hear. 35, 105–120.\ndoi:10.1055/s-003401372527\nJastreboﬀ, P. J., and Jastreboﬀ, M. M. (2015). Decreased sound t olerance:\nhyperacusis, misophonia, diplacousis, and polyacousis. Handb. Clin. Neurol.\n129,375–387.doi:10.1016/B978-0-444-62630-1.00021-4\nKayser, C., Petkov, C. I., Lippert, M., and Logothetis, N. K. (20 05). Mechanisms\nfor allocating auditory attention: an auditory saliency map. Curr. Biol. 15,\n1943–1947.doi:10.1016/j.cub.2005.09.040\nKılıç, C., Öz, G., Avano ˘glu, K. B., and Aksoy, S. (2021). The prevalence and\ncharacteristics of misophonia in ankara, turkey: population-based s tudy.\nBJPsychOpen 7,e144.doi:10.1192/bjo.2021.978\nKumar,S.,Dheerendra,P.,Erfanian,M.,Benzaquén,E.,Sedley, W.,Gander,P.E.,\net al. (2021). The motor basis for misophonia. J. Neurosci . 41, 5762–5770.\ndoi:10.1523/JNEUROSCI.0261-21.2021\nKumar, S., Forster, H. M., Bailey, P., and Griﬃths, T. D. (2008). M apping\nunpleasantness of sounds to their auditory representation. J. Acoust. Soc. Am.\n124,3810–3817.doi:10.1121/1.3006380\nKumar, S., Hancock, O., Cope, T., Sedley, W., Winston, J., and Gri ﬃths, T. D.\n(2014). Misophonia: a disorder of emotion processing of sounds. J. Neurol.\nNeurosurg.Psychiatry 85,e3.doi:10.1136/jnnp-2014-308883.38\nFrontiers in Neuroscience | www.frontiersin.org 16 May 2022 | Volume 16 | Article 879583"
    },
    {
      "section": "Page 17",
      "page_number": 17,
      "text": "Savard et al. Sound Identiﬁcation Affects Misophonic Responses\nKumar,S.,Tansley-Hancock,O.,Sedley,W.,Winston,J.S.,Calla ghan,M.F.,Allen,\nM., et al. (2017). The brain basis for misophonia. Curr. Biol. 27, 527–533.\ndoi:10.1016/j.cub.2016.12.048\nMcErlean,A.B.J.,andBanissy,M.J.(2018).Increasedmisophoni ainself-reported\nautonomoussensorymeridianresponse. PeerJ6,e5351.doi:10.7717/peerj.5351\nMcGeoch, P. D., and Rouw, R. (2020). How everyday sounds can trig ger strong\nemotions: ASMR, misophonia and the feeling of wellbeing. Bioessays 42,\n2000099.doi:10.1002/bies.202000099\nMcGuire, J. F., Wu, M. S., and Storch, E. A. (2015). Cognitive- behavioral\ntherapy for 2 youths with misophonia. J. Clin. Psychiatry 76, 3143.\ndoi:10.4088/JCP.14cr09343\nMilne, A. E., Bianco, R., Poole, K. C., Zhao, S., Oxenham, A. J., B illig, A. J., and\nChait, M.(2021).Anonline headphone screeningtest basedondi chotic pitch.\nBehav.Res.Methods 53,1551–1562.doi:10.3758/s13428-020-01514-0\nNäätänen,R.(1992). AttentionandBrainFunction .PsychologyPress.\nNaylor, J., Caimino, C., Scutt, P., Hoare, D. J., and Baguley, D. M. (2021). The\nprevalence and severity of misophonia in a uk undergraduate medical s tudent\npopulation and validation of the Amsterdam misophonia scale. Psychiatr. Q.\n92,609–619.doi:10.1007/s11126-020-09825-3\nNeal, M., and Cavanna, A. E. (2013). Selective sound sensitivi ty syndrome\n(misophonia) in a patient with tourette syndrome. J. Neuropsychiatry Clin.\nNeurosci. 25,E01.doi:10.1176/appi.neuropsych.11100235\nPalan,S.,andSchitter,C.(2018).Proliﬁc.ac–Asubjectpoolfo ronlineexperiments.\nJ.Behav.Exp.Fin. 17,22–27.doi:10.1016/j.jbef.2017.12.004\nPeirce,J.,Gray,J.R.,Simpson,S.,MacAskill,M.,Höchenberger, R.,Sogo,H.,etal.\n(2019).Psychopy2:experimentsinbehaviormadeeasy. Behav.Res.Methods 51,\n195–203.doi:10.3758/s13428-018-01193-y\nReuter, C., Oehler, M., and Mühlhans, J. (2014). “Physiologica l and acoustical\ncorrelates of unpleasant sounds,” in Proceedings of the Joint Conference\nICMPC13-APSCOM5 (Seoul:YonseiUniversity),97.\nRinne, T., Särkkä, A., Degerman, A., Schröger, E., and Alho, K. (20 06).\nTwo separate mechanisms underlie auditory change detection\nand involuntary control of attention. Brain Res. 1077, 135–143.\ndoi:10.1016/j.brainres.2006.01.043\nRosenthal, M. Z., Anand, D., Cassiello-Robbins, C., Williams, Z. J ., Guetta,\nR. E., Trumbull, J., et al. (2021). Development and initial validation\nof the Duke misophonia questionnaire. Front. Psychol. 12, 709928.\ndoi:10.3389/fpsyg.2021.709928\nRoushani, K., and Honarmand, M. M. (2021). The eﬀectiveness of c ognitive-\nbehavioral therapy on anger in female students with misophonia: a si ngle-case\nstudy.IranianJ.Med.Sci. 46,61.doi:10.30476/ijms.2019.82063\nRouw, R., and Erfanian, M. (2018). A large-scale study of misopho nia.J. Clin.\nPsychol.74,453–479.doi:10.1002/jclp.22500\nSchröder, A., van Diepen, R., Mazaheri, A., Petropoulos-Petalas, D ., Soto de\nAmesti,V.,Vulink,N.,etal.(2014).DiminishedN1auditoryevok edpotentials\nto oddball stimuli in misophonia patients. Front. Behav. Neurosci. 8, 123.\ndoi:10.3389/fnbeh.2014.00123\nSchröder, A., van Wingen, G., Eijsker, N., San Giorgi, R., Vuli nk, N. C.,\nTurbyne, C., and Denys, D. (2019). Misophonia is associated w ith altered\nbrain activity in the auditory cortex and salience network. Sci. Rep. 9, 1–9.\ndoi:10.1038/s41598-019-44084-8\nSchröder, A., Vulink, N., and Denys, D. (2013). Misophonia: dia gnostic\ncriteria for a new psychiatric disorder. PLoS ONE 8, e54706.\ndoi:10.1371/journal.pone.0054706\nSchröder,A.E.,Vulink,N.C.,vanLoon,A.J.,andDenys,D.A.( 2017).Cognitive\nbehavioral therapy is eﬀective in misophonia: an open trial. J. Aﬀect. Disord.\n217,289–294.doi:10.1016/j.jad.2017.04.017Siepsiak, M., Sliwerski, A., and Lukasz Dragan, W. (2020a). Dev elopment and\npsychometric properties of misoquest–a new self-report questionnaire\nfor misophonia. Int. J. Environ. Res. Public Health 17, 1797.\ndoi:10.3390/ijerph17051797\nSiepsiak, M., Sobczak, A. M., Bohaterewicz, B., Cichocki, Ł., and Dragan, W. Ł.\n(2020b). Prevalence of misophonia and correlates of its symptoms among\ninpatients with depression. Int. J. Environ. Res. Public Health 17, 5464.\ndoi:10.3390/ijerph17155464\nSilbert, N. H., de Jong, K., Regier, K., Albin, A., and Hao, Y.-C. ( 2014).\nAcoustic properties of multi-talker babble. J. Acoust. Soc. Am. 135, 2227.\ndoi:10.1121/1.4877284\nŠolcová, I. P., and La ˇcev, A. (2017). Diﬀerences in male and female\nsubjective experience and physiological reactions to emotional\nstimuli. Int. J. Psychophysiol. 117, 75–82. doi: 10.1016/j.ijpsycho.2017.\n04.009\nStiegler,L.N.,andDavis,R.(2010).Understandingsoundsen sitivityinindividuals\nwith autism spectrum disorders. Focus Autism Other Dev. Disabil. 25, 67–75.\ndoi:10.1177/1088357610364530\nSwedo,S.E.,Baguley,D.M.,Denys,D.,Dixon,L.J.,Erfanian ,M.,Fioretti,A.,etal.\n(2022). Consensus deﬁnition of misophonia: a Delphi study. Front. Neurosci.\n16,841816.doi:10.3389/fnins.2022.841816\nTyler, R. S., Pienkowski, M., Roncancio, E. R., Jun, H. J., Brozo ski, T.,\nDauman, N., et al. (2014). A review of hyperacusis and future directi ons:\npart I. deﬁnitions and manifestations. Am. J. Audiol. 23, 402–419.\ndoi:10.1044/2014_AJA-14-0010\nVitoratou, S., Uglik-Marucha, N., Hayes, C., Erfanian, M., Pea rson, O., and\nGregory, J. (2021). Item response theory investigation of misophon ia\nauditory triggers. Audiol. Res. 11, 567–581. doi: 10.3390/audiolres110\n40051\nWu, M. S., Lewin, A. B., Murphy, T. K., and Storch, E. A. (2014). M isophonia:\nincidence,phenomenology,andclinicalcorrelatesinanundergradu atestudent\nsample.J.Clin.Psychol. 70,994–1007.doi:10.1002/jclp.22098\nZald, D. H., and Pardo, J. V. (2002). The neural correlates of aversiv e auditory\nstimulation. Neuroimage 16,746–753.doi:10.1006/nimg.2002.1115\nZhou, X., Wu, M. S., and Storch, E. A. (2017). Misophonia symptoms\namong Chinese university students: incidence, associated i mpairment,\nand clinical correlates. J. Obsessive Compuls. Relat. Disord. 14, 7–12.\ndoi:10.1016/j.jocrd.2017.05.001\nConﬂict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be c onstrued as a\npotentialconﬂictofinterest.\nPublisher’sNote: Allclaimsexpressedinthisarticlearesolelythoseoftheauthors\nand do not necessarily represent those oftheir aﬃliated organizat ions, or those of\nthepublisher,theeditorsandthereviewers.Anyproductthatmayb eevaluatedin\nthis article, or claim that may be made by its manufacturer, is not gua ranteed or\nendorsedbythepublisher.\nCopyright © 2022 Savard, Sares, Coﬀey and Deroche. This is an open- access article\ndistributed under the terms of the Creative Commons Attribu tion License (CC BY).\nThe use, distribution or reproduction in other forums is perm itted, provided the\noriginal author(s) and the copyright owner(s) are credited a nd that the original\npublication in this journal is cited, in accordance with acc epted academic practice.\nNo use, distribution or reproduction is permitted which doe s not comply with these\nterms.\nFrontiers in Neuroscience | www.frontiersin.org 17 May 2022 | Volume 16 | Article 879583"
    }
  ]
}