{
  "doc_type": "scientific paper",
  "title": "Seeing Consciousness Through the lens of Memory",
  "authors": [
    "LeDoux"
  ],
  "year": 2020,
  "journal": "Neuroscience,",
  "doi": "10.1101/2020.03.13.990226",
  "abstract": null,
  "keywords": [],
  "research_topics": [],
  "created_at": "2025-05-04T23:08:19.018136Z",
  "source_pdf": "documents/research/Global/LeDoux 2020 Seeing Consciousness Through the lens of Memory.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Magazinell\nR1018  Current Biology 30, R1009–R1035, September 21, 2020 © 2020 Elsevier Inc.infected rhesus macaques. bioRxiv https://doi.\norg/10.1101/2020.03.13.990226 .\n 17. McCray Jr., P .B., Pewe, L., Wohlford-Lenane, C., \nHickey, M., Manzel, L., Shi, L., Netland, J., Jia, H.P ., Halabi, C., Sigmund, C.D., et al. \n(2007). Lethal infection of K18-hACE2 mice infected with severe acute respiratory syndrome coronavirus. J. Virol. 81, 813–821.\n 18. Docherty, A.B., Harrison, E.M., Green, C.A., \nHardwick, H.E., Pius, R., Norman, L., Holden, K.A., Read, J.M., Dondelinger, F ., Carson, G., et al. (2020). Features of 20,133 \nUK patients in hospital with covid-19 using the ISARIC WHO Clinical Characterisation Protocol: prospective observational cohort study. BMJ 369, m1985.\n 19. Mao, L., Jin, H., Wang, M., Hu, Y ., Chen, S., \nHe, Q., Chang, J., Hong, C., Zhou, Y ., Wang, D., et al. (2020). Neurologic manifestations of \nhospitalized patients with coronavirus disease 2019 in Wuhan, China. JAMA Neurol. 77, 1–9.\n 20. Poyiadji, N., Shahin, G., Noujaim, D., Stone, M., \nPatel, S., and Grifﬁ  th, B. (2020). COVID-19-\nassociated acute hemorrhagic necrotizing encephalopathy: CT and MRI features. 296, \nE119–E120.\n 21. Klok, F .A., Kruip, M., van der Meer, N.J.M., \nArbous, M.S., Gommers, D., Kant, K.M., Kaptein, F .H.J., van Paassen, J., Stals, M.A.M., Huisman, M.V., et al. (2020). Incidence of thrombotic \ncomplications in critically ill ICU patients with COVID-19. Thromb. Res. 191, 145–147.\n1Radboud University, 6525 XZ Nijmegen, \nThe Netherlands. 2University Medical Center, \nUtrecht Brain Center, Utrecht University, 3584 CG Utrecht, The Netherlands. \n3Netherlands Cancer Institute, 1066 CX \nAmsterdam, The Netherlands. 4Radboud \nUniversity Medical Center, 6525 GA Nijmegen, The Netherlands. \n5Maastricht \nUniversity, 6211 LK Maastricht, The Netherlands. \n6University of Groningen, 9712 \nCP Groningen, The Netherlands. 7University \nof Groningen, University Medical Center, 9713 GZ Groningen, The Netherlands. \n8Biomedical Primate Research Center, 2288 \nGJ Rijswijk, The Netherlands. 9Metris BV, \n2132 NG Hoofddorp, The Netherlands. \n10University Medical Center, 3584 CX Utrecht, \nThe Netherlands. 11Leiden University Medical \nCenter, 2333 ZA Leiden, The Netherlands. \n12Amsterdam University Medical Centers, \n1105 AZ Amsterdam, The Netherlands. \n13Erasmus University Medical Center, \n3015 GD Rotterdam, The Netherlands. \n14Netherlands Institute for Neuroscience, \nRoyal Netherlands Academy of Arts and Sciences, 1105 BA Amsterdam, The Netherlands. \n15Swammerdam Institute for \nLife Sciences, University of Amsterdam, 1098 XH Amsterdam, The Netherlands. \n16Charles \nRiver, 5231 DD Den Bosch, The Netherlands. \n17Oncode Institute, 3521 AL Utrecht, The \nNetherlands. 18Wageningen University, 6708 \nPB Wageningen, The Netherlands. 19Utrecht \nUniversity, 3512 JE Utrecht, The Netherlands. \n20Life and Medical Sciences Institute, \nUniversity of Bonn, 53115 Bonn, Germany. \n21Netherlands Institute of Ecology, 6708 PB \nWageningen, The Netherlands. 22Viroclinics \nXplore, 5374 RE Schaijk, The Netherlands. \n23Wageningen Bioveterinary Research, 8221 \nRA Lelystad, The Netherlands.*E-mail: \nl.genzel@donders.ru.nl ;\nJudith.Homberg@radboudumc.nlSeeing \nconsciousness through the lens of memory\nJoseph E. LeDoux1,2,3,*\nand Hakwan Lau4,5 \nWe humans have long thought of \nourselves in terms of bodily and mental spheres of existence. These days many of us understand that the mental aspect of who we are is embedded in the part of the body known as the brain, and is therefore also part of our physical, bodily self. Although most of us accept this scientiﬁ  c conclusion \nabout the physicality of the mind, many nevertheless feel as though their mind possesses some quality lacking in other physical systems within their body, and even within their brain — we have ﬁ  rst-hand knowledge \nof our thoughts and feelings, but not of the neural processes that control body processes related to digestion, respiration, heart rhythm, and so on, nor of the brain’s control of much of our behavior. \nIn this My Word, we explore the \nquestion of what is different about a brain state about which you are conscious from one that you are not? We will argue that all conscious experiences involve elements of memory and meta-representation. This framework may help us better understand the subjective qualitative character of conscious experiences, as well as why meta-representations may be involved in generating even the simplest of such experiences. \nPhenomenal ‘feel’ and conscious content\nWilliam James famously referred to the special property of conscious states in terms of ‘warmth and intimacy’. These days it is common to describe this as a phenomenal ‘feeling’ — the quality that makes red seem red, an apple seem like an apple, and fear feel fearful [\n1]. There is considerable \ndisagreement about what this quality is and how it may come about in the brain in relation to the actual content; My Wordwhat the experience is about, for example, an apple or a snake. \nFirst-order theories, such as \nrecurrent processing theory [\n2,3], posit \nthat consciousness originates in brain regions specialized in the processing of a given kind of information. For perceptual states of consciousness, these include, for instance, visual or auditory cortices. For emotions like fear, subcortical areas such as the amygdala have been proposed to be a ﬁ  rst-order locus [\n4]. In ﬁ  rst-\norder theories, the phenomenal feel and content of the experience are fully accounted for by some speciﬁ  c \npattern of neural activity within these ﬁ rst-order areas. \nHigher-order theories, on the \nother hand, suggest that ﬁ  rst-\norder representations may not be sufﬁ cient to account for either the \nphenomenal feel or the content of the conscious experience [\n5–7]. They \nposit that some higher-order cognitive mechanism, possibly involving circuits in prefrontal cortex, is needed in order to monitor or meta-represent the ﬁ rst-order information. As such, the \ninformation represented in ﬁ  rst-order \nstructures remains non-conscious (or pre-conscious) if no higher-order re-representation is involved. With respect to fear, this view posits that the amygdala controls non-conscious defensive responses, such as behavioral and physiological responses to threats, but that higher-order re-representation, possibly involving prefrontal cortex, is required in order to generate the subjective experience of fear in response to the threatening stimulus [\n7–9]. For higher-\norder theories, the phenomenal quality and conscious content both require the higher-order state. \nMemory and consciousness \nThe pioneering 19th century \npsychologist Hermann von Helmholtz proposed that conscious perception is an ‘unconscious inference’ based in part on memory. Consistent with von Helmholtz’s logic, we propose that all states of consciousness depend on memory [\n7–9], and speciﬁ  cally \non mechanisms that integrate sensory and memory information unconsciously (i.e. pre-consciously).\nA fundamental distinction in \nmemory research is between"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "Magazine\nCurrent Biology 30, R1009–R1035, September 21, 2020 R1019ll\nmemories that are formed and stored \nin a way that can be consciously retrieved, and memories that are stored implicitly, and hence are not consciously experienced when retrieved [\n10]. People can have \nconscious introspections and talk about explicit memories, but they can only show the effects of past implicit procedural learning through nonverbal behavior. One consequence is that a person with damage to the circuits underlying explicit memories can procedurally acquire and perform behaviors which they have no conscious memory of having acquired; conversely, damage to one of the many procedural memory circuits prevents behavioral learning by that system, but spares the ability to remember the episode in which they tried to learn the behavioral response.\nAn inﬂ  uential view of the relation \nbetween memory and consciousness was developed by Endel Tulving [\n11]. \nHe identiﬁ  ed three kinds of conscious \nstates that are each associated with a distinct kind of memory (\nTable 1 ). \nAlthough Tulving’s taxonomy was proposed to account for how memory contributes to consciousness, we believe it is also useful as a way of using memory to partition conscious states and thereby better understand consciousness itself.\nAutonoetic consciousness is \nexplicitly about your self in the present moment in relation to your past and future. It is grounded in episodic memories: memories about experiences you have had. The episodic record of your life provides a sense of continuity with your personal past (recollecting seeing a robin on a certain day and in a particular place); it also allows one to project into possible personal futures (wondering what kinds of birds you might see on your next outing). This ability to visit your personal past and hypothetical future is called mental time travel [\n11].Noetic states of consciousness \ndepend on semantic memories of factual and conceptual information about what things are and are not. For example, seeing a bird and recognizing it as a robin not only requires sensory processing of the visual properties of the present robin, but also semantic, including conceptual, memories about what birds and robins are. In sharp contrast to autonoesis, noetic states do not require explicit self-awareness and do not support mental time travel. \nA third kind of state recognized \nby Tulving is anoetic awareness. Although the most basic, it is the least intuitive, and requires some discussion. Tulving referred to anoetic consciousness as states of ‘non-knowing’, by which he meant that these do not themselves directly rely on or contribute to our conceptual, explicit knowledge, and hence are not readily available for introspection. They are conceptually similar to what ﬁ  rst-order theorists refer to as \n‘phenomenal consciousness’ [\n2,3], \nand have also been described as ‘non-reﬂ  ective qualia’ that occur in \nprimitive emotional states related to survival behaviors involving defense, mating, feeding and so on [\n4]. They \nexist on the ‘fringe’ or ‘penumbra’ of consciousness, to borrow expressions from William James.  \nAlthough Tulving and others \ndescribe anoetic states as temporally and spatially bound to the current moment, and mainly about the here and now, we believe this needs qualiﬁ  cation. This is true of \nthe sensory component of such states — but the involvement of implicit, procedural memories gives the moment a connection to relevant aspects of one’s implicit history with similar stimuli [\n11–13 ]. For \nexample, through past exposures to wavelengths within a certain range, the visual cortex, via synaptic plasticity, has implicitly learned relations between dynamical neural \nproﬁ les and sensory inputs. These \nimplicit memories are used to classify the wavelength of the present stimulus with other stimuli from the past with similar neural proﬁ  les. Indeed, \nempirical ﬁ  ndings show that colors \nand other low-level visual features are embedded in a local spatial and temporal contexts of other neurons and are processed relative to these [\n14]. The color of a stimulus, when \nnot conceptualized by semantic memory, can only be experienced relationally with respect to other possible color representations, which is what accumulated procedural memories offer. Accordingly, what we consciously see as red only looks red because of the way it looks similar to and different from other stimuli that have been seen in the past [\n13,14 ]. \nTo illustrate the relationship between \nthese three kinds of conscious states, consider the experience of seeing a red apple (\nFigure 1 ). An anoetic experience \nof ‘redness’, lacking the conceptual support of semantic memory, remains as a sensation of some complex set of wavelengths classiﬁ  ed in relation \nto past experiences with similar wavelengths stored via procedural memories. With semantic memory, the wavelengths become noetic states in which you are informed by what you conceptually understand ‘red’ to be, and how red relates to other features, such as shape, allowing an awareness that a red apple is present. If your self, via episodic memory, is explicitly brought into the experience, an autonoetic state of a red apple exists, perhaps involving the recollection of some experience involving apples from your past, or anticipating an experience in your future.\nMeta-representations and consciousness\n Each of Tulving’s three conscious \nstates have been said to be based on a pre-conscious meta-representation Table 1. Anoetic, noetic, and autonoetic consciousness.\nConsciousness Knowledge Memory Meta-representation Self Example thought\nAnoetic Non-knowing Procedural Non-cognitive Implicit Thought not involved\nNoetic Fact-knowing Semantic Cognitive Assumed “There is an apple”\nAutonoetic Self-knowing Episodic Cognitive Explicit “I see an apple”"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "Magazine\nR1020  Current Biology 30, R1009–R1035, September 21, 2020 ll\n[12]. As such, Tulving’s model can \nbe thought of as a kind of higher-order theory in which conscious awareness arises from the re-representation of a lower-order state by a higher-order one [\n5–9,12 ]. In \nother words, as in higher-order theory, the meta-representations are pre-conscious antecedents to conscious experiences. \nIn the case of anoetic \nconsciousness, the lower-order state is not simply a pure sensory state of visual cortex, as claimed by lower-order theories. It is, as noted, a representation in which raw sensory input has been compared with implicit procedural memories from similar past visual experiences. In further contrast to first-order theories, we suggest that even an anoetic, non-reflective, conscious experience of red depends on processing beyond visual cortex. For example, in order to experience red as being about a stimulus in the world the brain must distinguish it from other kinds of visual cortex states based on internal visual imagery or neural noise [\n15]. For this to happen, some additional \nmechanisms may have to implicitly retrieve, perhaps via an implicit schema (see below), the dynamical profiles of early sensory activity, in order to draw the correct perceptual inference. In this sense, we propose that meta-representations contribute to even the simplest perception of non-conceptualized redness [\n6,7,12 ].\nNoetic experiences add semantic \nknowledge stored in medial and lateral cortical areas of the temporal lobe [\n8,10] to the anoetic state. This \ncreates conceptualized perceptual content about what the stimulus is, and how it relates to the present situation. If you have the conscious thought that you are seeing the \nredness of an apple it is because you are noetically experiencing the content of the meta-representation. \nFor autonoetic states, episodic \nmemories about relevant past personal experiences stored in the temporal lobe are added to the noetic state. Through the mental time-travel feature of episodic memory, we feel consciously connected to our self over time, including our past, and our \npossible future, selves. \nIn summary, the three kinds of \nmeta-representations seem to serve the same purpose — they appear to function as higher-order re-representations of lower-order sensory and memory information. If correct, the implication is that all conscious experiences are preceded by a non-conscious meta-representation, without which there is no consciousness. We suggest that these meta-representations involve areas of prefrontal cortex, possibly including dorsal and ventral lateral prefrontal cortex, the frontal pole, and medial frontal areas [\n6–9,15–17 ]. Next, \nwe consider how these pre-conscious meta-representations might be translated into conscious content.\nThe stories we tell ourselves \nNovelists, inspired by William James’ description of ‘the stream of consciousness’, have capitalized on the narrative, story-like quality of the human mind. Scientists, too, have followed this lead [\n18–20 ], noting that \none’s self has a narrative-like structure that gives us psychological coherence over time. This coherence is probably maintained by perpetual revisions, with the results carried forward though memory. For example, if a new noetic or autonoetic experience is discordant with stored semantic or episodic memories, either the anomaly has to be accepted or the stored knowledge has to be updated. Although the term ‘narrative’, when used in relation to mental states, most commonly refers to a verbal story line told by our inner voice, our conscious experiences can be visual or even multimodal, and the underlying narratives, in turn, would be as well.\nA common assumption is that \nnarrations are outcomes of conscious states — they occur post-consciously. But we propose that narratives are also involved in the initial generation of the content of noetic and autonoetic consciousness. In particular, we suggest narratives reﬂ  ect the complex \nmemory processes known as schema [\n8,21]. These are collections of \nsemantic memories about recurring objects and situations that serve as non-conscious conceptual templates for storing new memories and for \nPre-conscious\nautonoetic\nMeta-representation\nEpisodic\nmemorySelf\nschemaAutonoeti c\nnarration\nPre-conscious\nnoetic\nMeta-representation\nSemantic\nmemoryConceptual\nschemaNoetic\nnarration\nPre-conscious\nanoetic\nMeta-representation\nSensory input +\nprocedural memoryProcedural\nschemaAnoetic\nnarrationAutonoetic\nconsciousnessNoetic\nconsciousnessAnoetic\nconsciousnessConscious\nstate\nSchema\nMeta-\nrepresentation\nLower-order\nstate\nExternal\nstimulus\nCon\nsc\nonsciou s\noetic\npresentat ion\nry input +\nral memory\nAnoet ic\nnarration\nonscious\noetic\nresentat ion\nmantic\nNoetic\nnarration\non\nono\npre\nCurrent Biology\nFigure 1. Meta-representations, narrations, schema, and consciousness. \nThe model developed in this paper involves three key ideas. First, conscious experiences of events in the world involve lower-order elements of memory that are meta-represented and ﬁ  l-\ntered by schemata that narrate the content of the conscious experience. Second, the lower-order state, meta-representation, schema, narrative, and content differ for anoetic, noetic, and auto-noetic experiences. Third, the states are hierarchical, such that the implicit procedural memory element of anoetic consciousness is passed on to noetic and autonoetic states, providing these explicit conscious experiences with a ‘phenomenal feel’ and sense of ownership."
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "Magazine\nCurrent Biology 30, R1009–R1035, September 21, 2020 R1021ll\nunderstanding present situations in \nrelation to one’s needs and goals [\n7–9,21 ]. Of interest is that the ventral \nmedial prefrontal cortex has a role in both schema [\n8,21] and narrations \n[22]. This area interconnects with \nother prefrontal areas that have been implicated in metacognition and consciousness, such as the dorsal lateral frontal cortex and the frontal pole [\n6–9,15–17,23,24 ]. We \nhypothesize that when the relevant prefrontal circuitry is damaged, pre-conscious narrations and the contents of conscious experiences should be affected.\nOwning up\nThe preceding discussion begs the question of how anoetic states ﬁ  t \ninto our narrative framework of noetic and autonoetic consciousness. We suggest that anoetic states may play a crucial role in the feeling of ownership we have about our mental states. \nMental state ownership is so natural \nand automatic that we never have to explicitly afﬁ  rm it. This fact is put into \nstark relief by certain neurological or psychiatric conditions in which people lose the sense that their thoughts and feelings belong to them [\n25]. A \ncommon view is that this personal relationship to mental states is due to autobiographical memory, which includes episodic and semantic memories about our self. Certainly, our autobiographical memories, especially episodic ones, are important in giving us a sense of continuity over time. But there may be more to the sense of ownership than that. \nAs we noted, procedural memories \ngive anoetic states a connection to implicit aspects of one’s history that are relevant to the present stimulus situation. The fringe or penumbral quality of these goes unnoticed because anoetic states are often embedded in noetic and/or autonoetic states with actual conscious content [\n4]. It is mainly in laboratory studies \nwhere explicit consciousness involvement is minimized that a pure anoetic experience can be isolated. But in a real-life situation the procedural memories, and their implicit connection to your past, may be what makes a noetic or autonoetic state feel it is, by mere acquaintance [\n25], yours without \nyou ever having to explicitly afﬁ  rm that. Now consider this idea in the \ncontext of a complex real-life situation in which you are not just seeing a stimulus but are in a life-threatening encounter with a dangerous stimulus such as a rattlesnake. Sensory information about the snake will not simply be transmitted from visual cortex areas to memory and higher cognitive circuits. It will also be transmitted to subcortical circuits, such as those involving the amygdala, that organize defensive behaviors and physiological reactions, and that also activate arousal systems. The behavioral and physiological responses also produce sensory and chemical signals that are represented in the brain as body states [\n4,8,9,26 ]. \nImportantly, these circuits have also acquired procedural memories about the relevant neural responses made in the past. These will determine, for example, how the present degree of activation of amygdala, arousal, or body state circuits match levels from the past. Still other implicit circuits are also likely activated. For example, object recognition or auditory pattern recognition circuits might be primed to detect related stimuli, and motor circuits primed to respond behaviorally. \nAll of these implicit states will \nbecome part of an anoetic background monitored by the meta-representation that also includes semantic conceptual content about snakes and episodic content about your personal experiences with snakes. The content of the meta-representation as a whole, we suggest, will be schematized (implicitly by procedural memory and explicitly by semantic memory) and narrated [\n27] (Figure 1 ). Hence you \nwill ﬁ nd yourself in the autonoetic \nstate of fear [ 8,9,27 ], without having \nto explicitly infer that fear is what you are feeling. You know it is fear because you know what fear feels like to you. Other people do not have your ﬁ  rst-hand procedural memories \nof your neurophysiological responses to threats that accompany your autonoetic states of fear narrated by your schema. That’s why emotions are personal — only you can have your emotions [\n8,9,27 ]. But through shared \nvocabulary, we can extrapolate and infer what others might feel in similar \nsituations [\n8,27]. Complicating our ability to understand the emotional \nlives of others is the fact that emotion schema, and hence emotional experiences, differ not only between individuals, but also between social and cultural groups [\n27,28 ].\nBy contrast with other proposals \nabout the role of anoetic states in phenomenal experience, our view differs in two key respects. In our model, ﬁ  rst-order neural \nactivity is not all there is to anoetic consciousness. Thus, we maintain that the phenomenal feel of visual consciousness is not simply a state of visual cortex [\n2,3], and the \nphenomenal feel of fear is neither an amygdala state [\n4] nor a state \nrepresenting body sensations [ 26]. \nOnly once lower-order states are meta-represented does anoetic phenomenal consciousness result. Second, we suggest in any real-world experience, many other procedural brain systems will also be implicitly activated, besides the obvious ones mentioned above, and all will contribute to the phenomenal feel, the familiarity, of the mental moment, when monitored by the meta-representation. \nThe philosopher Owen Flanagan \n[\n29] noted that theories about the self \noverrate the role of autobiographical memories, and underestimate the role of the much larger class of events that are experienced but not remembered. We broadly agree but suggest that the reason these experiences may contribute is because they are implicitly remembered via procedural memory. \nAs noted, prefrontal circuits \nhave been implicated in subjective metacognition, narratives, schemata, consciousness, including self-consciousness and emotional consciousness [\n6–9,15,16,17,23,24,27 ], \nbut also in the ownership of mental states [\n25], and in the ‘feeling of \nrightness’, ‘feeling of knowing’, and ‘feeling of familiarity’ of such states [\n21,25 ]. Perhaps a general purpose \nhigher-cognitive prefrontal network might underlie all kinds of conscious experiences [\n5–9,27 ]. \nReconciling ﬁ  rst-order and higher-\norder theories\nThe above provides a possible rapprochement between the ﬁ  rst-\norder and higher-order theories of"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "Magazine\nR1022  Current Biology 30, R1009–R1035, September 21, 2020 ll\nconsciousness. First-order theorists \nhave claimed that phenomenal consciousness is theirs alone, and that higher-order theory is only about cognitive access and interpretation of the experiences. For them higher-order theory, with its emphasis on cognition, makes consciousness overly complex. On the other hand, higher-order theorists say that ﬁ rst-order theory is too simple, as it \nignores conceptualized content, which is essential to real life conscious states. \nTulving’s scheme, however, \nallows us to see the division of labor more clearly. Anoetic states are functionally equivalent to what first order-theorists call phenomenal consciousness. But in our schema anoetic states require sensory representations that are colored by procedural memory, and also requires that they be meta-represented. While noetic and autonoetic consciousness involve more explicit forms of memories, they too inherit the phenomenal feel provided by anoetic consciousness in the background. In this sense, lower- and higher-order representations can be seen as components of a common theory of consciousness, rather than as elements of competing theories.\nConclusion\nThe nature of conscious experience in an organism hinges on the kinds of meta-representational states that its brain makes possible. Our brain has the capacity for anoetic, noetic, and autonoetic meta-representations, and schematic narrations that translate the meta-representational content into corresponding conscious experiences that we feel are ours. Better understanding of the detailed neural circuitries involved would help clarify whether a general-purpose mechanism of consciousness exists. While it is difﬁ  cult to study \nconsciousness in animals, research on meta-representations face far fewer hurdles and offer a reasonable proxy for comparative studies of the pre-conscious processes related to consciousness. \nGiven that we are both \nneuroscientists, why are we so concerned about these ‘philosophical’ issues? Scientists sometimes speculate on consciousness for \nsheer intellectual challenge. But our intentions are actually practical: we believe that progress in psychiatry and clinical psychology has been impeded by the fact that these ﬁ  elds have \nmarginalized the role of subjective experience in understanding and treating mental disorders. This may be because subjective experience has often been seen as too elusive for scientiﬁ  c and clinical investigation. \nExtension of the science of consciousness into the clinic could both offer novel insights into the nature of consciousness, and suggest new avenues for helping sufferers feel \nbetter subjectively. \nACKNOWLEDGEMENTS\nThe authors thank Patrick Haggard and \nBarton Anderson for comments on earlier versions of the manuscript. J.E.L. and H.L. are supported by a grant from the Templeton World Charity Foundation (TWCF0366). J.E.L. is also supported by the Vulnerable Brain Project and the National Institute of Health (RO1DA044445).\nREFERENCES\n 1. Chalmers, D.J. (1997). Availability: the \ncognitive basis of experience. Behav. Brain Sci. 20, 148–149.\n 2. Block, N. (2019). Empirical science meets \nhigher order views of consciousness: reply to Hakwan Lau and Richard Brown. In Blockheads! Essays on Ned Block’s Philosophy of Mind and Consciousness, A. Pautz and D. Stoljar, eds. (Cambridge, MA: MIT Press), pp. 199–214.\n 3. Lamme, V.A. (2010). How neuroscience will \nchange our view on consciousness. Cogn. Neurosci. 1, 204–220.\n 4. Vandekerckhove, M., and Panksepp, J. (2011). \nA neurocognitive theory of higher mental emergence: from anoetic affective experiences to noetic knowledge and autonoetic awareness. Neurosci. Biobehav. Rev. 35, 2017–2025.\n 5. Rosenthal, D.M. (2005). Consciousness and \nMind (Oxford: Oxford University Press).\n 6. Lau, H., and Rosenthal, D. (2011). Empirical \nsupport for higher-order theories of conscious awareness. Trends Cogn. Sci. 15, 365–373.\n 7. Brown, R., Lau, H., and LeDoux, J.E. (2019). \nUnderstanding the higher-order approach to consciousness. Trends Cogn. Sci. 23, \n754–768.\n 8. LeDoux, J. (2019). The Deep History of \nOurselves: The Four-Billion-Year Story of How We Got Conscious Brains (New York: Viking).\n 9. LeDoux, J.E., and Brown, R. (2017). A higher-\norder theory of emotional consciousness. Proc. Natl. Acad. Sci. USA 114, E2016–E2025.\n 10. Squire, L. (1987). Memory and Brain (New York, \nOxford: American Neurological Association).\n 11. Tulving, E. (1985). Ebbinghaus’s memory: what \ndid he learn and remember? J. Exp. Psychol. Learn. Mem. Cogn. 11, 485–490.\n 12. Metcalfe, J., and Son, L.K. (2012). Anoetic, \nnoetic and autonoetic metacognition. In Foundations of Metacognition, M. Beran, J.R. Brandl, J. Perner, and J. Proust, eds. (Oxford: \nOxford University Press), pp. 289–301.\n 13.  Clark, A. (2000). A Theory of Sentience (New \nYork: Oxford University Press).\n 14. Schwartz, O., Hsu, A., and Dayan, P . (2007). \nSpace and time in visual context. Nat. Rev. Neurosci. 8, 522–535.\n 15. Lau, H. (2019). Consciousness, metacognition, \n& perceptual reality monitoring. PsyArXiv \nhttps://doi.org/10.31234/osf.io/ckbyf\n 16. Fleming, S.M., and Dolan, R.J. (2012). The \nneural basis of metacognitive ability. Philos. Trans. R. Soc. Lond. B 367, 1338–1349.\n 17. Odegaard, B., Knight, R.T., and Lau, H. (2017). \nShould a few null ﬁ  ndings falsify prefrontal \ntheories of conscious perception? J. Neurosci. 37, 9593–9602.\n 18. Gazzaniga, M.S., and LeDoux, J.E. (1978). The \nIntegrated Mind (New York: Plenum).\n 19. Bruner, J. (1994). The “remembered” self. In \nThe Remembering Self: Construction and Accuracy in the Self-Narrative, R. Fivush and U. Neisser, eds. (Cambridge: Cambridge University Press), pp. 41–54.\n 20. Johnson-Laird, P .N. (1983). Mental Models: \nTowards a Cognitive Science of Language, Inference, and Consciousness (Cambridge, MA: Harvard University Press).\n 21. Gilboa, A., and Marlatte, H. (2017). \nNeurobiology of schemas and schema-mediated memory. Trends Cogn. Sci. 21, \n618–631.\n 22. D’Argembeau, A., Cassol, H., Phillips, \nC., Balteau, E., Salmon, E., and Van der Linden, M. (2014). Brains creating stories of selves: the neural basis of autobiographical reasoning. Soc. Cogn. Affect. Neurosci. 9, \n646–652.\n 23. Fleming, S.M., Dolan, R.J., and Frith, C.D. \n(2012). Metacognition: computation, biology and function. Philos. Trans. R. Soc. Lond. B 367, 1280–1286.\n 24. Dehaene, S., Lau, H., and Kouider, S. (2017). \nWhat is consciousness, and could machines have it? Science 358, 486–492.\n 25. Klein, S.B. (2015). The feeling of personal \nownership of one’s mental states: a conceptual argument and empirical evidence for an essential, but underappreciated, mechanism of mind. Psychol. Conscious. Theory Res. Pract. 2, 355–376.\n 26. Damasio, A., and Carvalho, G.B. (2013). \nThe nature of feelings: evolutionary and neurobiological origins. Nat. Rev. Neurosci. 14, \n143–152.\n 27. LeDoux, J.E. (2020). Thoughtful feelings. Curr. \nBiol. 30, R619–R623. \n 28. Barrett, L. (2017). How Emotions Are Made \n(Boston, New York: Houghton Mifﬂ  in, \nHarcourt).\n 29. Flanagan, O. (2011). My non-narrative, non-\nforensic Dasein: the ﬁ  rst and second self. In \nSelf and Consciousness, J.L. Liu and J. Perry, eds. (Cambridge: Cambridge University Press), pp. 214–240.\n1Center for Neural Science and Department \nof Psychology, New York University, New York, NY 1003, USA. \n2Department of \nPsychiatry, and Department of Child and Adolescent Psychiatry, New York University Langone Medical School, New York, NY 1003, USA. \n3Emotional Brain Institute, \nNathan Kline Institute, Orangeburg, NY 10962, USA.\n 4Department of Psychology and \nBrain Research Institute, UCLA, Los Angeles, 90095, USA. \n5Department of Psychology and \nState Key Laboratory of Brain and Cognitive Sciences, University of Hong Kong, Hong Kong. *E-mail: \njel1@nyu.edu"
    }
  ]
}