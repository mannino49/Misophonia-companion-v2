{
  "doc_type": "scientific paper",
  "title": "Detecting suicidality on social media machine learning at rescue",
  "authors": [
    "Rabani"
  ],
  "year": 2023,
  "journal": "Science, BGSBU, Rajouri, India",
  "doi": "10.1016/j.eij.2023.04.003",
  "abstract": null,
  "keywords": [
    "Suicidal ideation"
  ],
  "research_topics": [
    "Suicidal ideation"
  ],
  "created_at": "2025-05-05T00:46:09.719260Z",
  "source_pdf": "documents/research/Global/Rabani 2023 Detecting suicidality on social media machine learning at rescue.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Full length article\nDetecting suicidality on social media: Machine learning at rescue\nSyed Tanzeel Rabania, Akib Mohi Ud Din Khandaya, Qamar Rayees Khana,\nUmar Ayoub Hajama, Ali Shariq Imranb,⇑, Zenun Kastratic\naDepartment of Computer Science, BGSBU, Rajouri, India\nbDepartment of Computer Science (IDI), Norwegian University of Science and Technology (NTNU), Norway\ncDepartment of Informatics, Linnaeus University (LNU), Sweden\narticle info\nArticle history:\nReceived 6 January 2023Revised 3 April 2023Accepted 7 April 2023\nKeywords:\nSuicidal ideation\nSocial mediaFeature engineeringMachine learningEnsemble learningabstract\nThe rise in technological advancements and Social Networking Sites (SNS) made people more engaged in\ntheir virtual lives. Research has revealed that people feel more comfortable posting their feelings, includ-\ning suicidal thoughts, on SNS than discussing them through face-to-face settings due to the social stigma\nassociated with mental health. This research study aims to develop a multi-class machine learning clas-siﬁer for identifying suicidal risk levels in social media posts. The proposed Enhanced Feature Engineering\nApproach for Suicidal Risk Identiﬁcation (EFASRI) is used to extract features from a novel dataset col-\nlected from Twitter and Reddit platforms. Three machine learning algorithms, i.e. Support VectorMachine (SVM), Random Forest (RF) and Extreme Gradient Boosting (XGB) were employed for classiﬁca-\ntion. The study demonstrates signiﬁcant improvements in the precision, recall, and overall accuracy com-\npared to previous research that used classical feature extraction mechanisms. The best-performingalgorithm, Extreme Gradient Boosting (XGB), achieved an overall accuracy of 96.33%. The ﬁndings implythat different features contain different levels of information, and the right combination of the features\nsupplied to the machine learning algorithms may improve the prediction results.\n/C2112023 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artiﬁcial Intel-\nligence, Cairo University. This is an open access article under the CC BY-NC-ND license ( http://creative-\ncommons.org/licenses/by-nc-nd/4.0/ ).\n1. Introduction\nA detailed statistic provided by World Health Organisation\n(WHO) mentions that, on average, suicide occurs every forty sec-\nonds [1]. The report further says that approximately 800,000 peo-\nple commit suicide every year, and the number of suicide attempts\nis 20 times more than a completed suicide [2]. However, compared\nto the deaths due to various ailments, suicide is much underre-\nported. Thus, the global estimate of suicide mortality is approxi-\nmated to one million deaths per year [3]. The above statistics\nalso reveal that suicide is the leading cause of death among young-sters, particularly among women. Suicide is not about an ‘‘all or\nnothing” situation. The famous book related to suicide [4]indicatesthat it follows a proper process and pattern wherein suicidal idea-\ntion takes the ﬁrst place followed by a suicidal attempt which then\nmatures into the completed suicide. Suicidal ideation does not\nalways lead to suicide, but it poses a signiﬁcant threat to individu-\nals who may then attempt suicide. Suicidality gets noticed when\none often talks about it with his/her caretakers or when psychia-\ntrists/psychologists interact with the individuals and enquire\nabout their thinking and mood. By analyzing various warning\nsigns, caregivers can uncover the risk factors associated with suici-\ndality and take the necessary steps for prevention. American Foun-\ndation for Suicide Prevention [AFSP] [5]identiﬁed various risk\nfactors and warning signs related to suicidality to help potential\nsuicidal individuals. They categorized the risk factor into three\nmain classes. These factors are related to health (mental health,\npersistent pain), environment (stress, molestation, etc.) and family\nhistory (previous attempts of suicide etc.). The National Institutes\nof Health (NIH) further lists some of the indicators/warning signs\nof suicidal ideation, as shown in Fig. 1 .\nMany suicidal deaths can be prevented by understanding how\npeople communicate their distressrelated thoughts. Early under-\nstanding of the risk factors and warning signs can decrease the\nthreshold for suicide and help prevent many deaths. However,\nhttps://doi.org/10.1016/j.eij.2023.04.003\n1110-8665/ /C2112023 THE AUTHORS. Published by Elsevier BV on behalf of Faculty of Computers and Artiﬁcial Intelligence, Cairo University.\nThis is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/ ).⇑Corresponding author.\nE-mail address: ali.imran@ntnu.no (A.S. Imran).\nPeer review under responsibility of Faculty of Computers and Information, Cairo\nUniversity.\nProduction and hosting by ElsevierEgyptian Informatics Journal 24 (2023) 291–302\nContents lists available at ScienceDirect\nEgyptian Informatics Journal\njournal homepage: www. sciencedirect.com"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "the issue with suicidality is that people usually don’t cooperate\nwith clinicians due to the social stigma associated with mental ill-\nness. As stigma plays a deadly role in suicidality, clinical interven-\ntions for at-risk individuals at a large scale become almost\nimpossible. It is reported that 36% of individuals who die due to\nsuicide leave a note behind [6]. Researchers found that suicide\nnotes indicate that when the suicidal attempt of any individual\nfails, there is a high probability that they will still go for another\nattempt with more accuracy [7]. It is also found that these suicide\nnotes talk more about shame and apology suggest if any alterna-\ntive was there, they might have readily accepted that. However,\nmost of the suicide notes are found when suicide is completed or\nat least attempted [7]. Many efforts were made to screen the\npatients, but it was a challenging task to counsel the individuals\nto come for evaluation in a stigmatized society [8,9] . Research\nhas revealed that people feel more comfortable discussing their\ndaytoday happenings on Online Social Networks (OSN) without\nworrying about social stigma [10]. Moreover, recent research has\nalso found that monitoring social media can provide an alternative\nand excellent opportunity for uncovering the warning signs associ-\nated with the posts of at-risk individuals suffering from suicidality\n[11–13] . Thus social media, if appropriately mined, can act as a tool\nto prevent potential suicidal victims from taking the extreme step\nand also offer the necessary support. Moreover, the histories of\npersons on SNS who commit suicide can help understand the risk\nfactors associated with suicide. Researchers have put a lot of effort\ninto identifying the patterns in the language of social media [14,15]\nincluding mental health [16,17] . Some studies trained machine\nlearning models to separate suicidal content from non-suicidal\ncontent [16,18] . But the model that will separate the content\nreﬂecting suicidal ideation from depression and other low-riskposts requires a highlevel feature engineering mechanism. The\nneed for such a feature engineering mechanism is that the posts\nreﬂecting suicidal ideation and other stress-related content seem\nvery identical in its language. In this paper, signiﬁcant attention\nhas been made to employing novel hybrid feature engineeringmechanisms that will be used to train the machine learning models\nto help differentiate the highrisk posts from other categories. The\nmajor contributions that this research article makes to the already\nexisting literature are as follows:\n1. Novel dataset is collected from Twitter and Reddit. The dataset\nwas annotated with the scheme developed in consultation with\npsychiatrists and psychologists.\n2. We developed a methodology that could help differentiate the\nposts into three categories of risk: high risk, moderate risk,\nand no risk.\n3. We developed a novel hybrid feature engineering mechanism\nfor the extraction of the most relevant features.\n4. We trained three learning algorithms, viz., support vector\nmachine (SVM), random forest (RF), and extreme gradient\nboosting (XGB), with the features extracted through our pro-\nposed feature engineering mechanism.\nThe rest of our article is divided into various sections. Section 2dis-\ncusses the related work done in the domain of the detection and\nprevention of suicidality. Section 3discusses the proposed\nmethodology, which contains various subsections: data collection,\ndata pre-processing, proposed novel feature engineering mecha-\nnism and ﬁnally, training of machine learning algorithms. Section 4\nelaborates on the results and discussion. Section 5compares our\nwork with the previous research. Section 6provides the conclusion\nand future scope of the work.\n2. Literature Review\nMental health issues like depression and suicidality have usu-\nally been examined through psychological battery tests and clinical\nprocedures [6,19] . The stigma associated with mental illness made\nresearchers move towards informal sources like social media to\nunderstand language patterns of suicidal posts that could enhance\nthe interpretation of suicidal ideation in a better way.\nFig. 1. Warning Signs of Suicide.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n292"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "2.1. An overview of research on questionnaires, topic analysis, and\nmachine learning techniques\nThe study by [11,20] indicated that questionaries play a vital\nrole in detecting the mental state of a patient. However, due to\nthe boom in social networking sites, people feel comfortable and\nexpress their feelings freely on social media. Various studies\n[20,21] discuss several scales used to predict depression on social\nmedia. More studies [22,23] were conducted to analyse the topics,\nwhich potential suicidal individuals usually like to discuss on\nsocial media, and the behaviour of suicidal individuals was also\nevaluated through these studies. The advancement in natural lan-\nguage rocessing and machine learning techniques has made it pos-\nsible to process the semantic information from these social media\nposts to extract the various features, which can help automate theprediction of suicidal content [24,21] . Most of the research\nfocussed on using binary classiﬁcation mechanisms for identifying\nsuicidal content through various popular algorithms like Support\nvector machine, Decision trees and ensemble learning algorithms\n[25–28] . Deep learning methods have also been used to help pre-\ndict suicidal ideation [8].\n2.2. Feature extraction mechanism for detecting suicidal ideation\nOne of the most important parts of building a machine learning\nmodel is to ﬁnd the most relevant features that can help in differ-\nentiating suicidal content from non-suicidal content [18]. Alada\net al. [9]did a sentimental analysis of Reddit posts and differenti-\nated the suicidal content from non-suicidal ones using features\nextracted through term frequency-inverse document frequency\nand word count. O’Dea et al., [27] trained the classiﬁer that helped\nautomate and replicate the accuracy of human coders. Feature\nextraction was performed using unigrams, TF-IDF and Filter based\ntechniques. Vioules et al., [29] introduced a new approach that\nmeasures the warning signs of suicide, detects the posts that con-\ntain content related to suicide, and automatically identiﬁes the\nsudden changes in user behavior. The researchers developed the\nbehavioral features to measure the level of risk of a person con-\ncerned with his online behavior on Twitter. Two groups of behav-\nioral features, namely user-centric features and post-centric\nfeatures were established. Chadha et al., [30] discuss about the per-\nformance evaluation of various machine learning algorithms for\nidentifying and differentiating suicidal content from non-suicidal\ncontent on Twitter. The researchers manually selected the 112 fea-\ntures through a survey involving the doctors and patients of a psy-\nchiatric hospital. BOW and TFIDF weighting schemes were used to\ndiscard the irrelevant features. Abboute et al. [31] developed a list\nof terms for lexical feature extraction using nine suicidal topicsOkhapkina et al. [32] also developed a lexicon of terms using\nterm-frequency inverse document frequency technique that\nhelped in differentiating the suicidal content from non-suicidal\nones. In a study of suicide on Weibo, Cheng [33] largely employed\nSimpliﬁed Chinese Language Query and Word Count (SC-LIWC) to\ncount how many times each type of word appeared in users’ post-\nings. He then used logistic regression to look at the relationship\nbetween SC-LIWC features and ﬁve suicide risk factors.\nVery few studies used a hybrid feature model where features\nextracted through different techniques were combined and sup-\nplied to machine learning techniques for better prediction. Sawh-\nney et al. [18]collected numerous sets of features such as\nstatistical features, Linguistic Inquiry and Word Count (LIWC) fea-\ntures, term frequency-inverse document frequency, and topics\nprobability features. These features proved to be successful for\nthe binary classiﬁcation of tweets with stable precision and recall.\nShing et al. [34] also retrieved numerous features using the tech-\nnique of Bag of words, topic modeling, and linguistic inquiry andword count. Mbarek et al. [35]developed a suicide user proﬁle\ndetection model using a set of features that included a linguistic,\nemotional, facial, timeline, and public features. Mbarek et al.\n[36], in their other study, applied different machine learning algo-\nrithms to solve the suicidal user prediction problem using a rich set\nof features like Emotional features, Temporal features and Account\nfeatures that have been effective in detecting suicidal users. The\nfeasibility of their method was studied on people who committedsuicide, and the results were shown to be in line with expectations.\n2.3. Critical review of the existing literature\nDetection of suicidal ideation through social media is a growing\narea of research, with efforts directed towards building an intelli-\ngent mechanism through training classiﬁers using various algo-\nrithms and features. The ensemble approach has shown promise\nin improving prediction results by overcoming overﬁtting. How-\never, current research has primarily focused on training classiﬁers\non smaller datasets and tuning various parameters, with less atten-\ntion given to feature engineering. Moreover, Previous studies have\nmainly employed feature extraction techniques such as term-\nfrequency inverse document frequency and Bag of Words. In addi-\ntion, various feature selection techniques such as univariate selec-\ntion, feature importance, and correlation matrix have been used to\neliminate irrelevant attributes. In contrast, our study emphasizes\nbuilding a large real-world suicide dataset, utilizing a hybrid fea-\nture engineering mechanism to extract relevant features and train-\ning machine-learning models using these features.} The most\nrelevant articles related to our work, along with their contributions\nand the features used are summarised in Table 1 .\nThe literature survey indicated that work done in the ﬁeld of\ndata mining for predicting suicidal ideation on social media andits prevention is minimal that needs a lot of effort. Data scarcity\nis also a big problem due to the privacy and ethical issues related\nto this research. Moreover, the above literature mostly focuses on\nbinary classiﬁcation and uses ordinary feature extraction tech-\nniques. Our work made a novel effort to collect big data related\nto suicidal tweets using the API of Twitter and Reddit and also\nfocused on a feature extraction mechanism for the extraction of\nrich features. Then three machine learning algorithms were trained\nto classify the tweets into three classes of distress using the\nmethodology discussed in Section 3.\n3. Methodology\nThe methodology adopted in this research article for identifying\nand classifying social media posts into three levels of concern con-\nsists of four major steps as shown in Fig. 2 . In the ﬁrst step, relevant\ndata is extracted from SNS. The second step is about annotating the\nposts into three levels of risk based upon the annotation scheme\nthat is devised in consultation with mental health experts. The\nthird step involves preprocessing the posts to remove irrelevant\nand redundant information and proposing the feature extraction\nmechanism to extract the relevant features for training the\nmulti-class machine learning model. The last step is about classify-\ning the posts and evaluating the model using different metrics.\n3.1. Data Collection and Exploration\nThe data was collected from two famous SNS: Twitter and Red-\ndit through their APIs. We neither collected any identiﬁable human\ndata from the social posts nor saved any such information. A ran-\ndom identiﬁer was assigned to each post. Twitter API was used\nto collect the tweets using the phrases or words as used in previous\nresearch [11,14,26] and other words suggested by the mentalS.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n293"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "health experts over the period November 8, 2019, to February 26,\n2022. Some of those keywords for extraction of data from Twitter\nare as listed: ‘‘want to die; tired of myself; ending my life; be dead;\nsuicidal; feeling empty; feeling suicidal; feeling alone; feel anx-\nious; I feel helpless; unworthy life; suicide plan; cutting my wrist;\nInsomnia; fucking life; depression; pills depressed; diagonised\nschizophrenia; diagonised bipolar; MDD; never wake up; better\noff dead; go to sleep forever; tired of living; We also studied two\nsubreddits, r/SuicideWatch, and r/depression. To extract the suici-\ndal posts -and also those posts that don’t directly indicate suicidal-\nity but point to any of the risk factors related to the suicide, we\nselected postings from r/SuicideWatch and r/depression. We\nexpected that all r/SuicideWatch entries were suicidal and that\nthe vocabulary of r/depression would be the most comparable to\nthat of r/SuicideWatch as indicated by the previous research[30,31] , when several control subreddits were utilized for languagecomparison, implying that subreddits can be used as labels also.\nWe used the API of Reddit and Python Reddit API Wrapper (PRAW)\nto retrieve the data. PRAW can only be used when we authenticate\nourselves. For that, we need to develop an application and get the\nauthentication details like client id, client secret, and user agent.\nSome of the sample tweets and Reddit posts are shown in Table 2 .\nThe combined dataset collected through Twitter and Reddit was\nanalyzed through Word Cloud in Fig. 3 to get the frequent words\nused by individuals. The words like ‘‘life”, ‘‘feel”, ‘‘commit”, ‘‘want”,\n‘‘depress”, ‘‘think”, and ‘‘depression”, were found in abundance.\nThese words reﬂected that many individuals who post their feel-\nings on social media want people to listen to their online cry before\ntaking this harsh step of suicide. The extracted data also contains\ntweets about suicidal awareness, talking about killing oneself,\nreporting the third person, and using suicide in another way, e.g.,suicide door. The next step was to manually annotate the data byTable 1\nMost Relevant and Recent Work Related to the Detection of Suicidal Ideation on Social Media.\nStudy Contributions Data\nUsedFeatures Used\n[27] Developed Binary classiﬁer for suicide detection using various Machine learning techniques Twitter TFIDF,BOW\n[37] Developed Multi-class machine learning classiﬁer for classiﬁcation of suicide related\ncommunication on TwitterTwitter TFIDF\n[38] Developed Binary classiﬁer for suicide detection using Machine and ensemble methods. Twitter Manual features (34 known keywords used by\nsuicidal persons)\n[18] Develop and design new features to improve classiﬁcation of suicidal content. Twitter LIWC Features, Topics, TFIDF and part of\nspeech\n[30] Developed machine learning classiﬁer for suicidal identiﬁcation. Twitter Manual features (Suicidal Keywords),TFIDF\nand BOW\n[29] Quantiﬁcation of suicidal warning signs for detection of distress and suicide related content. Twitter Textual and Behavioural features\n[39] Prediction of suicidal ideation using Deep learning and Machine learning models. Reddit TFIDF and Word2Vec\nFig. 2. Proposed methodology for suicidality detection.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n294"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "developing the annotation scheme in consultation with psychia-\ntrists and Psychologists.\n3.2. Data Annotation\nA total number of 19915 tweets and reddit posts were collected.\nOut of these posts, the annotators labelled 7025 posts in the no-\nrisk category, 6590 in the moderate risk category and 6300 in the\nhigh-risk category. The annotation was performed in consultationwith mental health experts and the person’s active on social media.\nHuman annotation scheme was devised in such a way that annota-\ntors were asked to indicate about a post whether it will fall in any\none of the three categories of high risk, moderate risk or no risk\ncategories. All the posts indicating killing oneself or wishing to\nbe dead were asked to be put in the high-risk category. The\nmoderate-risk category includes those posts that talk about gen-\neral anxiety and depression. No risk category contains posts about\nnews about suicide, suicidal awareness and campaigning etc.Table 2\nSample Tweets/ Reddit Posts reﬂecting the Suicidalaity\nSuicidal Posts Type of Post\n‘‘I just want to end my life so badly. My life is completely empty and I don’t want to have to create meaning in it. Creating meaning is\npain. How long will I hold back the urge to run my car head-ﬁrst into the next person coming the opposite way. When will I stopfeeling jealous of tragic characters like Gomer Pile for the swift end they were able to bring to their lives?”Reddit Post (r/SuicideWatch)\n‘‘I’ve been suicidal for a while now. I’ve made 4 attempts this year. And yet, nobody seems to get it. I can’t afford to be hospitalized.\nI’m an emotional wreck. I keep breaking down, crying, and I don’t know why. I hate myself for this.”Reddit Post (r/SuicideWatch)\n‘‘My relationship is complicated and painful, but I don’t want to end it. While my girlfriend and I were broken up, I slept with her\nboyfriend. For three years I’ve been trying to make it up to her, but after a while, I realized I don’t think I ever will. I’m not sureshe’ll ever want to touch me again. She hasn’t wanted to touch me since that happened, no matter how hard I try, no matter what\nI do or say. She does it for me, but she looks bored the whole time and gets it over with asap. I feel worthless. She’s my soulmate. I\ncan’t live in this horrible world without her, but I don’t think she wants to be sexual with me. I’m so lonely. I wish I could just turnoff the part of my brain that feels.”Reddit Post (r/depression)\n‘‘I’m 21 y/o working student, I want to kill myself; life is unbearable. I have no skills no talents and I’m absolutely boring person so I\nspend most of my free time alone. I really want to ﬁnd a girlfriend but I see no way how could I ﬁnd one when I’m useless likethis. I used to go away from sadness by listening to music but these days I am bored of music and just want to go to sleep andnever wake up.”Reddit Post (r/depression)\n‘‘I am 19 years old. I’ve had anxiety my entire life and depression since I was 12, and it’s gotten worse and worse over the years. Add\nmisophonia to that and it makes life torture. It’s especially bad now because I don’t know what the fuck I’m doing in life. The onlyreason I have to live is for my friends and family and because I’m too scared to die (which is ironic because I wish I was dead mostof the time, or at least I wish I’d never been born). But life is scary, too. Anyway. If things don’t get better in the next 5–10 years,then I fucking quit. Or maybe I’ll pussy out like the pathetic piece of a shit coward I am. I don’t know.”Reddit Post (r/depression)\n‘‘I am gonna attempt suicide tonight. Bye Everyone. My last wishes are for my siblings to ﬁnish school and become emergency\nresponders”Tweet\n‘‘For the love of God leave me fucking alone. Plz leave ﬂowers on my grave. Fuck y’all.” Tweet\n‘‘Confession: I am not ok! I am trying but so far I am failing” Tweet\nFig. 3. Word Cloud of the suicidal dataset.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n295"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "Annotators were asked to select the post against the high risk and\nno risk categories and in case of ambiguity, put the post in\nmoderate-risk category, the default level. We used the Kappa coef-\nﬁcient to check the inter-annotator agreement between various\nposts.\nFor high-risk category:\n/C15Observed agreement: 0.92\n/C15Expected agreement: ((0.70252 ˆ) + (0.29752 ˆ)) = 0.5164\n/C15Kappa coefﬁcient: (0.92–0.5164)/ (1–0.5164) = 0.645\nFor moderate-risk category:\n/C15Observed agreement: 0.95\n/C15Expected agreement: ((0.65902 ˆ) + (0.34102 ˆ)) = 0.4533\n/C15Kappa coefﬁcient: (0.95–0.4533)/ (1–0.4533) = 0.673\nFor no-risk category:\n/C15Observed agreement: 0.98\n/C15Expected agreement: ((0.63002 ˆ) + (0.37002 ˆ)) = 0.3897\n/C15Kappa coefﬁcient: (0.98–0.3897)/ (1–0.3897) = 0.781\nTherefore, the Kappa coefﬁcient for the high-risk, moderate-risk,\nand no-risk categories are 0.645, 0.673, and 0.781, respectively that\nindicates a substantial agreement.\n3.3. Pre-processing and Feature Engineering\nData extracted through social media contains very noise. The\nestablished methods [32] like tokenisation, stop word removal,\nand lemmatization was applied to ﬁlter the data to use it for\nmachine learning. Moreover, the language of suicidal ideation lacks\nlexical and syntactic patterns. Therefore, there is a need for hand\nengineering to analyze a set of features. Feature engineering is pro-\nposed to differentiate between various levels of distress. Various\nfeatures that were used in our model are as under:\n/C15Statistical features : As per our analysis, the posts that users\ngenerate vary in length. Therefore, the length of a post is calcu-\nlated to use as a feature to train the machine learning model.\n/C15Term FrequencyInverse Document Frequency (TFIDF) : TFIDF\nis used to measure the importance of words in the whole cor-\npus. TFIDF is deﬁned below.\ntfidfðwÞ¼freqðwÞ/C3logN\njt2D:w2tjð1Þ\nWhere wrefers to the word feature, Nis the total number of\nposts, tis the document and Dis the document set.\n/C15Latent semantic indexing features : The features generated\nthrough TF-IDF had many inherent problems. As the dataset\ngrows, dimensionality increases. Moreover, the sparsity also\nincreases through the approach of the n-gram technique used\non the dataset. We used Singular Value Decomposition (SVD)\n[33] to generate features in ﬁve ranks of 50, 100, 150, 200,\nand 250 new features by ﬁnding the semantic relations between\nthe features generated through the TF-IDF scheme. Among the\nﬁve ranks, the most differentiating features were used.\n/C15Average Risk Similarity : Average risk similarity (ARS) is a fea-\nture that has been engineered for our multi-class classiﬁcation\nproblem on the basis of cosine similarity. The feature has been\nbuilt on a per-document basis. We used the following hypothe-\nsis to engineer the ARS feature.\n”On average, high-risk suicidal messages are going to have a higher\naverage cosine similarity with other high-risk messages than mod-erate and no-risk ones ”.\nCosine similarity measures the cosine of the angle between two\nvectors. The cosine measure is the metric whose range is\nbetween /C01 to 1. The smaller the angle between vectors, the\nmore similarity. When the angle between vectors is zero, the\nsimilarity becomes highest as (cos h= 1). Let aand bbe two fea-\nture vectors having the dimension of n. the feature vectors are\ndeﬁned as. a=fa1;a2;a3/C1/C1/C1angand b=fb1;b2;b3/C1/C1/C1bngThe\ncosine similarity between these vectors is deﬁned as:\nCS¼ða/C3bÞ\nðjaj/C3jbjð2Þ\nwhere,\na/C3b¼ða1/C3b1þa2/C3b2þ... ::þan/C3bnÞ¼Xn\ni¼iaibi\njaj¼Xn\ni¼ia2\ni\njbj¼Xn\ni¼ib2\ni\nCSis the Cosine Similarity and jajand jbjdeﬁne the magnitude of\ntwo feature vectors aand brespectively.\n/C15Topic Model Features : The suicidal and non-suicidal posts talk\nabout different themes. Moreover, the language of high risk,\nmoderate risk, and no risk posts also differ in their probabilities\nof expressing a particular topic. These themes/ topics if ana-\nlyzed can help in differentiating between these three categories.Latent Dirichlet Allocation (LDA) was used to identify 50 latent\ntopics from the corpus. The LDA function of the topic model\npackage with a parameter k was used to implement the LDA\nmodel. It was a challenge for us to select the optimal number\nof topics (k) that are very well segregated and can provide\nmeaningful information for classiﬁcation purposes. Thus, we\nselected k with different values and picked up the one that gave\nus the higher coherence value. The kvalue of ‘50’ marked the\nend of the rapid growth of the topic coherence. So, the 50 topics\nwere found to be optimal. Table 3 shows the topic coherence\nwhen kwas changed. Topic modelling assumes that mixtures\nof topics create a document. The topics generate various words\nbased on the probability distribution. Fig. 4 Shows the inter-\ntopic strength between those 50 generated topics. It is easy to\nobserve from the ﬁgure that the oval shaped ﬁgures refer to\nthe generated topics and the lines connecting the topics repre-\nsent the strength of the relationship between them. Thicker\nlines indicate a stronger relationship between topics, while\nTable 3\nNumber of Topics vs Coherence value\nNumber of Topics Coherence Value\n5 0.4581\n10 0.514315 0.548020 0.5722\n25 0.6099\n30 0.629835 0.749140 0.752045 0.769350 0.782855 0.783560 0.7843\n65 0.7848S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n296"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "thinner lines indicate a weaker relationship. The strength of the\nrelationship between topics is determined by the degree of\noverlap between the words that make up each topic. If two\ntopics share many common words, then they are likely to be\nstrongly connected, and the line between them will be thicker.\nOn the other hand, if two topics share few common words, then\nthey are likely to be weakly connected, and the line between\nthem will be thinner.\n3.4. Classiﬁcation\nSuicidal ideation Detection is treated as a multi-class machine\nlearning problem. The dataset we used to train our model consists\nof only two columns; the title of our text and the label. The prob-\nlem is in the same way as formulated by [18]. On a corpus consist-\ning of a set of posts/tweets fpign\niand labels flign\ni, training is\nprovided in such a manner that the model learns from the data\nconsisting of a set of all the engineered features and the corre-\nsponding labels that are provided in a supervised setting. The\nsupervisory function guides the model as under:\nli¼FunðpiÞð 3Þ\nli¼2 in case of pirepresenting the high risk of suicide. The value of\nli¼1 and 0 in case of pirepresenting the moderate risk and no risk\nof suicide respectively.We focused on the ’No Free Lunch’ theorem\nof machine learning that suggested that no algorithm can work well\nfor all problems. As a result, we tried top three well known machineand ensemble learning algorithms for text classiﬁcation [40,41] viz.\nSupport vector machine, Random forest and Extreme gradient\nboosting algorithm to train our multi-class classiﬁcation model.\nThe model is further validated through 5-cross validation tech-\nnique. The cross-validation approach reduces the bias and variance\nas the majority of the dataset is used for training the model, and\nmost of the data is also used for testing the model. The empirical\nevidence suggests that 10-fold cross-validation and 5-fold cross-validation is generally preferred, but it is not a thumb rule as k\ncan take any value.\nThe various metrics that were used to evaluate our classiﬁca-\ntion results are confusion matrix, Accuracy, Precision, Recall and\nF-Measure.\n/C15Confusion Matrix: The confusion matrix presents the four\nvalues i.e.True Positive (TP), Tru e Negative (TN), False Positive\n(FP), and False Negative (FN) in a matrix form. True positive is\na value, where the classiﬁcatio n model correctly predicts the\npositive class, while true negative is a value, where the classi-\nﬁer accurately predicts the nega tive class. The false positive is\nav a l u ew h e r et h ec l a s s i ﬁ e ri n c orrectly predicts the positive\nclass. Similarly, a false negative is a value where the classiﬁer\nincorrectly predicts the negati ve class. An ideal classiﬁer\nshould have more True positive and True negative values.\nThe perfect classiﬁer will have an off-diagonal value equal\nto zero, while all the values lie on the main diagonal, i.e.\n( F P=0 ,F N=0 ) .\nFig. 4. Strength of relation between various generated topics.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n297"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "/C15Accuracy: It is one of the common metrics used to evaluate the\nmachine learning classiﬁers. It measures the ratio of the total\nnumber of corrected predicted instances over the total number\nof predictions.\nAccuracy ¼TPþTN\nTPþTNþFPþFNð4Þ\nAccuracy is a good measure, but when the dataset is imbalanced,\naccuracy does not provide more information about the classi-\nﬁer’s performance.\n/C15Precision: It is a metric that determines the ratio of true posi-\ntives over the total predicted positives (TPR).\nPrecision ¼TP\nTPRð5Þ\n/C15Recall: It is a metric that determines the ratio of true posi-\ntives over total actual positives (TAP). Recall is preferred to\nselect the best model when the high cost is associated with\nfalse-negative, e.g. In disease prediction like in suicidal risk\nidentiﬁcation, the consequences can be very high if at-risk\nperson is misclassiﬁed.\nRecall ¼TP\nTAPð6Þ\n/C15F1-score: It is a metric that is used to measure the perfor-\nmance of the classiﬁer/model when that model needs a bal-\nance between Precision and Recall & also when the dataset is\nimbalanced, having a large number of actual negative values.\nUsually, for learning models, false positives and false nega-\ntives provide an important role. The F1 score tries to give\nmore weight to these values and contribute in minimizing\nthe impact of true negative values.\nF1/C0score ¼2/C3Precision /C3Recall\nPrecision þRecallð7Þ\nThe overall procedure that we used to detect level of suicidal\nideation in the social media posts is shown as a pseudocode\nnamed as Algorithm 1 Enhanced feature engineering approach\nfor suicidal risk identiﬁcation (EFASRI).\nAlgorithm1 : Enhanced Feature Engineering Approach for\nSuicidal Risk Identiﬁcation (EFASRI)\n1:Require: Filtered Posts (Tweets & Reddit) ðPin:csvÞ,\nClassiﬁer_Name, Classiﬁer_Hyperpar\n2:Ensure: No Risk (PNR), Moderate Risk (PMR) and High Risk\n(PHR)\n3:ST4733p33ART\n4:fori from 1 to n (Total Number of Posts) do\n5: C [i] = Pinput[i] $ Label//Adding labels\n6: Text.csv = c [i]//CSV ﬁle containing posts and corresponding\nlabels\n7:end for\n8: Pro = tokens (Text.csv)//Tokenization and other text\nstandardization’s\n9: Pro = tokens_tolower (Pro) // Lower casing\n10: Pro = tokens_remove (Pro)// Hand Engineered stop word\nremoval\n11: Pro = tokens_stem (Pro)// stemming\n12: Text2.csv = Pro// Processed ﬁle\n13: Processedcorpus = tm_map((tolower(Text), removewords\n(Text), remove_punctuation(Text), preserve_intra_word_d\nashes = true, removenumbers (Text). stemDocument(Text),\nstripwhitespace(Text))// processed corpus retained for\ntopic modelinga(continued )\nAlgorithm1 : Enhanced Feature Engineering Approach for\nSuicidal Risk Identiﬁcation (EFASRI)\n14:fori from 1 to n do\n15: P_length[i] = nchar (Text2[i])// length of Post\n16:end for\n17: Tokens = tokens_ngrams (Text2, n = 1:3)//ngram features\nup to 3 grams of whole dataset\n18: Tokens.dfm = dfm (Tokens)//make document feature\nmatrix\n19: dfm_trimmed = dfm_trim (Tokens.dfm, min_docfreq,\nmin_termfreq)// trimming the tokens having less\nimportance\n20: TFIDF_features = dfm_trimmed. Tﬁdf// Extracting TFIDF\nFeatures\n21: incomplete.cases <– which (! complete. cases\n(TFIDF_features))\n22: TFIDF_features [incomplete. cases,] <–rep (0.0, ncol\n(TFIDF_features))// replacing incomplete cases\n23: LSA_features = SVD (TFIDF_features, nv = 50,100,150,200\n250)// Most relevant features extracted by Dimensionality\nReduction using Singular value decomposition of LSA\n24: Train.similarities = cosine (LSA_Features)// Finding\nsimilarity of doc’s based on Cosine measure\n25:fori from 1 to n row do\n26: ARS [i] = mean (train. similarities [i, High Risk index)//\nFinding Average suicide similarity based on cosine measure\n27:end for\n28: topic_model_features <–LDA (processedcorpus.dtm,\nk = 50, method =”Gibbs)//topic modeling features on\npreprocessed document term matrix\n29: Optimal_Feature Set = LSA_features + P_length + ARS + t\nopic model features\n30: ClASSIFIER(Classiﬁer_Name, Classiﬁer_Hyperparameters,\nCV = 5,Optimal_Feature Set)// Training classiﬁer using our\nfeature engineering approach With hyperparameters tuned\nand 5 cross-validation technique\n31:END\n4. Results and Discussion\nTwitter and Reddit APIs were used to collect 19915 suicidal and\nnon-suicidal posts using different keywords and phrases used in\nprevious literature like [42,26] and also through various other\nterms deﬁned in our manual library that were collected in consul-\ntation with mental health experts. The data from two subreddits r/\ndepression and r/SuicideWatch were also extracted to get those\nposts that indicate the suicidal ideation and emotional state of\nthe potential suicidal users in more detail. After collecting a large\nenough dataset, we pre-processed the dataset to remove the\nredundancy and noise using various established methods [43].\nThereafter, the proposed feature engineering mechanism was used\nto extract the most relevant features for classifying suicidal tweets\ninto three classes of distress. The feature extraction mechanism\nconsists of TFIDF, Latent semantic features, length of the post, topic\nmodel features, and average risk similarity based on the cosine\nsimilarity measure. The initial experiments were conducted by\nsplitting the dataset into 80:20 and 70:30 because empirical\nresults [44] show the performance of algorithms increases on such\nsplitting. We found that the model’s performance increased\nslightly on increasing the training data. The technique of splitting\nthe dataset into training and testing folds suffer from inherentS.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n298"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "problem of bias and variance. In machine learning, it is not always\nthat the model that has ﬁt the training data will also work for the\nreal data. For that, we used the k-fold cross-validation technique to\nget assured that the model gets the correct patterns of the data and\nnot take too much noise. The model was validated through a 5-fold\ncross-validation mechanism. Python was selected to implement\nmachine learning algorithms. The various important packages used\nin coding are Skitlearn, pandas, and NLTK. We applied three well-\nknown machine and ensemble learning algorithms i.e., SVM, Ran-\ndom Forest, and XGB to train the suicide prediction model. The\nconﬁguration parameters of these machine-learning algorithms\nare highlighted in Table 4 . Among the three machine learning algo-\nrithms, XGB-EFASRI outperformed the other two algorithms with\nan overall accuracy of 0.9633.The main reason XGB-EFASRI per-\nformed better than SVM and Random Forest is because XGB han-dled both linear and nonlinear relationships between features. In\nsuicidal detection problem, there were complex relationships\nbetween the features and the target variable, which XGB captured\nbetter than SVM and Random Forest. Moreover, XGB uses gradient\nboosting, which involved training multiple models sequentially\nand combined their predictions. This helped reduce the variance\nof the model and improved its accuracy. The confusion metrics\ngenerated in our experimentation are shown in Fig. 5–7 . On Ana-\nlysing these ﬁgures, it can be seen that the rows represent the\nactual classes of the test data, while the columns represent the pre-\ndicted classes. The values in the cells of the confusion matrix indi-\ncate the number of instances that were classiﬁed as belonging to a\nparticular class. In our experimentation, confusion matrix gener-\nated has three rows and three columns, corresponding to three\nclasses of suicide risk: Label ‘0’, ‘1’, 2’ refers to the No Risk, Moder-\nate Risk, and High Risk, respectively. Fig. 5 depicts the confusion\nmatrix generated by applying SVM-EFASRI. Out of 1426 instances\nthat truly belong to the No Risk class, the model correctly predicted\n1275 and incorrectly predicted 41 as Moderate Risk and 110 as\nHigh Risk. Out of 1106 instances that truly belong to the Moderate\nRisk class, the model correctly predicted 905 and incorrectly pre-\ndicted 76 as No Risk and 125 as High Risk. Out of 1451 instances\nthat truly belong to the High-Risk class, the model correctly pre-\ndicted 1229 and incorrectly predicted 154 as No Risk and 68 as\nModerate Risk. Fig. 6 depicts the confusion matrix generated by\napplying RFEFASRI. Out of 1384 instances that truly belong to the\nNo Risk class, the model correctly predicted 1357 and incorrectly\npredicted 1 as Moderate Risk and 26 as High Risk. Out of 1157instances that truly belong to the Moderate Risk class, the model\ncorrectly predicted 1083 and incorrectly predicted 22 as No Risk\nand 52 as High risk. Out of 1442 instances that truly belong to\nthe HighRisk class, the model correctly predicted 1366 and incor-\nTable 4\nHyper-parameter tuning of various Machine Learning algorithms\nAlgorithm Conﬁguration Parameters\nSupport Vector\nMachine (SVM)C = 1.0, kernel=’poly’, shinking = True,\nprobability = True, coef0 = 0.0, degree = 3,decision_function_shape=’ovo’, max_iter=-1,Verbose = 10, cache-sixe = 200, class_wight = Nonetol = 0.0001, gamma=’auto deprecated’,random_state=’110’.\nRandom Forest (RF) n_estimators = 300, bootstrap = True, njobs = 6\nrandom_state = 42, verbose = True, oob score = False,\nCriterion=’entropy’, warm state = Falsemax_depth = 30, maximum_features=’sqrt’,minimum samples split = 5, class weight = None,minimum samples leaf = 1, minimum weight fractionleaf = 0.0, minimum impurity decrease = 0.0,maximum leaf nodes = None, minimum impuritysplit = None.\nExtreme boosting\nGradient (XGB)base_score = 0.5, ‘reg_alpha = 1.2’,\ncol_sample_bytree = 1, ‘reg_lambda = 1.3’booster=’gbtree’, n_jobs = 6, nestimators = 250,objective=’multi:softprob’, verbose = 1,validate = False, gamma = 0, subsample = 0.8.\nFig. 5. Confusion Matrix generated through SVM_EFASRI.\nFig. 6. Confusion Matrix generated through RF_EFASRI.\nFig. 7. Confusion Matrix generated through XGB_EFASRI.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n299"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "rectly predicted 55 as No Risk and 21 as Moderate Risk. Fig. 7\ndepicts the confusion matrix generated by applying XGBEFASRI.\nOut of 1373 instances that truly belong to the No Risk class, the\nmodel correctly predicted 1349 and incorrectly predicted 0 as\nModerate Risk and 24 as High Risk. Out of 1081 instances that truly\nbelong to the Moderate Risk class, the model correctly predicted\n1024 and incorrectly predicted 12 as No Risk and 45 as High risk.\nOut of 1529 instances that truly belong to the High-Risk class,\nthe model correctly predicted 1464 and incorrectly predicted 43\nas No Risk and 22 as Moderate Risk. The majority of the elements\nin the left diagonal of the confusion matrices indicates that the our\nmodel is performing well in predicting the correct class for most\ninstances. Table 5 shows the detailed comparison of the results\ngenerated through application of our proposed feature extraction.\nmechanism and implementation of various machine learning algo-rithms. We used the various standard metrics like Precision, Recall\nand F-measure to evaluate the performance of the machine learn-\ning algorithms using our proposed approach that provides the bet-\nter picture of the model’s performance. As our problem statement\nwas about the disease prediction where the high cost is associated\nwith the false negative values, the high recall indicates that the\nmodel is able to correctly identify a higher proportion of true pos-\nitive cases while minimizing false negatives. This is an important\noutcome in disease prediction, where correctly identifying positive\ncases is critical to ensure timely treatment and minimize negative\nconsequences.\nTable 6 shows the variation in performance accuracy of the\nXGB, the best performing algorithm on inclusion of different fea-\ntures sets. The First column depicts the combination of feature sets\nand last four columns reﬂects the accuracy in terms of variousevaluation metrics. It is observed that there is an increase in preci-\nsion, Recall and F measure when additional features are added and\nthus validates its use for increase in overall accuracy.\n5. Comparison with the previous research\nLimited research has been conducted on the classiﬁcation of\nsocial media data related to suicidal ideation. In this study, we\ncompared our proposed approach with the most recent and rele-\nvant studies [30,38] regarding the identiﬁcation of suicidal idea-\ntion. Our ﬁndings revealed that none of the previous studies\nachieved a level of accuracy comparable to our work. Furthermore,\nthe prior research employed simplistic feature extraction tech-\nniques. In contrast, our approach achieved higher precision, recall\nand overall accuracy due to the hybrid feature engineering\napproach for extracting the most relevant features. Table7 compar-\nison with the recent works.\n6. Conclusion\nIn light of the increased prevalence of Social Networking Sites\n(SNS) and the associated social stigma, individuals have become\nmore comfortable sharing their personal feelings on these plat-\nforms. In this article, we presented a text classiﬁcation approach\nfor detecting suicidal ideation on SNS, utilizing a hybrid feature\nengineering mechanism. The extracted features were then sup-\nplied to three machine learning algorithms, resulting in a maxi-\nmum achieved accuracy of 96.33%, demonstrating successful\nreplication of human accuracy. The high precision and recall values\nobtained using the proposed feature extraction approach indicate\nthat it could play a vital role in developing a reliable model with\nstable precision and recall. The ﬁndings of this research article offer\nvaluable insights for psychologists, psychiatrists, and patients,\nshedding light on the detection of suicidal ideation in a novel\nand effective manner. Some of the Future directions of the work\nare listed as under:\n1. Prediction models developed for binary classiﬁcation and multi-\nclass classiﬁcation can be deployed as a product that can gener-\nate the intervention messages. People can chat anonymously\nwith mental health experts/therapists without leaving their\nhomes and worrying about social stigma. When the user will\ngive feedback about how intervention messages helped them,\nit can be channelized to improve the model.\n2. The work can be extended to photos and videos related to sui-\ncidal ideation by including image and video processing.Table 5\nClassiﬁcation report of various algorithms based upon our proposed approach(EFASRI)\nClassiﬁer Metrics No Risk Moderate Risk High Risk\nSVM-EFASRI Accuracy 0.8558\nPrecision 0.8540 0.8905 0.8430Recall 0.8945 0.8243 0.8507F-measure 0.8702 0.8523 0.8205\nRF-EFASRI Accuracy 0.9555\nPrecision 0.9523 0.9820 0.9523Recall 0.9843 0.9432 0.9534\nF-measure 0.9638 0.9643 0.9535\nXGB-EFASRI Accuracy 0.9633\nPrecision 0.9621 0.9821 0.9523Recall 0.9834 0.9535 0.9635F-measure 0.9700 0.9623 0.9643\nTable 6\nVariation in performance accuracy of the XGB\nFeatures Precision Recall F- Measure Accuracy\nStatistical features (SF) +TFIDF 0.8850 0.8630 0.8730 0.8850\nSF + TFIDF + latent semantic indexing features 0.9013 0.9215 0.9330 0.9300\nSF + TFIDF_latent semantic indexing features + Average Risk Similarity (ARS) feature 0.9210 0.9315 0.9450 0.9415\nSF + TFIDF + latent semantic indexing features + Average Risk Similarity (ARS) feature + Topic model features 0.9523 0.9535 0.9643 0.9633\nTable 7\nComparison of our proposed work with the previous research\nStudy Features Used Accuracy Achieved\n[30] TFIDF, BOW 0.9292\n[38] Word2vec 0.9500\nProposed Work (XGBEFASRI) Statistical features, TFIDF, Latent Semantic\nIndexing features, Average risk similarity featuresbased upon cosine similarity and topic modelling features0.9633S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n300"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "3. Retrospective longitudinal analysis of those users needs to be\nanalyzed who died due to suicide that will help understand sui-\ncidal behavior in a better way and further improve the model.\n4. Questionnaires in consultation with mental health experts can\nbe used to extract the self-reported diagnosis (SRD) data that\nwill be supplied to the machine model to make it more\naccurate.\n5. The algorithm could be developed that can detect repeated\nname-calling and abuse directed at a particular user even\nthough the person does not complain about it or express his/\nher thoughts in implicit ways.\n6. Further ﬁne-grained classiﬁcation of suicidal at-risk individuals\nneeds to be performed on the basis of emotions like anger, dis-\ngust, etc. The classiﬁer detecting the same will help redirect the\ndifferent kinds of suicidal individuals to particular resources forintervention.\nDeclaration of Competing Interest\nThe authors declare that they have no known competing ﬁnan-\ncial interests or personal relationships that could have appeared\nto inﬂuence the work reported in this paper.\nReferences\n[1] Suicide, https://www.who.int/health-topics/suicide#tab=tab_1, (Accessed on\n09/11/2022).\n[2] J. Bilsen, Suicide and youth: Risk factors, https://www.frontiersin.org/articles/\n10.3389/fpsyt.2018.00540/full, (Accessed on 09/11/2022) (10 2018).\n[3] Värnik P. Suicide in the world. Int J Environ Res Public Health 2012;9\n(3):760–71. doi: https://doi.org/10.3390/ijerph9030760 . https://www.\nmdpi.com/1660-4601/9/3/760.\n[4] Keith Hawton KVH, The international handbook of suicide and attempted\nsuicide — wiley, https://www.wiley.com/en-in/The+International+Handbook\n+of+Suicide+and+Attempted+Suicide-p-9780470849590, (Accessed on 09/11/\n2022) (07 2002).\n[5] Risk factors, protective factors, and warning signs — afsp, https://afsp.org/risk-\nfactors-protective -factors-and- warning-signs/, (Accessed on 09/11/2022).\n[6] Shioiri T, Nishimura A, Akazawa K, Abe R, Nushida H, Ueno Y, Kojika-\nMaruyama M, Someya T. Incidence of note-leaving remains constant despite\nincreasing suicide rates. Psychiatry Clin Neurosci 2005;59(2):226–8. doi:\nhttps://doi.org/10.1111/j.1440-1819.2005.01364.x . arXiv:https://\nonlinelibrary.wiley.com/doi/pdf/10.1111/j.1440-1819.2005.01364.x.\n[7] Foster T. Suicide note themes and suicide prevention. Int J Psychiatry Med\n2003;33(4):323–31. doi: https://doi.org/10.2190/T210-E2V5-A5M0-QLJU .\npMID: 15152783. arXiv:https://doi.org/10.2190/T210-E2V5-A5M0-QLJU.\n[8] Wang N, Luo F, Shivtare Y, Badal VD, Subbalakshmi K, Chandramouli R, Lee E,\nLearning models for suicide prediction from social media posts, arXiv preprint\narXiv:2105.03315.\n[9]Aladag ˘AE, Muderrisoglu S, Akbas NB, Zahmacioglu O, Bingol HO. Detecting\nsuicidal ideation on forums: proof-of-concept study. J Med Internet Res\n2018;20(6):e9840 .\n[10] Fu K-W, Cheng Q, Wong PWC, Yip PSF. Responses to a self-presented suicide\nattempt in social media: A social network analysis. Crisis 2013. doi: https://\ndoi.org/10.1027/0227-5910/a000221 .\n[11] Jashinsky J, Burton SH, Hanson CL, West J, Giraud-Carrier C, Barnes MD, Argyle\nT. Tracking suicide risk factors through twitter in the us. Crisis 2014;35\n(1):51–9. doi: https://doi.org/10.1027/0227-5910/a000234 . pMID: 24121153.\narXiv:https://doi.org/10.1027/0227-5910/a000234.\n[12] Ahuja AK, Biesaga K, Sudak DM, Draper J, Womble A, Suicide on Facebook,\nJournal of Psychiatric Practice 20 (2). URL: https://journals.lww.com/practicalpsychiatry/Fulltext/2014/03000/Suicide_on_Facebook. 8.aspx.\n[13] O’Dea B, Larsen ME, Batterham PJ, Calear AL, Christensen H. A linguistic\nanalysis of suicide-related Twitter posts. Crisis 2017. doi: https://doi.org/\n10.1027/0227-5910/a000443 .\n[14] Khanday AMUD, Khan QR, Rabani ST. Identifying propaganda from online\nsocial networks during COVID-19 using machine learning techniques. Int J\nInform Technol 2021;13(1):115–22. doi: https://doi.org/10.1007/s41870-020-\n00550-5 .\n[15] Khanday AMUD, Rabani ST, Khan QR, Rouf N, Mohiud Din M, Machine learning\nbased approaches for detecting COVID-19 using clinical text data, Int J Inform\nTechnol. doi:10.1007/s41870-020-00495-9. URL: https://doi.org/10.1007/\ns41870-020-00495-9[16] Rabani ST, Khan QR, Khanday AMUD. Detection of suicidal ideation on twitter\nusing machine learning & ensemble approaches. Baghdad Sci J 2020;17\n(4):1328. doi: https://doi.org/10.21123/bsj.2020.17.4.1328 . URL: https://bsj.\nuobaghdad.edu.iq/index.php/BSJ/article/view/5245.\n[17] Choudhury MD, Kiciman E, The language of social support in social media and\nits effect on suicidal ideation risk, 2017. URL: https://www.aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15662/14792.\n[18] Ji S, Yu CP, Fung S-F, Pan S, Long G. Supervised Learning for Suicidal Ideation\nDetection in Online User Content. Complexity 2018;2018:6157249. doi:\nhttps://doi.org/10.1155/2018/6157249\n.\n[19] Sikander D, Arvaneh M, Amico F, Healy G, Ward T, Kearney D, Mohedano E,\nFagan J, Yek J, Smeaton AF, Brophy J. Predicting risk of suicide using resting\nstate heart rate. In: 2016 Asia-Paciﬁc Signal and Information Processing\nAssociation Annual Summit and Conference (APSIPA). p. 1–4. doi: https://doi.\norg/10.1109/APSIPA.2016.7820833 .\n[20] Moreno MA, Jelenchick LA, Egan KG, Cox E, Young H, Gannon KE, Becker T.\nFeeling bad on facebook: depression disclosures by college students on a social\nnetworking site. Depression Anxiety 2011;28(6):447–55. doi: https://doi.org/\n10.1002/da.20805 . arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/\nda.20805 URL: https://onlinelibrary.wiley.com/doi/abs/10.1002/da.20805.\n[21] Shen JH, Rudzicz F, Detecting anxiety through reddit. In: Proceedings of the\nFourth Workshop on Computational Linguistics and Clinical Psychology-From\nLinguistic Signal to Clinical Reality, 2017, pp. 58–65.\n[22] Cash SJ, Thelwall M, Peck SN, Ferrell JZ, Bridge JA. Adolescent suicide\nstatements on myspace. Cyberpsychology, Behavior, Social Networking\n2013;16(3):166–74. doi: https://doi.org/10.1089/cyber.2012.0098 . pMID:\n23374167. arXiv:https://doi.org/10.1089/cyber.2012.0098.\n[23] Harris KM, McLean JP, Shefﬁeld J. Suicidal and online: How do online behaviors\ninform us of this high-risk population? Death Studies 2014;38(6):387–94. doi:\nhttps://doi.org/10.1080/07481187.2013.768313 . pMID: 24666145. arXiv:\nhttps://doi.org/10.1080/07481187.2013.768313.\n[24] Homan S, Gabi M, Klee N, Bachmann S, Moser A-M, Michel S, Bertram A-M,\nMaatz A, Seiler G, Stark E, et al. Linguistic features of suicidal thoughts and\nbehaviors: A systematic review. Clinical Psychol Rev 2022;95:102161 .\n[25] Desmet B, Hoste V. Online suicide prevention through optimised textclassiﬁcation. Inf Sci 2018;439:61–78\n.\n[26] Chiang W-C, Cheng P-H, Su M-J, Chen H-S, Wu S-W, Lin J-K. Socio-health with\npersonal mental health records: suicidal-tendency observation system on\nfacebook for taiwanese adolescents and young adults. In: 2011 IEEE 13th\nInternational Conference on e-Health Networking, Applications andServices. IEEE; 2011. p. 46–51\n.\n[27] O’dea B, Wan S, Batterham PJ, Calear AL, Paris C, Christensen H. Detecting\nsuicidality on twitter. Internet Interventions 2015;2(2):183–8 .\n[28] De Choudhury M, Kiciman E, Dredze M, Coppersmith G, Kumar M, Discovering\nshifts to suicidal ideation from mental health content in social media. In:\nProceedings of the 2016 CHI conference on human factors in computing\nsystems, 2016, pp. 2098–2110.\n[29] Vioules MJ, Moulahi B, Azé J, Bringay S. Detection of suicide-related posts in\ntwitter data streams. IBM J Res Dev 2018;62(1). 7–1 .\n[30] Chadha A, Kaushik B. Performance evaluation of learning models for\nidentiﬁcation of suicidal thoughts. Computer J 2022;65(1):139–54 .\n[31] Abboute A, Boudjeriou Y, Entringer G, Azé J, Bringay S, Poncelet P, Mining\ntwitter for suicide prevention. In: Natural Language Processing and\nInformation Systems: 19th International Conference on Applications of\nNatural Language to Information Systems, NLDB 2014, Montpellier, France,\nJune 18–20, 2014. Proceedings 19, Springer, 2014, pp. 250–253.\n[32] Okhapkina E, Okhapkin V, Kazarin O. Adaptation of information retrieval\nmethods for identifying of destructive informational inﬂuence in social\nnetworks. In: 2017 31st International Conference on Advanced InformationNetworking and Applications Workshops (WAINA). IEEE; 2017. p. 87–92\n.\n[33] Cheng Q, Li TM, Kwok C-L, Zhu T, Yip PS. Assessing suicide risk and emotional\ndistress in chinese social media: a text mining and machine learning study. J\nMed Internet Res 2017;19(7):e243 .\n[34] Shing H-C, Nair S, Zirikly A, Friedenberg M, Daumé III H, Resnik P, Expert,\ncrowdsourced, and machine assessment of suicide risk via online postings. In:\nProceedings of the ﬁfth workshop on computational linguistics and clinical\npsychology: from keyboard to clinic, 2018, pp. 25–36.\n[35] Mbarek A, Jamoussi S, Charﬁ A, Hamadou AB. Suicidal proﬁles detection in\ntwitter. In: WEBIST. p. 289–96 .\n[36] Mbarek A, Jamoussi S, Hamadou AB. An across online social networks proﬁle\nbuilding approach: Application to suicidal ideation detection. FutureGeneration Computer Syst 2022;133:171–83\n.\n[37] Burnap P, Colombo G, Amery R, Hodorog A, Scourﬁeld J. Multi-class machine\nclassiﬁcation of suicide-related communication on twitter. Soc Netw Media\n2017;2:32–44 .\n[38] Chadha A, Kaushik B. A survey on prediction of suicidal ideation using machineand ensemble learning. Computer J 2021;64(11):1617–32\n.\n[39] Aldhyani TH, Alsubari SN, Alshebami AS, Alkahtani H, Ahmed ZA. Detecting\nand analyzing suicidal ideation on social media using deep learning and\nmachine learning models. Int J Environ Res Public Health 2022;19(19):12635 .\n[40] Kowsari K, Jafari meimandi K., Heidarysafa M, Mendu S, Barnes L, Brown D,\nText Classiﬁcation Algorithms: A Survey. Information 10 (4).S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n301"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "[41] Gasparetto A, Marcuzzo M, Zangari A, Albarelli A. A survey on text\nclassiﬁcation algorithms: From text to predictions. Information 2022;13(2):83 .\n[42] Huang X, Zhang L, Chiu D, Liu T, Li X, Zhu T. Detecting suicidal ideation in\nchinese microblogs with psychological lexicons,. In: 2014 IEEE 11th Intl Conf\non Ubiquitous Intelligence and Computing and 2014 IEEE 11th Intl Conf on\nAutonomic and Trusted Computing and 2014 IEEE 14th Intl Conf on ScalableComputing and Communications and Its Associated Workshops. IEEE; 2014. p.\n844–9\n.[43] Anand N, Goyal D, Kumar T, Analyzing and preprocessing the twitter data for\nopinion mining. In: Proceedings of International Conference on Recent\nAdvancement on Computer and Communication, Springer, 2018, pp. 213–221.\n[44] Gholamy A, Kreinovich V, Kosheleva O, Why 70/30 or 80/20 relation between\ntraining and testing sets: a pedagogical explanation.S.T. Rabani, A.M. Ud Din Khanday, Q.R. Khan et al. Egyptian Informatics Journal 24 (2023) 291–302\n302"
    }
  ]
}