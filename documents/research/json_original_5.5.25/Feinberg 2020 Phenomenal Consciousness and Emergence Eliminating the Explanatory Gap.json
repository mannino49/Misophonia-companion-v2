{
  "doc_type": "scientific paper",
  "title": "Phenomenal Consciousness and Emergence Eliminating the Explanatory Gap",
  "authors": [
    "Feinberg"
  ],
  "year": 2020,
  "journal": "journal",
  "doi": "10.3389/fpsyg.2020.01041",
  "abstract": null,
  "keywords": [
    "animal consciousness",
    "explanatory gap",
    "evolution",
    "complex systems",
    "physicalism",
    "neurobiology",
    "weak"
  ],
  "research_topics": [
    "animal consciousness",
    "explanatory gap",
    "evolution",
    "complex systems",
    "physicalism",
    "neurobiology",
    "weak"
  ],
  "created_at": "2025-05-05T03:23:17.484034Z",
  "source_pdf": "documents/research/Global/Feinberg 2020 Phenomenal Consciousness and Emergence Eliminating the Explanatory Gap.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 1\nHYPOTHESIS AND THEORY\npublished: 12 June 2020\ndoi: 10.3389/fpsyg.2020.01041\nEdited by:\nMarjan Persuh,\nBorough of Manhattan Community\nCollege, United States\nReviewed by:\nKarl Friston,\nUniversity College London,\nUnited Kingdom\nPeter Beim Graben,\nBrandenburg University of Technology\nCottbus–Senftenberg, Germany\n*Correspondence:\nTodd E. Feinberg\ntodd.feinberg@mountsinai.org\nJon Mallatt\nmallatt@wsu.edu\nSpecialty section:\nThis article was submitted to\nConsciousness Research,\na section of the journal\nFrontiers in Psychology\nReceived: 21 February 2020\nAccepted: 27 April 2020\nPublished: 12 June 2020\nCitation:\nFeinberg TE and Mallatt J (2020)\nPhenomenal Consciousness\nand Emergence: Eliminating\nthe Explanatory Gap.\nFront. Psychol. 11:1041.\ndoi: 10.3389/fpsyg.2020.01041\nPhenomenal Consciousness and\nEmergence: Eliminating the\nExplanatory Gap\nTodd E. Feinberg1*and Jon Mallatt2*\n1Icahn School of Medicine at Mount Sinai, Psychiatry and Neurology, New York, NY, United States,2The University\nof Washington, WWAMI Medical Education Program, The University of Idaho, Moscow, ID, United States\nThe role of emergence in the creation of consciousness has been debated for over a\ncentury, but it remains unresolved. In particular there is controversy over the claim that a\n“strong” or radical form of emergence is required to explain phenomenal consciousness.\nIn this paper we use some ideas of complex system theory to trace the emergent\nfeatures of life and then of complex brains through three progressive stages or levels:\nLevel 1 (life), Level 2 (nervous systems) , and Level 3 (special neurobiological features) ,\neach representing increasing biological and neurobiological complexity and ultimately\nleading to the emergence of phenomenal consciousness, all in physical systems. Along\nthe way we show that consciousness ﬁts the criteria of an emergent property—albeit\none with extreme complexity. The formulation Life + Special neurobiological features\n!Phenomenal consciousness expresses these relationships. Then we consider the\nimplications of our ﬁndings for some of the philosophical conundrums entailed by the\napparent “explanatory gap” between the brain and phenomenal consciousness. We\nconclude that consciousness stems from the personal life of an organism with the\naddition of a complex nervous system that is ideally suited to maximize emergent\nneurobiological features and that it is an example of standard (“weak”) emergence\nwithout a scientiﬁc explanatory gap. An “experiential” or epistemic gap remains,\nalthough this is ontologically untroubling.\nKeywords: animal consciousness, explanatory gap, evolution, complex systems, physicalism, neurobiology, weak\nemergence, multiple realizability\nINTRODUCTION\nDespite some of life’s unique features (Mayr, 2004) all basic life processes remain in principle\nexplainable within the constraints of normal physics and chemistry. However, while the scientiﬁc\nbasis of life is no longer a philosophical or scientiﬁc mystery, in the case of consciousness—more\nspeciﬁcally in the case of subjective experience (phenomenal consciousness, primary consciousness,\nraw “feelings” or irreducible “qualia”) – there appears to be what philosopher Levine (1983) called\nan “explanatory gap” between the subjective experiences and the physical brain:\nFrontiers in Psychology | www.frontiersin.org 1 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 2\nFeinberg and Mallatt Consciousness and Emergence\nHowever, there is more to our concept of pain than its causal\nrole, there is its qualitative character, how it feels; and what is left\nunexplained by the discovery of C-ﬁber ﬁring is why pain should\nfeel the way it does ! For there appears to be nothing about C-ﬁber\nﬁring which makes it naturally “ﬁt” the phenomenal properties of\npain, any more than it would ﬁt some other set of phenomenal\nproperties. The identiﬁcation of the qualitative side of pain with\nC-ﬁber ﬁring (or some property of C-ﬁber ﬁring) leaves the\nconnection between it and what we identify it with completely\nmysterious. One might say, it makes the way pain feels into merely\nbrute fact (Levine, 1983, p. 357).\nIn this paper, we discuss the critical role emergence plays\nin creating phenomenal consciousness and how this role helps\nexplain what appears to be a scientiﬁc explanatory gap between\nthe subjective experience and the brain, but which is actually not\na scientiﬁc gap at all.\nNote that we only consider basic, phenomenal consciousness\n(having any experience at all), not any higher types like reﬂective\nconsciousness, self-consciousness, or higher-order cognition\n(Nagel, 1974, 1986; Block, 1995; Chalmers, 1995, 1996; Metzinger,\n2003; Revonsuo, 2010; Churchland, 2013; Carruthers, 2016).\nWHAT IS EMERGENCE?\nGeneral Features\nAmong the aforementioned features of life that Mayr (1982,\n2004) discussed, the feature of emergence stands out as especially\nimportant for analyzing the creation of consciousness and\nthe explanatory gap within a scientiﬁc framework. Emergence\noccurs when novel entities and functions appear in a system\nthrough self-organization. Our focus is on emergence in\nevolving complex systems as revealed by systems theory\n(Salthe, 1985; Morowitz, 2002; Ellis, 2006). We especially\ncover biology and neurobiology, although emergence can also\napply to physical systems, mathematical and informational\nsystems, philosophy, developmental psychology, and many other\ndisciplines. For example, see the center manifold theorum\nof Carr (1981), the synergetics ﬁeld of Haken (1983) and\nTschacher and Haken (2007), the philosophical treatnents of\nBedau and Humphreys (2008), the human-development focus\nof Beckermann et al. (2011) and Witherington (2011), and\nthe general treatments by Simon (1973), Clayton (2006) and\nClayton and Davies (2006).\nModern formulations of emergence stem from eﬀorts to\nunderstand the nature of lifein the early part of the twentieth\ncentury, when it was realized that both the then-dominant\nhypotheses were scientiﬁcally inadequate: namely, vitalism (a\nmysterious life force) and reductionism (life can be explained\nmechanically as the mere sum of its parts) (Davies, 2006). With\nthe concept of emergence, scientists could relinquish the idea\nof vital forces and also deny that life properties can be fully\nreduced to the mechanics of their parts. Instead they embraced a\nlayered picture of nature consisting of ascending and interacting\nlevels of increasing organizational complexity ( Figure 1 ), with\neach higher level depending in part upon, but inexplicable in\nterms of, the properties of lower levels alone [adapted from\nFIGURE 1 | Emergence through a hierarchy in a complex system. Lower\nlevels combine to make the higher levels. New features emerge (E) in the\nsystem as more levels are added. The many connections are reciprocal, as\nshown by the back-and-forth arrows, both between and within levels. Also\nseeTable 1 . Figure © Mount Sinai School of Medicine.\nWitherington (2011), after Broad (1925)]. Emergentism gained\ntraction later in the century when complexity theory and\ndetailed computer simulations generated many emergent features\n(Clayton and Davies, 2006).\nHere in this “What Is Emergence?” section we summarize the\ngeneral features of emergence in complex systems ( Figure 1 ).\nThen in the next section, “A Model for the Emergence of\nConsciousness, ” we will analyze how these general features\ncontribute to the emergence of consciousness.\nThe following six features are often recognized as present in\nall emergent phenomena ( Table 1 ).\nFeatures 1 and 2\nEmergence occurs in complex systems in which novel properties\nemerge through the aggregate functions of the parts of that\nsystem. In the less complex of the complex systems, subatomic\nparticles aggregate into atoms, which form molecules, etc.\nfrom which emerge all the nonliving chemical and geological\nprocesses. Favorite examples of such systems are the gravitational\ninteractions among the heavenly bodies of the solar system, the\nturbulent ﬂow of water, and weather systems (Morowitz, 2002;\nNunez, 2016). Although we focus on complex living systems,\nFrontiers in Psychology | www.frontiersin.org 2 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 3\nFeinberg and Mallatt Consciousness and Emergence\nTABLE 1 | Major features of emergence in general.\n1. Emergence is a property of complex systems , with many interacting parts\na. The interactions are processes , so processes are important (not just the physical parts)\n2.Aggregate system functions that are not present in the parts alone\na. Whole is more than the simple sum of the parts; is not reducible to its individual parts\n3.Hierarchical arrangement of different levels\na. Novel properties emerge in the system as higher levels are added\nb. Emergent properties are novel properties\nc. More novelty emerges if the system elaborates or evolves further\nd. If the hierarchical system elaborates, there is more specialization of its parts and levels, both structurally and functionally\n4.Reciprocal connections exist among structures within and between levels of the neural hierarchy\na.Circular causality : Lower levels bring about the higher levels, which then inﬂuence the lower levels (Salthe, 1985: Rothschild, 2006; Bedau, 2008; Nunez, 2016;\nKoch, 2019); and structures within the same level also inﬂuence each other via extensive reciprocal connectivity\n5.Constraints :\na. The whole—and the emergent features of the system—constrain what the parts can do or be, and vice versa\nb. External environment also constrains the whole and parts\nc. Increasing a system’s complexity (more emergence) involves pruning the possibilities (Morowitz, 2002) to only those that let the system persist\n6. There are multiple routes to an emergent end-phenomenon, from different sets of lower-level features (Bedau, 2008, pp. 181–182; Koch, 2019, pp. 122–124)\nthese “simpler” systems ﬁt the criteria for emergence and should\nnot be forgotten.\nA theoretical consequence for aggregate system functions is\nthat the novel emergent functions cannot be explained by the\nparts alone , but rather must be explained by the properties of\nthe parts and their interactions (Pattee, 1970; Allen and Starr,\n1982; Salthe, 1985; Ahl et al., 1996; Bedau, 1997, 2008; Mayr,\n2004; Clayton and Davies, 2006; Bedau and Humphreys, 2008;\nBeckermann et al., 2011).\nFeatures 3 and 4\nHierarchical arrangements are particularly important in emergent\nsystems because they allow reciprocal connections between levels\nwhere each higher or additional level gives the system novel\nemergent properties that are based on that level’s unique features\nas well as its interactions with the pre-existing (lower) levels on\nwhich it is built (Pattee, 1970; Allen and Starr, 1982; Mayr, 1982;\nSalthe, 1985; Ahl et al., 1996). For example, for our body to stay\nalive (highest level), our heart, its pumping muscle cells, and the\nenergy-producing mitochondria in these cells (lower levels) must\nall interact reciprocally for the blood to be pumped.\nThis feedback entails circular causality between the levels\nof the system (Nunez, 2016; also see Haken, 1983). That is,\nemergence not only involves bottom-up causation by which the\nparts at the lower levels interact to cause novel (emergent)\nfeatures at the higher levels, but it also involves top-down\ncausation wherein the higher levels inﬂuence (constrain) the\nlower levels by making the lower levels subserve the whole\nsystem. For example, in a multicellular animal or plant, the\norgan and tissue components cannot act in ways that cause the\norganism to disassemble into its cells.\nCircular causality is nicely incorporated in the Contextual\nEmergence Theory (Atmanspacher and beim Graben, 2009;\nAtmanspacher, 2012, 2015) and the Biological Relativity Theory\n(Noble et al., 2019). Both these theories emphasize top-down\nmore than bottom-up causation, which is helpful for balance\nbecause it corrects past overemphases on the bottom-up causes inemergence (Witherington, 2011). Contextual emergence theory\n(CE), which is a scheme for describing a system’s relationships\nby comparing its higher and lower levels, oﬀers additional\ninsights. For example, CE shows that reductionist physicalism\nfails to explain nonlinear physical systems because their higher-\nlevel conditions (the “contingent context”) inﬂuence or stabilize\nor constrain the system’s lower-level mechanics, so the latter\nalone cannot explain the emergent properties (Bishop and\nAtmanspacher, 2006; beim Graben, 2014).\nFeature 5\nEmergence goes hand in hand with constraint. The system\nrequirements themselves constrain what the parts can do:\na living body cannot survive, for example, if some of its\ncells deprive others of vital resources (e.g. as occurs with a\ncancer) just as the external environment (e.g. extreme heat,\ncold, and aridity etc.) imposes constraints upon anything living\nunder such conditions. And increasing a system’s complexity\n(meaning new levels and features emerge) involves pruning the\npossibilities to only those that let the system persist (Morowitz,\n2002). As an example of this pruning, animals move and\nthey evolved fast, Na+-based action potentials that signal\nneuromuscular-based mobility, whereas land plants are sessile\nautotrophs with rigid cell walls that prevent anything like\nneuronal branching or the extensive cell-to-cell communication\nof neural networks (Taiz et al., 2020). Therefore, even though\nland plants have evolved into enormously complex organisms\nthey cannot use neuromuscular signaling like animals can.\nStated in our terms, that option has been “pruned from”\nthe plant lineage.\nFeature 6\nFinally, an end phenomenon may emerge through multiple,\nalternate routes . Two examples of this are traﬃc jams that can\nstem either from road construction or bad weather or a glut of\nvehicles (Bedau, 2008); and water waves that can stem from wind\nor an earthquake or a rock thrown into the water.\nFrontiers in Psychology | www.frontiersin.org 3 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 4\nFeinberg and Mallatt Consciousness and Emergence\nBedau (2008, p. 181) called this alternate-routes feature\n“macro explanatory autonomy, ” and it is akin to the\npsychological concept of multiple realizability (which says a\ngiven mind state can have diﬀerent causes: Bickle, 2019). It\nalso matches the biological concept of convergent evolution of\nsimilar traits in diﬀerent clades of organisms (Stayton, 2015;\nNatarajan et al., 2016).\nAnother argument that multiple routes/multiple realizability\nis a feature of all complex systems comes from the above-\nmentioned contextual emergence theory. The argument is that\nthe component parts of one system (“individual states, L i”) are\nallowed to diﬀer in some ways from those in a second system that\nhas the same emergent function (same “ensemble property, ” such\nas consciousness), as long as the diﬀering parts also share the key\nsimilarities that contribute to the emergent function (i.e. when the\ntwo sets of parts “are indistinguishable with respect to a particular\nensemble property:” Atmanspacher, 2015: p. 360).\nWeak Versus Strong Emergence and\nConsciousness\nThe view that consciousness is an emergent process is not\nnew (Lewes, 1877; Broad, 1925; Feigl, 1958; Popper and Eccles,\n1977; Sperry, 1990; Searle, 1992; Scott, 1995; Bedau, 1997, 2008;\nKim, 1998, 2006; Andersen et al., 2000; Feinberg, 2001, 2012;\nVan Gulick, 2001; Chalmers, 2006; Clayton and Davies, 2006;\nThompson, 2007; Bedau and Humphreys, 2008; Beckermann\net al., 2011; Deacon, 2011; Nunez, 2016; Mallatt and Feinberg,\n2017). The important question for the nature of consciousness\nis:what sort of emergence are we talking about? And what are its\nimplications for the explanatory gap?\nWhile opinions vary on the relationship between emergence\nand consciousness, there are two main opposing schools of\nthought. One says that the operations of standard, scientiﬁc\nemergence that we have outlined ( Table 1 ) can fully explain\nthe emergence of consciousness. This is often described as\nthe “weak emergence” theory (Bedau, 1997, 2008) or what\nSearle called emergence1 (Searle, 1992; Feinberg, 2001, 2012;\nFeinberg and Mallatt, 2016a). In this view, consciousness\nis or will be in the future fully understandable as an\nemergent property of micro-level brain process and the causal\nrelations between them.\nThe other position is called strong emergence (Bedau,\n1997, 2008; Chalmers, 2006; Clayton, 2006; Revonsuo,\n2010) or emergence2 (Searle, 1992) or radical emergence\n(Feinberg, 2001; Van Gulick, 2001). It claims that no\nknown properties of neurons could ever scientiﬁcally\nreconcile the diﬀerences between subjective experience\nand the brain; i.e. that the explanatory gap can never\nbe closed. Antti Revonsuo nicely summarizes this\nposition:\nSupporters of strong emergent materialism point to the\nfundamental diﬀerences between the subjective psychological\nreality and the objective physical (or neural) reality. The former\nincludes qualitative experiences that feel like something and exist\nonly from the ﬁrst-person point of view; the latter consists of\nphysical entities and causal mechanisms that involve nothing\nFIGURE 2 | Organisms at the three emergent levels in the evolution of\nconsciousness. Below, the colony of one-celled choanoﬂagellates shows how\nmulticellular animals may have originated. Figure © Mount Sinai School of\nMedicine.\nsubjective or qualitative about them and exist from the third-\nperson point of view or objectively. Nothing we can think about\nor imagine could make an objective physical process turn into or\n“secrete” subjective, qualitative “feels.” It is like trying to squeeze\nwine out of pure water: it is just not there, and there can be\nno natural mechanism (short of magic) that could ever turn the\nformer into the latter (Revonsuo, 2010, p. 30).\nNext, we will explore the central role that emergence plays\nin the creation of consciousness. We then derive a “weak” or\nstandard model and argue that the emergence of consciousness\nis simply a matter of the degree of standard emergence, not a\ndiﬀerent kind of emergence. Finally we analyze how and why the\nrole of emergence in the creation of consciousness contributes to\ntheappearance of a scientiﬁc explanatory gap that does not exist,\nbut also that there is an experiential distinction or “gap” between\nﬁrst-person and third-person points of view.\nA MODEL FOR THE EMERGENCE OF\nCONSCIOUSNESS\nOur model for the natural emergence of consciousness (Feinberg\nand Mallatt, 2013, 2016a,b, 2018a, 2019) has three levels.\nThese are Level 1 (life), Level 2 (nervous systems) , and\nLevel 3 (special neurobiological features of consciousness) that\nFrontiers in Psychology | www.frontiersin.org 4 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 5\nFeinberg and Mallatt Consciousness and Emergence\nTABLE 2 | Three emergent levels in the evolution of consciousness, and the new features at each level (adapted from Feinberg and Mallatt, 2019).\nLevel 1. Life\nA. Simplest system that has life is the cell, with bacteria and archaea being the simplest cells\nB. First appearance: \u00183.7 billion years ago\nC. Emergent structures: macromolecules (proteins, nucleic acids, sugars, lipids), organelles, cells\nD. Emergent processes:\n\u000fThe strong boundary condition of embodiment : semipermeable membrane encloses cell contents to concentrate the chemical reactions and keep the reaction\nproducts from diffusing away (Morowitz, 2002)\n\u000fInformation-based organization, directed by DNA/genes, and coded to specify the chemical reactions; the gene-coded “purpose” of Mayr (2004)\n\u000fMetabolism, to convert food to energy (ATP) and make new cellular materials; efﬁcient use of energy and of vital molecules slows entropy (energy waste lost as heat)\n\u000fSelf-upkeep and goal-directed properties (Mayr, 2004; Godfrey-Smith, 2019)\n\u000fGrowth and self-replication/reproduction\n\u000fSensitivity and movement\n\u000fHomeostasis: maintaining a constant internal environment in response to changes in the external environment\n\u000fAdaptation to the environment\n\u000fEvolution; natural selection becomes the pruning process that limits the possibilites of evolutionary change and of what features emerge in the system from this\nlevel onward (Morowitz, 2002)\nE. Adaptive advantage of this emergence: world’s ﬁrst self-perpetuation of complex systems over time\nLevel 2. Nervous systems, From Reﬂexes Through the Level of Simple, Core Brains (Not Conscious)\nA. Organisms possessing it: most invertebrate animals; for example, most worms\nB. First appearance: \u0018580 million years ago\nC. Emergent structures: multicellular animal body with different cell types including neurons, neural reﬂex arcs, sensory receptors, motor effectors (muscles, glands);\nnerve nets, then a consolidation into central and peripheral nervous system; some of the animals have a simple brain with movement-patterning circuits; the sensory\nreceptors are mechano-, chemo- and photoreceptor cells\nD. Emergent processes:\n\u000fSpeed: neurons transmit signals fast enough to control the actions of a large, multicellular body in response to sensory stimuli\n\u000fConnectivity: reﬂex arcs and neuron networks coordinate all the parts of a large body\n\u000fCore-brain processes:\n\u000eControl complex reﬂexes for inner-body homeostasis\n\u000eBasic motor programs and central pattern generators for rhythmic locomotion, feeding, and other stereotyped movements\n\u000eSet the level of arousal\nE. Adaptive advantages of this emergence: Sustains a large body that can move far through the environment, following sensory stimuli to ﬁnd food, safety, and mates\nLevel 3. Consciousness\nA. Organisms possessing it: vertebrates, arthropods, cephalopod molluscs\nB. First appearance: 560–520 million years ago\nC and D. Emergent structures and processes: the special neurobiological features of consciousness:\n\u000fNeural complexity (more than exists in a simple, core brain)\n\u000eBrain with many neurons ( >100,000?)\n\u000eMany subtypes of neurons\n\u000fElaborated sensory organs\n\u000eImage-forming eyes, receptor organs for touch, hearing, smell\n\u000fNeural hierarchies with neuron-neuron interactions\n\u000eExtensive reciprocal communication in and between the pathways for the different senses\n\u000eBrain has many neural computing modules and networks that are distributed but integrated (separate but highly interconnected), leading to local functional\nspecialization plus global coherence (Nunez, 2016; Mogensen and Overgaard, 2017) (see Figure 3 )\n\u000eSynchronized communication by brain-wave oscillations; neural spike trains form representational codes\n\u000eThe higher levels allow the complex processing and unity of consciousness\n\u000eHigher brain levels exert more inﬂuence on the lower levels such as motor neurons, for increased top-down causality\n\u000eHierarchies that let consciousness model events a fraction of a second in advance (Clark, 2013; Gershman et al., 2015; Jylkkä and Railo, 2019; Solms, 2019)\n\u000fPathways that create mapped mental images or affective states\n\u000eNeurons are arranged in topographic sensory maps of the outside world and body structures\n\u000eValence coding of good and bad, for affective states\n\u000eFeed into premotor brain regions to motivate, choose, and guide movements in space\n\u000fBrain mechanisms for selective attention and arousal\n\u000fMemory, short-term or longer\n(Continued)\nFrontiers in Psychology | www.frontiersin.org 5 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 6\nFeinberg and Mallatt Consciousness and Emergence\nTABLE 2 | Continued\nE. Adaptive advantages of this emergence:\n\u000fConsciousness organizes large amounts of sensory information into a detailed, uniﬁed simulation of the world, so the subject can choose the best behavioral\nresponses\n\u000eThis is a large, effective, expansion of the basic life-property of sensing the environment and responding\n\u000fWith mental maps, one can navigate through space even when no sensory stimuli for guidance are present\n\u000fConsciousness ranks all the sensed stimuli by importance, by assigning affects to them (good, bad), thereby simplifying decisions on how to respond\n(Cabanac, 1996)\n\u000fConsciousness provides behavioral ﬂexibility: adjusts fast to new stimuli so it deals well with the changing challenges of new environments\nFIGURE 3 | Some special neurobiological features of conscious systems,\nshown by the human brain and nervous system. These features include\nelaborate sensory organs (e.g. eye), neural hierarchical levels from the spinal\ncord upward, extensive reciprocal communication between neural processing\ncenters (the rectangular boxes and the connecting arrows), and processing\ncenters for image-based versus affective consciousness (green versus purple\nboxes). For more, see Table 2 ,Level 3 .(A)Consciousness relies on\nprocessing centers that are widely distributed but integrated. While neural\nprocessing goes on within the centers, communication also occurs among\nthe centers, leading to both local functional specialization and global\ncoherence. (B)Schematic drawing showing processing within a center. The\ncenter has subcenters for subprocessing operations that are subsequently\nintegrated to produce the center’s outputs. Abbreviations in (A)are CPGs:\ncentral pattern generators for various stereotyped movements; L Hab: lateral\nhabenula; Median raphe r.: median raphe region of the reticular formation; N\nAcc: nucleus accumbens; PAG: periaqueductal gray; Sup coll: superior\ncolliculus (optic tectum) of midbrain; VTA: ventral tegmental area of the\nmidbrain. Figure © Mount Sinai School of Medicine.\nevolved in sequence and represent increasing biological and\nneurobiological complexity ( Table 2 ). Each level displays novel\nemergent features, plus the features that emerged in the levels\nbelow it, plus the general features of all complex systems.Figure 2 shows some organisms at each level in the progression\nto consciousness, and Figure 3 shows some of the special\nfeatures of consciousness at Level 3. We will now cover\nTable 2 step by step.\nLevel 1. General Life Functions\nLiving systems are replete with examples of emergent system\nfeatures (Mayr, 1982, 2004; Salthe, 1985; Morowitz, 2002;\nRothschild, 2006; Van Kranendonk et al., 2017). Even the simplest\none-celled life involves chemical reactions far more complex than\nin any known nonliving system, and fossils indicate that life on\nEarth has been around for a long time – arising in seas, springs\nor ponds at least 3.7 billion years ago. From simple organic\nmolecules must have arisen a boundary membrane, providing\nembodiment to form a protocell. This boundary enclosed and\ncontained the molecules that used energy for vital processes\n(the catalytic and substrate molecules for metabolism ) plus the\ninformation molecules RNA and DNA that instructed these\nprocesses and allowed the protocells to sustain and reproduce\nthemselves (England, 2013). Only those protocells that sustained\nthemselves long enough and reproduced often enough avoided\nthe destructive vicissitudes of the external environment. This\nled to a competition for survival that favored those cells that\nmost eﬃciently maintained their internal chemistry ( homeostasis\nbased on cooperating subcellular systems) and also were best\nadapted to the external environment. This was the ﬁrst organic\nevolution by natural selection and it has driven life’s adaptations\nover billions of years, including the emergence of increased\ncomplexity in higher organisms. Natural selection also limited\n(constrained) the directions that living organisms could take,\nto those changes that are compatible with organic-based and\nwater-based life.\nFrom this, we reiterate that life itself is an emergent process\ncreated by the constituent parts of the organism. So for instance\nthe life of a single cell is an aggregate emergent feature of the\natoms, molecules, proteins, membranes, ribosomes, etc. of which\nit is composed and their interactions.\nEvolution proceeded over billions of years in one-celled\norganisms. Then more complexity emerged in some marine\ncells about 1.5 billion years ago when one type (perhaps\nakin to today’s microbes called archaea) engulfed a species\nof bacterium that was especially eﬃcient at extracting energy\nfrom nutrients, so those bacteria became the energy-producing\nmitochondria within a new, larger, symbiotic system called\nthe eukaryotic cell. Some eukaryote cells joined into large,\nmulticellular groups – likely because larger organisms are\nFrontiers in Psychology | www.frontiersin.org 6 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 7\nFeinberg and Mallatt Consciousness and Emergence\nharder for predators to kill and eat—that evolved into the\nﬁrst animals 700 or 600 million years ago. These ﬁrst animals\nmay have resembled immotile sponges, but the ability to\nmove followed because movement oﬀered great advantages for\nreaching the best places in the environment for food, mates,\nand safety. All this led to selection for a specialization of cells\nwithin the multicellular body, for a division of labor, into\nmuscle cells, gut-digestive cells, sex cells – and nerve cells to\ncoordinate the activities of the muscle and all the other cell\ntypes . For accounts of this evolutionary sequence of emergent\nfeatures, see Lane and Martin (2010), Feinberg and Mallatt\n(2016a), Brunet et al. (2019), Brunk and Martin (2019), and\nWatson (2019).\nLevel 2. Nervous Systems, Reﬂexes,\nCore Brains\nJudging from modern cnidarians (jellyﬁsh and their kin:\nFigure 2 ) and some simple marine worms, the ﬁrst nervous\nsystems were nerve networks distributed over the body,\nwithout any central or brain-like structures. The neurons\ncommunicated quickly (nerve ﬁbers carry their signals at\n0.5 to 100 m per second) and tightly (with synapses), to\nproduce fast reﬂexes and eﬀective movements. Thus, the\nwhole body participated in receiving sensory stimuli and\nin the resulting motor reactions. The animals at this stage\nhad sensory mechanoreceptor cells for touch stimuli, basic\nchemoreceptor cells for tastes and scents, and photoreceptor\ncells for light intensity (but no visual images in this eye-\nless stage).\nThen around 580 to 520 million years ago the worm\nancestors gave rise to many groups of animals, including\nmost of the invertebrate groups and the vertebrates. In\nmany of these descendant lineages, parts of the nerve net\ncondensed and enlarged for information processing, most\nso in the head region that received sensory information\nﬁrst as the animal moved forward through its environment;\nand from these neural enlargements there extended nerve\ncords that carried motor commands along the body\naxis. These were the ﬁrst brain and nerve cord of an\nincipient central nervous system. Many living invertebrates\nreﬂect this incipient stage (e.g. roundworms, earthworms,\nﬂatworms, sea slugs, and the ﬁsh-like cousin of vertebrates\ncalled amphioxus: Figure 2 ). Such invertebrates have\nrelatively simple “core brains” that integrate sensory\ninformation, adjust inner-body processes (digestion, sex\nactivity of the gonads, hormone secretion), and set the\nanimal’s overall level of arousal (placid, excitable). Core\nbrains also contain basic motor programs for rhythmic\nlocomotion, feeding movements, and other stereotyped\nactions. For accounts of the sequence of emerging\nneural features just described, see Feinberg and Mallatt\n(2016a), Bosch et al. (2017), Shigeno et al. (2017), Lacalli\n(2018), and Arendt et al. (2019).\nElaborate neural connections and many behaviors emerged\nat this core-brain stage, but it is not conscious. We deduce\nthis because it is entirely reactive and therefore, reﬂexive. The\ninvertebrates at this stage sense and follow stimuli that areessential to their survival, but if they lose the sensory trail — with\nno more stimuli to react to — they cannot go further and resort to\nsystemic but untargeted searching to try to relocate the stimulus.\nSee the evidence for this from foraging roundworms by Klein and\nBarron (2016) and Feinberg and Mallatt (2018a). Consciousness\nevolved to solve this problem of becoming lost, and it involved\nacquiring a new set of emergent features.\nLevel 3. the Special Neurobiological\nFeatures of Consciousness\nHow We Deduced These Features\nThe special neurobiological features of complex brains, combined\nwith the more basic life functions, reﬂexes, and core brain, create\nconsciousness ( Table 2 ,Level 3 ). Before putting these special\nfeatures into an emergent evolutionary scenario, we should tell\nhow we derived them. They are our versions of the “neural\ncorrelates of consciousness” or NCCs, namely our minimal set\nof neuronal traits that are collectively suﬃcient for consciousness\n(Edelman et al., 2005; Searle, 2007; Seth, 2009; Koch, 2019).\nNCCs are the traits that all investigators must establish before\nthey can study consciousness any further. Whereas most other\ninvestigators base their correlates on studies of the mammalian\nor human cerebral cortex — as if consciousness only emerged\nwith or in the cortex — we instead derived our correlates\nfrom two fundamental assumptions (Feinberg and Mallatt, 2013,\n2016a, 2018a, 2019): (1) If an animal has neural pathways\nthat carry mapped, point-by-point signals from the sensed\nenvironment, from diﬀerent senses (e.g. vision, touch, hearing),\nand if these sensory maps converge in the brain, then that animal\nconsciously experiences a uniﬁed, mapped, multisensory image\nof the environment; and (2) If an animal shows complex operant\nlearning, i.e. learning and remembering from experience to avoid\nharmful stimuli and to approach helpful stimuli, then that animal\nhas the negative and positive feelings of aﬀective consciousness\n(also see Bronfman et al., 2016 and Ginsburg and Jablonka, 2019).\nThe only animals that meet these two criteria are the vertebrates,\narthropods, and cephalopod molluscs (octopus, squid, cuttleﬁsh)\n(Figure 2 ). After recognizing this, we sought and tallied the other\nnovel neural features shared by all three of these taxa, to complete\nour list of special features in Table 2 ,Level 3 .\nThe Special Features Are Emergent Features\nThe special features of consciousness in Table 2 ,Level 3 ﬁt all the\ncriteria for emergence in Table 1 . Consciousness ﬁts Features 1\nand 3 of Table 1 because it is a novel process that comes from\nacomplex, hierarchical system of living and nervous elements,\nwith its novelty attained through addition of the special neural\nfeatures; and it is not present in the system’s parts such as in\nan individual neuron nor the ancestral, core brain (Feature 2\ninTable 1 ).\nWith consciousness, there is more elaboration, specialization\nand subdivision of the hierarchy’s parts (Feature 3d in\nTable 1 ). The ﬁrst example of this is that the senses\nof vertebrates, arthropods and cephalopods are much\nmore elaborate than the simple ancestral photorecepters,\nmechanoreceptors and chemoreceptors, in including image-\nforming eyes, ears for hearing, taste buds, and olfactory organs\nFrontiers in Psychology | www.frontiersin.org 7 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 8\nFeinberg and Mallatt Consciousness and Emergence\n(Feinberg and Mallatt, 2016a). Second, the sensory pathways\nhave more levels (levels added to the hierarchy), namely the\nbrain’s higher-processing and motor-command centers. The best\nexample of this is that the vertebrate brain has new levels in its\nhighest part (forebrain) that were not present in prevertebrates\nas judged from the brains of our invertebrate cousins, the\namphioxus and tunicates (sea squirts). More speciﬁcally, only\nthe vertebrates have an enlarged and complex cerebrum in\ntheir forebrain.\nAs a third example of the great elaboration and specialization\nassociated with consciousness, the more-advanced animal brains\nhave the largest numbers of neuron types , with highly complex\ninteractions (Strausfeld, 2012; Feinberg and Mallatt, 2016a;\nHodge et al., 2019). As a fourth example, the brains of conscious\nanimals have many more brain regions than do the ancestral\ncore brains. Some of these added regions process the extensive\nsensory inputs. In vertebrates, for instance, visual information\nis extensively processed in the retina, thalamus, parts of the\ncerebrum, and optic tectum; and in arthropods in the retina,\nlamina, medulla, lobula and central complex of the brain\n(Strausfeld, 2012; Feinberg and Mallatt, 2016a). As another\nillustration of extreme regional specialization, the core of the\nvertebrate brain has elaborated a dizzying number of centers\nfor aﬀective (emotional) consciousness: the habenula, basal\nforebrain, periaqueductal gray, parts of the reticular formation\nand more ( Figure 3 ; Berridge and Kringelbach, 2015; Feinberg\nand Mallatt, 2016a; Hu, 2016; Feinberg and Mallatt, 2018a;\nSiciliano et al., 2019; Szõnyi et al., 2019).\nThe special neural features of consciousness include the\nemergent feature of more reciprocal connections (Feature 4 in\nTable 1 ). For this, the functional centers communicate back and\nforth through extensive interconnections ( Figure 3 ), commonly\nby synchronized oscillatory signals or reverberations (Lamme,\n2006; Koch et al., 2016; Feinberg and Mallatt, 2018a; Koch, 2019).\nLack of extensive cross-communication is thought to be why\nsome of our complex brain regions operate nonconsciously; an\nexample is the cerebellum, which nonconsciously smooths and\ncoordinates our body movements (Tononi and Koch, 2015).\nThe related property of circular causality (Feature 4a) is\nmore pronounced in conscious than in core-brain systems.\nFor example, the lower levels that receive sensory input\ninﬂuence the higher brain levels that in turn dictate motor\noutput, and they do so far more extensively than in the\nmore reﬂex-dominated nervous systems of nonconscious animals\n(Grillner and El Manira, 2020).\nExtensive reciprocal communication also allows\nconsciousness to be an eﬀective prediction device , modeling\nevents a fraction of a second into the future so the subject is\nalways prepared in advance. Stated brieﬂy, all this crosstalk lets\nthe hierarchy continuously sense the current events, make the\npredictions, and perpetually adjust these predictions to optimize\nthe behaviors the hierarchy signals. Predictive processing is\na large focus of consciousness research nowadays, and we\nexplain more about it in our book, Consciousness Demystiﬁed\n(Feinberg and Mallatt, 2018a).\nConsciousness and the neural features that support it come\nwith constraints (Feature 5 in Table 1 ). The complex neuralprocesses are energy expensive. Due to this cost constraint,\n(1) a conscious individual cannot attend to every stimulus\nthat is sensed but must instead use selective attention (see for\ninstance Tsuchiya and Koch, 2008; Chica et al., 2010; Block, 2012;\nTsuchiya and Van Boxtel, 2013; Koch, 2019) that might miss\nsome important stimuli; (2) some brain processes must run on\nautomatic without consciousness, such as those for swallowing\nand well-practiced motor skills; (3) many bilaterian animals never\nevolved consciousness due to its cost, having instead evolved\nshortcuts for survival, defense and ﬁnding food (e.g. the tiny-\nbrained, ﬁlter-feeding clams in their protective shells).\nAs for the multiple routes feature of emergent phenomena\n(Feature 6 in Table 1 ), this is exactly what we found for\nconsciousness (Feinberg and Mallatt, 2016a,b, 2018a), in the\nabove-mentioned form called the multiple realizability of a\nmental state. For example, the complex brains of vertebrates,\narthropods, and cephalopods – each of which has all the special\nfeatures of consciousness – evolved independently of one another\nfrom a brainless ancestral state (Northcutt, 2012), meaning their\nconsciousnesses evolved by three diﬀerent routes ( Figure 4 ). As\nanother example of the multiple realizability of consciousness,\nin mammals the mapped, conscious images of the sensed world\nprimarily involve a diﬀerent part of the brain (cerebral cortex)\nthan does the aﬀective consciousness of emotions (subcortical\nbrain regions) (Panksepp, 2004, 2016; Denton, 2005; Merker,\n2007; Damasio, 2010; Aleman and Merker, 2014; Berridge and\nKringelbach, 2015; Feinberg and Mallatt, 2016a).\nSigniﬁcantly, we have reported this “diversity” of the conscious\nsubstrates in the past (Feinberg and Mallatt, 2016a,b, 2018a,\n2019), but we only recently recognized it as the multiple-routes\nand multiple-realizability feature, and therefore as a hallmark of\nemergence in complex systems in general (Bedau, 2008).\nDating When the Special Features Emerged\nFrom the evidence that consciousness is conﬁned to vertebrates,\narthropods, and cephalopods, it is easy to deduce when\nconsciousness emerged and to see that it did so rapidly,\nin evolutionary terms. The earliest arthropod, vertebrate and\ncephalopod fossils are from Cambrian rocks, products of the\n“Cambrian explosion” that produced all 30+ known phyla of\nbilaterian animals between about 540 and 500 million years\nago (Erwin and Valentine, 2013). This explosion is thought\nto have been sparked by the evolution of the ﬁrst predatory\nanimals (the earlier, ancestral worms had fed on sea-ﬂoor\nscum), leading to an adaptive arms race that yielded many\ndistinct taxa with diﬀerent defensive and predatory strategies.\nJudging from their modern relatives with similar locomotory and\nsensory morphologies, the Cambrian arthropods, vertebrates,\nand cephalopods were highly active and far-ranging animals\nthat could navigate through space to ﬁnd food and mates, and\navoid danger. By this reasoning, they all must have had the\nmapped mental images of the environment that signify conscious\nawareness. Consciousness was a big advance that also contributed\nto the further (later) success of these taxa: arthropods have\nalways been an extremely diverse and abundant phylum, and\nvertebrates include the largest animals with the biggest brains,\nat the top of the food chain. For documentation of these ideas,\nFrontiers in Psychology | www.frontiersin.org 8 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 9\nFeinberg and Mallatt Consciousness and Emergence\nFIGURE 4 | The phylogenetic “bush of life” showing that consciousness (as three-leaved stems) emerged independently in three different lines of animals. Figure ©\nMount Sinai School of Medicine.\nsee Plotnick et al. (2010), Trestman (2013), Feinberg and Mallatt\n(2016a), Godfrey-Smith (2016), Godfrey-Smith (2019), Klein and\nBarron (2016), and Ginsburg and Jablonka (2019).\nTo summarize, this section shows that consciousness evolved\nin some animals along with an elaboration of their body\nplans, and it did so in the Cambrian Period as a key\nadaption in the history of life on Earth. Many special neural\nfeatures evolved with it, and these features ﬁt the criteria\nof emergent features in general ( Table 1 ). This close ﬁt\nimplies our special features of consciousness really are emergent\nfeatures. Yet these features are highly elaborated extensions\nof those in simpler brains so they reﬂect huge increases in\nemergent novelties.\nEMERGENCE, CONSCIOUSNESS, AND\nTHE EXPLANATORY GAP: SOME\nPHILOSOPHICAL IMPLICATIONS\nThe Case for the Weak (Natural)\nEmergence of Consciousness\nWe have argued, by comparing the general features of\nemergence ( Table 1 ) with the features that appeared\nduring the evolution of consciousness ( Table 2 ), that\nconsciousness is a naturally emergent feature of life\nand complex brains. We summarize this formulation as\nLife + Special neurobiological features ! Phenomenal\nconsciousness . The neural-reﬂexive stage (Level 2) serves as\nan evolutionary and neurobiological bridge between Lifeand the\nSpecial features .However, as we noted above, the idea that consciousness is\nan emergent process is not new. The important question here\nis whether we are correct in concluding that consciousness\nis produced by “standard” emergent principles that are\namenable to standard scientiﬁc investigation, and is\nthus an example of weak emergence. In other words,\ncan we explain the emergence of consciousness in a\nseamless way with no scientiﬁc explanatory gap between life\nand consciousness?\nWe will now argue that the two main factors – life and the\nspecial features – make crucial contributions to the creation\nof consciousness but at the same time they contribute to the\n(mistaken) appearance of a scientiﬁc explanatory gap where none\nactually exists.\nLife Is Crucial to Explaining the\nSubjective Aspect of “Feeling”\nFirst we consider the role of life. Note that in Levine’s\n(1983) view and that of many philosophers of consciousness\n(Broad, 1925; Nagel, 1974, 1986; Chalmers, 1995, 1996;\nShear, 1999) it is the subjective ,personal nature of\nconsciousness that makes it so perplexing and mysterious\nand makes strong emergence seem like a reasonable –\nif not a default – position. So how can the personal\nsubjective nature of consciousness be explained by objective\nneurobiological science?\nFirst, because consciousness is built upon the emergence\nof life in any single organism, and because both life and\nconsciousness are system features of embodied organisms , then\nit follows that conscious feelings (perceptions, “qualia, ” etc.)\nFrontiers in Psychology | www.frontiersin.org 9 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 10\nFeinberg and Mallatt Consciousness and Emergence\nare system functions of certain complex, personal brains, and\neach feeling is a personal system-feature of that individual\nliving organism just as life itself is an embodied personal\nsystem-feature of the organism. Therefore, life provides the\nnatural initial conditions for the emergence of subjective\nconsciousness (Feinberg, 2012; Feinberg and Mallatt, 2016a,b,\n2018a). In short, life means embodiment, which means\nan individual body, which ultimately allows an individual\nperspective (subjectivity).\nBut as Thompson (2007) notes, the explanatory gap by no\nmeans goes away simply because consciousness is a feature of life.\nNot all living organisms or body organs are conscious (see Mallatt\nand Feinberg, 2017), so life only partly ﬁlls that gap. To ﬁnish\nﬁlling the gap, the special neurobiological features of conscious\nbrains are needed to explain what is unique about consciousness.\nThese features are personal but also novel.\nSome Brains Are Ideally and Uniquely\nSuited to Create Novel Emergent\nFeatures\nOur main ﬁnding so far is the remarkable correspondence\nbetween the special features of conscious brains listed in Table 2 ,\nLevel 3 and the general features of emergence in allcomplex\nsystems listed in Table 1 . The special features not only correspond\nto the general features but markedly extend them, to levels\nof much greater complexity. This provides good evidence that\nconsciousness is complex, with complex causes, and is not simply\ncaused by one fundamental, or psychic, force of nature as some\nhave claimed (Chalmers, 1996; Velmans, 2008; Skrbina, 2009;\nGoﬀ et al., 2017).\nAnother way to say this is that when we compare\nTable 1 with Table 2 ,Level 3 , we ﬁnd that the neural\nhierarchies for consciousness are ideally suited to maximize\nemergent novelty.\u0003These neural hierarchies have large\nnumbers of tightly and reciprocally connected neural levels\nand centers, which interact extensively, and enhanced\nneuron-neuron communications that maximize the\ndistributed yet interconnected neural levels ( Figure 3 ).\nThey also have an enormously increased diﬀerentiation\nof neuron subtypes in the setting of enhanced aggregate\nfunctioning. This is much more elaborate than in less-\ncomplex systems because of its greater number of\ninteracting parts.\nThus, while it has been proposed that consciousness requires\na strong type of emergence that is diﬀerent in kind from\nstandard (weak) emergence, we see that the emergence of\nconsciousness is simply a matter of a greater magnitude of\nstandard emergence with an accompanying exponential increase\nin novel emergent properties. Such a large quantitative increase\ngives the impression of a qualitative explanatory gap between\nthe brain and consciousness when there actually is none. This\n\u0003See Jordan and Ghin (2006: p. 64) for another perspective on why the novel\nemergent features for consciousness can accumulate and then accelerate over\nevolutionary time in living, self-sustaining, systems. Their basic idea is that every\nadaptive advance sets the stage (the context) for novelty at the next higher level,\nwhile this context also stabilizes the lower levels.realization, along with the personal point of view that comes from\nembodied life, is our solution to the longstanding problem of the\nexplanatory gap. But we will see later that a diﬀerent gap remains,\nthough that gap is fully explainable as well.\nConsciousness, Emergence and\nDownward Causation\nAnother assumption that contributed to the idea of an\nexplanatory gap is the view that consciousness emerges “at\nthe top” of the neural hierarchy. According to one version\nof this view, the “mental properties” that emerge at the\nhighest level can then cause “physical changes” in a downward\nfashion upon the material brain. (For a discussion of this and\nother accounts of downward causation and consciousness, see\nEmmeche et al., 2000).\nIn a prototypical example of this kind of theory, Nobel\nlaureate Sperry (1984, 1990) argued that the “mysterious” features\nof consciousness are radically/strongly emergent, non-material\nfeatures of the brain:\n... consciousness was conceived to be a dynamic emergent of\nbrain activity, neither identical with, nor reducible to, the neural\nevents of which it is mainly composed. Further, consciousness\nwas not conceived as an epiphenomenon, inner aspect, or other\npassive correlate of brain processing, but rather to be an active\nintegral part of the cerebral process itself, exerting potent causal\neﬀects in the interplay of cerebral operations. In a position of\ntop command at the highest levels in the hierarchy of brain\norganization, the subjective properties were seen to exert control\nover the biophysical and chemical activities at subordinate levels.\nIt was described initially as a brain model that puts “conscious\nmind back into the brain of objective science in a position of\ntop command ... a brain model in which conscious, mental,\npsychic forces are recognized to be the crowning achievement ...\nof evolution (Sperry, 1990, p. 382).\nAnd:\nFor the subjective qualities we look higher in the system at\norganizational properties that are select and special to operations\nat the top levels of the brain hierarchy (Sperry, 1984, p. 671).\nFeinberg (2001) pointed out the error in this analysis. While\nconsciousness is clearly an emergent feature of complex brains, it\nis asystem feature , and as such does not emerge at the “top” or any\nother “point” of the neural hierarchy . It is a product of the entire\nsystem and many levels contribute.\nThe view of a strongly emergent – but immaterial – feature\nthat somehow “pops out” at the summit of the nervous\nsystem contributes to the idea of an explanatory gap (see\nthe Revonsuo, 2010, quote above) that in reality does not\nexist (Feinberg, 2001). It also contributes to the mistaken,\ndualistic, claim that immaterial consciousness miraculously\ncontrols the material brain.\nConsciousness, Multiple Realizability,\nand Emergence\nWe have provided evidence for the multiple realizability of\nconsciousness, which is the idea that a given mental state\nFrontiers in Psychology | www.frontiersin.org 10 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 11\nFeinberg and Mallatt Consciousness and Emergence\nFIGURE 5 | Phenomenal consciousness is an emergent system function that relies on neural hierarchies and also on embodied life ( Table 2 ,Level 1 ) and special\nneurobiological features ( Table 2 ,Level 3 ). Our formulation summarizes this: Life + Special neurobiological features !Phenomenal consciousness. Figure © Mount\nSinai School of Medicine.\ncan have diﬀerent causes. This concept was put forth by\nPutnam (1967). He introduced it as a rebuttal of the strictly\nreductionist idea that the mental is identical to the physical.\nSuch a reductionist identity could allow just one physical cause\nfor a mental state, not multiple causes, so multiple realizability\nwas an eﬀective rebuttal. Its appeal led many physicalist\nphilosophers to become nonreductive physicalists (Kim, 1992;\nBickle, 2019).\nHowever, extensive analyses of the multiple-realizability\nconcept over the decades have led some scholars to\nquestion its premise that a multiply realizable mental\nstate is a single entity or “kind” (Block, 1980; Kim, 1992;\nEndicott, 1993). For example, pain in insects does not\nhave the same physical basis as pain in humans, so these\ntwo types of pain could actually be called two distinct\nentities. This challenge would mean that every multiply\nrealizable mental state is a composite or conjunction\nof states (if from diﬀerent species), and in being a\nmixture is not amenable to scientiﬁc analysis—which\nKim (1992) claimed prevents psychology from being a\nscientiﬁc discipline.\nOur ﬁndings refute this challenge for the particular\nmental state of consciousness. We found that every multiply\nrealizable conscious system—in vertebrates versus arthropods\nversus cephalopods, and for aﬀective- versus image-based\nconsciousness—has a large number of physical featuresin common , all of which are listed in Table 2 ,Level 3 .\nThe commonalities are so numerous that consciousness,\nwe argue, despite its variations, can indeed be treated\nas a single mental kind. Another criterion for a mental\nstate to be a single kind is if all its variations have the\nsame causal powers (Kim, 1992), and we demonstrated\nthis too, in that the conscious state causes active, directed\nbehaviors in all the conscious taxa (see above). The many,\nunifying regularities we uncovered for the conscious state\nare not coincidental or trivial, but instead comprise a\nsuite of essential adaptations, convergently molded by the\nselective evolutionary constraints needed for highly mobile\nanimals to operate proactively in a directed manner in\ncomplex environments.\nThese considerations demonstrate the value of multiple\nrealizability in consciousness studies and psychology in general—\nand we have shown that multiple realizability comes directly\nfrom the multiple-routes feature of all emergent systems\n(Table 1 , Feature 6).\nConsciousness, Emergence, and the\n“Experiential Gap”: Being Versus\nDescribing\nWhile we ﬁnd no scientiﬁc explanatory gap between the brain\nand subjective experience from the standpoint of biology and\nFrontiers in Psychology | www.frontiersin.org 11 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 12\nFeinberg and Mallatt Consciousness and Emergence\nFIGURE 6 | Some kinds of knowledge can only be obtained by experience.\nKnowing is of two types, experiential (left) and descriptive (right). An observer\ncannot fully know an experience (X at the right) without directly experiencing it,\neven though the experience is generated physically by neurons in a living brain\n(center column). The distinction here between ﬁrst- and third- person points of\nview does not entail dualism between the brain and the mind or require a\n“non-physical” explanation for phenomenal consciousness. Also see Feinberg\nand Mallatt (2018b). Figure © Mount Sinai School of Medicine.\nneurobiology, we acknowledge that there remains an experiential\n(“point of view”) gap between objective scientiﬁc explanations\nof the brain and subjective experiences of consciousness. The\nquestion is whether this gap causes a problem for a complete\nscience of consciousness.\nTo illustrate the experiential gap, C. D. Broad argued that even\nif an omniscient “mathematical archangel” could fully explain\nthe chemistry of ammonia and the functions of the brain, the\narchangel still could not predict the subjective smell of ammonia:\nHe [the archangel] would know exactly what the microscopic\nstructure of ammonia must be; but he would be totally unable to\npredict that a substance with this structure must smell as ammonia\ndoes when it gets into the human nose. The utmost that he could\npredict on this subject would be that certain changes would take\nplace in the mucous membrane, the olfactory nerves and so on.\nBut he could not possibly know that these changes would be\naccompanied by the appearance of a smell in general or of the\npeculiar smell of ammonia in particular, unless someone told him\nso or he had smelled it for himself (Broad, 1925, p. 71).\nWe fully agree with Broad that no amount of explanation\nof the neurobiology of the brain can eliminate the need\nfor the subjective aspect of personal experience, any more\nthan describing one’s ﬁrst-person experience can substitute\nfor having that experience. And we agree that no amount\nof indirect knowledge or description of brain functions\ncan be equated with, fully capture or can substitute for\n“something it is like to be, ” phenomenal consciousness , the\nﬁrst-person versus third-person point of view , or knowledge\nby acquaintance versus knowledge by description (Russell,\n1910, 1912, 1914; Nagel, 1974, 1986; Jackson, 1982, 1986;\nLevine, 1983; Velmans, 1991; Searle, 1992, 2007; Conee,\n1994; Block, 1995; Chalmers, 1995, 1996; Metzinger, 1995,\nMetzinger, 2003; Tye, 2002; Revonsuo, 2006; Teller, 2011;Carruthers, 2016; Choifer, 2018; Hasan and Fumerton, 2019;\nNida-Rümelin and O Conaill, 2019).\nSo how do we scientiﬁcally reconcile the experiential divide\nbetween these ﬁrst- and third- person points of view without\ninvoking any dualism between the brain and the mind? How can\nthe divide be compatible with physicalism? (See for instance the\n“knowledge argument” against physicalism: Jackson, 1982, 1986;\nConee, 1994; Nida-Rümelin and O Conaill, 2019).\nHere is our answer. If it is true, as we propose, that\nthe personal life of an embodied organism is an emergent\nprocess of a physical system ( Table 1 and Table 2 ,Level 1 ),\nthen subjectivity is a critical but biologically natural\nelement of what we experience as a phenomenal state;\nand if it is also true, as we propose, that the addition\nof the special neurobiological features of complex brains\n(Table 2 ,Level 3 ) provides the biologically natural elements\nnecessary for the hierarchical emergence of phenomenal\nconsciousness, then we have enumerated all the prerequisites\nthat are required for the natural emergence of subjective\nexperience ( Figure 5 ).\nThus we ﬁnd that the distinction between being and\nexperiencing versus observing and describing is accounted\nfor by phenomenal consciousness as an emergent feature\nof living complex brains ( Figure 6 ). This means the\n“knowledge by description” of phenomenal consciousness –\nas sought by Broad’s archangel—is diﬀerent from direct\n“knowledge by acquaintance” or phenomenal knowledge\nbecause some kinds of knowledge can only be obtained\nthrough experience, even in a completely physical world\n(Conee, 1994). By this account, the “experiential gap” does not\nviolate physicalism, nor does it support the strong emergence\nof consciousness.\nCONCLUSION\nIn summary, our proposed solution to the explanatory gap is\nthat ﬁrst, the emergence of phenomenal consciousness has a\nscientiﬁc explanation that adheres to and is consistent with\nthe principles of emergence in the rest of nature. A close\nconsideration of the special features of conscious systems\n(Table 2 ,Level 3 ) shows these features ﬁt all the criteria of\nemergent features of complex systems in general ( Table 1 ),\nthereby conﬁrming that consciousness is a complex-systems\nphenomenon, and that it is not just one thing arising from one\ncause, such as a new “fundamental” physical force of nature\n(Chalmers, 1995, 1996).\nSecond, our formulation for consciousness as a physically\nemergent process is Life + Special neurobiological features !\nPhenomenal consciousness , in which the (personal) Life aspect is\nthe ultimate basis of subjectivity and the Special features aspect is\nthe necessary additional basis of conscious experiences. We show\nhow this formulation explains consciousness as an instance of\nstandard, weak emergence without a need for strong emergence\nor a scientiﬁcally unbridgeable explanatory gap.\nThird, with the natural emergence of consciousness\nthus explained, the only remaining gap is a mere\nFrontiers in Psychology | www.frontiersin.org 12 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 13\nFeinberg and Mallatt Consciousness and Emergence\n“experiential gap” between ﬁrst-person experience and third-\nperson description that poses no obstacle for a naturalistic\nexplanation of consciousness.\nAUTHOR CONTRIBUTIONS\nTF focused more on the neurobiology, theory and philosophy. JM\nfocused more on the neurobiological and evolutionary aspects.Both authors contributed to the emergent features and their\nrelation to consciousness.\nACKNOWLEDGMENTS\nWe thank Jill K. Gregory at the Instructional Technology,\nIcahn School of Medicine at Mount Sinai for the professional\nartwork of the ﬁgures.\nREFERENCES\nAhl, V., Allen, T. F., and Allen, T. F. H. (1996). Hierarchy Theory: A Vision,\nVocabulary, and Epistemology . New York, NY: Columbia University Press.\nAleman, B., and Merker, B. (2014). Consciousness without cortex:\na hydranencephaly family survey. Acta Paediatr. 103, 1057–1065.\ndoi: 10.1111/apa.12718\nAllen, T. F., and Starr, T. B. (1982). Hierarchy: Perspectives for Ecological\nComplexity . Chicago, IL: University of Chicago.\nAndersen, P. B., Emmeche, C., Finnemann, N. O., and Christiansen, P. V. (2000).\nDownward Causation :Minds, Bodies and Matter . Aarhus: Aarhus University\nPress.\nArendt, D., Bertucci, P. Y., Achim, K., and Musser, J. M. (2019). Evolution of\nneuronal types and families. Curr. Opin. Neurobiol. 56, 144–152. doi: 10.1016/j.\nconb.2019.01.022\nAtmanspacher, H. (2012). Identifying mental states from neural states under\nmental constraints. Interface Focus 2, 74–81. doi: 10.1098/rsfs.2011.\n0058\nAtmanspacher, H. (2015). Contextual emergence of mental states. Cogn. Process.\n16, 359–364. doi: 10.1007/s10339-015-0658-0\nAtmanspacher, H., and beim Graben, P. (2009). Contextual emergence.\nScholarpedia 4:7997. doi: 10.4249/scholarpedia.7997\nBeckermann, A., Flohr, H., and Kim, J. (eds) (2011). Emergence or Reduction?\nEssays on the Prospects of Nonreductive Physicalism . New York, NY: Walter de\nGruyter.\nBedau, M. A. (1997). Weak emergence. Philos. Perspect. 11, 375–399. doi: 10.1111/\n0029-4624.31.s11.17\nBedau, M. A. (2008). “Downward causation and the autonomy of weak emergence, ”\ninEmergence: Contemporary Readings in Philosophy and Science , eds M. A.\nBedau and P. Humphreys (Cambridge, MA: MIT Press), 155–188.\nBedau, M. A., and Humphreys, P. (2008). Emergence: Contemporary Readings in\nPhilosophy and Science . Cambridge, MA: MIT Press.\nbeim Graben, P. (2014). Contextual emergence of intentionality. J. Conscious. Stud.\n21, 75–96. doi: 10.1007/s12124-010-9117-8\nBerridge, K. C., and Kringelbach, M. L. (2015). Pleasure systems in the brain.\nNeuron 86, 646–664. doi: 10.1016/j.neuron.2015.02.018\nBickle, J. (2019). Multiple Realizability. Encyclopedia of Cognitive Science . Available\nonline at: https://plato.stanford.edu/archives/spr2019/entries/multiple-\nrealizability (accessed May 14, 2020).\nBishop, R. C., and Atmanspacher, H. (2006). Contextual emergence in the\ndescription of properties. Found. Phys. 36, 1753–1777. doi: 10.1007/s10701-\n006-9082-8\nBlock, N. (1980). Troubles with functionalism. Read. Philos. Psychol. 1, 268–305.\nBlock, N. (1995). On a confusion about a function of consciousness. Behav. Brain\nSci.18, 227–247. doi: 10.1017/S0140525X00038188\nBlock, N. (2012). The grain of vision and the grain of attention. Thought J. Philos.\n1, 170–184. doi: 10.1002/tht3.28\nBosch, T. C., Klimovich, A., Domazet-Lošo, T., Gründer, S., Holstein, T. W., Jékely,\nG., et al. (2017). Back to the basics: cnidarians start to ﬁre. Trends Neurosci. 40,\n92–105. doi: 10.1016/j.tins.2016.11.005\nBroad, C. D. (1925). The Mind and its Place in Nature . London: Routledge.\nBronfman, Z. Z., Ginsburg, S., and Jablonka, E. (2016). The transition to minimal\nconsciousness through the evolution of associative learning. Front. Psychol.\n7:1954. doi: 10.3389/fpsyg.2016.01954Brunet, T., Larson, B. T., Linden, T. A., Vermeij, M. J., McDonald, K., and\nKing, N. (2019). Light-regulated collective contractility in a multicellular\nchoanoﬂagellate. Science 366, 326–344. doi: 10.1101/661009\nBrunk, C. F., and Martin, W. F. (2019). Archaeal histone contributions to the origin\nof eukaryotes. Trends Microbiol. 27, 703–714. doi: 10.1016/j.tim.2019.04.002\nCabanac, M. (1996). On the origin of consciousness, a postulate and its corollary.\nNeurosci. Biobehav. Rev. 20, 33–40. doi: 10.1016/0149-7634(95)00032-A\nCarr, J. (1981). Applications of Centre Manifold Theory . Berlin: Springer-Verlag.\nCarruthers, P. (2016). Higher-Order Theories of Consciousness. Stanford\nEncyclopedia of Philosophy . Available online at: https://plato.stanford.edu/\narchives/fall2016/entries/consciousness-higher/ (accessed May 14, 2020).\nChalmers, D. J. (1995). Facing up to the problem of consciousness. J. Conscious.\nStud. 2, 200–219.\nChalmers, D. J. (1996). The Conscious Mind: In Search of a Fundamental Theory .\nNew York, NY: Oxford University Press.\nChalmers, D. J. (2006). “Strong and weak emergence, ” in The Re-Emergence of\nEmergence: The Emergentist Hypothesis from Science to Religion , eds P. Clayton\nand P. Davies (Oxford: Oxford University Press), 244–254.\nChica, A. B., Lasaponara, S., Lupiáñez, J., Doricchi, F., and Bartolomeo, P.\n(2010). Exogenous attention can capture perceptual consciousness: ERP and\nbehavioural evidence. Neuroimage 51, 1205–1212. doi: 10.1016/j.neuroimage.\n2010.03.002\nChoifer, A. (2018). A new understanding of the ﬁrst-person and third-person\nperspectives. Philos. Pap. 47, 333–371. doi: 10.1080/05568641.2018.1450160\nChurchland, P. M. (2013). Matter and Consciousness . Cambridge, MA: MIT press.\nClark, A. (2013). Whatever next? Predictive brains, situated agents, and the\nfuture of cognitive science. Behav. Brain Sci. 36, 181–204. doi: 10.1017/\nS0140525X12000477\nClayton, P. (2006). “Conceptual foundations of emergence theory, ” in The Re-\nEmergence of Emergence: The Emergentist Hypothesis from Science to Religion ,\neds P. Clayton and P. Davies (Oxford: Oxford University Press), 1–31.\nClayton, P., and Davies, P. (2006). The Re-Emergence of Emergence: The Emergentist\nHypothesis from Science To Religion . Oxford: Oxford University Press.\nConee, E. (1994). Phenomenal knowledge. Aust. J. Philos. 72, 136–150. doi: 10.\n1080/00048409412345971\nDamasio, A. (2010). Self Comes to Mind: Constructing the Conscious Brain .\nNew York, NY: Vintage.\nDavies, P. (2006). “Preface, ” in The Re-Emergence of Emergence :The Emergentist\nHypothesis from Science to Religion , eds P. Clayton and P. Davies (Oxford:\nOxford University Press), ix–xiv.\nDeacon, T. W. (2011). Incomplete Nature: How Mind Emerged from Matter .\nNew York, NY: WW Norton and Company.\nDenton, D. (2005). The Primordial Emotions: The Dawning of Consciousness .\nOxford: Oxford University Press.\nEdelman, D. B., Baars, B. J., and Seth, A. K. (2005). Identifying hallmarks of\nconsciousness in non-mammalian species. Conscious. Cogn. 14, 169–187. doi:\n10.1016/j.concog.2004.09.001\nEllis, G. (2006). “On the nature of emergent reality, ” in The Re-Emergence of\nEmergence: The Emergentist Hypothesis from Science to Religion , eds P. Clayton\nand P. Davies (Oxford: Oxford University Press), 79–107.\nEmmeche, C., Køppe, S., and Stjernfelt, F. (2000). “Levels, emergence, and three\nversions of downward causation, ” in Downward Causation. Minds, Bodies\nand Matter , eds P. B. Andersen, C. Emmeche, N. O. Finnemann, and P. V.\nChristiansen (Århus: Aarhus University Press), 13–34.\nFrontiers in Psychology | www.frontiersin.org 13 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 14\nFeinberg and Mallatt Consciousness and Emergence\nEndicott, R. P. (1993). Species-speciﬁc properties and more narrow reductive\nstrategies. Erkenntnis 38, 303–321.\nEngland, J. L. (2013). Statistical physics of self-replication. J. Chem. Phys.\n139:121923. doi: 10.1063/1.4818538\nErwin, D. H., and Valentine, J. W. (2013). The Cambrian Explosion: The\nConstruction of Animal Biodiversity . Greenwood Village, CO: Roberts and Co.\nFeigl, H. (1958). The ‘Mental’ and the ‘Physical’ . Minneapolis, MN: University of\nMinnesota Press.\nFeinberg, T. E. (2001). Why the mind is not a radically emergent feature of the\nbrain. J. Conscious. Stud. 8, 123–145.\nFeinberg, T. E. (2012). Neuroontology, neurobiological naturalism, and\nconsciousness: a challenge to scientiﬁc reduction and a solution. Phys.\nLife Rev. 9, 13–34. doi: 10.1016/j.plrev.2011.10.019\nFeinberg, T. E., and Mallatt, J. (2013). The evolutionary and genetic origins of\nconsciousness in the Cambrian Period over 500 million years ago. Front.\nPsychol. 4:667. doi: 10.3389/fpsyg.2013.00667\nFeinberg, T. E., and Mallatt, J. (2016a). The Ancient Origins of Consciousness: How\nthe Brain Created Experience . Cambridge, MA: MIT Press.\nFeinberg, T. E., and Mallatt, J. (2016b). The nature of primary consciousness: a new\nsynthesis. Conscious. Cogn. 43, 113–127. doi: 10.1016/j.concog.2016.05.009\nFeinberg, T. E., and Mallatt, J. (2018a). Consciousness Demystiﬁed . Cambridge, MA:\nMIT Press.\nFeinberg, T. E., and Mallatt, J. (2018b). Unlocking the “Mystery” of\nConsciousness. Scientiﬁc American, Observations . Available online at:\nhttps://blogs.scientiﬁcamerican.com/observations/unlocking-the-mystery-\nof-consciousness (accessed January 13, 2020).\nFeinberg, T. E., and Mallatt, J. M. (2019). Subjectivity “demystiﬁed”: neurobiology,\nevolution, and the explanatory gap. Front. Psychol. 10:1686. doi: 10.3389/fpsyg.\n2019.01686\nGershman, S. J., Horvitz, E. J., and Tenenbaum, J. B. (2015). Computational\nrationality: a converging paradigm for intelligence in brains, minds, and\nmachines. Science 349, 273–278. doi: 10.1126/science.aac6076\nGinsburg, S., and Jablonka, E. (2019). The Evolution of the Sensitive Soul: Learning\nand the Origins of Consciousness . Cambridge, MA: MIT Press.\nGodfrey-Smith, P. (2016). “Animal evolution and the origins of experience” in How\nBiology Shapes Philosophy: New Foundations for Naturalism , ed. D. L. Smith\n(Cambridge: Cambridge University Press), 23–50.\nGodfrey-Smith, P. (2019). Evolving Across the Explanatory Gap. Philosophy,\nTheory, and Practice in Biology . Available online at: https://quod.lib.umich.\nedu/cgi/t/text/text-idx?cc=ptpbio;c=ptb;c=ptpbio;idno=16039257.0011.001;g=\nptpbiog;rgn=main;view=text;xc=1 (accessed October 11, 2018).\nGoﬀ, P., Seager, W., and Allen-Hermanson, S. (2017). Panpsychism. The Stanford\nEncyclopedia of Philosophy . Available online at: https://plato.stanford.edu/\narchives/win2017/entries/panpsychism/ (accessed May 14, 2020).\nGrillner, S., and El Manira, A. (2020). Current principles of motor control, with\nspecial reference to vertebrate locomotion. Physiol. Rev. 100, 271–320. doi:\n10.1152/physrev.00015.2019\nHaken, H. (1983). Synergetics: An Introduction. Non-Equilibrium Phase Transition\nand Self-Organization in Physics . Berlin: Springer-Verlag.\nHasan, A., and Fumerton, R. (2019). Knowledge by Acquaintance vs. Description.\nThe Stanford Encyclopedia of Philosophy . Available online at: https://plato.\nstanford.edu/archives/sum2019/entries/knowledge-acquaindescrip/ (accessed\nMay 14, 2020).\nHodge, R. D., Bakken, T. E., Miller, J. A., Smith, K. A., Barkan, E. R., Graybuck,\nL. T., et al. (2019). Conserved cell types with divergent features in human versus\nmouse cortex. Nature 573, 61–68. doi: 10.1038/s41586-019-1506-7\nHu, H. (2016). Reward and aversion. Annu. Rev. Neurosci. 39, 297–324. doi: 10.\n1146/annurev-neuro-070815-014106\nJackson, F. (1982). Epiphenomenal qualia. Philos. Q. 32, 127–136. doi: 10.2307/\n2960077\nJackson, F. (1986). What Mary didn’t know. J. Philos. 83, 291–295. doi: 10.2307/\n2026143\nJordan, J. S., and Ghin, M. (2006). (Proto-) consciousness as a contextually\nemergent property of self-sustaining systems. Mind Matter 4, 45–68.\nJylkkä, J., and Railo, H. (2019). Consciousness as a concrete physical phenomenon.\nConscious. Cogn. 74, 102779. doi: 10.1016/j.concog.2019.102779\nKim, J. (1992). Multiple realization and the metaphysics of reduction. Philos.\nPhenomenol. Res. 52, 1–26.Kim, J. (1998). Mind in a Physical World: An Essay on the Mind–Body Problem and\nMental Causation . Cambridge, MA: MIT Press.\nKim, J. (2006). “Being realistic about emergence, ” in The Re-Emergence of\nEmergence :The Emergentist Hypothesis from Science to Religion , eds P. Clayton\nand P. Davies (Oxford: Oxford University Press), 190–202.\nKlein, C., and Barron, A. B. (2016). Insects have the capacity for subjective\nexperience. Anim. Sent. 9, 1–19. doi: 10.1073/pnas.1520084113\nKoch, C. (2019). The Feeling of Life Itself . Cambridge, MA: MIT Press.\nKoch, C., Massimini, M., Boly, M., and Tononi, G. (2016). Neural correlates of\nconsciousness: progress and problems. Nat. Rev. Neurosci. 17, 307–321. doi:\n10.1038/nrn.2016.22\nLacalli, T. (2018). Amphioxus neurocircuits, enhanced arousal, and the origin of\nvertebrate consciousness. Conscious. Cogn. 62, 127–134. doi: 10.1016/j.concog.\n2018.03.006\nLamme, V. A. (2006). Towards a true neural stance on consciousness. Trends Cogn.\nSci.23, 571–579. doi: 10.1016/j.tics.2006.09.001\nLane, N., and Martin, W. (2010). The energetics of genome complexity. Nature 467,\n929. doi: 10.1038/nature09486\nLevine, J. (1983). Materialism and phenomenal properties: the explanatory gap.\nPac. Philos. Q. 64, 354–361. doi: 10.1111/j.1468-0114.1983.tb00207.x\nLewes, G. H. (1877). Problems of Life and Mind . London: Trübner & Company.\nMallatt, J., and Feinberg, T. E. (2017). Consciousness is not inherent in but\nemergent from life. Anim. Sent. 1, 1–7.\nMayr, E. (1982). The Growth of Biological Thought: Diversity, Evolution, and\nInheritance . Cambridge, MA: Harvard University Press.\nMayr, E. (2004). What Makes Biology Unique? Considerations on the Autonomy of a\nScientiﬁc Discsipline . Cambridge: Cambridge University Press.\nMerker, B. (2007). Consciousness without a cerebral cortex: a challenge for\nneuroscience and medicine. Behav. Brain Sci. 30, 63–81. doi: 10.1017/\nS0140525X07000891\nMetzinger, T. (2003). Being No One: The Self-Model Theory of Subjectivity .\nCambridge, MA: MIT Press.\nMetzinger, T. (ed.) (1995). Conscious Experience . Thorverton: Imprint Academic.\nMogensen, J., and Overgaard, M. (2017). Reorganization of the connectivity\nbetween elementary functions–A model relating conscious states to neural\nconnections. Front. Psychol. 8:625. doi: 10.3389/fpsyg.2017.00625\nMorowitz, H. J. (2002). The Emergence of Everything: How the World Became\nComplex . New York, NY: Oxford University Press.\nNagel, T. (1974). What is it like to be a bat? Philos. Rev. 83, 435–450.\nNagel, T. (1986). The View from Nowhere . New York, NY: Oxford University press.\nNatarajan, C., Hoﬀmann, F. G., Weber, R. E., Fago, A., Witt, C. C., and Storz,\nJ. F. (2016). Predictable convergence in hemoglobin function has unpredictable\nmolecular underpinnings. Science 354, 336–339. doi: 10.1126/science.aaf9070\nNida-Rümelin, M., and O Conaill, D. (2019). Qualia: The Knowledge Argument.\nThe Stanford Encyclopedia of Philosophy . Available online at: https://plato.\nstanford.edu/archives/win2019/entries/qualia-knowledge/ (accessed May 14,\n2020).\nNoble, R., Tasaki, K., Noble, P. J., and Noble, D. (2019). Biological relativity requires\ncircular causality but not symmetry of causation: so, where, what and when are\nthe boundaries? Front. Physiol. 10:827. doi: 10.3389/fphys.2019.00827\nNorthcutt, R. G. (2012). Evolution of centralized nervous systems: two schools of\nevolutionary thought. Proc. Natl. Acad. Sci. U.S.A. 109(Suppl. 1), 10626–10633.\ndoi: 10.1073/pnas.1201889109\nNunez, P. L. (2016). The New Science of Consciousness . Amherst, NY: Prometheus\nBooks.\nPanksepp, J. (2004). Aﬀective Neuroscience: The Foundations of Human and Animal\nEmotions . New York, NY: Oxford University Press.\nPanksepp, J. (2016). The cross-mammalian neurophenomenology of primal\nemotional aﬀects: from animal feelings to human therapeutics. J. Comp. Neurol.\n524, 1624–1635. doi: 10.1002/cne.23969\nPattee, H. H. (1970). “The problem of biological hierarchy, ” in Towards a\nTheoretical Biology 3, Drafts , ed. C. H. Waddington (Edinburgh: Edinburgh\nUniversity Press), 117–136.\nPlotnick, R. E., Dornbos, S. Q., and Chen, J. (2010). Information landscapes and\nsensory ecology of the Cambrian Radiation. Paleobiology 36, 303–317. doi:\n10.1666/08062.1\nPopper, K. R., and Eccles, J. C. (1977). The Self and its Brain . New York, NY:\nSpringer.\nFrontiers in Psychology | www.frontiersin.org 14 June 2020 | Volume 11 | Article 1041"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "fpsyg-11-01041 June 10, 2020 Time: 20:44 # 15\nFeinberg and Mallatt Consciousness and Emergence\nPutnam, H. (1967). “Psychological predicates, ” in Art, Mind, and Religion , eds\nW. H. Capitan and D. D. Merrill (Pittsburgh, PA: University of Pittsburgh\nPress), 37–48.\nRevonsuo, A. (2006). Inner Presence: Consciousness as a Biological Phenomenon .\nCambridge, MA: MIT Press.\nRevonsuo, A. (2010). Consciousness: The Science of Subjectivity . Hove: Psychology\nPress.\nRothschild, L. J. (2006). “The role of emergence in biology, ” in The Re-Emergence of\nEmergence :The Emergentist Hypothesis from Science to Religion , eds P. Clayton\nand P. Davies (Oxford: Oxford University Press), 151–165.\nRussell, B. (1910). Knowledge by acquaintance and knowledge by description”.\nProc. Arist. Soc. 11, 108–128.\nRussell, B. (1912). The Problems of Philosophy . New York, NY: Henry Holt and\nCompany.\nRussell, B. (1914). On the nature of acquaintance. Monist 24, 161–187.\nSalthe, S. N. (1985). Evolving Hierarchical Systems: Their Structure and\nRepresentation . New York, NY: Columbia University Press.\nScott, A. (1995). Stairway to the Mind: The Controversial New Science of\nConsciousness . New York, NY: Springer-Verlag.\nSearle, J. R. (1992). The Rediscovery of the Mind . Cambridge, MA: MIT Press.\nSearle, J. R. (2007). Dualism revisited. J. Physiol. Paris 101, 169–178. doi: 10.1016/j.\njphysparis.2007.11.003\nSeth, A. (2009). Explanatory correlates of consciousness: theoretical and\ncomputational challenges. Cogn. Comput. 1, 50–63. doi: 10.1007/s12559-009-\n9007-x\nShear, J. (ed.) (1999). Explaining Consciousness: The Hard Problem . Cambridge,\nMA: MIT Press.\nShigeno, S., Murakami, Y., and Nomura, T. (eds) (2017). Brain Evolution by Design:\nFrom Neural Origin to Cognitive Architecture . New York, NY: Springer.\nSiciliano, C. A., Noamany, H., Chang, C. J., Brown, A. R., Chen, X., Leible, D., et al.\n(2019). A cortical-brainstem circuit predicts and governs compulsive alcohol\ndrinking. Science 366, 1008–1012. doi: 10.1126/science.aay1186\nSimon, H. (1973). “The organization of complex systems, ” in Hierarchy Theory:\nThe Challenge of Complex Systems , ed. H. H. Patee (New York, NY: George\nBraziller), 1–27.\nSkrbina, D. (ed.) (2009). Mind that Abides: Panpsychism in the New Millennium ,\nVol. 75. Amsterdam: John Benjamins Publishing.\nSolms, M. (2019). The hard problem of consciousness and the free energy principle.\nFront. Psychol. 9:2714. doi: 10.3389/fpsyg.2018.02714\nSperry, R. W. (1984). Consciousness, personal identity and the divided\nbrain. Neuropsychologia 22, 661–673. doi: 10.1016/0028-3932(84)90\n093-9\nSperry, R. W. (1990). “Forebrain commissurotomy and conscious awareness, ” in\nBrain Circuits and Functions of the Mind , ed. C. Trevarthen (New York, NY:\nCambridge University Press), 371–388.\nStayton, C. T. (2015). What does convergent evolution mean? The interpretation of\nconvergence and its implications in the search for limits to evolution. Interface\nFocus 5:20150039. doi: 10.1098/rsfs.2015.0039\nStrausfeld, N. J. (2012). Arthropod Brains: Evolution, Functional Elegance, and\nHistorical Signiﬁcance . Cambridge, MA: Belknap Press of Harvard University\nPress.Szõnyi, A., Zichó, K., Barth, A. M., Gönczi, R. T., Schlingloﬀ, D., Török, B., et al.\n(2019). Median raphe controls acquisition of negative experience in the mouse.\nScience 366:eaay1094. doi: 10.1126/science.aay8746\nTaiz, L., Alkon, D., Draguhn, A., Murphy, A., Blatt, M., Thiel, G., et al. (2020).\nReply to Trewavas et al. and Calvo and Trewavas. Trends Plant Sci. 25, 218–220.\ndoi: 10.1016/j.tplants.2019.12.020\nTeller, P. (2011). “Subjectivity and knowing what it’s like, ” in Emergence or\nReduction? Essays on the Prospects of Nonreductive Physicalism , eds A.\nBeckermann, H. Flohr, and J. Kim (New York, NY: Walter de Gruyter),\n180–200.\nThompson, E. (2007). Mind in Life: Biology, Phenomenology and the Sciences of\nMind . Cambridge, MA: Harvard University Press.\nTononi, G., and Koch, C. (2015). Consciousness: here, there and everywhere?\nPhilos. Trans. R. Soc. B Biol. Sci. 370:20140167. doi: 10.1098/rstb.2014.\n0167\nTrestman, M. (2013). The Cambrian explosion and the origins of embodied\ncognition. Biol. Theory 8, 80–92. doi: 10.1007/s13752-013-0102-6\nTschacher, W., and Haken, H. (2007). Intentionality in non-equilibrium systems?\nThe functional aspects of self-organized pattern formation. New Ideas Psychol.\n25, 1–15. doi: 10.1016/j.newideapsych.2006.09.002\nTsuchiya, N., and Koch, C. (2008). “The relationship between consciousness and\nattention, ” in The Neurology of Consciousness: Cognitive Neuroscience and\nNeuropathology , eds G. Tononi and S. Laureys (Oxford: Elsevier Academic),\n63–78.\nTsuchiya, N., and Van Boxtel, J. J. (2013). Introduction to research topic: attention\nand consciousness in diﬀerent senses. Front. Psychol. 4:249. doi: 10.3389/fpsyg.\n2013.00249\nTye, M. (2002). Consciousness, Color, and Content . Cambridge, MA: MIT Press.\nVan Gulick, R. (2001). Reduction, emergence and other recent options on the\nmind/body problem. A philosophic overview. J. Conscious. Stud. 8, 1–34.\nVan Kranendonk, M. J., Deamer, D. W., and Djokic, T. (2017). Life springs. Sci.\nAm. 317, 28–35.\nVelmans, M. (1991). Consciousness from a ﬁrst-person perspective. Behav. Brain\nSci.14, 702–719.\nVelmans, M. (2008). Reﬂexive monism. J. Conscious. Stud. 15, 5–50.\nWatson, T. (2019). The trickster microbes shaking up the tree of life. Nature 569,\n323–324. doi: 10.1038/d41586-019-01496-w\nWitherington, D. C. (2011). Taking emergence seriously: the centrality of circular\ncausality for dynamic systems approaches to development. Hum. Dev. 54,\n66–92. doi: 10.1159/000326814\nConﬂict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be construed as a\npotential conﬂict of interest.\nCopyright © 2020 Feinberg and Mallatt. This is an open-access article distributed\nunder the terms of the Creative Commons Attribution License (CC BY). The use,\ndistribution or reproduction in other forums is permitted, provided the original\nauthor(s) and the copyright owner(s) are credited and that the original publication\nin this journal is cited, in accordance with accepted academic practice. No use,\ndistribution or reproduction is permitted which does not comply with these terms.\nFrontiers in Psychology | www.frontiersin.org 15 June 2020 | Volume 11 | Article 1041"
    }
  ]
}