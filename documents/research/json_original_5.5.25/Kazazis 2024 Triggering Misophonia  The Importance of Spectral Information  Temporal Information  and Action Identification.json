{
  "doc_type": "scientific paper",
  "title": "Triggering Misophonia  The Importance of Spectral Information  Temporal Information  and Action Identification",
  "authors": [
    "Kazazis"
  ],
  "year": 2024,
  "journal": "journalInformation?journalCode=rpac20Auditory Perception & Cognition",
  "doi": "10.1080/25742442.2024.2302295",
  "abstract": null,
  "keywords": [
    "Misophonia",
    "action"
  ],
  "research_topics": [
    "Misophonia",
    "action"
  ],
  "created_at": "2025-05-04T23:30:35.934022Z",
  "source_pdf": "documents/research/Global/Kazazis 2024 Triggering Misophonia  The Importance of Spectral Information  Temporal Information  and Action Identification.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Full Terms & Conditions of access and use can be found at\nhttps://www.tandfonline.com/action/journalInformation?journalCode=rpac20Auditory Perception & Cognition\nISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/rpac20\nTriggering Misophonia: The Importance of Spectral\nInformation, Temporal Information, and Action\nIdentification\nSavvas Kazazis, Iza Korsmit & Stephen McAdams\nTo cite this article:  Savvas Kazazis, Iza Korsmit & Stephen McAdams (08 Jan 2024): Triggering\nMisophonia: The Importance of Spectral Information, Temporal Information, and Action\nIdentification, Auditory Perception & Cognition, DOI: 10.1080/25742442.2024.2302295\nTo link to this article:  https://doi.org/10.1080/25742442.2024.2302295\n© 2024 The Author(s). Published by Informa\nUK Limited, trading as Taylor & Francis\nGroup.\nPublished online: 08 Jan 2024.\nSubmit your article to this journal \nView related articles \nView Crossmark data"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "Triggering Misophonia: The Importance of Spectral \nInformation, Temporal Information, and Action Identification\nSavvas Kazazisa,b,c, Iza Korsmitc and Stephen McAdamsc\naFaculty of Fine Arts, School of Music Studies, Aristotle University of Thessaloniki, Thessaloniki, Greece; \nbDepartment of Informatics and Telecommunications, National and Kapodistrian University of Athens, \nAthens, Greece; cSchulich School of Music, McGill University, Montreal, Canada\nABSTRACT\nMisophonia is characterized by severe negative emotional \nresponses to specific environmental sounds. In this experiment, \nwe investigated the importance of spectral and temporal acoustic \ninformation, as well as the role of action identification (e.g., chew -\ning) in triggering misophonia. Eighteen participants with severe \nmisophonia completed the experiment. In total, three stimulus \nsets were used: the first set consisted of recorded sounds that \nwere either common misophonic triggers or neutral sounds that \nare not expected to trigger misophonia; the other two sets were \neach generated by applying temporal and spectral modifications to \nthe unmodified (recorded) stimulus set. Participants rated how \ntriggered they were by each sound (i.e., aversiveness) and were \nasked to identify the action category of each sound. The unmodi -\nfied trigger sounds were rated to be more aversive than neutral \nsounds (p < 0.0001). The main effects of modification type and \nidentification on aversiveness of trigger sounds were significant \n(p = 0.0001 and p = 0.006, respectively), but their interaction was \nmarginally significant (p = 0.053). Although the unmodified and \ntemporally modified sounds were not significantly different from \neach other (p = 0.4), spectrally modified sounds were rated signifi -\ncantly less aversive than both the temporally modified (p = 0.003) \nand unmodified sounds (p = 0.001). Regarding identification, the \nsounds that were incorrectly identified were on average rated as \nless aversive than the correctly identified sounds (p = 0.006). \nFurthermore, the interaction shows that the identification effect \nwas largest for the spectrally modified sounds. This shows that \nboth identification and spectral information play an important \nrole in triggering misophonia.ARTICLE HISTORY \nReceived 29 January 2023  \nAccepted 22 December 2023 \nKEYWORDS \nMisophonia; action \nidentification; spectral \ninformation; temporal \ninformation; psychological \ndisorders\nIntroduction\nMisophonia is a psychological disorder that is characterized by severe aversive responses \nto specific environmental sounds (i.e., triggers). Although there are many idiosyncrasies \nin what may trigger a person with misophonia, the most common triggers are created by \nCONTACT Savvas Kazazis \n savvas.kazazis@mail.mcgill.ca \n Faculty of Fine Arts, School of Music Studies, Aristotle \nUniversity of Thessaloniki, University Campus, Thessaloniki 54124, GreeceAUDITORY PERCEPTION & COGNITION               \nhttps://doi.org/10.1080/25742442.2024.2302295\n© 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.  \nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/ \nlicenses/by/4.0/ ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly \ncited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or \nwith their consent."
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "other humans, such as the sound of someone chewing, clearing their throat, tapping their \nfoot, or typing on a keyboard. Given the high prevalence of such sounds in everyday life, \nhaving misophonia can have large negative effects on one’s functioning in personal, \nacademic, and work environments. Wang et al. (2022 ) found that anxiety and depression \nsymptoms, negative beliefs about emotions, and disgust sensitivity were related either to \nthe functional impact of misophonia or to misophonic outbursts (Vitoratou et al., 2021 ).\nThe disorder is not yet recognized by the Diagnostic and Statistical Manual − 5th \nversion (DSM-5; American Psychiatric Association, 2013 ), but there has been an increas -\ning amount of research on the characterization and treatment of misophonia (Vitoratou \net al., 2021 ; see also Brout et al., 2018 , for a review). Recently, Rosenthal et al. (2022 ) \ninvestigated the relationship between misophonia and psychiatric disorders in the DSM- \n5. They found that among the disorders that were correlated with misophonia, the most \nsignificant predictors of misophonia severity were borderline personality disorder, \nobsessive compulsive disorder, and panic disorder.\nResearch has shown that misophonia manifests itself on a physiological, neurophy -\nsiological, and neurobiological basis. Both the subjective judgment of aversiveness and \nthe physiological measure of skin conductance response (SCR) increase when people \nwith misophonia are presented with triggers (Edelstein et al., 2013 ). Furthermore, an \nEEG study showed that the N1-component, which is related to auditory attention and \nsound detection, was diminished for misophonics in response to unexpected (oddball) \nsounds compared to control participants (Schröder et al., 2014 ). Furthermore, an fMRI \nstudy found that people with misophonia show increased response in the anterior insular \ncortex (AIC) in response to misophonic sounds, compared to control participants and \nother unpleasant or neutral sounds (Kumar et al., 2017 ). They also show increased \nconnectivity between the AIC and the default mode network (DMN): the AIC is related \nto the salience that people attribute to environmental stimuli (Seeley et al., 2007 ) as well \nas visceral emotions (Craig, 2009 ), such as the processing of disgusting stimuli (see, for \ninstance, Kober et al., 2008 ); the DMN is related to memory recall and internal thoughts \n(Raichle et al., 2001 ). Consequently, the increased AIC reactivity may be causing intense \nvisceral emotions, and the AIC-DMN connectivity may be interpreted as an increased \nsalience attributed to environmental sounds due to associative learning and memory. \nBoth AIC and DMN function may potentially be linked to the identification of the source \nof the sound, an aspect we address in our study.\nAlthough it has been suggested that misophonia is mainly an auditory disorder \nthat affects auditory processing in the early stages (Schröder et al., 2014 ), misophonics \ncan also be triggered by visual cues (Brout et al., 2018 ). Samermit et al. (2022 ) \nexamined whether misophonic responses can be modulated by visual cues. Using \na sound-swapped video database, they found that when trigger sounds were paired \nwith “positive attributable video sources,” they were rated as significantly less unplea -\nsant than when they were paired with the original video sources. During interviews \nthat Edelstein et al. (2013 ) conducted with misophonics, some people reported that \nthey react less severely or not at all when their trigger sounds are produced by \nanimals or infants. Moreover, they report especially aversive responses to trigger \nsounds produced by family and friends, but less aversive responses when the sounds \nare produced by strangers or even themselves, further suggesting a role of sound \nsource identification. Indeed, a later study by Edelstein et al. (2020 ) found that 2\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "incorrect identification or incorrect text descriptions accompanying trigger sounds \nchanged the subjective aversiveness of those sounds. This indicates that misophonia is \nnot a purely auditory processing disorder but is also influenced by a top-down \nprocess of source identification. More recently, Heller and Smith (2022 ) found that \nthe identification of spectrally degraded sounds had an effect on participants’ plea-\nsantness ratings of everyday sounds. This study did not include exclusively misopho -\nnic participants, although a few common misophonic triggers were used. A similar \neffect of spectral degradation could potentially be found on the experienced (un) \npleasantness of trigger sounds in a strictly misophonic population sample as was \ninvestigated in the current study.\nWe consider both the effects of top-down identification, as well as bottom-up auditory \nattention in terms of spectral and temporal acoustic information. We present an experi -\nment that exclusively addressed misophonic participants. First, we investigate the impor -\ntance of spectral and temporal acoustic information in triggering misophonia. We test \nwhether and the extent to which spectral and temporal modifications of trigger sounds \nadd to or attenuate the feelings of aversiveness. We do not have a hypothesis as to \nwhether the spectral or the temporal information of sound events is more important in \ntriggering misophonia. We also test whether action identification (e.g., chewing, slurp -\ning, typing, etc.) of original recorded sounds and spectral or temporal modifications of \nthose sounds affects the severity of misophonic response. Our main hypothesis concerns \nonly misophonic trigger sounds: we hypothesize that incorrect identification will attenu -\nate the severity of aversive responses to these sounds.\nMethods\nParticipants\nParticipants were recruited online through misophonia support groups on Facebook. \nThey filled out a pre-screening questionnaire (Misophonia Assessment Questionnaire; \nMAQ, see materials) and were selected to complete the main experiment if their score \nclassified them to have at least moderate misophonia. The pre-screening questionnaire \nwas completed by 33 participants, of which three were rejected because of low MAQ \nscores. From the 30 invited participants, only 18 (16 female) with an average age of 36.1  \nyears (SD = 14.1; range: 19–61) were willing to proceed and completed the main experi -\nment. Their average MAQ score was 44.83 out of 63 (SD = 10.5), which would be \nclassified as severe misophonia. Participants were also instructed to complete the \nAmsterdam Misophonia Scale questionnaire (A-MISO-S; see Materials ) at the end of \nthe experiment. Their average A-MISO-S score was 15.44 out of 24 (SD = 2.66), which \nagain classifies them as severe misophonics.\nEight participants resided in the United States; two each were from Canada, the \nUnited Kingdom, the Netherlands, and Belgium; followed by one participant from \nGermany and one from South Africa. Three participants reported auditory disorders of \ntinnitus and hyperacusis. Seven participants reported comorbid psychological disorders \nof anxiety, obsessive compulsive disorder, and depression. It is also worth noting that \n50% of the participants reported that they have experienced Autonomous Sensory AUDITORY PERCEPTION & COGNITION\n 3"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "Meridian Response (ASMR), as has been reported by previous studies as well (Rouw & \nErfanian, 2018 ). Participants were compensated for their time through PayPal.\nMaterials\nQuestionnaires\nParticipants filled out the Misophonia Assessment Questionnaire (MAQ; Dozier, 2015 ) \nas a pre-screening test. It contains 21 items about the negative impact of misophonia on \none’s activities, thoughts, and feelings, which are rated on a Likert-scale from 0 (not at all) \nto 3 (almost all the time). Scores can range from 0 to 63. Johnson (2014 , as cited by \nDozier, 2015 ) classified a score of 0–21 as mild, 22–42 as moderate, and 43–63 as severe \nmisophonia. Consequently, all participants that scored 22 or higher on the MAQ were \ninvited to participate in the main experiment. Additionally, in the pre-screening experi -\nment we asked participants the types of sounds they are usually triggered by. They could \ntick the boxes of “Eating or drinking sounds (e.g., eating an apple),” “Respiratory sounds \n(e.g., sniffling),” “Tapping sounds (e.g., typing),” “Material sounds (e.g., plastic),” or \n“Other” with the option to fill in other triggers. This was to ensure that the participants \nwere triggered by the types of sounds that we included in the experiment, and not merely \nby a very specific sound that was not included.\nAfter the listening task of the main experiment, participants filled out demographic \nquestions concerning their age, country of residence, gender identity, biological sex, \nhearing issues, and comorbid psychological disorders. We asked them whether the action \nsounds included in the experiment were habitually triggering for them and also triggered \nthem in the experiment to further confirm that our stimuli caused a misophonic \nresponse. Additionally, we asked the participants from what age their misophonia started \nand whether any of their family members suffered from misophonia. Finally, we \ndescribed the phenomenon of ASMR, asked participants if they had ever experienced \nthe phenomenon, and to describe which, if any, sounds elicited the response.\nIn addition to the pre-screening MAQ, in the post-experiment survey participants \nfilled out the Amsterdam Misophonia Scale (A-MISO-S; Schröder et al., 2013 ) and the \nMisophonia Coping Responses questionnaire (MCR; Dozier, 2015 ). We wanted to \ninclude several misophonia scales, as there are no validated misophonia assessment \nquestionnaires, and this allowed us to corroborate our findings on the severity of \nmisophonia in our participant pool. The A-MISO-S measures the severity of misophonia \nsymptoms with six items that are rated on a multiple-choice scale that scores zero to four. \nTotal scores can range from zero to 24, with a score between 0–4 considered as \nsubclinical misophonia, 5–9 as mild, 10–14 moderate, 15–19 severe, and 20–24 extreme \nseverity of misophonia symptoms. The MCR measures the coping mechanisms of people \nwith misophonia when they are confronted with trigger sounds. It contains 22 items that \nare rated on the same scales as the MAQ. There are no classifications available for the \nMCR, but scores can range from zero to 66.\nStimuli\nIn total, three stimulus sets were used. The first set consisted of recorded sounds that \nwere either common misophonic triggers or neutral sounds that are not expected to \ntrigger misophonia. Table 1 lists all the stimuli (organized in categories of trigger and 4\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "neutral sounds) along with their respective action labels that describe the physical action \nthat produced the sound. The sounds were recorded in the acoustically treated sound- \nisolation labs of the Centre for Interdisciplinary Research in Music Media and \nTechnology (CIRMMT). Two microphones were placed in close and distant positions \n(approximately 12 in and 30 in, respectively) from the sound sources leading to two \ndifferent recording sets. After listening to comparisons between the two recording sets, \nwe decided to use only the distant recordings, because they sounded more natural with \nrespect to everyday listening conditions. For instance, in some cases the close-miked \nrecordings sounded as if someone was chewing right inside one’s ears. The recording \nequipment consisted of two Neumann U87 condenser microphones, which were inter -\nfaced through an RME Audio Fireface UFX. The outputs of each microphone were \nmonitored by two people through two Sennheiser HD280 headphones.\nThe second stimulus set was generated by applying temporal modifications on the \nunmodified (i.e., as recorded) stimulus set. Temporal modifications were achieved by \nsegmenting the audio signal into short overlapping frames of 25 ms and shuffling them \nover a radius of 250 ms. The amount of overlap was set to 50% and the frames were \nHann-windowed. The shuffling was performed by a random permutation of the frames \n(within the given radius) without replacement. The permutation was conditioned by \na Gaussian probability distribution which controls the difference between the original \nand final frame positions (Ellis, 2010 ). This minimizes possible audible artifacts that \nwould result from large displacements from the original frame positions (e.g., if \na uniform probability distribution was used instead). The standard deviation of the \ndistribution was empirically set to 16 (frame indices) after informal listening tests Table 1. List of stimuli and their respective categories and action \nlabels.\nStimulus Name Category Action Label\nAlmonds Misophonic Chewing\nApple Misophonic Chewing\nBanana Misophonic Chewing\nChips Misophonic Chewing\nNoodles Misophonic Chewing\nSoup Misophonic Slurping\nStraw Misophonic Slurping\nNose Sniffling Misophonic Respiration\nSnoring Misophonic Respiration\nSighing Misophonic Respiration\nPlastic Crinkling Misophonic Crinkling\nSwallowing Drink Misophonic Drinking\nTyping Keyboard Misophonic Typing\nApple Pealing Neutral Pealing\nBrushing Hair Neutral Brushing Hair\nCrashing Plastic Neutral Crushing Plastic\nDoor Creaking Neutral Creaking Door\nFlipping Pages Neutral Handling Paper\nRipping Paper Neutral Handling Paper\nPouring Lentils Neutral Handling Dried Beans\nStirring Lentils Neutral Handling Dried Beans\nShaking Water Bottle Neutral Shaking Liquid\nTwisting Bottle Cap Neutral Opening Bottle\nWriting Marker Neutral Writing on Paper\nWriting Pen Neutral Writing on Paper\nZipper Neutral ZippingAUDITORY PERCEPTION & COGNITION\n 5"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "conducted among the authors. The resynthesis was performed by overlap-add. Overall, \nthis process preserved the short-term average spectrum (over the 250-ms radius) but \ndistorted the global amplitude envelope (Figure 1).\nThe third stimulus set was generated by applying spectral modifications on the \nunmodified stimulus set. Spectral modifications were achieved through spectral whiten -\ning while preserving the global amplitude envelope. This was done by first estimating the \nspectral envelope of the input signal on 20-ms frames through a 13th-order Linear \nPredictive Coding (LPC) model. The signal was resynthesized by feeding white noise \n(instead of the original excitation signal) into the filter’s structure and the amplitude \nenvelope was controlled by the gain of the filter. The code for analyzing and resynthesiz -\ning the signal was adopted from Slaney’s Auditory Toolbox (Slaney, 1998 ). Overall, this \nprocess had the effect of removing the spectral fine structure of the input signal through \nwhitening while preserving its global amplitude envelope (within 20-ms frames) through \nthe time-varying gain of the filter (Figure 1).\nAll stimuli (including the unmodified stimulus set) had a duration of 10 s and were \nhigh-pass filtered with an 80-Hz cutoff frequency to reduce audible artifacts caused by \nthe modification processes. The last processing stage was loudness normalization, which \nwas implemented according to the algorithm of Moore et al. (1997 ). All stimuli were \nprocessed and synthesized in MATLAB (The MathWorks, Inc., Natick, MA).\nProcedure\nThe pre-screening and main experiment were executed online, hosted on secure servers \nat McGill University. Before the experiment, participants gave informed consent. As \nmentioned above, only participants with a MAQ score of at least 22 were selected to \nproceed to the main experiment. The experimental instructions required participants to \nFigure 1. Spectrograms (top) and respective waveforms (bottom) of the first two seconds of the \nstimulus set “almonds”.6\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "have normal hearing thresholds; use a laptop or desktop computer; use headphones or \nearphones, be inside a quiet room, and not currently be taking medical or recreational \ndrugs that affect wakefulness and vigilance. Before the main trials, participants were \nasked to adjust the volume of their headphones/earphones to a comfortable listening \nlevel according to a reference sound sample. They were further instructed to not change \nthis level throughout the experiment.\nIn each trial, participants were first presented with a stimulus and then were \nasked to rate with a slider “How effectively does this sound trigger misophonia for \nyou?” The rating scale was a continuous 9-point analogical-categorical scale (Weber,  \n1991 ) and the two extremes were labeled as “Not effectively” and “Very effectively”. \nAfterwards, they were asked to “Identify the action that produced the sound” \nthrough a drop-down menu that displayed all the action labels listed in Table 1. \nIdentification was deemed correct whenever the participant’s answer matched the \n“Action Label” of the respective “Stimulus Name,” as shown in Table 1. No feedback \nwas provided on the correctness of participants’ responses. Participants were \nallowed to play back each stimulus as many times as they wished prior to making \ntheir judgments. The two tasks were presented in consecutive screens and partici -\npants were not able to go back from the identifying task to the rating task (i.e., they \ncould not adjust their rating after identifying the action).\nThe presentation order of each stimulus was randomized across all stimulus categories \nand for each participant. At the end of the experimental session, participants were asked \nto fill in the post-experimental survey as described in the Materials section. The total \nduration of the experiment was approximately 1 hour.\nData Analysis\nAll statistical analyses were conducted in R version 4.2.1 (www.r-project.org ). For the \nShapiro-Wilk test we used the shapiro_test function from the rstatix library (Kassambara,  \n2023 ) on the aversiveness ratings grouped by stimulus category, modification, and \nidentification. For the non-parametric Wilcoxon signed-rank test, we used the inbuilt \nwilcox.test function, and the wilcox_effectsize from the rstatix library to test the r effect \nsize. The linear mixed model (LMM) was implemented using the lmer function with the \nbobyqa optimizer from the lmerTest package (Kuznetsova et al., 2020 ). Eta-squared is not \na reliable statistic for evaluating a local effect size (i.e., a particular main effect) in mixed- \neffects models because of the presence of random effects (and therefore shared/parti -\ntioned variance). Post-hoc analyses were done with the emmeans function to calculate the \nestimated means, and the eff_size function to calculate the Cohen’s d, both from the \nemmeans package (Lenth et al., 2022 ). In the absence of appropriate effect size measures \nfor LMMs, Cohen’s d in the post-hoc contrasts should give a sufficient idea of effect sizes. \nFor the independent factorial ANOVA, we used the inbuilt aov function, and the \npartial_eta_squared function from the rstatix library to calculate the η2\np effect size. \nPlanned contrasts were defined with the inbuilt contrasts function. With respect to the \nsound modification effect, the first contrast compared the unmodified sounds to both the \nspectrally and temporally modified sounds. Then, a second contrast compared the \nspectrally and temporally modified sounds to each other. Effect sizes are reported only \nfor statistically significant results (p ≤0.05).AUDITORY PERCEPTION & COGNITION\n 7"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "Results\nDue to the relatively small number of participants, we investigated the normality \ndistribution of the variable combinations in order to determine the appropriate statistical \nmethods. Shapiro-Wilk tests showed that the rating distributions for all combinations of \nstimulus category (i.e., misophonic or neutral stimulus), modification (i.e., unmodified, \nspectral, or temporal), and identification (i.e., correct or incorrect) showed evidence of \nnon-normality (all p < .01). For this reason, and due to the unbalanced design of the \nexperiment (i.e., number of correct versus incorrect identification responses), we used \nlinear mixed modeling (LMM) to predict the aversiveness ratings of misophonic triggers, \nand to test for the main and interaction effects of modification type and identification.\nSince our main hypothesis concerns only (misophonic) trigger sounds, the effective -\nness of trigger manipulation on the aversiveness ratings of the unmodified stimulus set \nwas studied first (Figure 2). The non-parametric Wilcoxon signed-rank test showed that \nthe group of sounds which were categorized a priori as trigger sounds (Table 1) were \nindeed rated significantly higher (i.e., as more aversive; M = 5.04, SD = 3.30) than the \nneutral sounds (M = 2.20, SD = 2.40; Z = −18.77, p < .0001, r = .43). Therefore, the follow -\ning analysis concerns only the groups of trigger sounds within each stimulus set.\nAfter experimenting with different LMM effect structures, we selected the model that \nperformed the best in terms of the Akaike Information Criterion (AIC), Bayesian \nInformation Criterion (BIC), and log likelihood.1 The employed model had the following \nstructure: the aversiveness ratings of the misophonic stimuli were set as the dependent \nvariable; the fixed effects consisted of modification type and identification correctness \n(the latter coded as a binary variable per participant and per stimulus), along with their \nFigure 2. Mean and standard error of aversiveness ratings separated by stimulus category and \nmodification type.8\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "interaction; random intercepts were used per participant, and per stimulus; random \nslopes were used for both modification type and identification per participant.\nWe conducted Type III Wald F-tests to analyze the main and interaction effects of the \nLMM. The main effects of modification type, F(2, 51.85) = 11.04, p = .0001, and identi -\nfication, F(1, 19.87) = 9.69, p = < .006, were found to be significant. The interaction effect \nbetween these two variables was marginally significant, F(2, 641.88) = 2.96, p = .053. With \nrespect to modification type, Bonferroni-corrected post-hoc comparisons showed that \nalthough there was no significant difference between the aversiveness ratings of the \nunmodified stimuli (estimated M = 6.01, SE = 0.60) and temporally modified stimuli \n(estimated M = 5.32, SE = 0.60), the spectrally modified stimuli (estimated M = 3.40, \nSE = 0.53) were rated as significantly less aversive than both the unmodified, \nt(48.5) = 4.61, p = .0001, Cohen’s d = 1.62 (hereafter reported as d), and temporally \nmodified stimuli, t(39.9) = −3.61, p = .003, d = −1.19. With respect to the identification \neffect, the correctly identified stimuli (estimated M = 5.64, SE = 0.53) were overall rated \nas significantly more aversive, t(20.1) = 3.11, p = .006, d = 0.96, than the incorrectly \nidentified stimuli (estimated M = 4.18, SE = 0.56).\nRegarding the interaction between modification type and identification (correct vs. \nincorrect), the identification effect (i.e., the differences in aversiveness ratings between \ncorrectly and incorrectly identified stimuli) per modification type was significant for \nboth the spectral and temporal modifications, t(28.6) = 3.96, p = .0004, d = 1.26; and \nt(26.4) = 2.18, p = .004, d = 0.68, respectively. However, for the unmodified stimuli, the \nidentification effect was marginally significant, t(62) = 1.97, p = .05, d = 0.77. As can also \nbe inferred from Figure 3, the identification effect was largest for the spectrally modified \nstimuli, followed by the unmodified and temporally modified stimuli. However, only the \ndifference in identification effect between the spectral and temporal modifications was \nfound to be marginally significant (t(638) = 2.38, p = .05, d = 1.87), whereas the rest were \ninsignificant (p > .3).\nFigure 3. Boxplot of aversiveness ratings separated by stimulus category, modification type, and \nidentification. Plots show the median (box midline), first and third quartile (box outlines), minimum \n(Q1–1.5*IQR) and maximum (Q3 + 1.5*IQR) scores (whiskers), and outliers (dots).AUDITORY PERCEPTION & COGNITION\n 9"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "As a more general remark, we investigated the stimuli’s proportion of correct \nidentification, i.e., the proportion of participants that correctly identified each \nstimulus. An independent factorial ANOVA with the proportion correct identifi -\ncation as dependent variable and stimulus category (misophonic/neutral) and \nmodification as independent variables showed that the difference in proportion \ncorrect identification between the misophonic and neutral stimulus sets (Figure 4) \nwas not significant, F(1, 72) = 1.89, p = .17. However, there was an effect of \nmodification type, F(2, 72) = 20.71, p < .0001, η2\np = .37, where the planned contrasts \nshowed that proportion correct identification was higher for the unmodified \nsounds compared to both the spectral and temporal modifications, t(72) = −5.95, \np < .0001, d = −1.43. The proportion correct identification was also slightly higher \nfor the temporal than the spectral modifications, t(72) = −2.46, p =.02, d = −0.68. \nThere was no significant interaction between the stimulus category and modifica -\ntion, F(2, 72) = 1.06, p = .35.\nDiscussion\nThe main purpose of this experiment was to test whether action identification plays a role \nin evoking misophonic responses and the extent to which these relate to spectral and \ntemporal stimulus information. To this end, we modified recorded stimuli that are \ngenerally considered to be triggers while aiming to preserve either their spectral or \ntemporal similarities to the recorded sounds.\nPost-hoc tests related to modification type show that temporal modifications of 25-ms \nframes within a 250-ms radius did not reduce aversiveness responses compared to the \nunmodified stimuli. It can therefore be concluded that spectral information averaged \nFigure 4. Mean and standard error of proportion correct identification separated by stimulus category \nand modification type.10\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "over 250 ms is important in triggering misophonia, and that the random temporal micro- \nfluctuations over 25-ms frames (or longer) did not statistically affect the misophonic \nresponses compared to the unmodified stimuli. In addition, given that the identification \neffect on temporally modified stimuli was significant (although weak) and that there was \na relatively high proportion of correct identification of temporally modified trigger \nsounds (65.8%; Figure 4), it can be concluded that both spectral information and action \nidentification contributed to high aversiveness ratings.\nThis is further supported by the results obtained from spectral modifications. \nPreserving the temporal information, and therefore any repetitive patterns of the unmo -\ndified stimuli over 20-ms frames while whitening the signal, significantly reduced the \naversiveness ratings to a level similar to the neutral stimulus sets (Figure 2). This leads \nagain to the conclusion that spectral information is more important than the temporal \norganization of amplitude micro-fluctuations in triggering misophonia. The identifica -\ntion effect of this modification type was the largest, although percent correct action \nidentification was relatively poor (34.6%; Figure 4). Nonetheless, correct identification of \nthese stimuli significantly increased the aversiveness ratings (Figure 3). In general, these \nresults are also similar to those obtained by Heller and Smith (2022 ) according to which \nspectral degradations made the sounds more neutral across their “Positive” and \n“Negative” valence groups of sounds. The authors attributed this effect to the high rate \nof misidentification and uncertainty about the sounds’ causal properties (e.g., with \nrespect to actions, such as impact sounds, or to the geometric/material properties of \nthe object).\nAlthough we acknowledge that the interaction effects between modification type and \nidentification were marginally significant (p = .05), we believe that the reported results \noffer additional insights and complete the picture of the present analysis. The marginally \nsignificant p-value of the interaction effect is probably due to the relatively small number \nof participants and the high variance of ratings, especially with respect to the incorrect \nidentifications of the unmodified stimulus set (Figure 3). The unmodified stimulus set \ncan be thought of as a control set in which action identification should not play a role at \nall. In fact, almost all participants were able to correctly identify the action labels of the \nunmodified stimuli (92.7% correct identification of trigger sounds, 82.1% correct identi -\nfication of neutral sounds; Figure 4). We attribute the high variance of the aversiveness \nratings of the unmodified stimulus set (see right panel of Figure 3) to systematic \nmisidentification: for instance, a participant may have consistently misidentified \na stimulus as “Chewing” whereas the experimenters had labeled it as “Slurping,” as in \nthe “Noodles” stimulus label (Table 1). Nonetheless, the weak p-value of .05 and the small \nnumber of participants due to the difficulty of recruiting moderate to severe misophonic \nparticipants notwithstanding, the overall conclusion of the present analysis is that both \naction identification and spectral information play an important role in triggering \nmisophonia.\nThe results are consistent with our initial hypothesis regarding action (or source) \nidentification and support the findings reported by Edelstein et al. (2020 ) according to \nwhich incorrect identification of trigger sounds changed the subjective aversiveness of \nthose sounds. The spectrally modified sounds reduced the misophonic responses, which \nsuggests that this type of modification acted as a “neutralizer” for the misophonic \nstimulus set (Figure 2). Similar results were reported by Heller and Smith (2022 ) with AUDITORY PERCEPTION & COGNITION\n 11"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "respect to pleasantness ratings of everyday sounds. On a final note, we do not claim that \ntemporal information is unrelated to action identification. The present analysis concerns \nonly the aforementioned type of temporal modification on misophonic sounds. \nExamining the importance of individual amplitude and frequency modulation rates is \ncurrently under investigation.\nNote\n1. The results of this report are slightly different from the results presented in the extended \nabstract of the 21st Annual Auditory Perception, Cognition & Action Meeting (APCAM) \ndue to differences between the employed LMM effect structures.\nAcknowledgments\nWe would like to thank Xin Wang and Valentijn Nieman for their help during the recording \nsessions and Bennett K. Smith for setting up the online experiment and for programming the user \ninterface.\nDisclosure statement\nNo potential conflict of interest was reported by the author(s).\nFunding\nThis project was partially funded by CIRMMT Student Awards to SK and IK and a Canadian \nNatural Sciences and Engineering Discovery Grant [RGPIN-2020-04022] and a Canada Research \nChair [950-231872] to SMc.\nReferences\nAmerican Psychiatric Association. (2013 ). Diagnostic and statistical manual of mental disorders \n(5th ed.). American Psychiatric Publishing.\nBrout, J. J., Edelstein, M., Erfanian, M., Mannino, M., Miller, L. J., Rouw, R., Kumar, S., & \nRosenthal, M. Z. (2018 ). Investigating misophonia: A review of the empirical literature, clinical \nimplications, and a research agenda. Frontiers in Neuroscience , 12, 36. https://doi.org/10.3389/ \nfnins.2018.00036  \nCraig, A. D. (2009 ). Emotional moments across time: A possible neural basis for time perception in \nthe anterior insula. Philosophical Transactions of the Royal Society B: Biological Sciences , 364 \n(1525), 1933–1942. https://doi.org/10.1098/rstb.2009.0008  \nDozier, T. H. (2015 ). Counterconditioning treatment for misophonia. Clinical Case Studies , 14(5), \n374–387. https://doi.org/10.1177/1534650114566924  \nEdelstein, M., Brang, D., Rouw, R., & Ramachandran, V. S. (2013 ). Misophonia: Physiological \ninvestigations and case descriptions. Frontiers in Human Neuroscience , 7, 296. https://doi.org/ \n10.3389/fnhum.2013.00296  \nEdelstein, M., Monk, B., Ramachandran, V. S., & Rouw, R. (2020 ). Context influences how \nindividuals with misophonia respond to sounds. bioRxiv , Preprint. https://doi.org/10.1101/ \n2020.09.12.292391  \nEllis, D. P. W. (2010 ). Time-domain scrambling of audio signals in Matlab . Retrieved January 16, \n2023, from http://www.ee.columbia.edu/~dpwe/resources/matlab/scramble/ 12\n S. KAZAZIS ET AL."
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "Heller, L. M., & Smith, J. M. (2022 ). Identification of everyday sounds affects their pleasantness. \nFrontiers in Psychology , 13, 894034. https://doi.org/10.3389/fpsyg.2022.894034  \nJohnson, M. (2014 ). 50 cases of misophonia using the MMP. Paper presented at the misophonia \nconference of the Tinnitus Practitioners Association, Atlanta, GA.\nKassambara, A. (2023 ). Rstatix: Pipe-friendly framework for basic statistical tests (0.7.2) . https:// \ncran.r-project.org/web/packages/rstatix/index.html \nKober, H., Barrett, L. F., Joseph, J., Bliss-Moreau, E., Lindquist, K., & Wager, T. D. (2008 ). Functional \ngrouping and cortical–subcortical interactions in emotion: A meta-analysis of neuroimaging \nstudies. Neuroimage , 42(2), 998–1031. https://doi.org/10.1016/j.neuroimage.2008.03.059  \nKumar, S., Tansley-Hancoc, O., Sedley, W., Winston, J. S., Callaghan, M. F., Allen, M., Cope, T. E., \nGander, P. E., Bamiou, D. E., & Griffiths, T. D. (2017 ). The brain basis for misophonia. Current \nBiology , 27(4), 527–533. https://doi.org/10.1016/j.cub.2016.12.048  \nKuznetsova, A., Brockhoff, P. B., Christensen, R. H. B., & Jensen, S. P. (2020 ). lmerTest: Tests in \nlinear mixed effects models (3.1-3). https://CRAN.R-project.org/package=lmerTest \nLenth, R. V., Buerkner, P., Herve, M., Jung, M., Love, J., Miguez, F., Riebl, H., & Singmann, H. \n(2022 ). Emmeans: Estimated marginal means, aka Least-Squares means (1.8.0) . https://CRAN. \nR-project.org/package=emmeans \nMoore, B. C. J., Glasberg, B. R., & Baer, T. (1997 ). A model for the prediction of thresholds, \nloudness, and partial loudness. Journal of the Audio Engineering Society , 45(4), 224–240.\nRaichle, M. E., MacLeod, A. M., Snyder, A. Z., Powers, W. J., Gusnard, D. A., & Shulman, G. L. \n(2001 ). A default mode of brain function. Proceedings of the National Academy of Sciences , 98 \n(2), 676–682. https://doi.org/10.1073/pnas.98.2.676  \nRosenthal, M. Z., McMahon, K., Greenleaf, A. S., Cassiello-Robbins, C., Guetta, R., Trumbull, J., \nAnand, D., Frazer-Abel, E. S., & Kelley, L. (2022 ). Phenotyping misophonia: Psychiatric \ndisorders and medical health correlates. Frontiers in Psychology , 13, 941898. https://doi.org/ \n10.3389/fpsyg.2022.941898  \nRouw, R., & Erfanian, M. (2018 ). A large-scale study of misophonia. Journal of Clinical Psychology , \n74(3), 453–479. https://doi.org/10.1002/jclp.22500  \nSamermit, P., Young, M., Allen, A. K., Trillo, H., Shankar, S., Klein, A., Kay, C., Mahzouni, G., \nReddy, V., Hamilton, V., & Davidenko, N. (2022 ). Development and evaluation of a \nsound-swapped video database for misophonia. Frontiers in Psychology , 13, 890829. https:// \ndoi.org/10.3389/fpsyg.2022.890829  \nSchröder, A., van Diepen, R., Mazaheri, A., Petropoulos-Petalas, D., Soto de Amesti, V., \nVulink, N., & Denys, D. (2014 ). Diminished N1 auditory evoked potentials to oddball stimuli \nin misophonia patients. Frontiers in Behavioral Neuroscience , 8, 123. https://doi.org/10.3389/ \nfnbeh.2014.00123  \nSchröder, A., Vulink, N., Denys, D., & Fontenelle, L. (2013 ). Misophonia: Diagnostic criteria for \na new psychiatric disorder. PLoS One, 8(1), e54706. https://doi.org/10.1371/journal.pone.0054706  \nSeeley, W. W., Menon, V., Schatzberg, A. F., Keller, J., Glover, G. H., Kenna, H., Reiss, A. L., & \nGreicius, M. D. (2007 ). Dissociable intrinsic connectivity networks for salience processing and \nexecutive control. Journal of Neuroscience , 27(9), 2349–2356. https://doi.org/10.1523/ \nJNEUROSCI.5587-06.2007  \nSlaney, M. (1998 ). Auditory toolbox . Interval Research Corporation, Tech. Rep., 10. Retrieved \nAugust 6, 2023, from https://engineering.purdue.edu/~malcolm/interval/1998-010/ \nVitoratou, S., Uglik-Marucha, C., Hayes, E., & Gregory, J. (2021 ). Listening to people with \nmisophonia: Exploring the multiple dimensions of sound intolerance using a new psychometric \ntool, the S-Five, in a large sample of individuals identifying with the condition. Psych , 3(4), \n639–662. https://doi.org/10.3390/psych3040041  \nWang, Q., Vitoratou, S., Uglik-Marucha, N., & Gregory, J. (2022 ). Emotion processes predicting \noutbursts and functional impact in misophonia. Frontiers in Psychology , 13, 903142. https://doi. \norg/10.3389/fpsyg.2022.903142  \nWeber, R. (1991 ). The continuous loudness judgement of temporally variable sounds with an \n‘analog’ category procedure. In A. Schick, J. Hellbrück, & R. Weber (Eds.), Fifth Oldenburg \nSymposium on Psychological Acoustics (pp. 267–294). BIS.AUDITORY PERCEPTION & COGNITION\n 13"
    }
  ]
}