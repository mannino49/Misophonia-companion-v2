{
  "doc_type": "scientific paper",
  "title": "The Mnemonic Basis of Subjective Experience",
  "authors": [
    "Lau"
  ],
  "year": 2022,
  "journal": "neuroscience of memory, mental imagery, decision- making and emotions",
  "doi": null,
  "abstract": "| Conscious experiences involve subjective qualities, such as colours, sounds, smells and emotions. In this Perspective, we argue that these subjective qualities can be understood in terms of their similarity to other experiences. This account highlights the role of memory in conscious experience, even for simple percepts. How an experience feels depends on implicit memory of the relationships between different perceptual representations within the brain. With more complex experiences such as emotions, explicit memories are also recruited. We draw inspiration from work in machine learning as well as the cognitive neuroscience of learning and decision making to make our case and discuss how the account could be tested in future experiments. The resulting findings might help to reveal the functions of subjective experience and inform current theoretical debates on consciousness.",
  "keywords": [],
  "research_topics": [],
  "created_at": "2025-05-05T01:48:54.452753Z",
  "source_pdf": "documents/research/Global/Lau 2022 The Mnemonic Basis of Subjective Experience.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "0123456789();: Every conscious experience comes with \ndistinctive qualities, such as associated \ncolours, sounds, smells or emotions. \nWhat an experience feels like is called the ‘subjective quality’ or ‘subjective character’ of the experience. These subjective qualities \nare sometimes said to be ineffable. For \nexample, most people are familiar with the simple perceptual experience of seeing red. But it would be quite difficult to explain \nwhat it is like to see red to someone naive \nto this experience. If pressed to describe the experience, one would probably use comparative statements to relate it to other \nexperiences: “seeing red is a bit like seeing \npink or orange; it is a bit like seeing purple, more so than it is like seeing blue; it is nothing like seeing black, or white, ” and so \non. People use these comparative statements \namong similar experiences to tell others what it is like to have a particular experience.\nAccording to a relational or structural \naccount of conscious experience, the subjective character of a conscious experience can be exhaustively described by a set of precise comparative statements relative to all other possible experiences\n1–3. \nFor example, the subjective character \nof seeing red can be fully described by \nstatements relating red to other experiences, including all perceptible colours. These comparative statements might be difficult More complex experiences are likely \nto involve both explicit memories and \nimplicit memories. For example, some \npeople are familiar with the experience of tasting steamed grouper fish with soy sauce. Thinking about the qualities \nassociated with this experience invokes \ncomplex processes including semantic categorization and autobiographical memory, without which the experience \nwould be strange and unfamiliar. In the late \nnineteenth century, the sensory physiologist Ewald Hering noted that memory holds consciousness together. Around the \nsame time, Hermann von Helmholtz \nproposed that past experiences influence perception by supporting unconscious inferences. In the twentieth century, there \nwere numerous demonstrations of how \nexpectations, which are extrapolations from memory, influence what people consciously see and hear\n8–14. This literature highlights \nhow explicit memory provides semantic \nknowledge, which in turn forms the \nconceptual basis of perceptual meaning.\nIn this Perspective, we suggest that \nconscious experiences derive their subjective \ncharacter from both implicit and explicit \nmemories. We review current work on the cognitive neuroscience of memory, mental imagery, decision- making and emotions \nto explore how memory could underlie subjective experience. First, we introduce the concept of a mental quality space that defines the similarity between a particular \nexperience and all other experiences. Next, \nwe consider the degree to which theories of consciousness incorporate this space using self- monitoring. Then we focus on a specific \nhigher- order theory of consciousness that \ndepends on implicit self- monitoring and \nexplicit memory replay to generate rich subjective experiences. We discuss the \ncomputational advantages of memory \nreplay and conclude with recommendations for testing the higher- order mnemonic \nview in future work.\nMental quality space\nAccording to some accounts of conscious-ness, the subjective quality of a conscious \nexperience is determined by its comparison \nto other experiences\n1–3. If one can tell  \nprecisely how similar an experience is to  \nall other possible experiences, perhaps that to express verbally, but can be succinctly captured in terms of distances within a similarity space. If this view is taken \nseriously, the brain must encode, maintain \nand exploit this spatial relational structure between all experiences. Current work on the cognitive neuroscience of memory, \nmental imagery, decision- making and \nemotions can help us to answer whether \nand how this scheme is implemented in the human brain.\nThe relationship between consciousness \nand memory has long been investigated. In particular, memories have been categorized on the basis of accompanying \nsubjective experiences during memory \nrecall, distinguishing between implicit and explicit memory\n4. Implicit memories \nare procedural and they have little or no \nconsciously accessible content, whereas \nexplicit memories can be defined by their conscious content. Somewhat less attention has been paid to how memory mechanisms might contribute to conscious perception\n4–6. \nHowever, some theorists have argued that \nimplicit procedural memory might underlie \nthe ability to compare sensory experiences and thereby determine simple subjective qualities\n7. These implicit mnemonic \nmechanisms could explain the subjective \nqualities involved in simple perceptual \nexperiences, as in seeing red.The mnemonic basis of subjective \nexperience\nHakwan Lau  , Matthias Michel, Joseph E. LeDoux and Stephen M. Fleming\nAbstract | Conscious experiences involve subjective qualities, such as colours, \nsounds, smells and emotions. In this Perspective, we argue that these subjective \nqualities can be understood in terms of their similarity to other experiences. This \naccount highlights the role of memory in conscious experience, even for simple \npercepts. How an experience feels depends on implicit memory of the relationships \nbetween different perceptual representations within the brain. With more complex \nexperiences such as emotions, explicit memories are also recruited. We draw \ninspiration from work in machine learning as well as the cognitive neuroscience \nof learning and decision making to make our case and discuss how the account \ncould be tested in future experiments. The resulting findings might help to reveal the functions of subjective experience and inform current theoretical debates on \nconsciousness.\nPErSPECTIVES\nNature reviews | Psychology"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "0123456789();: is a complete description of that experience.  \nOne version of this view, known as quality \nspace theory1, defines similarity between \ntwo experiences as the inverse of the pairwise discriminability between the relevant stim-\nuli, as assessed empirically. Discriminability refers to the extent to which one stimulus can be distinguished from another, as assessed \nusing psychophysical testing. This concrete \ndefinition avoids the circularity of defining the subjective quality of one experience in terms of the subjective character of other \nexperiences, which might also need explain-\ning. Instead, mental qualities are identified functionally. For example, scarlet and crim-son are subjectively similar to each other \nbecause they are less discriminable from \neach other than from blue. This relationship can be shown graphically: the subjective quality of a colour experience is determined \nby its position in a space defined by the \ndiscriminability of each colour from all other colours \n(Fig.  1a). Because the pairwise \ndistance is defined by each person’s per -\nceptual experiences, the space encapsu  lates \na great deal of knowledge that the subject \nhas about their own perceptual capacities. \nThus, each person’s quality space would be different.\nIt is implausible that humans explicitly \naccess and visualize a mental quality space in everyday life, owing to its vastness and multidimensionality. Unlike the \ncaricature of a mental quality space for \ncolour, a full mental quality space would contain all possible experiences, across multiple modalities (such as vision and \nhearing). Different modalities are defined \non the basis of these similarity relations; experiences from the same modality are subjectively and functionally more similar \nthan experiences from different modalities. \nAlthough cross- modal similarities might \nseem less important for determining subjective quality than similarities within \na modality, they are still relevant. First, \nqualities can often be meaningfully compared across modalities along some dimensions, such as intensity\n15. Second, the \ncontributions of cross- modal similarities \nmight be subtle yet meaningful. For instance, a face can be perceived as more similar to the sound of thunder than to a gentle stroke on the back of one’s hand. These cross- modal \nsimilarity relationships partly constitute the \nsubjective experience of seeing that face, \nwhich might be troubled rather than serene.\nDespite the complexity of the quality \nspace, the full space containing all possible \nexperiences can be plausibly implemented \nin the brain. The nature of sensory \nrepresentations in the human brain permits an implicit implementation of quality \nspace through two properties of sensory representations. The first relevant property \nis sparseness: very few sensory neurons need to be activated to signal the presence \nof a certain feature in the environment\n16. \nIn a hypothetical scenario of extreme sparsity, each neuron would have a unique \nlabel based on what stimulus it primarily responds to (and therefore can be said to represent). In reality, sparseness comes in \ndegrees. Human sensory cortices show \na relatively high degree of sparsity\n16. For \nexample, in the visual cortex, a typical \nsimple stimulus excites only a small \nnumber of neurons (Fig.  1b). By contrast, the \nprefrontal cortex demonstrates a relatively \ncomplex coding scheme. Neurons in this \nregion have a relatively high degree of mixed selectivity\n17,18, meaning that most neurons \nrespond to many different stimuli, to varying \ndegrees. In the prefrontal cortex, neurons \nwith mixed selectivity encode multiple aspects of a stimulus, task or motor response simultaneously.\nThe second property of sensory \nrepresentations is smoothness. In the \nmammalian sensory cortex, coding is \nsmooth\n19,20; the content typically conforms \nto a continuum, rather than to discrete, \nabsolute categories. For example, humans \nsubjectively see individual colours as falling within a continuous space; purple is on the colour continuum between red and \nblue. This continuity is a consequence of \nsimilarity across neural representations \n(Fig.  1b). Smoothness is especially obvious \nwithin a single modality such as vision. \nBut even across sensory modalities, there \nis considerable interdependence and interaction between sensory cortices\n21. \nImportantly, some modality pairs (such \nas vision and hearing) are probably more \nmutually interdependent than other pairs (such as olfaction and touch). Certain senses have strong interconnections at the \nneuronal level and are similar in containing \ninformation regarding the spatial location of external stimuli. As such, there might also \nbe smoothness across sensory modalities, \nwhich could allow the similarity between two stimuli in different modalities to be meaningfully assessed.\nHowever, sensory coding is not \nnecessarily smooth. For example, in the visual system of the mantis shrimp, different colours are coded symbolically as absolute \ncategories\n22. Any colour is either detected or \nnot by the relevant sensors. Different colours are categorically different and cannot be \nmeaningfully compared in a fine- grained \nmanner. In such a non- smooth space, there \nis no sense in which red is more similar to \npurple than to green.\na b\nBlueScarlet\nCrimson\nFig. 1 | An example mental quality space for colour. a | In this space, the distance between two \npoints reflects how subjectively discriminable the relevant stimuli are, for a given person at a certain \ntime. Each point reflects the quality of the subjective experience of perceiving a stimulus, determined by how subjectively similar that stimulus is to all other stimuli in the space. This space is smooth, in that the content is continuous rather than categorical. b  | Smoothness can be achieved by neuronal popu­\nlation coding. For example, two shades of red (scarlet and crimson) are represented by partially over ­\nlapping neuronal populations, indicating their high degree of similarity. A distinct colour, blue, might be represented by a rather different set of neurons. This coding scheme is also sparse; only a small set of the neurons is active to signal a specific colour. Taken together, knowing all the tuning properties of \nthe relevant sensory neurons is tantamount to knowing the mental quality space.\nwww.nature.com/nrpsycholPersPectives"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "0123456789();: Taken together, sparsity and smoothness \nenable the sensory quality space to be \nefficiently implemented in the brain. Sparsity \nmeans that two sensory representations can be approximately referred to by their neuronal ‘addresses’— the location of \ntheir neural representations in sensory \nquality space. Two neural populations with different addresses probably represent highly discriminable contents. Owing to \nsmoothness, one can also meaningfully \ninfer the discriminability of the content of two neuronal populations. Thus, a functional brain mechanism that has access \nto the precise functional layout of human \nsensory cortices would possess an implicit grasp of the human mental quality space. Given a percept and the layout of the quality \nspace, such a mechanism would ‘know’ \nexactly how similar the relevant experience is to all other stimuli encoded within the entire sensory space.\nTheories of consciousness\nThe mental quality space is one account of how the subjective character of conscious \nexperiences are represented. This idea has \nbeen explored by theorists holding otherwise contrasting views about consciousness. Existing cognitive neuroscience theories \nof consciousness fall into three broad \nclasses: local theories, global workspace theory and higher- order theories. These \ntheories can be distinguished along three \nmain dimensions: the brain mechanisms \nresponsible for subjective experience (the neural correlates of consciousness), the degree to which consciousness is \nimportant for executive cognitive functions, \nand whether self- monitoring is required for \nconsciousness. Self- monitoring here refers \nto the implicit, automatic evaluation of the \nreliability of one’s own sensory processes. \nWe focus on the role of self- monitoring \nacross theories because this capacity may  \nentail an implicit grasp of the quality \nspace. Local theories and global workspace \ntheories do not consider self- monitoring \nto be necessary for consciousness, but it is a key component of higher- order theories. \nFor further comparison between theories (including some not discussed here), \nsee \nreFs23–25.\nTheories without self-  monitoring. According \nto local theories of consciousness26–32, \nneuronal activity in sensory cortices solely \ndetermines the subjective character of an \nexperience. These theories are called ‘local’ because consciousness of a given perceptual feature does not require any cognitive \nprocesses beyond the sensory areas where that feature is first processed. Consciousness \ndoes not require higher cognitive functions such as self- monitoring and working \nmemory (the ability to hold information in mind for short- term maintenance and \nmanipulation), nor does it necessarily facilitate such functions. To explain \nsubjective qualities, proponents of local \ntheories have adopted views similar to the mental quality space account described above\n33. One proposal is that the qualitative \ncharacter of an experience within a given \ncategory (such as colour), is determined by \nthe relative differences between the patterns of cortical activation generated by other stimuli within that category\n33. According \nto this account, local lateral connections \nin sensory brain areas implicitly capture a \nquality space for each category of experience.\nHowever, some neural findings are \ndifficult to explain using local theories. \nFor instance, subliminal stimulation \n(such as visual presentation of stimuli that participants are not aware of) activates the same sensory circuits as fully visible stimuli\n31,34. Because similar activity \ncan be triggered both consciously and \nnon- consciously, activity in early sensory \ncircuits seems insufficient to support \nconsciousness.\nTo meet this challenge, one could \npostulate that the neural dynamics or activity level within sensory areas determine whether subjective experience occurs. Some local theories posit that consciousness arises \nonly when the relevant activity crosses \na threshold\n33. Others hypothesize that \nrecurrent activity between sensory areas is \nnecessary for consciousness26,27. An account \nalong either of these lines can explain the activation of the early sensory cortex by \nsubliminal stimuli. However, conscious experience is also found in individuals who lack the early visual cortical area V1\n35–38. \nThus, at least in the case of visual awareness, \nneural recurrent activity would need to take \nplace outside the early sensory cortex33.\nConsidering the downstream impact of \nlocal sensory activity can help to explain why such activity needs to reach a certain threshold for conscious experiences to arise; it is possible that the threshold is required \nfor signals to be transferred to other areas. \nAn influential alternative to local theories of consciousness is the global workspace theory. According to this theory, sensory \nsignals become conscious through entry into \na ‘global workspace. ’ The global workspace is a hypothesized system akin to working memory. In the global workspace, neural \nsignals from sensory areas are amplified and \nstabilized across the brain\n39–41. The theory postulates that non- conscious perception \ninvolves neural activity only in early sensory areas, whereas conscious perception involves a more widespread pattern of activity across the brain referred to as ‘global ignition’ .\nAlthough multiple findings have been \ninterpreted as confirming that neural activity is more widespread during awareness than during lack of awareness\n42, \nthere are arguments against the global \nworkspace theory23,24. A central problem \nwith the theory is that broadcast seems to determine the ability to cognitively access \ninformation and to perform tasks, rather than to enable subjective experience per se. For example, when holding information \nin working memory, this information \nseems to be globally accessible by different processes. Y et, working memory content is not confusable with normal perception of \nthat content. For instance, simply thinking \nabout a friend’s face is not the same sensory experience as seeing it. Thus, entry into the global workspace does not seem to always entail subjective experience.\nFurther evidence regarding the role of \nworking memory in consciousness comes from individuals with aphantasia, who do not experience vivid mental imagery. \nAccording to a preprint, these individuals \ncan perform comparably to individuals with intact mental imagery in working memory tasks, such as mental rotation, \nwhich are often interpreted as involving \nthe maintenance and manipulation of perceptual representations\n43. And yet, \nthey do not consciously experience vivid \nimagery while doing so44. The mechanisms \nby which individuals with aphantasia accomplish working memory tasks should \nbe investigated further, because they probably differ from the mechanisms used by individuals with intact visual imagery\n45. \nStill, these findings suggest that the function \nof global broadcast, which seems to be \nintact in individuals with aphantasia when they perform working memory tasks, is \nnot always accompanied by conscious \nexperience. Additional discussion of the relationship between consciousness and higher cognitive functions, such as working \nmemory, can be found elsewhere\n46,47.\nHigher- order theories. A third class of \ntheories, known as higher- order theories, \navoids these problems of local theories and \nglobal workspace theories. According to \nhigher- order theories, subjective experience \nis determined by specific self- monitoring \nmechanisms in the prefrontal and parietal \ncortices23,24,48,49. These mechanisms are \nimplicit, so consciousness does not require \nNature reviews | PsychologyPersPectives"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "0123456789();: explicit cognition about oneself. Because \nthese implicit self- monitoring mechanisms \nare highly specific — unlike in the global workspace theory — conscious experiences are not broadly associated with higher cognitive functions.\nIn this context, monitoring refers to \nthe process of determining the source or reality of a memory or percept. People generally do not confuse the contents of \nworking memory with normal perception. \nFor instance, holding visual images in mind does not result in mistaking those images for the outside world. The same is true when \nrecalling long- term memories: people do not \nmistake the recalled content for a current \npercept. Under normal circumstances, one can also easily judge whether the recalled \nimage was seen or whether it came from \none’s imagination. These distinctions all  \ndepend upon monitoring. In the memory literature, monitoring the source of \nmnemonic representations is called \nsource monitoring, whereas monitoring whether an event actually occured is known as reality monitoring\n50–52. A failure \nof reality monitoring would mean that \none confuses actual past experiences with \none’s imagination.\nFollowing this tradition, the notion \nof perceptual reality monitoring focuses \non the ability to identify the nature of \nongoing perceptual (rather than mnemonic) representations\n53. When a perceptual \nsignal occurs, it could reflect the presence \nof an external stimulus. However, it could \nalso be driven internally; for example, by imagination or working memory maintenance. Although the content \nof working memory can reflect reality \n(rather than imagination), it does not reflect the present state of perception. Alternatively, such a perceptual signal might only reflect \nspontaneous noise. Perceptual reality \nmonitoring is the function of distinguishing  \nbetween these possibilities. Although  closely related to source and reality \nmonitoring in memory, perceptual \nreality monitoring probably depends on distinct mechanisms\n54,55.\nPerceptual reality monitoring is \nimportant for determining conscious experiences, because the mere presence of a perceptual signal does not create a conscious experience. Patients with damage to the \nprimary visual cortex lack corresponding \nconscious experiences in the visual modality. However, the internal perceptual signal seems to be sufficient for them to perform \nwell in some visual tasks\n35–38. One possibility \nis that the perceptual reality monitor fails to recognize the source of such a signal as reflecting current external reality, so \nconscious experience is absent. When a perceptual signal is generated internally, \nas in mental imagery, there is a conscious \nexperience, but not one of typical vision reflecting the outside world. Importantly, in aphantasia, internally generated \nperceptual signals do not come with vivid \nconscious experiences.\nHowever, some internally generated \nperceptual experiences do form part of \nconscious experience. Although external  \nstimulus input is absent during hallucinations \nand dreams, the corresponding experiences feel as though they represent reality, and \nare highly similar to the normal conscious \nexperience of seeing. The explanation of this feeling is that the mechanisms contributing to perceptual reality monitoring \ncan malfunction. There are two main \nways in which failures of perceptual reality monitoring could lead to hallucinations\n56. \nThe reality monitoring mechanisms could be \ndysfunctional — as found in certain clinical \npopulations52. Alternatively, anomalies in the \nsystems that generate inputs to the reality \nmonitoring system, such as hyper- activation \nof sensory cortices or an absence of cognitive \ncontrol, could also lead to impaired reality monitoring\n57. In either case, the perceptual \nreality monitor misinterprets internally \ngenerated perceptual signals as reflecting \nstimuli in the external world, leading to hallucination. Such a failure could also explain conscious experiences in dreams\n53.\nIt is important to note that perceptual \nreality monitoring mechanisms operate implicitly: they are automatic and largely not subject to volitional control. The distinction between explicit and implicit \nreality monitoring can be illustrated by the \nphenomenon of lucid dreaming\n58. During \nlucid dreams, explicit reality monitoring \nenables one to recognize the illusory nature \nof the experiences. Despite this explicit knowledge, these experiences continue to feel as though they reflect the present \nreality, presumably because the perceptual \nreality monitoring mechanism still implicitly categorizes the relevant perceptual signals as reflecting external reality.\nPerceptual reality monitoring forms \nthe basis of our version of a higher- order \ntheory of consciousness. According to this account, consciousness does not depend \nsolely on local activity in sensory brain areas, \nnor on activity in a global workspace across the brain. Rather, consciousness depends on implicit self- monitoring of the nature \nof perceptual signals. The mechanisms of perceptual reality monitoring are discussed in the following section.Self- monitoring in the brain\nMechanisms for perceptual reality monitoring are likely to depend on \nprefrontal and parietal areas, similar to \nmnemonic reality monitoring\n52,54,59–61. \nTo infer the presence or absence of an \nexternal signal, one needs to implicitly \nmonitor the statistical properties of one’s internal sensory responses\n62. \nA computational framework has been \nproposed in which self- monitoring tracks \nthe signal- to- noise statistics of sensory \nrepresentations63. For example, if baseline \nnoise in a sensory area is very high, a certain level of activity might be less meaningful \nthan if baseline noise is low. Along these lines, monitoring might be achieved by tracking the precision or clarity — rather \nthan content — of sensory representations \nwithin the mental quality space\n64.\nProponents of local theories of \nconsciousness could argue that the activation profile within the sensory cortices is sufficient to account for different perceptual sources without a dedicated \nmonitoring mechanism. During working \nmemory, mental imagery, and episodic recall, neural activity is entirely top- down, \nfrom frontoparietal to sensory cortex. \nBecause top- down (feedback) projections \nterminate at different cortical layers than \nbottom- up (feedforward) projections (from \nsensory cortex to frontoparietal areas), they \nlead to spatially distinguishable patterns of \nactivity. In principle, these local differences could explain the phenomenological differences between imagery and normal \nperception because imagery is associated \nwith top- down signals and perception \nis associated with bottom- up signals\n65. \nHowever, in dreams and hallucinations \nthere is no external stimulus and therefore \na lack of bottom- up, feedforward input, \nyet the percepts associated with dreams and hallucinations are misintrepreted as \nreflecting reality. Thus, it is unclear whether \nthe layer profile of local sensory activities alone can explain the phenomenology during these conditions.\nReturning to the role of prefrontal \nareas, atypical prefrontal activity has been associated with dreams and hallucinations\n66–68. Reduced activation levels \nare often found, relative to the level found \nduring ordinary conscious experience, \nalthough the extent of such reduction has been debated\n69. During dreaming \nand hallucinations, reduced prefrontal \nactivity might lead to the perceptual reality \nmonitoring system going ‘offline’ , such that internal signals are misinterpreted as being externally triggered and dreams and \nwww.nature.com/nrpsycholPersPectives"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "0123456789();: hallucinations are accordingly misjudged as \nreflecting reality.\nFurther data suggesting the importance \nof the prefrontal cortex for perceptual reality monitoring come from transcranial electrical stimulation. Stimulation of the \nprefrontal cortex changed not only the rates \nof lucid dreaming, but also the reported realism and frequency of dreams (see the supplementary information in \nreF.58). Thus, \nboth explicit and implicit perceptual reality \nmonitoring seem to depend on activity \nin the prefrontal cortex. This conclusion is congruent with the general motif that explicit and implicit forms of the same \ncomputation often depend on similar brain \nregions\n31,34.\nFurther critical evidence localizing \nperceptual reality monitoring to the prefrontal cortex comes from neuronal recordings in non- human primates. Activity \nin the dorsolateral prefrontal cortex in \nmacaque monkeys distinguishes contents \nmaintained in working memory from current percepts\n70. Whereas perceived and \nmemorized contents can both be decoded \nfrom this region, they are represented \nby largely distinct neuronal populations. Accordingly, it has been theorized that prefrontal activity plays a part in \ndistinguishing between internally generated \nand externally triggered sensory activity. This finding might help to explain why the atypical prefrontal activity during dreams \nand psychosis in humans\n66–68 can lead to \nconfusion between internally generated activity and reflections of external reality. \nIn such conditions, alterations to prefrontal cortex function could lead to a failure to properly distinguish between internally and \nexternally generated sensory activity, and \ntherefore cause confusion between the two.\nOne potential function of a perceptual \nreality monitoring mechanism is to enable \nthe smooth running of predictive processing. \nPredictive accounts of perception suggest that perception is a product of top- down \nand bottom- up interactions that create \nan internal model of the environment. In such schemes, it is important to keep track of primarily top- down (imagination) \nor primarily bottom- up (perception) states \nto generate appropriate predictions\n53,71.\nThe putative existence of perceptual \nreality monitoring mechanisms, whether or not they are localized to the prefrontal cortex, supports higher- order theories of \nconsciousness. Perceptual reality monitoring \nserves the role of implicit self- monitoring in \ndetermining whether perceptual awareness \narises in a given situation. However, current accounts of perceptual reality monitoring do not address how subjective qualities are determined. Although reality monitoring might determine whether mental qualities occur consciously or unconsciously, \nthis function alone does not explain why \nexperienced qualities feel the way they do.\nHigher- order mnemonic view\nCombining the concepts of quality space theory and perceptual reality monitoring, \nwe hypothesize that the subjective quality \nof an experience is not determined within the local sensory circuitry alone. Instead, higher- order mechanisms support how \npeople automatically know what an experience is like without effort. The local theorist might argue that when early sensory signals are strong enough, the \nrelevant knowledge is easily accessible \nby higher- order mechanisms. However, \nsuch access tends to be task- dependent, \nsubject to attentional modulation, and often \ninvolves cognitive effort. This access seems \nincompatible with direct and effortless grasp of the subjective qualities of an experience, regardless of the task required at present. \nThe higher- order mnemonic approach is \nan evolution of higher- order theories, and \nposits that consciousness depends strongly \nupon both implicit and explicit forms \nof memory. Implicit memory supports \ndirect access to the mental quality space, whereas explicit memory provides complex categories, schema and emotions for \neveryday subjective experience \n(Fig.  2).\nImplicit mnemonic process. Information \nrelevant to subjective qualities is not easily verbalized and therefore might not be represented explicitly. Instead, humans \nmight have some degree of implicit \nfamiliarity regarding how similar a conscious percept is to all other experiences. We propose that this access to the mental \nquality space depends on procedural \nmemory, akin to a skill — one can be highly skilled in a procedure without being able to articulate how it is done\n7.\nBecause the mechanisms for perceptual \nreality monitoring are involved in determining whether a subjective experience occurs, it is possible that the same mechanisms might also support \nthe implicit procedural mnemonic process \nfor accessing the mental quality space. Prefrontal and parietal cortices send top- down signals to various sensory areas \ntargeting specific representations for the purposes of attentional modulation and inhibition of those representations\n72–75. \nAs such, these prefrontal and parietal \nmechanisms must contain some implicit knowledge of what different sensory \nneurons represent. Computational models have highlighted how prefrontal circuits \ncould store this knowledge abstractly, \nmuch like how computer programmes use variables and pointers to store memory addresses and to reference specific locations \nin memory\n76. Advances in the decoding of \nensemble activity in the prefrontal cortex also show that neuronal populations can \nencapsulate rich information and enable meaningful abstraction and generalization over different contexts\n18. Thus, it is not \nimplausible for prefrontal areas to implicitly \ntrack the mental quality space encoded in \nsensory areas.\nImportantly, because the mental quality \nspace reflects knowledge of one’s perceptual \ncapacities, an implicit grasp of this space \nprobably depends upon learning. Early in development, the brain adapts to its sensory milieu and extracts regularities that \nwire cortical sensory circuits\n77–79. Sensory \nplasticity continues throughout life as an individual encounters novel sensory \nevents\n80–83. Building and maintaining a \nConscious experiencePerceptual reality monitoringSensory codes with\nsmoothness and sparsityMental qualities\nImplicit memory Explicit memory\nCompact, dedicated\nencoding of mental\nquality spaceSemantic categories,\nschemas, self and body\nstate information\nFig. 2 | The higher -order mnemonic account of \nconsciousness. Because of the smooth and sparse \ncoding in sensory cortices, perceptual representa­tions can be described in terms of subjective men­tal qualities. However, for these qualities to be meaningfully related to consciousness, the infor ­\nmation needs to be succinctly encoded at a stage of processing that is readily available for cognitive access. We propose that an implicit mnemonic \nprocess represents the mental quality space in \nsome specialized format. A higher ­ order mecha­\nnism with the relevant information regarding the functional layout of early sensory coding is key to this process. This mechanism is also hypothesized to support the function of perceptual reality mon­itoring, which determines whether perceptual awareness occurs at all. At some stage after this process of implicit, automatic self­ monitoring, \nexplicit mnemonic information is also taken into account. Together, both implicit and explicit memories contribute to subjective experience.\nNature reviews | PsychologyPersPectives"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "0123456789();: current mental quality space to support \nsubjective experience might require \ncontinued learning about the world and \nhow experiences relate to each other62.\nOne intriguing hypothesis is that \ncertain prefrontal areas might develop dedicated, specialized representations of the quality space. Insights come from how physical space is represented for \nspatial navigation in rodents. Neural \nrepresentations of space often use a grid code, in which neurons respond to specific locations of the external environment in a \nhexagonal grid pattern\n84–87. These ‘grid cell’ \nneurons fire to specific landmark locations, which follow a regimented pattern evenly \ndistributed across a physical space. Thus, their firing patterns can tell an animal how far it has moved in space. These cells have also been identified in humans\n88–91.\nThere is evidence that similar grid cells \nalso encode abstract conceptual spaces89,92,93, \nas well as non- spatial sensory quantities \nsuch as the frequency of an auditory stimulus\n94. In one human study, the authors \nasked participants to imagine trajectories \nthrough a two- dimensional sensory space \ndefined by the mixing of two different \nodours95. For instance, one region of odour \nspace could be defined by a high quantity  \nof odour A and a low quantity of odour B,  \nand another region by a low quantity of A and  \nhigh quantity of B. High quantity of both odours defined a third region. Voxels in the ventromedial prefrontal cortex showed activity reflecting hexagonal grid coding \nas participants imagined moving from \none odour to another within odour space. Thus, this brain region might encode the relationships between different sensory \nstimuli. Relational coding in areas such \nas the ventromedial prefrontal cortex could represent the subjective similarity relationships between sensory experiences. \nThis way of representing the mental quality \nspace could underlie the human capacity to effortlessly access what an experience is like.\nSpecifically, we hypothesize a general \nmechanism that represents the entire mental quality space, including all possible subjective experiences across modalities \n(such as colour, sound, and touch). This \nspace reflects the nature of neuronal coding in sensory cortices, with specialized ‘spatial’ representations in higher- order \nbrain regions (such as the prefrontal cortex) enabling one to ‘know’ what it is like to have a certain subjective experience. Importantly, this knowing is not explicit: \nit happens automatically and the content \nis often hard to articulate. Neural codes that track multiple points within a quality space (such as hexagonal grid codes) \ncould support implicit access to the quality \nof experience by making the relational information within the sensory cortices more readily available. This possibility \nremains to be tested carefully.\nIn summary, we propose that the sense \nof what an experience is like depends on \nimplicit, procedural memories, stored \nwithin higher- order mechanisms that \nare also responsible for monitoring and \ndetermining the source of early sensory signals. The medial prefrontal region \nidentified as possibly representing sensory \nquality space information\n95 is distinct \nfrom the lateral prefrontal areas linked \nto reality monitoring. However, these \nareas are densely connected. We believe that a complex network of multiple prefrontal areas could interact to determine \nsubjective experience, each having different \nand complementary roles \n(Fig.  3). The \ninteractions between these areas might be \nparticularly important for the contribution \nof explicit memories to conscious experiences and/or for monitoring the precision of quality space information.\nThe role of explicit memory. Whereas \nimplicit quality space memories might be sufficient for determining the subjective \nquality of simple experiences — such as \nseeing red — explicit memories probably play a large part in determining the \na\nbLateral prefrontal cortex Medial prefrontal cortex\nFPMACC\nOFC VM\nLateral prefrontal cortex\nMedial prefrontal cortexSensory systems\nTemporal lobe\nmemory systemsVisual cortex\nBody states\nInsula\nAmygdala\nHypothalamus\nBrainstemSemantic/episodic\nmemoryFrontal\npoleFrontal\neye ﬁeldsDorsal\nlateral\nOrbitalAnterior\ncingulateVentral\nmedial\nFEF\nDL\nFPL\nINS\nFig. 3 | Prefrontal cortex connections with memory systems. a | Anatomical locations of some key \nareas within the prefrontal cortex, as well as the insula. b  | Connectivity of prefrontal areas with sensory, \nmemory and body state areas. Lateral prefrontal areas receive feedforward input from sensory systems \nand send feedback signals back to them. This pathway has been linked to perceptual monitoring func­tions. Although only connectivity with the visual cortex is shown here, other sensory areas also connect with the lateral prefrontal cortex. Medial prefrontal areas are also intricately interconnected with lateral prefrontal areas and they probably work together in some contexts. Medial prefrontal areas might be involved in representations of the quality space. Medial prefrontal areas also receive mne­monic information from the temporal lobe, which might be how semantic memories, including sche­\nmata, give sensory information meaning and how episodic memories contribute to the experience of \neveryday perception. Medial prefrontal areas are also involved in self­ related processing and receive \ninputs from other cortical and subcortical brain processes for monitoring bodily state information. As such, these pathways might also be important for emotional experiences. FEF , frontal eye fields; DL, dorsolateral prefrontal cortex; FPL, lateral frontal pole; INS, insula; ACC, anterior cingulate cortex; VM, ventromedial prefrontal cortex; FPM, medial frontal pole; OFC, orbitofrontal cortex.\nwww.nature.com/nrpsycholPersPectives"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "0123456789();: subjective quality of complex everyday \nexperiences. Everyday experiences often \nconcern emotions and thereby, one’s bodily \nstates and oneself over time. Everyday experiences also are not isolated incidents but rather form a coherent narrative \nwithin which individual experiences are \ninterpreted. These complex processes require explicit memories.\nMedial prefrontal areas that mediate \nbetween semantic and episodic memory circuits and lateral prefrontal areas that have direct inputs from sensory systems are crucial for integrating explicit \nmemories and conscious experience \n(Fig.  3). \nFor example, medial prefrontal areas might use memory to rapidly form predictions \nin perceptual inference\n73,74. Another related \nrole of medial prefrontal areas might be to \nconstruct schemata that underlie humans’ \nconceptual understanding of the world and themselves\n7,96–98. These schemata are \ncollections of semantic memories about \nrecurring objects and situations98. For \nexample, when perceiving a restaurant scene, one naturally expects certain objects and \nsensations, such as seeing menus, touching a table, and smelling food. These conceptual templates help humans to acquire and \norganize memories and enable a better \nunderstanding of the present situation relative to one’s goals.\nSchemata, especially schemata \nconcerning one’s self, have also been proposed to play an important role in emotional processing. For example, stimuli associated with danger activate self and \nfear schemata via interrelations between \nexplicit memory circuits and medial prefrontal cortex (PFC) (in addition to eliciting behavioural and physiological \nfear responses). Conscious emotions, \nin this view, are higher- order states that \nemerge in biologically or psychologically important situations\n7,23,96,97,99.\nAccording to this higher- order \ntheory of emotions, lateral prefrontal integration of perceptual and memory signals with signals related to brain and body states to form situational, self- related and \nemotional schematic memories are key to emotional experience. These processes might be supported by medial frontal brain areas, which have been linked to processing of \nself- related information\n100– 104. In particular, \nthe anterior cingulate receives episodic memory inputs from the middle temporal \nlobes\n105. The ventromedial prefrontal cortex \nintegrates these inputs. Moreover, both \nthe cingulate cortex and the ventromedial \nprefrontal cortex connect with the dorsolateral prefrontal cortex\n106. Body state information107 also reaches the dorsolateral \nprefrontal cortex via the insula108.\nAreas of the parietal cortex also \nmediate between memory and prefrontal circuits\n109– 114. Several parietal areas are \ndensely connected with specific prefrontal \nregions, so regions across the two lobes \nmight work together on some functions115. \nThese functions include the incorporation \nof autobiographical episodic memories116 \ninto prefrontal emotional mental models via temporal–parietal connections with medial \nprefrontal areas\n106.\nIn summary, a broad network of \nprefrontal and parietal brain areas incorporate explicit mnemonic information into everyday conscious experiences, providing a high degree of informational \nrichness \n(Fig.  3). These include brain circuits \noutside the prefrontal cortex that route through and interact with the implicit \nmnemonic functions that depend on specific prefrontal mechanisms.\nMemory replay\nTo summarize, consciousness relies on implicit memory processes for the \nautomatic access of mental quality space \ninformation, and on explicit memory to integrate complex schemata regarding one’s body and oneself. As long as the perceptual \nreality monitor is involved in determining \nwhether a perceptual signal should give rise to conscious experience, that signal is interpreted in terms of the relevant position \non the mental quality space. Thus, one \nalways ‘knows’ what a conscious experience is like.\nGiven that the explicit memory system \nitself does not require the perceptual reality monitor \n(Fig.  2), it might seem advantageous \nfor the brain to store explicit memories in \na compact internal format that would not \nnecessarily contain fine- grained quality \nspace information117,118. However, humans \nseem to project memory details back into the \nquality space during conscious recollection. \nMemory replay in computational models has various functional benefits, including enhancing learning, preventing memories \nfrom being overwritten, and prioritizing \ncertain events for future planning\n119. \nHowever, replay in modelling contexts \ndoes not typically involve reactivation \nof detailed sensory representations. Instead, these replays take place via abstract internal states that are symbolic \nand categorical, rather than smooth and \ngraded like the subjective qualities of conscious experiences. We hypothesize that memory projection in humans takes \nadvantage of the quality space to improve generalization in learning and novelty \ndetection. In turn, graded generalization and novelty detection might be some of the key \nadvantages of having subjective conscious \nexperiences, especially in memory recall and in comparing concurrent percepts with past experiences.\nThe potential benefits of projecting \nepisodic memory information back to sensory space might relate to the computational characteristics of sparse \nand functionally smooth sensory coding. \nThese properties are observed in humans and a wide variety of non- human animals, \nincluding in the olfactory system in fruit \nflies\n120,121. Although fruit flies are not \nnecessarily conscious — they probably lack the relevant higher- order mechanisms \n— the organization of their olfactory \ncoding might still inform the computational functions of the human sensory system. \nIn particular, the fruit fly olfactory system \nhas been compared with artificial neural networks\n122,123. Researchers have identified \nan active ‘sparsification’ architecture in \nthe projections of the olfactory receptors \nto another anatomical structure known as the mushroom body, in which relatively few neurons project to a higher number of \nneurons, leading to a neuronal code that is \nsparser than at the initial stage.\nA sparsification architecture facilitates \nhigh performance in two kinds of \ncomputational problems. The first is \nsimilarity search, in which an agent spontaneously comes up with similar examples to a stimulus. Sparsification can \nbe useful for generalization in learning \nbecause graded generalization comes naturally if learning is performed on representations that smoothly link similar \nstimuli together\n124. The second problem that \nsparsification aids is determining whether a stimulus has been encountered previously, \nknown as novelty detection. If a certain sparse and smooth representation has not been activated previously within a \ncontext, the relevant stimulus is likely \nto be novel. And yet, this novel stimulus can be meaningfully related to other past stimuli in terms of its relative similarity. \nOwing in part to these benefits, the sparse \nand smooth circuit architecture found in fruit flies can outperform even some of the best current computer algorithms for \nsimilarity search and novelty detection\n122,123. \nThese benefits cannot in principle arise from sensory coding like that found in the mantis \nshrimp, which is symbolic and unsmooth\n22.\nImportantly, the smooth and sparse \narchitecture of the fruit fly olfactory system is also present in human sensory systems.  \nNature reviews | PsychologyPersPectives"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "0123456789();: We speculate that smooth and sparse \narchitecture enables efficient ‘model-based’ \nlearning when humans project episodic \nmemories back to sensory space. Model-  \nbased learning involves constructing mental models (also called cognitive maps) about \nhow events are causally related in the world\n125.\nUsing the retrospective re- evaluation \nparadigm, one can assess whether people \ncan understand the causal relations between events to maximize reward\n126,127. \nConceptually, the retrospective re- evaluation \nparadigm tests updating the consequences of an initial action. As an everyday example, imagine that you have experienced dining in your favourite restaurant. The restaurant \nmight be famous for a particular chicken \ndish, which you regularly order and which is rewarding to eat. Suppose at some point you get food poisoning from eating chicken at \nhome, which leads to aversion to chicken in \ngeneral. Consequently, you might lose the strong motivation to go to your favourite restaurant again. Rather than being due to \ndirect experience at the restaurant (which \nhas itself never been aversive), this change might be driven by reasoning through the potential consequences of eating chicken \nand weighing them accordingly in a mental \nmodel. The retrospective re- evaluation \nparadigm mimics a similar situation under gamified experimental settings. \nIt was found that this process of indirectly \nupdating the reward likelihood of an initial action requires the replay of the relevant experiences\n126,127. For example, researchers \nhave tried to block episodic memory replay \nby requiring a concurrent effortful task \n— such as a working memory task — and found that retrospective re- evaluation was \nimpaired\n126.\nHumans typically subjectively \nre- experience the specific details of the \nexperience during memory replay6,128,129. \nMemories of a bad meal, when vividly \nrecalled, are often about a specific dish, \nrather than a general category of food. As one recalls episodes in the sensory space where vivid details are represented, one \nre- experiences the perceptual experiences \nand how similar they are to other stimuli. \nProjecting information back into sensory space might enable a generalization across \nthe fine- grained subjective similarity \nbetween specific experiences, rather than \ncoarser generalization across different conceptual categorizations without \nreplay. Future experiments could test this \npossibility, specifically in decisional and learning contexts involving episodic recall.\nThe functional benefits of replay might \nalso apply to the prospective role of episodic memory, also known as mental time travel\n128,129. When thinking about the future, \npeople tend to think in sensory terms, rather \nthan in purely conceptual and categorical \nterms. One possibility is that imagery enables one to easily compare the similarity between future potential experiences and \nmemories of past experiences. Projecting \nfuture scenarios in sensory space might facilitate fine- grained generalizations \nfrom past experiences, enabling people \nto maximize future reward and avoid \nthreatening outcomes\n124. Additionally, by \nimagining the future in subjective sensory \nterms, one might more easily predict \nwhether a certain scenario would lead to outcomes that have not been experienced in the past (within a certain context). It might \nbe beneficial to anticipate novel scenarios \nto minimize unexpected risks and to optimize the balance between exploration (of new options) and exploitation (of known \noutcomes)\n130. These speculations remain to \nbe tested.\nIn summary, quality space representations \nunderpinning conscious experience also \nallow projection of memories back into sensory space. Projection has a range of \ncomputational advantages — including the \ncapacity to generalize reward expectations across experiences that share sensory qualities, recognize novelty and similarity, \nand to plan within sensory, rather than \nconceptual, space. More broadly, projection enables relationships between experiences to be encoded within the naturalistic \nspace of stimuli, rather than only between \nabstract concepts.\nConclusion\nConscious perception of a stimulus involves automatically and implicitly remembering \nhow similar or dissimilar it is to other \nexperiences, past and present. We propose that this comparison is a consequence of higher- order mechanisms in the brain \nthat have learned the organization of the corresponding sensory representations. These higher- order representations can \nbe considered an implementation of a \nmental quality space of similarity among \nprevious simple experiences. These mechanisms enable one to effortlessly compare experiences of the past, present and \nfuture, in a fine- grained analogue manner. \nThis automatic, implicit comparison gives \neven the simplest conscious experiences subjective richness, because a single percept \nencapsulates a great deal of self- knowledge. \nIn everyday experiences beyond simple \nperception, explicit mnemonic processes further embellish this complexity.If this account of the subjective quality \nof experience is correct, it pressures current theories of consciousness to make room for the relevant mechanisms of self- monitoring. \nMajor cognitive theories such as the global workspace view have largely neglected these issues, especially regarding the role of implicit \nmemories in determining subjective qualities. \nBy contrast, local theories might be correct that sensory circuits could be described in the context of relational mental qualities, but \nthis fact alone does not explain why people \nhave immediate and automatic access to the relevant information. The subjective quality of conscious experience cannot meaningfully \nexist in a vacuum. The scientific challenge \nis to explain how people seem to effortlessly know what experiences are like. Existing theories are somewhat silent on these issues, \nand they also leave little room for explicit \nmemories to be substantively involved in consciousness.\nWe speculate that implicit procedural \nmemories of the mental quality space might be represented spatially via grid- like coding\n84 \nin the ventromedial prefrontal cortex95. \nHowever, it is currently unclear whether such \nactivity is spontaneously employed outside \nexperimental settings, in which participants were trained to navigate over the space. Future experiments could test whether these \nrepresentations spontaneously contribute \nto subjective experiences. For instance, outside the context of a navigation task, experimenters could causally manipulate the \nrelevant brain activity and evaluate reported \nchanges in experience.\nThe relation between the representation \nof mental quality space and perceptual \nreality monitoring also remains unclear. \nOne hypothesis is that a medial prefrontal grid- like code represents location in \na quality space informed by sensory \nactivity, whereas other regions such as the \nfrontopolar cortex might track the reliability of these signals. This view would align with these latter regions’ role in tracking \nconfidence in perceptual and memory \ntasks\n131,132, and work showing that lateral \nfrontopolar cortex monitors the uncertainty \nof medial prefrontal representations \nduring decision- making133,134. Alternatively, \nsubjective confidence in the presence of a \nstimulus, as given by the perceptual reality \nmonitoring process, might be inherent to the quality space representation\n135. For instance, \nconfidence in a discrimination judgement \ntask has been reliably linked to the activation \nprofile of medial frontal areas55,136– 138.\nFinally, to further investigate the \nfunctional benefits of conscious memory recall, studies of aphantasia might be \nwww.nature.com/nrpsycholPersPectives"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "0123456789();: particularly informative. Whereas memory \nrecall can be blocked by concurrent working \nmemory tasks126, such a procedure probably \nalso impairs cognition and decision- making \nin general. Individuals with aphantasia, \non the other hand, generally have intact cognitive replay capacities. Although they lack the conscious experience of \nvivid mental imagery, this absence seems \nrelatively selective. It will be useful to pin down any specific cognitive disadvantages of aphantasia, especially in the context of \nmemory recall and comparing current and \npast experiences.\nTo understand the nature of subjective \nexperiences in psychological terms, one \nmust understand their functions. We have \noutlined here how higher- order theories \nmight be extended and further tested to meet this challenge. We hope that fruitful \nresearch avenues can be opened up by \nintegrating consciousness studies into the burgeoning literature of the cognitive and computational neurosciences of \nmemory, mental imagery, emotions and \ndecision- making.\nHakwan Lau  1 ✉, Matthias Michel2, \nJoseph E. LeDoux3 and Stephen M. Fleming4,5,6\n1Laboratory for Consciousness, RIKEN Center for Brain \nScience, Wako, Japan.\n2Center for Mind, Brain and Consciousness, New York \nUniversity, New York, NY, USA.\n3Center for Neural Science and Department of \nPsychology, New York University, New York, NY, USA.\n4Department of Experimental Psychology, University \nCollege London, London, UK.\n5Wellcome Centre for Human Neuroimaging, University \nCollege London, London, UK.\n6Max Planck UCL Centre for Computational Psychiatry \nand Ageing Research, University College London, \nLondon, UK.\n✉e- mail: hakwan.lau@riken.jp\nhttps://doi.org/10.1038/s44159-022-00068-6\nPublished online xx xx xxxx\n1. Rosenthal, D. How to think about mental qualities. \nPhil. Issues 20, 368–393 (2010).\n2. Clark, A. A Theory of Sentience (Oxford Univ. Press, 2000).\n3. Sellars, W. Science, Perception and Reality  \n(Humanities Press, 1963).\n4. Squire, L. R. Memory and Brain vol. 315 (Oxford Univ. \nPress, 1987).\n5. Schacter, D. L., Buckner, R. L. & Koutstaal, W. Memory, consciousness and neuroimaging. Phil. T rans. \nR. Soc. Lond. B 353, 1861–1878 (1998).\n6. T ulving, E. in The Missing Link In Cognition: Origins Of \nSelf- reflective Consciousness Vol. 364 (ed. T errace, H. S.) \n3–56 (Oxford Univ. Press, 2005).\n7. LeDoux, J. E. & Lau, H. Seeing consciousness through the lens of memory. Curr. Biol. 30, R1018–R1022 \n(2020).\n8. Bruner, J. S. & Leigh Minturn, A. Perceptual identification and perceptual organization.  \nJ. Gen. Psychol. 53, 21–28 (1955).\n9. Allport, F. H. Theories of perception and the concept of structure: a review and critical analysis with  \nan introduction to a dynamic- structural theory  \nof behavior. Optom. Vis. Sci. 33, 216 (1955).\n10. Gregory, R. L. Concepts And Mechanisms Of Perception (Charles Scribner’s Sons, 1974).11. Graham, D. J., Friedenberg, J. D., Rockmore, D. N.  \n& Field, D. J. Mapping the similarity space of paintings: image statistics and visual perception. Vis. Cogn. 18, \n559–573 (2010).\n12. Summerfield, C. & de Lange, F. P . Expectation in perceptual decision making: neural and computational \nmechanisms. Nat. Rev. Neurosci. 15, 745–756 (2014).\n13. Murray, E. A., Wise, S. P. & Graham, K. S. The Evolution of Memory Systems: Ancestors, Anatomy, \nand Adaptations (Oxford Univ. Press, 2017).\n14. Lamy, D., Carmel, T . & Peremen, Z. Prior conscious \nexperience enhances conscious perception but does not affect response priming. Cognition 160, 62–81 \n(2017).\n15. Marks, L. E. et al. Magnitude- matching: the \nmeasurement of taste and smell. Chem. Senses 13, \n63–87 (1988).\n16. Olshausen, B. A. & Field, D. J. Sparse coding of sensory inputs. Curr. Opin. Neurobiol. 14, 481–487 \n(2004).\n17. Rigotti, M. et al. The importance of mixed selectivity  \nin complex cognitive tasks. Nature 497, 585–590 \n(2013).\n18. Bernardi, S. et al. The geometry of abstraction in  \nthe hippocampus and prefrontal cortex. Cell 183, \n954–967.e21 (2020).\n19. Rosca, M., Weber, T ., Gretton, A. & Mohamed, S.  \nA case for new neural network smoothness constraints. Preprint at arXiv https://arxiv.org/abs/2012.07969 \n(2020).\n20. Jin, P ., Lu, L., T ang, Y. & Karniadakis, G. E. Quantifying \nthe generalization error in deep learning in terms of \ndata distribution and neural network smoothness. Neural Netw. 130, 85–99 (2020).\n21. Bauer, A.-K. R., Debener, S. & Nobre, A. C. Synchronisation of neural oscillations and cross- modal \ninfluences. T rends Cogn. Sci. 24, 481–495 (2020).\n22. Thoen, H. H., How, M. J., Chiou, T .-H. & Marshall, J. A different form of color vision in mantis shrimp. Science  \n343, 411–413 (2014).\n23. Brown, R., Lau, H. & LeDoux, J. E. Understanding  \nthe higher- order approach to consciousness.  \nT rends Cogn. Sci. 23, 754–768 (2019).\n24. Lau, H. & Rosenthal, D. The higher- order view does \nnot require consciously self- directed introspection: \nresponse to Malach. Trends Cogn. Sci. 15, 508–509 \n(2011).\n25. Michel, M. & Lau, H. On the dangers of conflating strong and weak versions of a theory of consciousness. \nPhiMiSci https://doi.org/10.33735/phimisci.2020.II.54 \n(2020).\n26. Lamme, V. A. F. T owards a true neural stance on \nconsciousness. T rends Cogn. Sci. 10, 494–501 \n(2006).\n27. Lamme, V. A. F. Why visual attention and awareness \nare different. T rends Cogn. Sci. 7, 12–18 (2003).\n28. Malach, R. Conscious perception and the frontal lobes: \ncomment on Lau and Rosenthal. T rends Cogn. Sci. 15, \n507 (2011).\n29. Zeki, S. The disunity of consciousness. T rends Cogn. \nSci. 7, 214–218 (2003).\n30. Zeki, S. Localization and globalization in conscious \nvision. Annu. Rev. Neurosci. 24, 57–86 (2001).\n31. Macknik, S. L. Visual masking approaches to visual \nawareness. \nProg. Brain Res. 155, 177–215 (2006).\n32. Macknik, S. L. & Martinez- Conde, S. in The Cognitive \nNeurosciences (ed. Gazzaniga,  M. S.) 1165–1175 \n(MIT Press, 2009).\n33. Malach, R. Local neuronal relational structures \nunderlying the contents of human conscious experience. Neurosci. Conscious. 2021, niab028 \n(2021).\n34. Kouider, S. & Dehaene, S. Levels of processing during \nnon- conscious perception: a critical review of visual \nmasking. Phil. T rans. R. Soc. Lond. B 362, 857–875 \n(2007).\n35. Mazzi, C., Savazzi, S. & Silvanto, J. On the ‘blindness’ \nof blindsight: what is the evidence for phenomenal \nawareness in the absence of primary visual cortex \n(V1)? Neuropsychologia 128, 103–108 (2019).\n36. Silvanto, J., Cowey, A., Lavie, N. & Walsh, V.  \nMaking the blindsighted see. Neuropsychologia 45, \n3346–3350 (2007).\n37. Weil, R. S., Plant, G. T ., James- Galton, M. & Rees, G. \nNeural correlates of hemianopic completion across  \nthe vertical meridian. Neuropsychologia 47, 457–464 \n(2009).\n38. Weiskrantz, L. Prime- sight and blindsight. Conscious. \nCogn. 11, 568–581 (2002).\n39. Dehaene, S., Lau, H. & Kouider, S. What is consciousness, and could machines have it? Science \n358, 486–492 (2017).40. Dehaene, S. Consciousness And The Brain: \nDeciphering How the Brain Codes Our Thoughts  \n(Penguin, 2014).\n41. Baars, B. J. A Cognitive Theory of Consciousness  \n(Cambridge Univ. Press, 1988).\n42. Mashour, G. A., Roelfsema, P ., Changeux, J.-P .  \n& Dehaene, S. Conscious processing and the global \nneuronal workspace hypothesis. Neuron 105,  \n776–798 (2020).\n43. Pounder, Z., Jacob, J., Evans, S., Loveday, C.,  \nEardley, A. F., & Silvanto, J. Only minimal differences \nbetween individuals with congenital aphantasia and \nthose with typical imagery on neuropsychological \ntasks that involve imagery. Cortex 148, 180–192 \n(2022).\n44. Keogh, R. & Pearson, J. The blind mind: no sensory \nvisual imagery in aphantasia. Cortex 105, 53–60 \n(2018).\n45. Kay, L., Keogh, R., Andrillion, T . & Pearson, J. The eyes have it: the pupillary light response as a physiological \nindex of aphantasia, sensory and phenomenological \nimagery strength. Elife 11, e72484 (2022).\n46. Dehaene, S. & Naccache, L. T owards a cognitive \nneuroscience of consciousness: basic evidence and  \na workspace framework. Cognition 79, 1–37 (2001).\n47. Lau, H. Volition and the functions of consciousness. \nNeurosci. Res. 65, S28 (2009).\n48. Rosenthal, D. Consciousness And Mind (Clarendon, \n2005).\n49. Lycan, W. in The Stanford Encyclopedia of Philosophy  \n(Stanford University, 2019).\n50. Johnson, M. K. & Raye, C. L. Reality monitoring. \nPsychol. Rev. 88, 67–85 (1981).\n51. Johnson, M. K. Reality monitoring: an experimental \nphenomenological approach. J. Exp. Psychol. Gen.  \n117, 390–394 (1988).\n52. Simons, J. S., Garrison, J. R. & Johnson, M. K. Brain \nmechanisms of reality monitoring. T rends Cogn. Sci.  \n21, 462–473 (2017).\n53. Lau, H. Consciousness, metacognition, & perceptual \nreality monitoring. Preprint at PsyArXiv https://doi.org/ \n10.31234/osf.io/ckbyf (2019).\n54. McCurdy, L. Y. et al. Anatomical coupling between \ndistinct metacognitive systems for memory and visual \nperception. J. Neurosci. 33, 1897–1906 (2013).\n55. Morales, J., Lau, H. & Fleming, S. M. Domain- general \nand domain- specific patterns of activity supporting \nmetacognition in human prefrontal cortex.  \nJ. Neurosci. 38, 3534–3546 (2018).\n56. Garrison, J. R. et al. T esting continuum models of \npsychosis: no reduction in source monitoring ability  \nin healthy individuals prone to auditory hallucinations. \nCortex 91, 197–207 (2017).\n57. Dijkstra, N., Mazor, M., Kok, P . & Fleming, S. \nMistaking imagination for reality: congruent mental imagery leads to more liberal perceptual detection. Cognition 212, 104719 (2021).\n58. Voss, U. et al. Induction of self awareness in dreams \nthrough frontal low current stimulation of gamma \nactivity. Nat. Neurosci. 17, 810–812 (2014).\n59. Fleming, S. M., Ryu, J., Golfinos, J. G. & Blackmon, K. E.  \nDomain- specific impairment in metacognitive accuracy \nfollowing anterior prefrontal lesions. Brain 137, \n2811–2822 (2014).\n60. Ye, Q., Zou, F., Lau, H., Hu, Y. & Kwok, S. C. Causal \nevidence for mnemonic metacognition in human precuneus. J. Neurosci. 38, 6379–6387 (2018).\n61. Miyamoto, K. et al. Causal neural network of \nmetamemory for retrospection in primates. Science  \n355, 188–193 (2017).\n62. Cleeremans, A. et al. Learning to be conscious.  \nT rends Cogn. Sci. 24, 112–123 (2020).\n63. Fleming, S. M. Awareness as inference in a higher-  \norder state space. Neurosci. Conscious 2020, niz020 \n(2020).\n64. Whyte, C. J. & Smith, R. The predictive global neuronal \nworkspace: a formal active inference model of visual \nconsciousness. Prog. Neurobiol. 199, 101918 (2021).\n65. Koenig- Robert, R. & Pearson, J. Why do imagery and \nperception look and feel so different? Phil. T rans. R. Soc. Lond. B 376, 20190703 (2021).\n66. Muzur, A., Pace- Schott, E. F. & Hobson, J. A. The \nprefrontal cortex in sleep. T rends Cogn. Sci. 6,  \n475–481 (2002).\n67. Zmigrod, L., Garrison, J. R., Carr, J. & Simons, J. S. The \nneural mechanisms of hallucinations: a quantitative \nmeta- analysis of neuroimaging studies. Neurosci. \nBiobehav. Rev. 69, 113–123 (2016).\n68. Narayanan, N. S., Rodnitzky, R. L. & Uc, E. Y. Prefrontal \ndopamine signaling and cognitive symptoms of \nParkinson’s disease. Rev. Neurosci. 24, 267–278 \n(2013).\nNature reviews | PsychologyPersPectives"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "0123456789();: 69. Fazekas, P . & Nemeth, G. Dream experiences and  \nthe neural correlates of perceptual consciousness  \nand cognitive access. Phil. Trans. R. Soc. Lond. B 373, \n20170356 (2018).\n70. Mendoza- Halliday, D. & Martinez- T rujillo, J. C. \nNeuronal population coding of perceived and \nmemorized visual features in the lateral prefrontal \ncortex. Nat. Commun. 8, 15471 (2017).\n71. Gershman, S. J. The generative adversarial brain. Front. Artif. Intell. Appl. 2, 18 (2019).\n72. Barceló, F., Suwazono, S. & Knight, R. T . Prefrontal \nmodulation of visual processing in humans.  \nNat. Neurosci. 3, 399–403 (2000).\n73. Bar, M. et al. T op- down facilitation of visual \nrecognition. Proc. Natl Acad. Sci. USA 103, 449–454 \n(2006).\n74. Bar, M. A cortical mechanism for triggering  \ntop- down facilitation in visual object recognition.  \nJ. Cogn. Neurosci. 15, 600–609 (2003).\n75. T sushima, Y., Sasaki, Y. & Watanabe, T . Greater disruption due to failure of inhibitory control on  \nan ambiguous distractor. Science 314, 1786–1788 \n(2006).\n76. Kriete, T ., Noelle, D. C., Cohen, J. D. & O’Reilly, R. C. \nIndirection and symbol- like processing in the \nprefrontal cortex and basal ganglia. Proc. Natl Acad. Sci. USA 110, 16390–16395 (2013).\n77. Held, R. & Hein, A. Movement- produced stimulation  \nin the development of visually guided behavior.  \nJ. Comp. Physiol. Psychol. 56, 872–876 (1963).\n78. Hubel, D. H., Wiesel, T . N. & LeVay, S. Plasticity  \nof ocular dominance columns in monkey striate  \ncortex. Phil. T rans. R. Soc. Lond. B 278, 377–409 \n(1977).\n79. King, A. J., Hutchings, M. E., Moore, D. R. & Blakemore, C. Developmental plasticity in the visual and auditory representations in the mammalian \nsuperior colliculus. Nature 332, 73–76 (1988).\n80. Weinberger, D. R. From neuropathology to neurodevelopment. Lancet 346, 552–557 (1995).\n81. Merzenich, M. M. & Sameshima, K. Cortical plasticity \nand memory. Curr. Opin. Neurobiol. 3, 187–196 \n(1993).\n82. Fiser, J. & Aslin, R. N. Unsupervised statistical learning of higher- order spatial structures from visual \nscenes. Psychol. Sci. 12, 499–504 (2001).\n83. Recanzone, G. H. Rapidly induced auditory plasticity: the ventriloquism aftereffect. Proc. Natl Acad. Sci. \nUSA 95, 869–875 (1998).\n84. Moser, E. I., Kropff, E. & Moser, M.-B. Place cells, grid \ncells, and the brain’s spatial representation system. Annu. Rev. Neurosci. 31, 69–89 (2008).\n85. O’Keefe, J. & Burgess, N. Dual phase and rate coding in hippocampal place cells: theoretical significance and relationship to entorhinal grid cells. Hippocampus 15, \n853–866 (2005).\n86. Hafting, T ., Fyhn, M., Molden, S., Moser, M.-B.  \n& Moser, E. I. Microstructure of a spatial map in the entorhinal cortex. Nature 436, 801–806 (2005).\n87. Qasim, S. E., Fried, I. & Jacobs, J. Phase precession  \nin the human hippocampus and entorhinal cortex.  \nCell 184, 3242–3255.e10 (2021).\n88. Doeller, C. F., Barry, C. & Burgess, N. Evidence for  \ngrid cells in a human memory network. Nature 463, \n657–661 (2010).\n89. Bellmund, J. L. S., Gärdenfors, P ., Moser, E. I. & \nDoeller, C. F. Navigating cognition: spatial codes for \nhuman thinking. Science 362, eaat6766 (2018).\n90. Nau, M., Navarro Schröder, T ., Bellmund, J. L. S.  \n& Doeller, C. F. Hexadirectional coding of visual space  \nin human entorhinal cortex. Nat. Neurosci. 21,  \n188–190 (2018).\n91. Bellmund, J. L., Deuker, L., Navarro Schröder, T .  \n& Doeller, C. F. Grid- cell representations in mental \nsimulation. eLife 5, e17089 (2016).\n92. Constantinescu, A. O., O’Reilly, J. X. & Behrens, T. E. J. Organizing conceptual knowledge in humans with a \ngridlike code. Science 352, 1464–1468 (2016).\n93. Mark, S., Moran, R., Parr, T ., Kennerley, S. W. & \nBehrens, T . E. J. T ransferring structural knowledge \nacross cognitive maps in humans and models.  \nNat. Commun. 11, 4783 (2020).\n94. Aronov, D., Nevers, R. & T ank, D. W. Mapping of a \nnon- spatial dimension by the hippocampal–entorhinal \ncircuit. Nature 543, 719–722 (2017).\n95. Bao, X. et al. Grid- like neural representations support \nolfactory navigation of a two- dimensional odor space. \nNeuron 102, 1066–1075.e5 (2019).96. LeDoux, J. The Deep History of Ourselves: the Four-Billion-Year Story of How We Got Conscious Brains  \n(Penguin, 2019).\n97. LeDoux, J. E. Thoughtful feelings. Curr. Biol. 30, \nR619–R623 (2020).\n98. Johnson- Laird, P . N. Mental Models: T owards  \na Cognitive Science of Language, Inference, and \nConsciousness (Harvard Univ. Press, 1983).\n99. LeDoux, J. E. What emotions might be like in other animals. Curr. Biol. 31, R824–R829 (2021).\n100. Passingham, R. E., Bengtsson, S. L. & Lau, H. C. \nMedial frontal cortex: from self- generated action to \nreflection on one’s own performance. T rends Cogn. Sci.  \n14, 16–21 (2010).\n101. Wagner, D. D., Haxby, J. V. & Heatherton, T . F.  \nThe representation of self and person knowledge  \nin the medial prefrontal cortex. Wiley Interdiscip.  \nRev. Cogn. Sci. 3, 451–470 (2012).\n102. Sutherland, K. & Bryant, R. A. Autobiographical \nmemory and the self- memory system in posttraumatic \nstress disorder. J. Anxiety Disord. 22, 555–560 \n(2008).\n103. Olsson, A., Knapska, E. & Lindström, B. The neural \nand computational systems of social learning.  \nNat. Rev. Neurosci. 21, 197–212 (2020).\n104. Isoda, M. The role of the medial prefrontal cortex in moderating neural representations of self and other  \nin primates. Annu. Rev. Neurosci. 44, 295–313 \n(2021).\n105. Ritchey, M., Libby, L. A. & Ranganath, C. Cortico-  \nhippocampal systems involved in memory and \ncognition: the PMAT framework. Prog. Brain Res. 219, \n45–64 (2015).\n106. Gilboa, A. & Marlatte, H. Neurobiology of schemas \nand schema- mediated memory. T rends Cogn. Sci. 21, \n618–631 (2017).\n107. Damasio, A. & Carvalho, G. B. The nature of feelings: \nevolutionary and neurobiological origins. Nat. Rev. \nNeurosci. 14, 143–152 (2013).\n108. Yeterian, E. H., Pandya, D. N., T omaiuolo, F. & Petrides, M. The cortical connectivity of the prefrontal cortex in the monkey brain. Cortex 48, 58–81 (2012).\n109. Curtis, C. E. Prefrontal and parietal contributions  \nto spatial working memory. Neuroscience 139,  \n173–180 (2006).\n110. Vilberg, K. L. & Rugg, M. D. Memory retrieval  \nand the parietal cortex: a review of evidence from  \na dual- process perspective. Neuropsychologia 46, \n1787–1799 (2008).\n111. Cabeza, R., Ciaramelli, E., Olson, I. R. & Moscovitch, M. The parietal cortex and episodic memory: an attentional account. Nat. Rev. Neurosci. 9, 613–625 (2008).\n112. Fischer, M., Moscovitch, M. & Alain, C. A systematic review and meta- analysis of memory- guided attention: \nfrontal and parietal activation suggests involvement  \nof fronto- parietal networks. Wiley Interdiscip. Rev. \nCogn. Sci. 12, e1546 (2021).\n113. Wagner, A. D., Shannon, B. J., Kahn, I. & Buckner, R. L. Parietal lobe contributions to episodic memory retrieval. T rends Cogn. Sci. 9, 445–453 (2005).\n114. Berryhill, M. E., Picasso, L., Arnold, R., Drowos, D.  \n& Olson, I. R. Similarities and differences between parietal and frontal patients in autobiographical and \nconstructed experience tasks. Neuropsychologia 48, \n1385–1393 (2010).\n115. Katsuki, F. & Constantinidis, C. Unique and shared \nroles of the posterior parietal and dorsolateral prefrontal cortex in cognitive functions. Front.  \nIntegr. Neurosci. 6, 17 (2012).\n116. Berryhill, M. E., Phuong, L., Picasso, L., Cabeza, R.  \n& Olson, I. R. Parietal lobe and episodic memory: \nbilateral damage causes impaired free recall  \nof autobiographical memory. J. Neurosci. 27,  \n14415–14423 (2007).\n117. T anaka, K. Z. & McHugh, T . J. The hippocampal \nengram as a memory index. J. Exp. Neurosci. 12, \n1179069518815942 (2018).\n118. T eyler, T . J. & Rudy, J. W. The hippocampal indexing \ntheory and episodic memory: updating the index. \nHippocampus 17, 1158–1169 (2007).\n119. Wittkuhn, L., Chien, S., Hall- McMaster, S. &  \nSchuck, N. W. Replay in minds and machines. \nNeurosci. Biobehav. Rev. https://doi.org/10.1016/ \nj.neubiorev.2021.08.002 (2021).\n120. Endo, K., T suchimoto, Y. & Kazama, H. Synthesis  \nof conserved odor object representations in a  \nrandom, divergent- convergent network. Neuron   \n108, 367–381.e5 (2020).121. Pashkovski, S. L. et al. Structure and flexibility in \ncortical representations of odour space. Nature 583, \n253–258 (2020).\n122. Dasgupta, S., Stevens, C. F. & Navlakha, S. A neural algorithm for a fundamental computing problem. \nScience 358, 793–796 (2017).\n123. Dasgupta, S., Sheehan, T . C., Stevens, C. F. & \nNavlakha, S. A neural data structure for novelty \ndetection. Proc. Natl Acad. Sci. USA 115, \n13093–13098 (2018).\n124. Dunsmoor, J. E. & Murphy, G. L. Categories, concepts, \nand conditioning: how humans generalize fear.  \nT rends Cogn. Sci. 19, 73–77 (2015).\n125. T olman, E. C. Cognitive maps in rats and men. Psychol. Rev. 55, 189–208 (1948).\n126. Gershman, S. J., Markman, A. B. & Otto, A. R. Retrospective revaluation in sequential decision making: a tale of two systems. J. Exp. Psychol. Gen.  \n143, 182–194 (2014).\n127. Momennejad, I., Otto, A. R., Daw, N. D. &  \nNorman, K. A. Offline replay supports planning  \nin human reinforcement learning. eLife 7, e32548 \n(2018).\n128. Schacter, D. L. & Addis, D. R. On the constructive episodic simulation of past and future events.  \nBehav. Brain Sci. 30, 331–332 (2007).\n129. Schacter, D. L. Constructive memory: past and  \nfuture. Dialogues Clin. Neurosci. 14, 7–18 (2012).\n130. Addicott, M. A., Pearson, J. M., Sweitzer, M. M., Barack, D. L. & Platt, M. L. A primer on foraging  \nand the explore/exploit trade- off for psychiatry \nresearch. Neuropsychopharmacology 42,  \n1931–1939 (2017).\n131. Mazor, M., Friston, K. J. & Fleming, S. M. Distinct \nneural contributions to metacognition for detecting, \nbut not discriminating visual stimuli. eLife 9, e53900 \n(2020).\n132. Miyamoto, K., Setsuie, R., Osada, T . & Miyashita, Y. \nReversible silencing of the frontopolar cortex \nselectively impairs metacognitive judgment on  \nnon- experience in primates. Neuron 97, 980–989.e6 \n(2018).\n133. Martino, B. D., De Martino, B., Fleming, S. M., Garrett, N. & Dolan, R. J. Confidence in value- based \nchoice. Nat. Neurosci. 16, 105–110 (2013).\n134. Donoso, M., Collins, A. G. E. & Koechlin, E. Foundations of human reasoning in the prefrontal \ncortex. Science 344, 1481–1486 (2014).\n135. Morales, J. & Lau, H. in Qualitative Consciousness: Themes from the Philosophy of David Rosenthal   \n(ed. Weisberg, J.) (Cambridge Univ. Press, 2021).\n136. Gherman, S. & Philiastides, M. G. Human VMPFC \nencodes early signatures of confidence in perceptual \ndecisions. eLife 7, e38293 (2018).\n137. Bang, D. & Fleming, S. M. Distinct encoding of decision confidence in human medial prefrontal \ncortex. Proc. Natl Acad. Sci. USA 115, 6082–6087 \n(2018).\n138. Wittmann, M. K. et al. Self- other mergence in the \nfrontal cortex during cooperation and competition. Neuron 91, 482–493 (2016).\nAcknowledgements\nS.M.F. is funded by a Wellcome/Royal Society Sir Henry Dale Fellowship (206648/Z/17/Z) and a Philip Leverhulme Prize \nfrom the Leverhulme Trust. The Wellcome Centre for Human \nNeuroimaging is supported by core funding from the \nWellcome T rust (203147/Z/16/Z). The Max Planck UCL \nCentre is a joint initiative supported by UCL and the Max Planck Society.\nAuthor contributions\nH.L. led the writing and all other authors contributed equally to the remaining aspects of the article.\nCompeting interests\nThe authors declare no competing interests.\nPeer review information\nNature Reviews Psychology thanks Peter Fazekas,  \nRafael Malach and the other, anonymous, reviewer for their \ncontribution to the peer review of this work.\nPublisher’s note\nSpringer Nature remains neutral with regard to jurisdictional \nclaims in published maps and institutional affiliations.\n \n© Springer Nature America, Inc. 2022\nwww.nature.com/nrpsycholPersPectives"
    }
  ]
}