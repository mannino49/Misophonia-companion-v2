{
  "doc_type": "scientific paper",
  "title": "Cross Sensory Stimuli Modulate Reactions to Aversive Sounds",
  "authors": [
    "Samermit"
  ],
  "year": 2019,
  "journal": "Psychology Department, University of California, Santa Cruz, USA",
  "doi": "10.1163/22134808-20191344",
  "abstract": "We propose that cross-sensory stimuli presenting a positive attributable source of an aversive sound can modulate negative reactions to the sound. In Experiment 1, participants rated original video sources (OVS) of eight aversive sounds (e.g., nails scratching a chalkboard) as more aversive than eight positive attributable video sources (PA VS) of those same sounds (e.g., someone playing a ﬂute) when these videos were presented silently . In Experiment 2, new participants were presented with those eight aversive sounds in three blocks. In Blocks 1 and 3, the sounds were presented alone; inBlock 2, four of the sounds were randomly presented concurrently with their corresponding OVS videos, and the other four with their corresponding PA VS videos. Participants rated each sound, pre- sented with or without video, on three scales: discomfort ,unpleasantness ,a n d bodily sensations .W e found the concurrent presentation of videos robustly modulates participants’ reactions to the sounds:compared to the sounds alone (Block 1), concurrent presentation of PA VS videos signiﬁcantly re-duced negative reactions to the sounds, and the concurrent presentation of OVS videos signiﬁcantly increased negative reactions, across all three scales. These effects, however, did not linger into Block 3 when the sounds were presented alone again. Our results provide novel evidence that negative re-actions to aversive sounds can be modulated through cross-sensory temporal syncing with a positiveattributable video source. Although this research was conducted with a neurotypical population, weargue that our ﬁndings have implications for the treatment of misophonia.",
  "keywords": [
    "Cross-modal attenuation",
    "multisensory integration",
    "audition",
    "vision",
    "emotion"
  ],
  "research_topics": [
    "Cross-modal attenuation",
    "multisensory integration",
    "audition",
    "vision",
    "emotion"
  ],
  "created_at": "2025-05-05T02:31:24.639838Z",
  "source_pdf": "documents/research/Global/Samermit 2019 Cross Sensory Stimuli Modulate Reactions to Aversive Sounds.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Multisensory Research 32 (2019) 197–213 brill.com/msr\nCross-Sensory Stimuli Modulate Reactions to Aversive\nSounds\nPatrawat Samermit∗,Jeremy Saal and Nicolas Davidenko\nPsychology Department, University of California, Santa Cruz, USA\nReceived 5 September 2018; accepted 21 February 2019\nAbstract\nWe propose that cross-sensory stimuli presenting a positive attributable source of an aversive sound\ncan modulate negative reactions to the sound. In Experiment 1, participants rated original video\nsources (OVS) of eight aversive sounds (e.g., nails scratching a chalkboard) as more aversive than\neight positive attributable video sources (PA VS) of those same sounds (e.g., someone playing a ﬂute)\nwhen these videos were presented silently . In Experiment 2, new participants were presented with\nthose eight aversive sounds in three blocks. In Blocks 1 and 3, the sounds were presented alone; inBlock 2, four of the sounds were randomly presented concurrently with their corresponding OVS\nvideos, and the other four with their corresponding PA VS videos. Participants rated each sound, pre-\nsented with or without video, on three scales: discomfort ,unpleasantness ,a n d bodily sensations .W e\nfound the concurrent presentation of videos robustly modulates participants’ reactions to the sounds:compared to the sounds alone (Block 1), concurrent presentation of PA VS videos signiﬁcantly re-duced negative reactions to the sounds, and the concurrent presentation of OVS videos signiﬁcantly\nincreased negative reactions, across all three scales. These effects, however, did not linger into Block\n3 when the sounds were presented alone again. Our results provide novel evidence that negative re-actions to aversive sounds can be modulated through cross-sensory temporal syncing with a positiveattributable video source. Although this research was conducted with a neurotypical population, weargue that our ﬁndings have implications for the treatment of misophonia.\nKeywords\nCross-modal attenuation, multisensory integration, audition, vision, emotion\n1. Introduction\nImagine a person scratching his ﬁngernails on a blackboard in your lecture\nhall. Most people would respond with a multitude of negative sensations in-\n*To whom correspondence should be addressed. E-mail: psamermi@ucsc.edu\n©Koninklijke Brill NV , Leiden, 2019 DOI:10.1163/22134808-20191344"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "198 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\ncluding physiological responses such as cringing, shivering, and screaming,\nand psychological responses such as generally feeling unpleasant and uncom-\nfortable. Although there is a clinical condition known as misophonia, in whichthese reactions are marked, regular, and uncontrollable, often in reaction to\nspeciﬁc sounds that originate from the mouth (Jastreboff and Jastreboff, 2002),\nthese types of reactions are still prevalent in neurotypical populations, people\nwho have not been diagnosed with misophonia. However, are these reactions\nthe direct consequence of the auditory properties of these sounds, or could\nthey also be mediated by higher-level knowledge of their physical source?\nCertain sounds may elicit strong negative reactions among the general pop-\nulation. For example, the sound of ﬁngernails scratching across a chalkboard,\nthe sound of metal scraping glass, or the sound of someone chewing or suck-\ning loudly may each produce negative emotional and physiological reactions\nin different observers (Kumar et al ., 2008; Zald and Pardo, 2002). Reuter\net al . (2014) found that while aversive reactions to sounds often depended\non their physical properties, certain reactions were based on deep emotional\nconnections with the sound. Moreover, Thibodeau (2016) found that semanticfeatures of certain words, like ‘moist’ and its association with disgusting bod-\nily functions, was a more prominent source of people’s displeasure with the\nword than its phonological properties. Thus, semantic knowledge about the\nphysical source of a sound may inﬂuence how we perceive the sound itself. For\nexample, participants rated the psychoacoustics of chalkboard squeaking as\nworse when they knew the original source of the sound (chalkboard squeaks)\nas compared when they were told the sound was pulled from a modern musicalcomposition (Reuter and Oehler, 2011).\nCox (2008) conducted a study to examine whether concurrently presenting\nan image that is thematically related to the sound could affect how negatively\nthe sounds were perceived. Neurotypical participants heard horrible sounds\n(e.g., nails on a chalkboard, or a screaming baby) and disgusting sounds re-\nlating to human bodily functions (e.g., vomiting, eating, coughing, or spitting)\nthat were paired with either a thematically associated still image (e.g., scream-ing baby sound paired with screaming baby picture), an unassociated still\nimage (e.g., screaming baby sound paired with a picture of a lily ﬂower and\npad on a pond), or a green square as control. Results showed that the associ-\nated image made the participants perceive the horrible sounds as signiﬁcantly\nmore horrible than when the sound was presented with an unassociated or con-\ntrol image. However, the disgusting sounds were not perceived as signiﬁcantly\nmore or less disgusting based on the auditory–visual pairing. This ﬁnding sug-gests that some (but not all) negative reactions to sounds can be mediated by\npresenting concurrent, thematically related associated visual cues.\nCritically, thematically unrelated images in Cox (2008), while more pos-\nitive in nature, did not drive the horrible sounds to be perceived as any less"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 199\nhorrible than the control. Therefore, the author proposes that the effect is\ndriven by semantic congruence — the negative images are semantically as-\nsociated with listeners’ expectations for the sound’s source, which removesambiguity around what sound they are actually hearing, while the positive im-\nages were semantically unrelated and had no effect. Cox (2008) has shown\nthat having horrible sounds paired with visual, semantically related imagescan increase neurotypicals’ negative responses to horrible sounds themselves,\nbut semantically unrelated, positive images do not decrease how horrible they\nﬁnd the sounds. This ﬁnding, which proposes a higher-level association be-tween the sound and source, and not one simply related to the valence of a\nvisual associate, lends itself to the question of association and attributability.\nBased on this past body of research, we propose that neurotypicals’ aversive\nresponses to certain sounds are not driven purely by the auditory properties of\nthe sounds, but rather by a multisensory simulation of the sounds’ physicalsource. A large body of research supports the idea that sensory modalities are\nnot modular but rather information is integrated across sensory modalities as\nit is processed (see Shimojo and Shams, 2001, for a review). For example, intheventriloquist effect , the perceived spatial source of a sound is inﬂuenced\nby audio-visually synced movements, such that people perceive the sound as\ncoming from a dummy’s mouth rather than from the ventriloquist (Alais andBurr, 2004).\nStudies on visual-auditory interactions have indicated that the temporal syn-\nchronization of visual and auditory information creates a stronger integration\nof the two sources. Sekuler et al. (1997) showed that ambiguous visual mo-\ntion can be reinterpreted when synced with a correctly-timed sound. In thebounce–pass illusion, two identical disks move towards each other and cross,\nwith the motion interpreted as passing over each other and continuing in their\noriginal directions. However, when a sound such as a click is synced at or nearthe point where these two disks cross each other, participants perceive the two\ndisks bouncing off each other and moving in an opposite direction than they\nwere moving before the moment they cross. Critically, the synchronization ofthe auditory click and the visual merging of the two disks signiﬁcantly pre-\ndicts the perception of a bounce, indicating that integrated visual cues may be\nunderstood as an attributable source of a sound and reinterpreted as such.\nSimilarly, in the McGurk effect, the same auditory phoneme, /ba/, is per-\nceived as /da/ when participants view the lips synchronously creating thephoneme /ga/ (McGurk and MacDonald, 1976). Additionally, a follow-up\nstudy on the McGurk effect explored the role of temporal synchrony of the vi-\nsual and auditory cues on the perceptions of phonemes (Munhall et al., 1996).\nResults showed that an exact temporal synchrony between the visual and audi-\ntory cues is not necessary for the effect to arise, but when the two cues were in"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "200 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\nperfect temporal synchrony, the McGurk effect was strongest. Temporal syn-\nchronization, as in the McGurk effect, lends itself to stronger attribution of\nsound coming from the visual source.\nHowever, the role of an attributable and synchronized video source on the\nperception of an aversive sound has yet to be investigated in a neurotypical\npopulation. With Cox’s (2008) ﬁndings indicating a thematically related imagecan make a perceived sound worse for neurotypicals, it is worth investigating\nwhat a dynamic video of an attributable source of the sound can do, where the\nauditory and visual cues are temporally synced. In particular, does viewing apositive attributable source for an aversive sound help reduce neurotypicals’\nnegative visceral and emotional reactions to the sound?\nThe present experiments examine whether presenting sounds synced with\neither the original video source (OVS) or a positive attributable video source\n(PA VS) differentially affects observers’ responses to these sounds. Unlike Cox(2008), who only examined the semantic association between a thematically\nrelated visual image and sound, our experiments utilize videos that are time-\nsynced to the sounds. The videos, then, function as an attributable sourcefor the sound, allowing for more cohesive visual–auditory integration and a\ngreater opportunity for change in the sound’s perceived qualities. The dy-\nnamic aspect of the video, which is temporally synced to the sound, makesthis attribution possible in a way that is similar to the McGurk effect, bounce–\npass illusion, or other auditory–visual illusions. Our study goes beyond high-\nlevel semantic associations through a still image, and grounds the integration\ntemporally through videos. We hypothesize that concurrent presentation of a\nPA VS video will attenuate negative responses to aversive sounds, whereas con-current presentation of the OVS video will increase the negative responses,\nrelative to hearing the sounds alone.\nTo test this, we conducted two experiments. In Experiment 1, participants\nwatched 16 silent videos (the eight OVS videos that produced the eight aver-\nsive sounds, as well as eight PA VS videos that could plausibly produce the\nsame sounds; see Supplementary Videos) and provided three behavioral rat-ings following each short ∼5-s silent video: how uncomfortable the video\nmade them feel, how unpleasant it was, and the intensity of any felt bodily\nsensations . In Experiment 2, a different group of participants completed three\nblocks where they rated each of the eight aversive sounds on the same discom-\nfort, unpleasantness, and bodily sensation scales, now asking how each sound\nmade them feel. Participants were asked to rate each sound alone in the block\n1 (pre-video) and block 3 (post-video). In block 2 (concurrent video), half of\nthe sounds were presented with their associated OVS video, and the other halfwere presented with their associated PA VS video, showing an alternative, less\naversive potential source of the sound."
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 201\nWe predicted that PA VS-paired aversive sounds would reduce ratings of\ndiscomfort, unpleasantness, and intensity of felt bodily sensations compared\nto sounds presented alone in block 1, whereas OVS-paired sounds would in-\ncrease these ratings. We also predicted that there might be a lingering effect\nof the sound–video pairings, manifesting as lower ratings on the PA VS-paired\nsounds compared to OVS-paired sounds even when presented with no video\nin block 3.\n2. Experiment 1: Reactions to Silent Videos\n2.1. Participants\nTwenty-three undergraduate students (16 female, 7 male; mean age =20 years\nold) from the University of California, Santa Cruz psychology research pool\ncompleted an online experiment in exchange for course credit. Participantswere required to sign a consent form that indicated they could stop the study\nat any time should they feel uncomfortable. None of the participants reported\nbeing diagnosed with misophonia or tinnitus.\n2.2. MaterialsParticipants were presented with 16 silent videos (averaging 5 s each). Eight of\nthe videos were demonstrations of actions that produced aversive sounds that\ninduce negative emotional and visceral responses. The eight original video\nsources (OVS) were: (1) A knife grating on glass, (2) a chalk screeching on a\nchalkboard, (3) nails scratching a chalkboard, (4) a person rubbing a balloon to\nmake it squeak, (5) a dry marker on paper, (6) someone loudly chewing/suck-\ning on hard candy, (7) a fork scratching glass and (8) someone popping theirﬁngers loudly. We ﬁlmed some of these events ourselves (e.g., rubbing a bal-\nloon, dry marker on paper, knife and fork scratching glass) and found other\nevents on YouTube.\nWe generated the other eight positive attributable video sources (PA VS) that\ncould provide a plausible alternative source for each of the aversive sounds.\nFor example, for the sound of someone scratching their nails on a chalkboard,the PA VS video showed a person tearing a sheet of paper in sync with the nails\nbeing dragged on the board. To construct PA VS, we created or found videos\nof events that could plausibly produce the eight aversive sounds but involvedless grating actions. These PA VS (respective to the eight OVS listed above)\nincluded: (1) a bird chirping, (2) a man playing a wooden ﬂute, (3) paper being\ntorn in half, (4) a cricket visibly chirping with its wings moving back and forthquickly, (5) a bunny licking another bunny, (6) someone handling rocks, (7) a\nchild jumping on a bed, and (8) someone tapping a pencil on a table. The eight\nOVS videos, eight PA VS videos, and eight sounds used in these experimentsare all available for download as Supplementary Videos."
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "202 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\n2.3. Measures\nThree 7-point scales were used to assess the participants’ reaction to each\nsilent video: a discomfort scale, an unpleasantness scale, and a bodily sen-sation scale. The discomfort scale measured participants’ affective feeling\ntoward the video, ranging from 1 indicating comfortable to 7 indicating un-comfortable. The unpleasantness scale measured participants’ general per-\nception of the video, where 1 indicated pleasant, and 7 indicated unpleasant.Finally, the bodily sensation measured the intensity of any bodily experienceswhen listening to the video, with 1 being ‘None at all’ and 7 being ‘Very in-tense’. Participants were presented with these three scales, in the same order,after every video.\nAt the end of the study, participants were given a debrieﬁng question-\nnaire asking about their general experiences with positive and negative sounds,\nautonomous sensory meridian response (ASMR), and whether they have ex-perienced symptoms of tinnitus or misophonia (no participants did).\n2.4. Procedure\nParticipants were asked to sign a consent form prior to participating in the\nstudy. They were then presented with instructions and watched the 16 silentvideos in random order, and were asked to provide ratings on the three scalesbased on their reaction to each video. At the end of the study, the participantscompleted the debrieﬁng questionnaire. The procedure took approximately tenminutes.\n2.5. ResultsTo compare the differences between ratings for OVS and PA VS silent videos,\nwe conducted paired-samples t-tests between each of the three types of rat-\nings for OVS versus PA VS videos. Across all three scales, participants ratedthe OVS videos as signiﬁcantly more negative than the paired PA VS videos(Fig. 1). Mean discomfort ratings were signiﬁcantly higher for OVS videos(M: 4.45, SE: 0.17) than PA VS videos ( M: 3.30, SE: 0.18; t(22)=5.99,p<\n0.00001); similarly, mean unpleasantness ratings were signiﬁcantly higher\nfor OVS videos (M: 4.59, SE: 0.15) than PA VS videos ( M: 3.36, SE: 0.14;\nt(22)=8.20,p< 0.00001); ﬁnally, mean bodily sensation ratings were sig-\nniﬁcantly higher for OVS videos ( M: 3.25, SE: 0.24) than PA VS videos ( M:\n2.57, SE: 0.18; t(22)=3.92,p=0.0007).\nTo account for variability in the use of the scales across participants, we also\ncomputed normalized responses across participants by subtracting the meanand dividing by the standard deviation of each participant’s responses in each\nscale. Across all three normalized scales, participants rated OVS videos as\nsigniﬁcantly more negative than their respective PA VS videos. Mean normal-ized discomfort ratings were signiﬁcantly higher for OVS videos than PA VS"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 203\nFigure 1. Mean responses across 23 participants in Experiment 1 to silent videos across three\n7-point scales: discomfort, unpleasantness, and bodily sensations. Higher values indicate morenegative responses. Original (OVS) videos are shown in red and positive (PA VS) videos areshown in blue. Error bars indicate standard error of the mean across participants.\nvideos ( t(22)=6.67,p<0.000001); similarly for mean normalized unpleas-\nantness ratings ( t(22)=9.43,p< 0.00000001), and for mean normalized\nbodily sensation ratings ( t(22)=4.04,p=0.0005). Thus, the results based\non the normalized scales are nearly identical to those based on the raw scales.\nFinally, to determine whether the three scales are assessing independent in-\nformation, we computed pairwise correlations among the three scales based\non each participant’s mean rating on each scale. We found that discomfortand unpleasantness were positively correlated across participants ( r=0.84,\np< 0.00001), but bodily sensation ratings were not correlated with either\ndiscomfort ( r=0.24,p=0.26) or unpleasantness ( r=0.35,p=0.1). For\nclarity, we report results for all three measures separately in subsequent anal-yses, but note that the discomfort and unpleasantness scales appear to beinterpreted similarly by participants.\n2.6. Discussion\nThe results of Experiment 1 show that the silent OVS videos were perceived\nas more negative and elicited more intense bodily sensations than the silentPA VS videos. This was evident across all three scales. Overall, these data\nvalidate that our PA VS videos were less aversive than the OVS videos that pro-\nduced each aversive sound. In Experiment 2, the eight aversive sounds werepresented alone or paired with an OVS or PA VS video to test whether the con-current presentation of an attributable source decreases (for PA VS videos) or\nincreases (for OVS videos) the negative visceral and emotional response."
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "204 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\n3. Experiment 2: Reactions to OVS- and PA VS-Paired Sounds\n3.1. ParticipantsForty undergraduate students (32 female, 8 male; mean age =20 years old)\nfrom the University of California, Santa Cruz psychology research pool par-\nticipated in exchange for course credit. Participants were required to sign a\nconsent form indicating they were informed that in the experiment they wouldhear possibly unpleasant noises that may cause feelings of anxiety and thatthey could leave at any point.\n3.2. MaterialsWe used the eight aversive sounds corresponding to the eight OVS videos\ndescribed above: (1) A knife grating on glass, (2) chalk screeching on a chalk-\nboard, (3) nails on a chalkboard, (4) a person rubbing a balloon so it squeaks,(5) a dry marker on paper, (6) someone loudly chewing/sucking on hard candy,(7) a fork scratching glass and (8) someone popping their ﬁngers loudly. Fig-ure 2 shows spectrograms for each of the eight sounds, a still image of the\nOVS video, and a still image of the PA VS video (see Supplementary Videos to\nview and hear the eight OVS and eight PA VS videos).\n3.3. MeasuresThe same measures were collected in Experiment 2 as in Experiment 1, with\none important difference: rather than rating the videos, participants were askedto rate the sounds that were presented with or without an accompanying video.\nAt the end of the study, participants were given a debrieﬁng questionnaire\nasking about their general experiences with positive and negative sounds,autonomous sensory meridian response (ASMR), and whether they have ex-perienced symptoms of tinnitus or misophonia (no participants did).\n3.4. ProcedureParticipants were asked to sign a consent form before beginning the exper-\niment. They were then read the instructions and presented with the three\npractice trials in order to familiarize them with the pleasantness, comfort, andbodily sensation scales. Participants were asked to rate each sound alone inblock 1 (pre-video) and block 3 (post-video). In block 2 (concurrent video),half of the sounds were presented with their associated OVS video, and the\nother half were presented with their associated PA VS video, showing an al-\nternative, less aversive potential source of the sound. The assignment of eachsound to an OVS or PA VS video in the second block, as well as the presen-tation order of sounds within each block, was randomized across participants.\nEach participant was only exposed to one video per sound. Subjects were in-\nstructed to rate each sound they were presented with in each block, regardless"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 205\nFigure 2. Audio spectrograms, original video source (OVS), and positive attributable video\nsource (PA VS) videos for the eight sounds used in Experiment 1."
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "206 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\nof whether or not a video was presented concurrently. Finally, participants\ncompleted a short questionnaire and were debriefed about the study.\n3.5. ResultsTo compare the differences between responses to OVS-paired and PA VS-\npaired sounds, we computed pairwise t-tests between responses in block 1\n(sound only), block 2 (sound concurrent with video), and block 3 (sound only),separately for the three scales. Because participants rated only four sounds ineach condition on each scale, there was not enough within-participant variabil-ity in the responses to compute reliable normalized ratings, as in Experiment\n1, so we report only results based on raw ratings on the 1–7 scale.\nAcross each of the three scales, we found that concurrent presentation of\nOVS videos signiﬁcantly increased negative reactions to sounds (comparedto pre- and post-video baselines), whereas concurrent presentation of PA VSvideos signiﬁcantly reduced negative reactions to the sounds (see Figs 3, 4,and 5). First, average discomfort ratings to OVS-paired sounds were 5.42 (SE:\n0.11) when presented with the video, signiﬁcantly higher than both the pre-\nvideo baseline ( M: 4.97; SE: 0.12; t(39)=4.26,p=0.0001) and the post-\nvideo baseline ( M: 5.05; SE: 0.12; t(39)=3.36,p=0.002; see Figure 3).\nConversely, average discomfort ratings to PA VS-paired sounds were 4.77 (SE:0.11) when presented with the video, signiﬁcantly lower than the pre-videobaseline ( M: 5.09; SE: 0.09; t(39)=3.93,p=0.0003) and marginally lower\nthan the post-video baseline ( M: 4.93, SE: 0.11; t(39)=1.83,p=0.08).\nA similar pattern of results was observed for ratings of unpleasantness\n(Fig. 4). Average unpleasantness ratings to OVS-paired sounds were 5.59 (SE:\nFigure 3. Discomfort ratings to aversive sound before (left), during (middle), and following\n(right) pairing with synced OVS (red) and PA VS (blue) videos. Each bar denotes the averagerating on the 7-point discomfort scale across 40 participants’ responses, and error bars indicatethe standard error of the mean across participants."
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 207\nFigure 4. Unpleasantness ratings to aversive sounds before (left), during (middle), and fol-\nlowing (right) pairing with synced OVS (red) and PA VS (blue) videos. Each bar denotes theaverage rating on the 7-point unpleasantness scale across 40 participants’ responses, and error\nbars indicate the standard error of the mean across participants.\nFigure 5. Ratings of bodily sensations to aversive sounds before (left), during (middle), and\nfollowing (right) pairing with synced OVS (red) and PA VS (blue) videos. Each bar denotes theaverage rating on the 7-point bodily sensation scale across 40 participants’ responses, and errorbars indicate the standard error of the mean across participants.\n0.11) when presented with the video, signiﬁcantly higher than both the pre-\nvideo baseline ( M: 5.13; SE: 0.13; t(39)=4.73,p=0.00003) and the post-\nvideo baseline ( M: 5.26; SE: 0.13; t(39)=4.12,p=0.0002). Conversely,\naverage unpleasantness ratings to PA VS-paired sounds were 5.04 (SE: 0.11)\nwhen presented with the video, marginally lower than both the pre-video base-line (M: 5.21; SE: 0.11; t(39)=1.85,p=0.07) and the post-video baseline\n(M: 5.18, SE: 0.13; t(39)=1.72,p=0.09)."
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "208 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\nFinally, the ratings of the intensity of bodily sensations to the sounds were\nalso inﬂuenced by the concurrent presentation of OVS or PA VS videos (Fig. 5).\nAverage bodily sensation ratings to OVS-paired sounds were 4.18 (SE: 0.21)\nwhen presented with the video, signiﬁcantly higher than both the pre-videobaseline ( M: 3.60; SE: 0.18; t(39)=3.96,p=0.0003) and the post-video\nbaseline ( M: 3.60; SE: 0.22; t(39)=3.58,p=0.0009). Conversely, average\nbodily sensation ratings to PA VS-paired sounds were 3.26 (SE: 0.18) when\npresented with the video, signiﬁcantly lower than the pre-video baseline ( M:\n3.59; SE: 0.21; t(39)=2.42,p=0.02). Interestingly, the post-video ratings\nof bodily sensations for PA VS-paired sounds remained low ( M: 3.33, SE: 0.19)\nand were not signiﬁcantly different from the during-video ratings ( t(39)=\n0.57,p> 0.5). In fact, the post-video ratings of PA VS-paired sounds were\nmarginally lower than the pre-video ratings ( t(39)=1.91,p=0.06), hinting\nat a potential lingering effect of pairing positive attributable video sources with\naversive sounds on subsequent bodily sensations to the sounds alone.\n3.6. Discussion\nOverall, when aversive sounds were paired with their OVS videos, participants\nrated the sounds as producing more discomfort, being more unpleasant, and\ncausing more intense bodily sensations than when they were presented alone.\nConversely, when the same sounds were paired with their PA VS videos, par-ticipants rated them as producing less discomfort, being less unpleasant, and\ncausing less intense bodily sensations than when they were presented alone.\nThese ﬁndings support our ﬁrst prediction that presenting synced attributable\nsource videos with aversive sounds can modulate negative visceral and emo-\ntional responses. However, we did not ﬁnd consistent evidence supporting oursecond prediction that these effects would linger into the post-video block.\nOnly in one case (bodily sensation ratings on PA VS-paired sounds) did this\nlingering effect approach signiﬁcance.\n4. General Discussion\nThese experiments aimed to test whether an attributable visual source that was\ntemporally synced with an aversive sound, such as the original video sourcefor the sounds or a positive attributable video source (PA VS), could mediate\nneurotypicals’ negative visceral and emotional reactions. Neurotypicals expe-\nrience automatic negative emotional and visceral responses associated with\nsome sounds such as nails on a chalkboard (Kumar et al ., 2008; Zald and\nPardo, 2002). It has been shown that images that are visually associated withhorrible sounds reliably make people perceive the sounds themselves as more"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 209\nhorrible than visually unassociated images or a control (Cox, 2008). Addition-\nally, cross-modal literature has illustrated that visual cues can be more power-\nfully integrated with auditory cues if they are temporally synced (Munhall et\nal., 1996; Sekuler et al., 1997).\nSince cross-modal associations may play a role in the high-level perception\nof sound, we hypothesized that upon the presentation of a temporally synced\npositive attributable visual source, participants would have lower discom-\nfort ratings, lower unpleasantness ratings, and less intense bodily sensations,\nwhereas viewing the original video source would increase discomfort and\nunpleasantness ratings, and cause more intense bodily sensations comparedto pre-test ratings of the sound. After validating the PA VS videos were less\naverise in Experiment 1, the ﬁndings of Experiment 2 support our hypothesis.\nThese results indicate that neurotypicals’ negative responses to everyday, aver-\nsive sounds may be momentarily attenuated by syncing positive attributable\nvideos to the sounds. While the mechanism of these ﬁndings is still untested,\nour results suggest there is some type of visual–auditory integration occurring\nin the high-level perception of the sound. This may be due to a learned se-mantic association between the sound itself and its physical source, similar to\npeople’s perception of the word ‘moist’ (Thibodeau, 2016). This ﬁnding points\ntowards a more complicated multimodal integration than may be predicted if\nvisual and auditory cues were simply combined in an additive way.\nIn Experiment 2, we found that there was no statistically signiﬁcant dif-\nference between the bodily sensation ratings during the video and post-video.\nAlthough the post-video and pre-video ratings were only marginally different,the data suggest that if participants were exposed repeatedly to pairings be-\ntween the sounds and the PA VS videos, it could produce longer-term effects\nwhen sounds are heard alone.\nWe acknowledge an important limitation of our study is that we did not ask\nparticipants to rate the plausibility of the PA VS videos as being attributable\nsources for the sounds. It could be the case that PA VS videos were perceived as\nless attributable than OVS videos. If this is the case, the reduction in negativeratings to the PA VS-paired sounds may have been driven by another mecha-\nnism, such as participants being distracted by apparent lack of attributability,\nand this distraction reduced negative reactions. Assuming our PA VS videos at-\ntenuated negative emotional and visceral responses due to their attributability,\na future control study could be run using positive videos that are not tempo-\nrally synced or semantically related to the sound. If attributability does play a\nrole, then temporally unsynced PA VS and semantically unrelated PA VS wouldnot attenuate the negative responses compared to temporally synced and at-\ntributable PA VS from Experiment 2.\nOne possible mechanism may be the construction of a mental simulation of\nthe sound’s attributable source from the visual cue. Speciﬁcally, higher-level"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "210 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\nassociations from the positive visual cues may down-modulate the perception\nof the original acoustic signals. Aversive sounds such as nails on a chalkboard,\nthe sound of metal scraping glass, or someone chewing and sucking on objectscause higher activation of the amygdala and auditory cortex compared to simi-\nlar but non-aversive sounds (Mirz et al., 2000; Viinikainen, Kätsyri and Sams,\n2012; Zald and Pardo, 2002). Kumar et al. (2012) found that the amygdala\nencodes not only the acoustic features of a sound stimulus, but also its va-\nlence, such as the sound’s perceived unpleasantness. The perceived valence of\na sound — its pleasantness or unpleasantness — provides feedback back to the\nauditory cortex, down-regulating the listener’s perception of the sound itself.They conclude that the amygdala augments the representation of a sound’s va-\nlence, making it so that a listener more readily and consciously registers the\nperception of an emotionally salient stimuli.\nAdditionally, Irwin et al. (2011) determined that the neural responses to nat-\nural sounds, such as a urban soundscapes, in the amygdala, posterior insula,\nand posterior auditory cortex are modulated by how pleasant or unpleasant the\nsound is perceived. Their results support a model of sound processing wheretwo streams of information — one for acoustic signals, and one for processing\nemotional content — interact with each other to inform the holistic percep-\ntion of a sound. The synced visual information may provide additional clues\nto the valence of the sound, creating a stronger ‘positive’ modulation of the\nperception of the sound itself and causing the sound to be perceived as less\nunpleasant overall.\nWhile most of us experience some negative reactions to certain sounds (like\nnails scratching a chalkboard), those with clinically signiﬁcant misophonia ex-\nperience more extreme reactions that may make them feel disgust, anxiety,\nanger, and even a desire to harm those producing the sounds (Edelstein et al.,\n2013). Sometimes these reactions are paired with a visceral ‘ﬁght-or-ﬂight’\nresponse that manifests as pressure in the chest and head, tightened muscles,\nincreased heart rate and body temperature, and even physical pain when indi-\nviduals are exposed to trigger sounds (Edelstein et al., 2013; Schröder et al.,\n2013). Misophonic responses are not necessarily related to physical properties\nof a trigger sound, such as its loudness or timbre (Jastreboff and Jastreboff,\n2014), but rather linked to higher-order features of the sound such as its mean-\ning, social context, and interpretation (Bruxner, 2016; Schröder et al., 2013).\nIt has been suggested that misophonia’s negative visceral and emotional re-\nsponse to speciﬁc trigger sounds is similar but opposite to the autonomous\nsensory meridian response (ASMR). ASMR is a phenomenon in which indi-viduals experience feelings of relaxation and well-being accompanied with a\ntingling sensation across the scalp, back of the neck, and other areas when\nthey perceive speciﬁc audio-visual triggers (Barratt and Davis, 2015; Taylor,\n2014). ASMR is not considered a clinical disorder, but can be experienced"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 211\nby the general population. Unlike people who experience misophonia, people\nwho experience ASMR actively seek out audio-visual triggers such as videos\nof whispering into a microphone and the sound of squishing soft materials orgiving massages (Barratt and Davis, 2015). However, McErlean and Banissy\n(2018) indicated that those who self-report experiencing ASMR also report\nhaving more misophonic symptoms as compared to a control group. The au-\nthors indicate that this ﬁnding is in agreement with Barratt and Davis (2015)’s\nsuggestion that misophonia and ASMR exist across a valenced spectrum of\nsound sensitivity. Perhaps these similar, yet distinct, emotional and physio-\nlogical experiences are both related to cross-modal associations that up- anddown-regulate the perception of a sound’s valence. However, to examine this\nrelationship, future research needs to examine the mechanism for and linger-\ning durability of PA VS’s attenuation effect.\nWe do not know whether visual–auditory integration may mediate clini-\ncal misophonics’ responses in the same way as in neurotypicals. Even if the\nattributability of sounds does play a role, new visual sources may still not be\neffective in misophonics if their associations to the aversive sounds are alreadyoverlearned across limbic and autonomic areas that control their perception of\nsounds (Jastreboff and Jastreboff, 2014). However, research has shown that\nmisophonic responses have an onset in childhood and get worse over time\n(Kumar et al., 2014; Rouw and Erfanian, 2018; Schröder et al., 2013), which\nlends itself to the idea that cross-modal associations are susceptible to plastic-\nity across the cortex (Shimojo and Shams, 2001).\nOur ﬁndings, paired with future research on the mechanism behind the\ncross-modal attenuation, may serve as a basis for therapeutic relief from se-\nvere misophonic responses. Currently, there are several proposed therapies for\ntreating misophonia, largely based on clinical experience and case reports.\nTinnitus retraining therapy involves adding noise to the environment using a\nwearable sound generator, and many misophonics prefer to altogether leave or\navoid a situation where a trigger sound may exist (Edelstein et al., 2013; Jas-\ntreboff and Jastreboff, 2014). This form of therapy is seen as a sophisticatedversion of avoidance therapy, which can lead to reduced quality of life. Addi-\ntionally, case studies have found that cognitive behavioral therapy (CBT) has\npositively affected misophonics’ negative reactions (Bernstein et al ., 2013;\nDozier, 2015). Schröder et al . (2017) conducted a mid-scale study ﬁnding\nCBT methods, such as attentionally shifting focus away from the sound, coun-\nterconditioning, stimulus manipulation, and relaxation exercises, effective in\nnearly half the patients over eight bi-weekly sessions. Part of the reframingprocess of cognitive behavioral therapy was stimulus manipulation, where a\npleasant unconditioned stimulus (e.g., a positive video or image) would be\nrepeatedly presented with a conditioned stimulus (e.g., a video of someone\nchewing). Unlike our design, these positive unconditioned stimuli are not"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "212 P . Samermit et al. / Multisensory Research 32 (2019) 197–213\nattributable to the sound. The temporal syncing of the sound with positive\nattributability may help increase the likelihood of success in this therapeutic\nprocess.\nAcknowledgements\nThe authors would like to acknowledge the contributions of John Collins in\nthe preparation of these studies, and of Nick Antrilli in the preparation of this\nmanuscript.\nSupplementary Material\nSupplementary material is available online at:\nhttps://brill.ﬁgshare.com/s/154fe0137a60121c0bcf\nReferences\nAlais, D. and Burr, D. (2004). The ventriloquist effect results from near-optimal bimodal inte-\ngration, Curr. Biol. 14, 257–262.\nBarratt, E. L. and Davis, N. J. (2015). Autonomous sensory meridian response (ASMR): a ﬂow-\nlike mental state, PeerJ 3, e851. DOI:10.7717/peerj.851.\nBernstein, R. E., Angell, K. L. and Dehle, C. M. (2013). A brief course of cognitive behavioural\ntherapy for the treatment of misophonia: a case example, Cogn. Behav. Therap. 6, e10.\nDOI:10.1017/S1754470X13000172.\nBruxner, G. (2016). ‘Mastication rage’: a review of misophonia — an under-recognised symp-\ntom of psychiatric relevance?, Australas. Psychiat. 24, 195–197.\nCox, T. J. (2008). The effect of visual stimuli on the horribleness of awful sounds, Appl. Acoust.\n69, 691–703.\nDozier, T. H. (2015). Counterconditioning treatment for misophonia, Clin. Case Stud. 14, 374–\n387.\nEdelstein, M., Brang, D., Rouw, R. and Ramachandran, V . S. (2013). Misophonia: physiological\ninvestigations and case descriptions, Front. Hum. Neurosci. 7, 296. DOI:10.3389/fnhum.\n2013.00296.\nIrwin, A., Hall, D. A., Peters, A. and Plack, C. J. (2011). Listening to urban soundscapes:\nphysiological validity of perceptual dimensions, Psychophysiology 48, 258–268.\nJastreboff, M. M. and Jastreboff, P. J. (2002). Decreased sound tolerance and tinnitus retraining\ntherapy (TRT), A u s t .N .Z .J .A u d i o l . 24, 74–84.\nJastreboff, P. J. and Jastreboff, M. M. (2014). Treatments for decreased sound tolerance (hyper-\nacusis and misophonia), Semin. Hear. 35, 105–120.\nKumar, S., Forster, H. M., Bailey, P. and Grifﬁths, T. D. (2008). Mapping unpleasantness of\nsounds to their auditory representation, The Journal of the Acoustical Society of America\n124, 3810–3817.\nKumar, S., von Kriegstein, K., Friston, K. and Grifﬁths, T. D. (2012). Features versus feelings:\ndissociable representations of the acoustic features and valence of aversive sounds, J. Neu-\nrosci. 32, 14184–14192."
    },
    {
      "section": "Page 17",
      "page_number": 17,
      "text": "P . Samermit et al. / Multisensory Research 32 (2019) 197–213 213\nKumar, S., Hancock, O., Cope, T., Sedley, W., Winston, J. and Grifﬁths, T. D. (2014). Misopho-\nnia: a disorder of emotion processing of sounds, J. Neurol. Neurosurg. Psychiat. 85, P023.\nDOI:10.1136/jnnp-2014-308883.38.\nMcErlean, A. B. J. and Banissy, M. J. (2018). Increased misophonia in self-reported au-\ntonomous sensory meridian response, PeerJ 6, e5351. DOI:10.7717/peerj.5351.\nMcGurk, H. and MacDonald, J. (1976). Hearing lips and seeing voices, Nature 264, 746–748.\nMirz, F., Gjedde, A., Sdkilde-Jrgensen, H. and Pedersen, C. B. (2000). Functional brain imaging\nof tinnitus-like perception induced by aversive auditory stimuli, Neuroreport 11, 633–637.\nMunhall, K. G., Gribble, P., Sacco, L. and Ward, M. (1996). Temporal constraints on the\nMcGurk effect, Percept. Psychophys. 58, 351–362.\nReuter, C. and Oehler, M. (2011). Psychoacoustics of chalkboard squeaking, J. Acoust. Soc.\nAm.130, 2545.\nReuter, C., Oehler, M. and Mühlhans, J. (2014). Physiological and acoustical correlates of\nunpleasant sounds, in: Proceedings of the Joint Conference ICMPC13-APSCOM5 . Yonsei\nUniversity, Seoul, Korea, p. 97.\nRouw, R. and Erfanian, M. (2018). A large-scale study of misophonia, J. Clin. Psychol. 74,\n453–479.\nSchröder, A., Vulink, N. and Denys, D. (2013). Misophonia: diagnostic criteria for a new psy-\nchiatric disorder, PloS One 8(1), e54706. DOI:10.1371/journal.pone.0054706.\nSchröder, A. E., Vulink, N. C., van Loon, A. J. and Denys, D. A. (2017). Cognitive behavioral\ntherapy is effective in misophonia: an open trial, J. Affect. Disord. 217, 289–294.\nSekuler, R., Sekuler, A. B. and Lau, R. (1997). Sound alters visual motion perception, Nature\n384, 308.\nShimojo, S. and Shams, L. (2001). Sensory modalities are not separate modalities: plasticity\nand interactions, Curr. Opin. Neurobiol. 11, 505–509.\nTaylor, V . (2014). Youtube videos trigger tingling ‘brain orgasms’ in ASMR practitioners. Avail-\nable from http://www.nydailynews.com/.\nThibodeau, P. H. (2016). A moist crevice for word aversion: in semantics not sounds, PloS One\n11, e0153686. DOI:10.1371/journal.pone.0153686.\nViinikainen, M., Kätsyri, J. and Sams, M. (2012). Representation of perceived sound valence in\nthe human brain, Hum. Brain Mapp. 33, 2295–2305.\nZald, D. H. and Pardo, J. V . (2002). The neural correlates of aversive auditory stimulation,\nNeuroimage 16, 746–753."
    },
    {
      "section": "Page 18",
      "page_number": 18,
      "text": "Copyright\nof\nMultisensory\nResearch\nis\nthe\nproperty\nof\nBrill\nAcademic\nPublishers\nand\nits\ncontent\nmay\nnot\nbe\ncopied\nor\nemailed\nto\nmultiple\nsites\nor\nposted\nto\na\nlistserv\nwithout\nthe\ncopyright\nholder's\nexpress\nwritten\npermission.\nHowever,\nusers\nmay\nprint,\ndownload,\nor\nemail\narticles\nfor\nindividual\nuse."
    }
  ]
}