{
  "doc_type": "scientific paper",
  "title": "Identification of Everyday Sounds Affects Their Pleasantness",
  "authors": [
    "Laurie M. Heller",
    "Jessica M. Smith"
  ],
  "year": 2022,
  "journal": "Frontiers in Psychology",
  "doi": "10.3389/fpsyg.2022.894034",
  "abstract": "This study examines the role of source identification in the emotional response to everyday sounds. Although it is widely acknowledged that sound identification modulates the unpleasantness of sounds, this assumption is based on sparse evidence on a select few sounds. We gathered more robust evidence by having listeners judge the causal properties of sounds, such as actions, materials, and causal agents. Participants also identified and rated the pleasantness of the sounds. We included sounds from a variety of emotional categories, such as Neutral, Misophonic, Unpleasant, and Pleasant. The Misophonic category consists of everyday sounds that are uniquely distressing to a subset of listeners who suffer from Misophonia. Sounds from different emotional categories were paired together based on similar causal properties. This enabled us to test the prediction that a sound's pleasantness should increase or decrease if it is misheard as being in a more or less pleasant emotional category, respectively. Furthermore, we were able to induce more misidentifications by imposing spectral degradation in the form of envelope vocoding. Several instances of misidentification were obtained, all of which showed pleasantness changes that agreed with our predictions.",
  "keywords": [
    "misophonia",
    "sound category",
    "sound emotion",
    "causal properties",
    "everyday sounds",
    "sound identification",
    "context effects",
    "unpleasant sounds"
  ],
  "research_topics": [
    "auditory cognition",
    "emotional response to sound",
    "sound source identification",
    "causal properties of sounds",
    "misophonia",
    "pleasantness ratings of sounds",
    "sound misidentification",
    "acoustic signal degradation",
    "experimental psychology",
    "sound perception"
  ],
  "created_at": "2025-05-05T01:33:13.943810Z",
  "source_pdf": "documents/research/Global/Heller 2022 Identification of Everyday Sounds Affects Their Pleasantness.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 1\nORIGINAL RESEARCH\npublished: 08 July 2022\ndoi: 10.3389/fpsyg.2022.894034\nEdited by:\nM. Zachary Rosenthal,\nDuke University, United States\nReviewed by:\nMercede Erfanian,\nUniversity College London,\nUnited Kingdom\nScott Vrana,\nVirginia Commonwealth University,\nUnited States\n*Correspondence:\nLaurie M. Heller\nlaurieheller@cmu.edu\n†These authors have contributed\nequally to this work\nSpecialty section:\nThis article was submitted to\nAuditory Cognitive Neuroscience,\na section of the journal\nFrontiers in Psychology\nReceived: 11 March 2022\nAccepted: 20 June 2022\nPublished: 08 July 2022\nCitation:\nHeller LM and Smith JM (2022)\nIdentiﬁcation of Everyday Sounds\nAffects Their Pleasantness.\nFront. Psychol. 13:894034.\ndoi: 10.3389/fpsyg.2022.894034\nIdentiﬁcation of Everyday Sounds\nAffects Their Pleasantness\nLaurie M. Heller *†and Jessica M. Smith†\nAuditory Lab, Department of Psychology, Carnegie Mellon University, Pittsburgh, PA, United States\nThis study examines the role of source identiﬁcation in the emotional response\nto everyday sounds. Although it is widely acknowledged that sound identiﬁcation\nmodulates the unpleasantness of sounds, this assumption is based on sparse\nevidence on a select few sounds. We gathered more robust evidence by having\nlisteners judge the causal properties of sounds, such as actions, materials, and causal\nagents. Participants also identiﬁed and rated the pleasantness of the sounds. We\nincluded sounds from a variety of emotional categories, such as Neutral, Misophonic,\nUnpleasant, and Pleasant. The Misophonic category consists of everyday sounds\nthat are uniquely distressing to a subset of listeners who suffer from Misophonia.\nSounds from different emotional categories were paired together based on similar causal\nproperties. This enabled us to test the prediction that a sound’s pleasantness should\nincrease or decrease if it is misheard as being in a more or less pleasant emotional\ncategory, respectively. Furthermore, we were able to induce more misidentiﬁcations by\nimposing spectral degradation in the form of envelope vocoding. Several instances of\nmisidentiﬁcation were obtained, all of which showed pleasantness changes that agreed\nwith our predictions.\nKeywords: misophonia, sound category, sound emotion, causal properties, everyday sounds, sound\nidentiﬁcation, context effects, unpleasant sounds\nINTRODUCTION\nEveryday sounds play an important role in our lives by providing information about the events\noccurring in the world around us. For example, sounds help to keep us alive by warning us of\napproaching danger in our environment, especially in the absence of visual information such as\nin the dark or when we are asleep. Similarly, sounds signal the start of new events, causing us to\ndivert our attention to sudden changes in sound (Neuhoﬀ and Heller, 2015). Upon hearing a sound,\nwe also cognitively infer features about its source and the physical event that produced it. Most\nsound-causing events are best described as a force applied to an object (or substance) causing it to\nvibrate. Since the sounds which humans hear are the result of the propagation of these vibrations\n(usually through air), sound provides vital information about the causal properties of the event.\nThe properties considered in this study are: causal action (e.g., an impact), causal object (properties\nof the object that make the sound, such as a hollow drum and a stick), and causal agent (such as\na person). There is evidence that people use causal properties when identifying sound sources. For\nexample, people can identify causal actions (Guastavino, 2007; Lemaitre and Heller, 2012; Martín\net al., 2015; Navolio et al., 2016; Lemaitre et al., 2018), causal materials and object properties (Arnott\net al., 2008; Grassi et al., 2013; Lemaitre et al., 2018), causal sound source (Ballas, 1993), and causal\nFrontiers in Psychology | www.frontiersin.org 1 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 2\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nagents (Caramazza and Shelton, 1998; Engel et al., 2009). While\neveryday sounds inform us about the environment, they are also\nqualitatively diﬀerent than other common sounds, particularly\nsocial ones such as language and music. In contrast to language\nand music, everyday sounds are not as structured, tonal, and\nrhythmic. Instead, they contain more noise and randomness,\nwhich makes their acoustical features generally diﬃcult to\ncharacterize (McDermott, 2012). Nonetheless, we have made\nprogress in ﬁnding acoustic regularities in everyday sounds which\ncan help discriminate their causal actions (Gygi et al., 2004; Heller\nand Sheikh, 2019).\nWhile sounds inform us about events, it is also common\nfor sounds to trigger emotional or physiological responses (Keil\net al., 2007). Some sounds, such as a favorite piece of music, can\nevoke joy or pleasant chills (Blood and Zatorre, 2001; Barratt\nand Davis, 2015), while other sounds, such as crying, can evoke\ndiscomfort (Zald and Pardo, 2002; Anders et al., 2008; Grewe\net al., 2011; Kumar et al., 2012; Ro et al., 2013). However, for a\nsubset of people, certain common sounds elicit irritation, rage,\nor even panic (Edelstein et al., 2013; Rouw and Erfanian, 2018).\nIndividuals who experience this type of debilitating response\nsuﬀer from a sound intolerance disorder known as Misophonia\n(Jastreboﬀ and Jastreboﬀ, 2001; Swedo et al., 2022). Estimates of\nMisophonia prevalence range from about six to twenty percent of\nthe population, depending on the criteria used, and Misophonia\ntends to impact more women than men (Potgieter et al.,\n2019). Misophonia has been characterized as a chronic disorder,\nand can be comorbid with other conditions, for example,\nobsessive–compulsive disorder, anxiety, and the personality trait\nof neuroticism (Cusack et al., 2018; Erfanian et al., 2019;\nCassiello-Robbins et al., 2020, 2021; Çolak et al., 2021). Although\nMisophonia is similar to other sound intolerance disorders such\nas Hyperacusis, a number of researchers have made a strong\ncase for Misophonia being a unique disorder in terms of its\nspeciﬁc symptoms and neural responses (Edelstein et al., 2013;\nCavanna and Seri, 2015; Kumar et al., 2017; Taylor, 2017; Brout\net al., 2018). Although more than one set of criteria exists for\nMisophonia, including the Amsterdam Misophonia Scale (A-\nMISO-S), MisoQuest, Misophonia Questionnaire (MQ), and the\nDuke Misophonia Questionnaire, there is good agreement on\nthe common trigger sounds (Schröder et al., 2013; Wu et al.,\n2014; Jager et al., 2020; Siepsiak et al., 2020; Naylor et al., 2021;\nRosenthal et al., 2021). More speciﬁcally, common trigger sounds\ntypically arise from everyday events which makes it particularly\ndiﬃcult to avoid triggers. Misophonia trigger sounds are often\nnoises made by the body of another person, especially nasal\nand oral sounds, like slurping and chewing, and/or repetitive\nnoises, such as keyboard typing or pencil tapping, but they are\nnot conﬁned to those categories (Enzler et al., 2021; Hansen\net al., 2021). The person or context producing the sounds can\naﬀect the trigger’s potency. When in the presence of triggers,\nthese sounds disturb mental faculties such as cognitive control\nand learning retention in misophonic individuals (Seaborne and\nFiorella, 2018; Daniels et al., 2020). The prevalence of these\ntriggers can cause people to avoid school, family, and friends. This\navoidance can severely damage social interactions and overall\nquality of life.Although misophonic triggers are well documented, there is\nno comprehensive or predictive explanation as to why certain\nsounds tend to become triggers. However, there is evidence\nin the literature that profound emotional responses to sound\ncan be driven by the meanings and causes of the events\nthat the sounds signify, rather than by the sounds’ acoustic\nqualities (Halpern et al., 1986; Brout et al., 2018; Edelstein\net al., 2020). This claim is supported by the observation that\nthe identiﬁcation of a sound can change its perceived valence.\nConsider the example of scratching a slate blackboard. Listeners\nwho are informed that the experiment used the sound of a\nscratched blackboard rated the sound as worse than participants\nwho were not given this information (Ely, 1975; Halpern\net al., 1986). It is worth asking whether this observation for\na generally unpleasant sound generalizes over a wider range\nof sounds. There is one known example of a similar eﬀect\nfor a misophonic sound, in which human eating sounds are\nrated as more unpleasant if correctly categorized at the time\nof the rating (Edelstein et al., 2020). For all types of sounds,\nmisophonic or not, it is useful to expand the repertoire of\nknown instances in which misidentiﬁcation of a sound changes\nits valence. Obtaining a larger number of examples will permit\nus to discover whether this eﬀect is systematic and if so,\nhow unpleasantness relates to the identiﬁcation and causal\nproperties of sounds.\nGiven that sound identiﬁcation can inﬂuence the emotional\nresponse to a sound, it follows that the perception of causal\nproperties should likewise aﬀect the pleasantness of a sound. Yet,\nit is unknown how each of these causal properties contribute\nto a misophonic response. The types of sounds that have been\nfound to precipitate misophonic responses are caused by a variety\nof actions (scraping, tapping, etc.), materials (metal, liquid,\netc.), and agents (human, machine, etc.). For example, it may\nbe the case that the same object produces either a disturbing\nor pleasant sound depending upon the action performed with\nit. One opportunity to study these questions is provided by\nmisidentiﬁcation of sounds because they reveal the eﬀect of the\nmeaning of a sound separate from its acoustics.\nTo create an experiment that produces misidentiﬁcations,\nwe started with the observation that listeners naturally infer\nqualities about sounds when they hear them. Our study addresses\nthis notion by asking listeners about the causal properties they\nhear in everyday sounds: actions, materials, and causal agents.\nIn some instances, listeners might identify only some of the\ncausal properties of a sound, but in others, they may infer\nmultiple possible causes or misattribute a certain causal property.\nConsidering that sound recognition is the endpoint of the\nauditory cognition process, causal properties such as actions\nand materials may be inferred (either correctly or incorrectly)\nregardless of whether the sound source is identiﬁed. Here we\ninvestigated whether misinterpretation of a sound’s cause altered\nits pleasantness. We hypothesized that a sound that is normally\nneutral should become more unpleasant if the causal action or\nmaterial is heard incorrectly as being that of a more negative\nsound. In contrast, a sound that is normally unpleasant should\nbecome more positive if the cause of the sound is misheard as\nhaving a more neutral source.\nFrontiers in Psychology | www.frontiersin.org 2 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 3\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nWe tested this hypothesis by including sounds that shared\nsimilar causal properties to encourage misidentiﬁcation.\nThe ﬁnal set of everyday sounds belonged to one of the\nfollowing categories: Neutral, Misophonic, Unpleasant,\nor Pleasant. Each Negatively valenced sound (from both\nUnpleasant and Misophonic categories) was paired with a\nNeutral sound; for example, the sound of Slurping a beverage ,\na Misophonic sound, was paired with the sound of a Sink\ndraining , a Neutral sound. Listeners judged the pleasantness,\ncausal actions, materials, and agents of all sounds before\nthey attempted to identify any of them. Our population was\nnot recruited or screened for any diagnosis, although we\nmeasured each listener’s self-reported tendency toward sound\nintolerance. In a second experiment, we address the fact that\nmisidentiﬁcation of causal properties of everyday sounds\ncan happen due to a degradation of the acoustic signal. For\nexample, distortion resulting from sensorineural hearing loss,\nhearing aids, and cochlear implants (CIs) may all degrade\nauditory inputs, thereby producing a higher rate of sound\nmisidentiﬁcations. We tested whether such experimentally\ninduced misidentiﬁcations would display the same eﬀect on\npleasantness seen in Experiment One and whether these acoustic\ndistortions reduce pleasantness overall.\nEXPERIMENT 1\nOur ﬁrst Experiment examined the role of source identiﬁcation\nin the pleasantness of everyday sounds. Naïve listeners assigned\ncausal properties, such as materials, actions, and agents, to\nunidentiﬁed brief everyday sounds. We used prior research\nto sort these sounds into four emotional categories: Neutral,\nPleasant, Unpleasant, or Misophonic (Cox, 2008; Enzler\net al., 2021; pilot data). The possible causal actions were:\ncrushing, scraping, tapping, ringing, blowing, puﬃng, suctioning,\nsplashing, and ﬂowing. The possible causal materials were:\nwood, metal, air, liquid, human body. The causal agents\nwere living (either human or non-human) or non-living.\nSubsequently, listeners rated sound pleasantness, and lastly,\nthey identiﬁed each sound from a closed set of possible labels.\nThe stimulus set was constructed so that each Unpleasant\nand Misophonic sound had an action and material that was\npresent in at least one Neutral sound. This design permitted\nthe exploration of whether misattribution of a property was\nassociated with a change in the pleasantness rating to match\nits attribution.\nMethods: Experiment 1\nParticipants\nRecruitment for both experiments was conducted through\nCarnegie Mellon University’s (CMU) Psychology Department for\ncourse credit. Consent and procedures were approved by CMU’s\nInstitutional Review Board. Participants under 18 years old or\nwith abnormal hearing were excluded. All participants ranged\nin age from 18 to 22, with the majority being undergraduate\nstudents. Experiment 1 had 39 participants who passed the\nscreening (21 male, 17 female, 1 other).Stimuli\nThe stimuli were fourteen brief everyday sounds covering a range\nof categories, actions, and materials. The sounds were sorted into\nNeutral, Pleasant, Unpleasant, and Misophonic categories based\non previous literature and preliminary tests (Cox, 2008; Enzler\net al., 2021). Table 1 displays all fourteen sound stimuli, with\ntheir names, categories, and pair labels. See the next paragraph\nfor a full discussion of the pair labels. Each sound was trimmed to\nhave a duration between 1 and 5 s (see Supplementary Table S1 ).\nSounds were diotic, 16-bit 44,100 Hz WAV ﬁles. Experiment\n1 stimuli were matched based on perceptual loudness, which\nwas equalized in two steps. First, the root mean square (RMS)\nof the sample amplitudes ( \u00001 to 1) in each sound ﬁle was\ncomputed (RMS ranged from 0.00343 to 0.02386) and scaled\nto be equal. Second, listening in the lab determined that some\nsounds needed to be adjust downwards in level to match the\nloudness of the others. This process was done for each sound\niteratively until they were agreed to match in loudness by a\npilot test of three listeners. We obtained these sounds from\nvarious sources, including the Dataset of Environmental Sound\nClassiﬁcation (ESC-50) ( Ringing church bells ,Slurping beverage ,\nWind blowing ), in-house recordings ( Tool scraping ,Squeezing\nspray bottle ,Sink draining ,Squeezing spray bottle ,Chewing food ),\nand freesound.org ( Woodpecker tapping ,Fork scraping plate ,\nRinging ﬁre alarm ,Nose sniﬄing ,Clicking a pen ,Stream ﬂowing )\n(Piczak, 2015).\nWe paired the six Misophonic and Unpleasant sounds with\neach Neutral sound by shared causal properties. For each, the pair\nnumber and sound category is labeled by C# (C = sound category,\neither N for Neutral, M for Misophonic, U for Unpleasant, or\nP for Pleasant, and # = pair number). The intended pairings\nfor Unpleasant sounds were the Fork scraping plate (U1) and\nTool scraping (N1), which shared the scraping action and metal\nTABLE 1 | Fourteen sound stimuli utilized in Experiment 1 and Experiment 2.\nSound number Sound name Category Pair label\n1 Tool scraping Neutral N1\n2 Ringing church bells Neutral N2\n3 Squeezing spray bottle Neutral N3\n4 Sink draining Neutral N4\n5 Stirring cereal Neutral N5\n6 Woodpecker tapping Neutral N6\n7 Nose snifﬂing Misophonic M3\n8 Slurping a beverage Misophonic M4\n9 Chewing food Misophonic M5\n10 Clicking a pen Misophonic M6\n11 Fork scraping a plate Unpleasant U1\n12 Ringing ﬁre alarm Unpleasant U2\n13 Wind blowing Pleasant P7\n14 Stream ﬂowing Pleasant P7\nThe emotional category is noted for each sound, with six sounds belonging\nto the neutral category, four sounds belonging to the misophonic category,\nand two sounds each belonging to the unpleasant and pleasant categories.\nEach sound has a pair label to represent each pairing between a Neutral and\nMisophonic/Unpleasant (negative) sound that share at least one causal property.\nEach label is structured as C# (C, valence category; #, the pair number). In following\ntables, the pair label is added to each sound name.\nFrontiers in Psychology | www.frontiersin.org 3 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 4\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nmaterial, and the Ringing ﬁre alarm (U2) and Ringing church bells\n(N2), which shared ringing action and metal material. These two\nintended pairs are denoted as Pairs 1 and 2, respectively. The\npairings with Misophonic sounds were as follows: Nose sniﬄing\n(M3) and Squeezing a spray bottle (N3) shared puﬃng action\nand air material; Slurping beverage (M4) and Sink draining (N4)\nshared suctioning/ﬂowing actions and liquid material; Chewing\nfood (M5) and Stirring cereal (N5) shared crushing action; and\nClicking a pen (M6) and Woodpecker tapping (N6) shared the\ntapping action. These pairings are denoted as Pairs 3–6. The\ntwo Pleasant sounds, Stream ﬂowing and Wind blowing were not\npaired with a shared action or material and are both referred to\nas Pair 7 (P7). Supplementary Table S1 shows the sound pairings\nand their presumed overlapping causal properties.\nDesign\nThe ﬁve sections of experimental questions about sound events\nwere: causal actions (nine items), causal materials (ﬁve items),\ncausal agent (one item), pleasantness, and identiﬁcation. These\nsections are displayed in Table 2 , including speciﬁc details about\neach. These seventeen questions were divided into three blocks,\nwith the fourteen sounds presented in random order within\neach block. The ﬁrst block consisted of three matrices that\ncontained the causal properties. Each sound was played once,\nwith instructions that permitted replaying only if there was a\ntechnical diﬃculty in hearing the sound. On a single page, all\nmatrices were presented beneath the sound clip and rated before\nmoving on to the next sound. The action questions, presented\nin a matrix format, asked how likely it was that a particular\naction could have produced some, or all, of the sound. The\naction verbs were: crushing, scraping, tapping, ringing, blowing,\npuﬃng, suctioning, splashing, and ﬂowing. This action set was\nbased on previous studies (Lemaitre and Heller, 2012; Heller\nand Sheikh, 2019; Elizalde et al., 2021) and piloting; they were\nsound-generating action verbs that ensured every sound had at\nleast one relevant action. We kept the number of verbs small\nby ensuring that they pertained to more than one sound and\ntherefore were not equivalent to identifying a single sound source.\nThe material matrix asked whether each material was directly\ninvolved in making the sound. The material words were: wood,\nmetal, air, liquid, and human body. The causal agent question\nwas a third matrix that asked how likely it was that the sound\nwas caused by the actions of a living being, irrespective of\nit being a human or an animal. This animate agent question\nspeciﬁcally asked whether a living source performing an action on\nan object caused the sound. This question allowed for the listener\nto indicate an animate cause (a human) directing the events\n(drumbeats) despite the core elements of the sound event being\ninanimate (a stick and a drum). In each of these rating questions,\nthe instructions encouraged participants to give ratings greater\nthan 1 for more than one question per sound. This instruction\nencouraged thoughtful responses and discouraged rating one\naction or material high and all others low.\nThe second experimental block contained questions about\nsound pleasantness. Sounds were presented one at a time on\nthe page in random order. Pleasantness ratings for each sound\nwere given via a slider scale ranging from –5 to 5, withendpoints labeled as very unpleasant, to very pleasant, with a 0\ndenoting neutrality.\nIn the third block, participants identiﬁed sounds in a closed-\nset task. Questions for each sound were presented one at a time,\nin random order. Each question only allowed for a single choice\nout of fourteen options, with each option correctly matching\nonly one of the fourteen sounds. Each answer choice used\nboth a noun and verb to describe the sound; this labeling\nmethod does not favor sounds that are described best by their\naction or by their object/source. The labels for the sounds were:\nchewing food, clicking a pen, fork scraping a plate, nose sniﬄing,\nringing church-bell, ﬁre-alarm ringing, sink draining, slurping\nbeverage, stream ﬂowing, stirring cereal, squeezing spray-bottle,\ntool scraping, wind blowing, and woodpecker tapping. This\nsection came last so that these sound labels would not aﬀect the\njudgments of causal properties or pleasantness.\nTo check for attentive online listening, a single oddball\nquestion was inserted between the ﬁrst (causal action, material,\nand agent) and second (pleasantness) blocks of experimental\ntrials. The oddball question contained a diﬀerent sound and\nquestion compared to what was used in the rest of the experiment.\nAfter the last experimental block, participants were asked to recall\nthe oddball question by answering a multiple-choice question\nabout its contents.\nFor Experiment 1, the oddball question was a recording\nof a voice saying the word “rolling” and the question asked\nwhich verb was spoken during that trial. The answer choices\nincluded multiple options of verbs, including all nine causal\naction items except suctioning and ﬂowing, and others (e.g.,\n“rolling, ” “clattering, ” “calling, ” “wailing, ” “rotating, ” “vibrating, ”\n“dripping). The recall question at the end of the survey tasked\nthe participant to choose the oddball sound from a list, including\nsimilar types of answers (e.g., “saying metal, ” “saying wood, ”\n“saying breaking”) or other environmental sounds (e.g., “dog\nbarking, ” “piano, ” “people clapping, ” “paper crumpling”).\nProcedure\nThe survey typically took 30–40 min to complete via a secure\nonline survey platform (Qualtrics). Participants were instructed\nto take the test in a private, quiet location of their choosing, to\nrefrain from eating or chewing gum, and to wear headphones.\nParticipants ﬁrst completed a consent form and read the\ninstructions for the experiment. They next completed questions\nabout age, gender, hearing status, and sound tolerance. The sound\ntolerance items were taken directly from MisoQuest (Siepsiak\net al., 2020), a questionnaire for Misophonia. They were asked to\nagree or disagree on a ﬁve-point Likert scale to the statements:\n“I ﬁnd some sounds made by the human body unbearable, ”\nand, “Some sounds bother me so much that I have diﬃculty\ncontrolling my emotions.” These two questions’ averaged score\nserved as a measure of general Sound Intolerance. This subset\nof questions from this questionnaire was chosen because it\nassesses reactions to a broad range of sounds eﬃciently without\ncontaining wording that presumes the participant has sound\ntolerance issues. Given that our participants were from a general\npopulation, we avoided questionnaires that speciﬁcally assume\nsound issues (e.g., MQ, MAQ, A-MISO-S, “My sound issues\nFrontiers in Psychology | www.frontiersin.org 4 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 5\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 2 | Main ﬁve survey sections of action, material, agent, pleasantness, and identiﬁcation questions.\nSurvey section Question(s) Question type Answer choice labels Scale # of Rating items Rating items\nAction For each action listed below,\nhow likely is it that the action is\npossibly producing some (or all)\nof the sound?Matrix Rating 1 – deﬁnitely not producing the sound,\n5 – deﬁnitely producing the sound1–5 9 Crushing, Scraping,\nTapping, Ringing,\nBlowing, Pufﬁng,\nSuctioning, Splashing,\nFlowing\nMaterial For each material, how much\ndoes it describe the object\ndirectly making the sound?Matrix Rating 1 – not present in sound at all, does not\ndescribe sound object, 5 – deﬁnitely\npresent in the sound, does describe\nsound object1–5, 5 Wood, Metal, Air,\nLiquid, Human Body\nAgent How likely is it that this sound\nwas caused by the actions of a\nliving being? (This includes\nactions performed by a person\non an object.)Single Rating 1 – non-living, 5 – living 1–5 1 Cause of action\nPleasantness How pleasant is the sound to\nyou?Single Rating \u00005 - very unpleasant, 0 - neutral, 5 -\nvery pleasant\u00005 –5 1 Pleasantness\nIdentiﬁcation For this sound, which noun and\nverb pair listed best identiﬁes\nthis sound?Multiple-Choice Chewing food, Clicking a pen, Fork\nscraping plate, Nose snifﬂing, Ringing\nchurch bell, Fire alarm ringing, Sink\ndraining, Slurping beverage, Stream\nﬂowing, Stirring cereal, Squeezing\nspray bottle, Tool scraping,\nWoodpecker tapping, Wind blowing– – –\nThe ﬁrst column displays each of the ﬁve survey question sections. The second column for each section displays the primary question asked during the section. The third\ncolumn shows what type of questions were in the section. The fourth column details the speciﬁc answer choice labels provided on the questions to the participant, and\nthe ﬁfth column shows the general rating scale that participants had to choose from. The last two columns describe the number and identity of rating items that were\nranked for each sound.\ncurrently make me feel helpless.”) (Rosenthal et al., 2021). A third\nquestion that was also related to Hyperacusis was also asked:\n“Most loud sounds cause me to experience unpleasant emotions.”\nNext, participants completed a volume calibration in which\nwhite noise was played; its volume started out at zero and then\nthe listener slowly increased it to a comfortable level. Next, a\nheadphone screening asked participants to correctly do a task on\nat least two out of three trials that required the use of headphones\n(Milne et al., 2021). Finally, there was a practice trial with the\nexperimental questions using a sound that was not in the main\nexperiment. After the practice trial, the experiment began.\nData Quality Criteria\nParticipant responses were removed from the analysis if: (1)\nthey indicated that they did not have normal hearing; (2)\nthey failed the headphone screening; or (3) they answered the\noddball questions incorrectly. Due to survey programming, some\nparticipants were not asked to complete headphone screening\ntrials; their data were included after verifying that there was no\nsigniﬁcant eﬀect of the screening condition on causal property\nratings. That is, the ratings of these participants were statistically\nindistinguishable from the screened participants (via an ANOV A\nthat treated the headphone screening condition as a between-\nparticipants factor).\nResults: Experiment 1\nData Analysis\nAnalysis of each experiment proceeds in four steps: (1) causal\nproperties of each sound, (2) pleasantness of the sound categories,(3) identiﬁcation accuracy of the sound categories, and (4)\nhow misidentiﬁcation changes both causal properties and\npleasantness. A subsequent section compares results between\nboth experiments, including sound intolerance self-ratings. All\nANOV As are reported with Greenhouse–Geisser corrections\nregardless of whether sphericity assumptions are signiﬁcantly\nviolated, and all Intraclass Correlation Coeﬃcients (ICC) are\nreported for Average Measures, random eﬀects, and consistency.\nCausal Properties\nA repeated measures ANOV A treated Sounds as a factor with\n14 levels and Causal Properties as a factor with 15 levels (nine\nactions, ﬁve materials, and 1 causal agent). Both factors produced\nsigniﬁcant main eﬀects [Sound: F(8.2,303) = 11.8, p<0.001,\nG-G Epsilon 0.631; Property: F(6.0,221.4) = 83.8, p<0.001, G-G\nEpsilon 0.427] which signiﬁcantly interact [Sound by Property:\nF(22.4,830) = 60.0, p<0.001, G-G Epsilon 0.123]. There is no\nbetween-groups main eﬀect of the dichotic headphone Screen\n[F(1,37) = 0.008, p= 0.93] nor is there an interaction. Therefore,\nall data were combined, and this between-participant factor was\nremoved from further analyses. Table 3 presents the mean ratings\nfor each property and sound. Median ratings show very similar\npatterns in Supplementary Tables S2, S3 .\nOverall, the causal property ratings were appropriate for\neach sound. Table 3 shows a heatmap of the average rating for\neach causal property and sound. Table 3A speciﬁcally shows\nthe average action ratings per sound while Table 3B shows the\naverage material and agent ratings per sound. The sounds that\nwere paired with each other are in adjacent rows. This table\nshows that the task had face validity. Listeners agree on the causal\nFrontiers in Psychology | www.frontiersin.org 5 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 6\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 3A | Mean causal action property ratings taken across all participants are indicated in each table entry, with rows corresponding to one of the fourteen sound\ntokens and columns corresponding to the nine causal actions.\nCategory Sound name Crushing Scraping Tapping Ringing Blowing Pufﬁng Suctioning Splashing Flowing\nNeutral (N1) Tool scraping 1.2 4.8 1.2 1.3 1.3 1.1 1.1 1.1 1.1\nUnpleasant (U1) Fork scraping plate 1.2 5.0 2.1 1.3 1.1 1.0 1.1 1.0 1.1\nNeutral (N2) Ringing church bells 1.2 1.3 1.7 4.9 1.2 1.1 1.1 1.1 1.1\nUnpleasant (U2) Ringing ﬁre alarm 1.0 1.1 1.8 5.0 1.1 1.0 1.1 1.0 1.0\nNeutral (N3) Squeezing spray bottle 1.6 2.5 1.3 1.0 1.9 2.0 2.0 1.6 1.4\nMisophonic (M3) Nose snifﬂing 1.2 1.4 1.0 1.0 3.4 3.7 2.4 1.1 1.1\nNeutral (N4) Sink draining 1.0 1.1 1.0 1.0 1.2 1.2 1.9 3.2 4.3\nMisophonic (M4) Slurping beverage 1.1 1.1 1.0 1.0 1.5 1.4 4.4 2.1 2.0\nNeutral (N5) Stirring cereal 1.8 1.5 2.4 1.1 1.1 1.1 1.7 3.0 2.2\nMisophonic (M5) Chewing food 2.7 3.9 1.3 1.1 1.2 1.2 1.2 1.1 1.1\nNeutral (N6) Woodpecker tapping 1.4 1.8 4.4 1.2 1.2 1.1 1.2 1.1 1.1\nMisophonic (M6) Clicking a pen 1.4 1.4 4.3 1.2 1.2 1.1 1.3 1.0 1.0\nPleasant (P7) Wind blowing 1.1 1.3 1.1 1.1 4.5 2.5 1.4 1.1 2.1\nPleasant (P7) Stream ﬂowing 1.0 1.1 1.2 1.0 1.2 1.1 1.3 2.8 4.8\nThe intended valence category (neutral, unpleasant, misophonic, or pleasant) is indicated in the far-left column. Properties judged to have the highest likelihood of being\nthe cause of a sound are colored in blue (mean >4.0). Entries colored in green indicate means >3 and <=4. Entries colored in yellow indicate means >2 and <=3.\nTABLE 3B | Mean causal material and causal agent property ratings taken across all participants are indicated in each table entry, with rows corresponding to one of the\nfourteen sound tokens and columns corresponding to the ﬁve materials and one agent.\nCategory Sound name Wood Metal Air Liquid Body Agent\nNeutral (N1) Tool scraping 1.3 4.9 1.3 1.0 1.4 3.5\nUnpleasant (U1) Fork scraping plate 1.3 5.0 1.1 1.0 1.3 4.3\nNeutral (N2) Ringing church bells 1.3 5.0 1.8 1.1 1.2 3.0\nUnpleasant (U2) Ringing ﬁre alarm 1.2 4.9 1.6 1.1 1.2 2.1\nNeutral (N3) Squeezing spray bottle 2.0 2.1 3.3 1.9 1.8 3.3\nMisophonic (M3) Nose snifﬂing 1.3 1.1 4.0 1.2 4.8 4.8\nNeutral (N4) Sink draining 1.1 1.2 1.3 4.9 2.3 3.5\nMisophonic (M4) Slurping beverage 1.0 1.1 1.7 4.5 4.3 4.7\nNeutral (N5) Stirring cereal 2.6 1.8 1.3 3.7 2.3 3.6\nMisophonic (M5) Chewing food 3.3 1.7 1.2 1.6 3.1 3.9\nNeutral (N6) Woodpecker tapping 4.2 1.9 1.3 1.1 1.7 3.8\nMisophonic (M6) Clicking a pen 2.1 3.5 1.3 1.2 2.1 4.0\nPleasant (P7) Wind blowing 1.2 1.6 4.9 1.4 1.5 1.9\nPleasant (P7) Stream ﬂowing 1.1 1.2 1.3 5.0 1.9 2.1\nThe intended valence category (neutral, unpleasant, misophonic, or pleasant) is indicated in the far-left column. Properties judged to have the highest likelihood of being\nthe cause of a sound are colored in blue (mean >4.0). Entries colored in green indicate means >3 and <=4. Entries colored in yellow indicate means >2 and <=3.\nproperties; the average measure Intraclass Correlation Coeﬃcient\n(ICC) was 0.987 [95% CI from 0.985 to 0.990, F(209,7942) = 79.5,\np<0.0001). Both the Tool scraping and the Fork scraping plate\nsounds were rated high on scraping and metal with an animate\ncausal agent. Both the Ringing church bells and Ringing ﬁre\nalarm sounds were rated high on ringing and metal. Both the\nSqueezing spray bottle and Nose sniﬄing were rated high for\nair, but only Nose sniﬄing was heard as caused by puﬃng and\nblowing from a body. Results suggested that the Squeezing spray\nbottle was heard as having some likelihood of being caused by\nscraping wood. The pair of Sink draining and Slurping beverage\nboth had splashing and liquid properties but Sink draining had\nmore ﬂowing, while Slurping beverage had more suctioning.\nThe pair of Stirring cereal and Chewing food diﬀered, with theStirring cereal being rated high on splashing and liquid whereas\nChewing food was rated higher on scraping and wood. Both\ntheWoodpecker tapping and Clicking a pen sounds were heard\nas tapping caused by an animate agent, but the materials were\nwood and metal, respectively. As expected, Wind blowing was\nrated high on blowing whereas Stream ﬂowing was rated high on\nﬂowing. Because of the many post hoc comparisons implicit in a\ntable of this size, signiﬁcance levels are not indicated. Instead, an\naverage standard error (SE) of 0.137 per table entry was computed\nby initially deriving the SE across all 39 participants for each\nproperty and sound combination before averaging across all 210\nof those SEs (ﬁfteen causal properties x fourteen sounds). For\nreference, the maximum SE of any single value in the table was\n0.32. Note the N per entry is equal for all cells.\nFrontiers in Psychology | www.frontiersin.org 6 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 7\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nFIGURE 1 | Mean pleasantness rating versus the sound emotional category for all participants in Experiment 1. A 95% conﬁdence interval ( t-test) is shown,\nrepresented by a thick black line. All four emotional categories are shown, in ascending order of average pleasantness (unpleasant, misophonic, neutral, and\npleasant).\nPleasantness\nAlthough there was variation in the pleasantness of individual\nsounds within each emotional category, the mean valence of\neach category was ordered as expected, as shown in Figure 1 .\nThe far-left bar shows that the most unpleasant (and most\nnegatively rated) category was the Unpleasant category (–2.08,\n99%CI = 0.723), followed by the Misophonic category (–1.30,\n99%CI = 0.627). The Neutral emotional category was rated close\nto the neutral zero rating (–0.150, 99%CI = 0.562) and the\nPleasant category was rated positively (2.09, 99%CI = 0.739).\nThe distribution of scores across participants did not violate\nnormality or sphericity assumptions. A one-way ANOV A on the\nmean ratings showed that there was a main eﬀect of Emotional\nCategory on the pleasantness rating ( F(2.6,100.1) = 69.5,\np<0.001, G-G Epsilon 0.88) with the caveat that the number of\nsounds in each category was unequal. Recall that the Unpleasant\nsounds were expected to be the most negatively rated given that\nour population did not overrepresent misophonic participants,\nbut note that the Misophonic sounds were still negative, on\naverage. Therefore, for some of our subsequent analyses on\nthe eﬀects of misidentiﬁcation, we group the Unpleasant and\nMisophonic categories into a broader Negative valence group.\nExamining individual sounds instead of categories reveals that\nthe most negatively rated single sound was Nose sniﬄing (mean\nof –2.56) and the most positively rated sound was a Stream\nﬂowing (mean of 3.02). Individual sounds remained in their\na priori category regardless of their pleasantness rating. Most\nsounds were rated congruently with their a priori emotional\ncategory (their conﬁdence interval of the average rating eitherwas below zero, included zero, or above zero, if their emotional\ncategory was in the Negative, Neutral, or Positive valence group,\nrespectively). The only exceptions were: two Neutral sounds\n(Ringing church bells rated positively and Squeezing spray bottle\nrated negatively) and two Misophonic sounds ( Clicking a pen and\nChewing food had negative averages but their CIs included zero).\nNonetheless, our analysis kept sounds in their a priori categories.\nSound Identiﬁcation Accuracy\nIdentiﬁcation accuracy was computed by the percentage of\nparticipants who correctly selected the sound label out of the\nfourteen closed set options. Sound identiﬁcation accuracy was\nhigh across all 39 participants ( M= 90.1%, SD= 8.1%, SE= 1.5%,\nMedian = 92.9%, Range = 61.5–100%). The overall identiﬁcation\naccuracy for each sound, the sound it was most confused with,\nand how the valence of the emotional category shifted (upwards\ne.g., going from Negative to Neutral, or downwards, e.g., going\nfrom Negative to Neutral) is presented in Table 4 ; a complete\nconfusion matrix is in Supplementary Table S4 .\nOur main hypothesis concerns sound tokens that were\nmisidentiﬁed as a sound in another valence group. These\nemotional categories were deﬁned a priori as indicated in Table 1 ,\nas well as the broader Negative valence group which was a\ncombination of the Misophonic and Unpleasant categories.\nBecause our hypothesis was speciﬁc to changes in valence, we did\nnot analyze sounds that were misidentiﬁed as another sound in\nthe valence group; for example, if a Sink draining was confused\nwith Stirring cereal , this would be a confusion between two\nNeutral sounds and therefore would not be analyzed. However,\nFrontiers in Psychology | www.frontiersin.org 7 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 8\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 4 | Percentage of correct identiﬁcation for each sound token and the sound (if applicable) it was most confused with across all participants in Experiment 1.\nSound name Correct ID% Most often confused with Category shift\n(N1) Tool scraping 61 :54 Fork scraping plate (38.00%) Neutral – Negative\n(U1) Fork scraping plate 89 :74 Tool scraping (8.00%) Negative – Neutral\n(N2) Ringing church bells 100 :00 – –\n(U2) Ringing ﬁre alarm 97 :44 Ringing church bells (3.00%) Negative – Neutral\n(N3) Squeezing spray bottle 94 :87 Tool scraping (5.00%) –\n(M3) Nose snifﬂing 100 :00 – –\n(N4) Sink draining 89 :74 Slurping beverage (5.00%) Neutral – Negative\n(M4) Slurping beverage 100 :00 –\n(N5) Stirring cereal 64 :10 Chewing food (13.00%) Neutral – Negative\n(M5) Chewing food 66 :67 Tool scraping (23.00%) Negative – Neutral\n(N6) Woodpecker tapping 100 :00 – –\n(M6) Clicking a pen 100 :00 – –\n(P7) Wind blowing 100 :00 – –\n(P7) Stream ﬂowing 97 :44 Sink draining (3.00%) –\nCorrect sound token names are in the ﬁrst column while the most frequently perceived misidentiﬁcation is in the second to last column. Based on the highest perceived\nmisidentiﬁcation, the last column denotes the objective shift in category and predicts how it affects pleasantness. The middle-left column contains the correct identiﬁcation\npercentage for each sound. Each sound name also contains the sound’s pair label (emotional category and pair number).\nifSink draining was confused for Slurping beverage , which\nis a change across categories to a Negative valence sound\n(Misophonia emotional category), it would be a candidate for\ninclusion in the following analysis. A further criterion for\ninclusion was that this sound had to be misidentiﬁed across\ncategories at least 10% of the time (i.e., by 4 of the 39 participants).\nThere were four such sounds that met these criteria. These\nfour qualifying sounds were subjected to subsequent analysis,\nas follows in the next section. There were two Neutral sounds\nmisheard as something more Negatively valenced : Tool scraping\nand Stirring cereal . There were two Misophonic or Unpleasant\nsounds that were occasionally misheard as something more\nsomething more positively valenced (in both cases this was a\nneutral sound: Chewing food , and Fork scraping plate . These\nare “empirically discovered pairs” of misidentiﬁcations that can\narise from the same sound; these are distinct from the planned\npairs of sounds that had diﬀerent sources and some overlapping\ncausal properties. They can be noted in the confusion matrix in\ntheSupplementary Table S4 , which shows the actual sound in\nrows and the perceived sound category in columns. None of the\nsounds in the Pleasant category ended up qualifying for inclusion\n(because there were very few misidentiﬁcations involving those\nsounds). To clarify, in the following analysis, the perceived sound\nidentity was determined from the identiﬁcation data, but the\nemotional category was based on a priori predictions and the\npleasantness data were not used to determine the emotional\ncategory.\nMisidentiﬁcations\nWe used the opportunity provided by these empirically\ndiscovered misidentiﬁcations to test the prediction that\npleasantness should be higher for the sounds heard in a more\nPositively valenced group than in a more Negatively valenced\ngroup, regardless of whether or not that identiﬁcation is correct\n(see Table 5 ; a table of medians is provided in Supplementary\nTable S5 ). The mean pleasantness ratings for the four sounds\nidentiﬁed in the more Positively valenced group were 1.35points higher than the Negatively valenced group, which\nwas a marginally signiﬁcant diﬀerence [independent samples\nt(3) = 1.991, p<0.07, one-tailed]. Because the number of\nmisidentiﬁed sounds is small, the power is low (Cohen’s d= 1.4,\nHedge’s correction = 1.6). In the following section, these data will\nbe combined with more examples obtained from Experiment 2.\nEXPERIMENT 2\nOur second experiment addresses the fact that misidentiﬁcation\nof causal properties of everyday sounds can happen due to\na degradation of the acoustic signal. For example, distortion\nresulting from sensorineural hearing loss, hearing aids, and\nCIs may degrade auditory inputs, thereby producing a higher\nrate of sound misidentiﬁcations. We used psychoacoustically\nplausible signal degradation for two reasons: (1) it is a tool\nto produce more instances of misidentiﬁcation to test our\nhypothesis, and (2) it is a step toward understanding how\nhearing loss can aﬀect an individual’s positive or negative\nexperience of everyday sounds. Therefore, we conducted a second\nexperiment in which we spectrally degraded sounds processed\nby an envelope vocoder modulating a 16-channel noise.\nIn prior experiments using envelope-modulated noise which\nremoved frequency information but preserved temporal cues,\nthe identiﬁability of roughly half of the sounds were impaired\nwhereas half of the sounds still showed good identiﬁcation\n(Gygi et al., 2004; Shaﬁro et al., 2011). We used the same\nprocedure as Experiment 1 with vocoded versions of the sounds\nfrom Experiment 1.\nMethods: Experiment 2\nParticipants\nThere were 21 new young adult participants (10 male, 10\nfemale, 1 other) in Experiment 2. Otherwise, the recruitment,\nconsent process, and student population were the same as\nin Experiment 1.\nFrontiers in Psychology | www.frontiersin.org 8 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 9\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 5 | Mean pleasantness ratings for the most frequently misidentiﬁed sounds in Experiment 1 as a function of how they are identiﬁed.\nSound name Identiﬁcation accuracy Rating when perceived as\nunpleasant or misophonicIdentiﬁcation\naccuracyRating when perceived as\nneutral or pleasantRating\ndifference\nTool scraping Incorrect –0.2 Correct –0.4 –0.2\nCereal stirring Incorrect –1.4 Correct 0.5 1.9\nChewing food Correct –0.9 Incorrect –0.1 0.8\nFork scraping plate Correct –2.4 Incorrect 0.5 2.9\nAverage \u00001.2 0.1\nFor each sound stimulus, the sound token name is presented in the ﬁrst column. The Identiﬁcation accuracy column illustrates whether participants identiﬁed the sound\ncorrectly, i.e., with a label that ﬁt into the same a priori emotional category (correct), or whether they misidentiﬁed the sound with a label that ﬁt into a different a priori\nemotional category (incorrect). For the Correct entries, the mean pleasantness rating is taken across those participants who correctly identiﬁed the sound (less than 39\nbut always greater than 4, see Table 4 ); for the Incorrect entries, the mean pleasantness rating is taken across the 4 or more participants who made similar mistakes on\nthe same sound. The bottom of the table shows the average mean pleasantness for when a sound is perceived as unpleasant or misophonic and when it is perceived\nas neutral or pleasant. The green and purple color code for these averages connects with the one seen in Supplementary Tables S4, S6 . Here, a green box denotes\nwhen any category of sound is perceived as a sound in a neutral valence group. A purple box denotes when any category of sound is perceived as a sound in a negative\nvalence group (either misophonic or unpleasant category). These average values can also be seen in the regular blue lines in Figure 2 .\nMethods, Procedure, and Design\nAll methods and procedures were the same as for Experiment 1\nexcept as noted here. The stimuli were 16-channel noise vocoded\nversions of the fourteen sounds used in Experiment 1. (AngelSim\ncochlear implant and hearing loss simulator, v1.08.011; envelope\ndetection cutoﬀ frequency was 160 Hz with a 24 dB/oct slope;\nthe signal was bandpass ﬁltered into 16 logarithmically spaced\nchannels that were bandpass ﬁltered were analyzed; analysis and\ncarrier ﬁlters used the Greenwood frequency function with low-\npass and high-pass cutoﬀs of 200–7000 Hz with a 24 dB/oct\nslope.) Vocoding disrupts the spectral properties of the original\nsound but, by applying the amplitude envelope of the sound\nto noise, it preserves some of the temporal properties. The\nvocoded sounds were presented at the same RMS value as in\nExperiment 1. During the pre-trial instructions, participants\nlistened to ﬁve examples of non-target sounds paired in their\noriginal and vocoded forms to familiarize themselves with the\nsound of vocoded sounds. All the participants were asked to\ncomplete the same headphone screening trials. In Experiment\n2, the oddball trial contained audio asking participants to ‘Rate\nevery action a 4’ while the visual format of the causal action\nresponse matrix looked the same as other trials. In the ﬁnal\nrecall question, participants indicated the spoken oddball sound\nthey heard in a multiple-choice format (e.g., “rate every material\na 2, ” “skip this question, ” etc.). Data from eleven out of 32\npeople were disqualiﬁed from Experiment 2 for failing any one\nof these criteria.\nResults: Experiment 2\nData Analysis\nAnalysis of Experiment 2 focuses primarily on the eﬀects of\nidentiﬁcation on pleasantness. These data will also be integrated\nwith several analyses that include data from both experiments.\nCausal Properties\nAs with the regular sounds in Experiment 1, the causal properties\nof each sound were summarized as means. Listeners agreed on\nthe causal properties [ICC = 0.936, 95%CI 0.922 to 0.948, F(209,\n1http://www.tigerspeech.com/angelsim/angelsim_about.html4180) = 15.6, p<0.0001]. A repeated measures ANOV A on\nvocoded sounds treated Sounds as a factor with 14 levels and\nCausal Properties as a factor with 15 levels. Both factors produced\nsigniﬁcant main eﬀects [Sound: F(6.9, 137) = 5.6, p<0.001, G-G\nEpsilon = 0.529; Property: F(6.7,135) = 31.7, p<0.001, G-G\nEpsilon = 0.481] that interact signiﬁcantly [Sound by Property:\nF(16.3,325) = 13.4, p<0.001, G-G Epsilon = 0.089].\nPleasantness\nThe average pleasantness of the vocoded sounds overall was –\n0.35. The average pleasantness for the six sounds in the\nNeutral category was –0.63 (95%CI = –1.18 to –0.076). The\nfour sounds in the Misophonic category had an average\npleasantness of –0.49 (95%CI = –1.10 to 0.120). The two\nsounds in the Unpleasant category had an average pleasantness\naverage of –1.43 (95%CI = –2.20 to –0.66). The two sounds in\nthe Pleasant category had the highest average pleasantness of\n1.83 (95%CI = 0.93 to 2.74). Only the mean of the Pleasant\ncategory had conﬁdence intervals that did not overlap with the\nother categories.\nSound Identiﬁcation Accuracy\nIn Experiment 2, we found that sound identiﬁcation of spectrally\ndegraded sounds was modest for most sounds ( M= 53.7%,\nSD= 33.4%). The average identiﬁcation accuracy for the Neutral,\nMisophonic, Unpleasant and Pleasant categories, respectively,\nwere 42.1% (95%CI = 35.5% to 48.6%), 83.3% (95%CI = 77.0%\nto 89.6%), 26.2% (95%CI = 16.4% to 36.0%), and 38.1%\n(95%CI = 29.6% to 46.6%). Only the mean of the Misophonic\nemotional category had conﬁdence intervals that did not overlap\nwith the other categories, showing a higher accuracy. Average\nidentiﬁcation accuracies for each vocoded sound, the sound it\nwas most confused with, and how the valence of the emotional\ncategory shifted (e.g., going from Negative to Neutral or from\nNegative to Neutral) are presented in Table 6 ; a complete\nconfusion matrix is in Supplementary Table S6 .\nMisidentiﬁcations\nPleasantness shifts mapped to misidentiﬁcation are\nshown in Table 7 ; a table of medians is provided in\nFrontiers in Psychology | www.frontiersin.org 9 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 10\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 6 | Percentage of correct identiﬁcation for each sound token and the sound it was most confused with across all participants in Experiment 2.\nSound name Correct ID% Most often confused with Category shift\n(V. N1) Tool scraping 42.86 Fork scraping plate (24.00%) Neutral – Negative\n(V. U1) Fork scraping plate 42.86 Tool scraping (33.00%) Negative – Neutral\n(V. N2) Ringing church bells 38.10 Wind blowing (33.00%) Negative – Neutral\n(V. U2) Ringing ﬁre alarm 9.52 Wind blowing (33.00%) Negative – Neutral\n(V. N3) Squeezing spray bottle 23.81 Tool scraping (33.00%) –\n(V. M3) Nose snifﬂing 95.24 Wind blowing (5.00%) Negative – Neutral\n(V. N4) Sink draining 28.57 Slurping beverage (29.00%) Neutral – Negative\n(V. M4) Slurping beverage 95.24 Sink draining (5.00%) Negative – Neutral\n(V. N5) Stirring cereal 23.81 Tool scraping, Squeezing spray bottle, Sink draining, Clicking a pen (14.00%) Neutral – Negative\n(V. M5) Chewing food 42.86 Tool scraping, Stirring cereal (14.00%) Negative – Neutral\n(V. N6) Woodpecker tapping 95.24 Tool scraping (5.00%) –\n(V. M6) Clicking a pen 100.00 – –\n(V. P7) Wind blowing 9.52 Stream ﬂowing (81.00%) –\n(V. P7) Stream ﬂowing 66.67 Sink draining (33.00%) –\nCorrect sound recordings names are in the ﬁrst column while the most frequently perceived misidentiﬁcation is in the second to last column. Based on the highest\nperceived misidentiﬁcation, the last column denotes the objective shift in category and predicts how it affects pleasantness. The middle column contains the correct\nidentiﬁcation percentage for each sound. Each sound name includes a ‘V’ to signify that it is vocoded and its pair label (emotional category and pair number).\nSupplementary Table S7 . There were seven sounds that were\nmisidentiﬁed at least three times as a sound in a diﬀerent valence\ngroup (10%, the same criterion number used in Experiment 1).\nThe top four rows of the table show a Neutral category sound,\nsuch as a Tool scraping in row 1, incorrectly identiﬁed as an\nUnpleasant sound (such as Fork scraping plate ); its mean rating\nwhen misidentiﬁed this way is shown in row 1, column 3. For\ncomparison, the rating of that sound when it was correctly\nidentiﬁed by other participants is shown in row 1, column 5.\nThe bottom three rows of the table show the mean rating of\na correctly identiﬁed Misophonic or Unpleasant sound (such\nasRinging ﬁre alarm in row 7, column 3). For comparison,\nthe rating of that sound when it was incorrectly identiﬁed as a\nNeutral sound (such as Sink draining orWind blowing ) is shown\nin row 7, column 5. In all seven cases, the mean rating decreases\nbetween column 3 and 5. In all cases, pleasantness increased\nor decreased as predicted when a sound group changed from\nNegative to Neutral, or from Neutral to Negative, respectively.\nThe mean pleasantness ratings for the seven sounds identiﬁed in\nthe more Positively valenced group were 0.95 points higher than\nthe Negatively valenced group, which was a signiﬁcant diﬀerence\n[t(6) = 4.102, p<0.003, one-tailed, Cohen’s d= 0.61, Hedge’s\ncorrection = 0.66].\nBecause all four misidentiﬁed sounds in Experiment 1 also\nappeared in Experiment 2, it was possible to combine sounds\nacross the two studies for comparison and analysis. Figure 2\nplots the mean valences for these four sounds as a function\nof their perceived sound category valence; the blue solid line\nindicates results from the regular (non-vocoded) stimuli in\nExperiment 1 and the orange dashed line indicates results from\nthe vocoded stimuli in Experiment 2. This graph shows that the\nvalence increases as the misidentiﬁcation changes the category\nfor both experiments. An ANOV A with factors of Vocoding and\nValence of Perceived Category shows a main eﬀect of Perceived\nCategory [ F(1,6) = 9.12, p<0.02], but there is no main eﬀect of\nVocoding and no signiﬁcant interaction between Vocoding and\nPerceived Category.Comparison Across Experiments 1 and 2\nfor All Sounds\nSound Intolerance Self-Rating\nThe distributions of Sound Intolerance scores are shown in the\nblue bars for Experiment 1 and in the orange bars for Experiment\n2 in Supplementary Figure S1 . Only ﬁve of our 60 participants\nearned a score of 4.5 or greater. In this section comparing\nexperiments, Sound Intolerance scores are included as a covariate\nin the omnibus analysis to assess whether the variation within\nthis unscreened population could account for variation in the\nproperty and pleasantness ratings.\nCausal Properties\nIn an ANCOV A that included Vocoding as a between-group\nfactor, Sound Intolerance rating as a covariate, and Sound\ntoken and Causal Properties as within-group factors, Vocoding\n(regular vs. vocoded stimuli) had a signiﬁcant main eﬀect on\naverage Property ratings [ F(1,57) = 4.6, p<0.04] as well as\na two-way interaction with the within-group factors of Sound\n[F(9.5,541) = 2.59, p<0.002], Causal Property [ F(7.6,433) = 12.6,\np<0.001], and a three-way interaction with the same factors\n[F(182,10374) = 10.5, p<0.001]. Sound Intolerance rating had\nno main eﬀect or interaction. There was a main eﬀect of sound\n[F(9.5,541) = 3.0, p<0.001, G-G Epsilon = 0.730], Property\n[F(7.6,433) = 12.6, p<0.001, G-G Epsilon = 0.543], and a Sound\nby Property interaction [ F(32,1841) = 7.06, p<0.001].\nThe sound pairs had causal property ratings that were mostly\nconsistent with the regular, non-vocoded sounds [ICC = 0.808,\n95%CI 0.749–0.854, F(209,4180) = 5.2, p<0.0001], with the\naverage changes described below. After vocoding, both the Tool\nscraping and the Fork scraping plate sound decreased on scraping\n(decreased by 0.8 and 1.5, respectively) and metal (decreased by\n2.7 and 2.4, respectively). Only Fork scraping plate decreased in\nanimate causal agent (decreased by 1). Ringing church bells and\nRinging ﬁre alarm sounds were rated less robustly in ringing\n(decreased by 3.3 and 3.5, respectively) and metal (by 2 and\nFrontiers in Psychology | www.frontiersin.org 10 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 11\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nTABLE 7 | Mean pleasantness ratings for the most frequently misidentiﬁed sounds in Experiment 2 as a function of how they are identiﬁed.\nSound name Identiﬁcation accuracy Rating when perceived as\nunpleasant or misophonicIdentiﬁcation\naccuracyRating when perceived as\nneutral or pleasantRating\ndifference\n(V) Tool Scrape Incorrect \u00000:8 Correct \u00000:4 0.4\n(V) Squeezing spray bottle Incorrect \u00001:0 Correct 0 :1 1.1\n(V) Sink draining Incorrect \u00001:5 Correct 0 :5 2.0\n(V) Stirring cereal Incorrect \u00001:0 Correct 0 :4 1.4\n(V) Chewing food Correct 0 :8 Incorrect 1 :5 0.7\n(V) Fork scraping plate Correct \u00002:0 Incorrect \u00001:3 0.7\n(V) Ringing ﬁre alarm Correct \u00001:5 Incorrect \u00001:2 0.3\nAverage \u00001.0 \u00000.1\nFor each sound stimulus, the sound token name is presented in the ﬁrst column, with an added ‘V’ to signify the sound is vocoded. The Identiﬁcation accuracy column\nillustrates whether participants identiﬁed the sound correctly, i.e., with a label that ﬁt into the same a priori emotional category (correct), or whether they misidentiﬁed the\nsound with a label that ﬁt into a different a priori emotional category (incorrect). For the correct entries, the mean pleasantness rating is taken across those participants\nwho correctly identiﬁed the sound (less than 21 but always greater than 3, see Table 6 ); for the incorrect entries, the mean pleasantness rating is taken across the 3 or\nmore participants who made similar mistakes on the same sound. The green and purple color code for these averages connects with the one seen in Supplementary\nTables S4, S6 . Here, a green box denotes when any category of sound is perceived as a sound in a Neutral valence group. A purple box denotes when any category of\nsound is perceived as a sound in a Negative valence group (either misophonic or unpleasant category).\nFIGURE 2 | Mean pleasantness rating versus the perceived emotional category for both regular, non-vocoded sounds (solid blue line) and vocoded sounds (dashed\norange line). Ratings of sounds misidentiﬁed within the same emotional category were subaveraged. The error bars denote standard error of the mean rating across\nsounds. If the sound was identiﬁed (regardless of correctness) as an item in one of our a priori negative categories (either a misophonic or unpleasant sound) then it\ncontributed to a data point on the left, whereas if the sound was identiﬁed as an item in our neutral category (regardless of correctness), contributed to a data point\non the right.\n3.1, respectively). While the Nose sniﬄing maintained a high\nrating for air, puﬃng, and body, Squeezing spray bottle mildly\ndecreased in all three of these properties (by 0.8, 0.6, and 0.4)\nwhile increasing its tendency to be heard as scraping wood (by\n0.9). Both Sink draining and Slurping beverage maintained their\nratings on splashing and liquid. Stirring cereal was still rated\nhigh on splashing and liquid whereas Chewing food was rated\nlower on scraping (decreased by 0.9) and body (by 1.4). Both\ntheWoodpecker tapping and Clicking a pen sounds maintained\na similar pattern to the regular sounds, with highest ratings ontapping and animate agent (within 1 point diﬀerence). While\nStream ﬂowing maintained a high rating on ﬂowing and liquid,\nWind blowing had a large increase in rating for both properties\n(increased by 2.6 and 3.6, respectively) and a large decrease in\nratings for blowing and air ratings (both decreased by 3.1).\nPleasantness of Spectrally Degraded Sounds\nOn average, vocoded sounds were rated more neutrally;\nthe Negatively valenced sound categories were rated as less\nunpleasant than in Experiment 1, whereas the Pleasant sound\nFrontiers in Psychology | www.frontiersin.org 11 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 12\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\ncategory was rated as less pleasant than in Experiment 1.\nAccordingly, an ANOV A showed no signiﬁcant main eﬀect of\nVocoding, but there was a signiﬁcant main eﬀect of the Emotional\nCategory [ F(2.4,140.3) = 71.7, p <0.001, G-G Epsilon = 0.806]\nand there was an interaction between Vocoding and Emotional\nCategory [ F(2.4,140.3) = 2.94, p<0.05].\nTo assess the eﬀect of vocoding on pleasantness for individual\nsounds (rather than sound categories), an ANCOV A was\ndone using the factors of Vocoding and Sound token and\na covariate of Sound Intolerance self-rating. There was a\nmain eﬀect of Sound on pleasantness [ F(9.5,542) = 2.57,\np<0.006] (G-G Epsilon = 0.723). Vocoding interacted with\nSound [ F(9.5,542) = 4.93, p<0.001]. There was no main eﬀect\nof Sound Intolerance nor did it interact. Relative to Experiment\n1, pleasantness ratings were mostly unchanged; although a few\nsounds did not have overlapping standard error bars, this was\nequally distributed for both positive and negative shifts in\npleasantness. Figure 3 shows the mean pleasantness ratings for\neach individual sound when it was presented as a regular sound\nin Experiment 1 (solid blue lines) and when it was spectrally\ndegraded via vocoding in Experiment 2 (dashed orange lines);\na similar ﬁgure showing medians is provided in Supplementary\nFigure S2 . The blue lines grouping the two regular Unpleasant\nsounds in the far-left region of the ﬁgure show that these sounds\nare rated more unpleasant, on average, than the regular Neutral\nand Misophonic sounds, with the orange lines showing that the\nvocoded versions were slightly less negative on average (but all\nerror bars overlap). The blue lines grouping the four regular\nMisophonic sounds in the left-middle region of the ﬁgure show\nthat these sounds overlap in range with the Unpleasant sounds\nand the lower end of the regular Neutral sounds. The orange linesshow that the vocoded Misophonic sounds are not consistently\nlower on average than the regular Misophonic sounds: Vocoded\npleasantness increased beyond the error bars of Chewing food\nand Nose sniﬄing . The blue lines grouping the six regular\nNeutral sounds in the right-middle region of the ﬁgure show\npleasantness ratings varying around the neutral point, ranging\nfrom -1.53 to 1.18, with the orange lines showing that the vocoded\nversions had no systematic eﬀect on pleasantness. While the\nRinging church bells and Woodpecker tapping sounds were less\npleasant on average when vocoded, the Squeezing spray bottle\nwas more pleasant when vocoded. The blue lines grouping the\ntwo regular Pleasant sounds on the far-right of the ﬁgure show\nthat the Pleasant sound category was rated more highly than\nthe other sounds on average. Vocoding reversed the pleasantness\nfor the two sounds, by increasing beyond the regular condition’s\nerror bars for Wind blowing while decreasing below the regular\ncondition’s error bars for Stream ﬂowing .\nIdentiﬁcation\nThe reduction in change in identiﬁcation accuracy between\nExperiment 1 and 2 is evident in Figure 4 . It displays\npercent accuracy as a function of each of the individual\nsound pairs for both Experiment 1 and 2. The process of\nvocoding produced an eﬀect on identiﬁcation in an ANOV A\nthat treated the individual sounds as a within-participants\nvariable and the two studies as a between-participants variable\n(regular or vocoded stimuli). Accuracy of 90.1% for regular\nsounds was higher than the accuracy of 53.6% for vocoded\nstimuli [ F(1,58) = 228.4, p<0.001]. There was also a main\neﬀect of Sound token [ F(6.73,390.4) = 22.7, p<0.001, G-G\nepsilon = 0.518] and an interaction between Vocoding and Sound\nFIGURE 3 | Mean pleasantness rating for each of the fourteen sounds when presented in Experiment 1, with no vocoding (solid blue lines), and when presented in\nExperiment 2 as vocoded (dashed orange lines). The error bars indicate the standard error of the mean across the sounds. Each of the fourteen sounds is plotted in\nitsa priori emotional category, with the far-left, left, right, and far-right denoting the categories of unpleasant, misophonic, neutral, and pleasant. The more pleasant a\nsound is rated, the higher on the y axis it is placed.\nFrontiers in Psychology | www.frontiersin.org 12 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 13\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nFIGURE 4 | Mean identiﬁcation accuracy for each of the fourteen sounds in their pairs for regular sounds in Experiment 1 (solid blue bars) and vocoded sounds in\nExperiment 2 (striped, orange bars). Each sound name is replaced with its pair label, with P7-W denoting Wind ﬂowing and P7-S denoting Stream ﬂowing. The\nhigher the identiﬁcation accuracy for a particular sound, the higher on the y axis it is placed.\n[F(6.73,390.4) = 13.8, p<0.001]. An ANOV A that had a within-\nsubjects factor of Emotional Category and a between-subjects\nfactor of Vocoding show that accuracy was signiﬁcantly diﬀerent\nfor the diﬀerent Emotional Categories [ F(2.68,155.6) = 27.6,\np<0.001, G-G epsilon = 0.894]. Emotional Category\ninteracts with Vocoding [ F(2.68,155.6) = 31.9, p<0.001].\nAn examination of the mean changes in accuracy between\nregular and vocoded sounds shows that the Neutral category\nsigniﬁcantly decreases from 85.0% (95%CI = 80.2% to 89.8%)\nto 42.1% (95%CI = 35.5% to 48.6%). For the Misophonic\ncategory, the accuracy does not reliably decrease from 91.7%\n(95%CI = 87.0% to 96.3%) to 83.3% (95%CI = 77.0%\nto 89.6%). The Unpleasant category accuracy signiﬁcantly\ndecreased from 93.6% (95%CI = 86.4% to 100.8%) to 26.2%\n(95%CI = 16.4% to 36.0%). The Pleasant category accuracy\nsigniﬁcantly decreased from 98.7% (95%CI = 92.5% to 105.0%)\nto 38.1% (95%CI = 29.6% to 46.6%). Despite these vocoding-\ninduced changes in identiﬁcation accuracy within categories,\nthey did not correspond systematically to similar changes in\npleasantness ratings.\nDISCUSSION\nSound identiﬁcation can inﬂuence sound pleasantness in\nways that generalize across sounds. We were able to predict\nwhich direction pleasantness ratings should change based on\nwhich misidentiﬁcations were made. In order to produce\nmisidentiﬁcations, we utilized sounds with similar causal\nproperties in Experiment One, and we utilized spectral\ndegradation in Experiment Two. Listeners rated the causal\nproperties of these sounds so that we could assess whether themisidentiﬁcations were in fact based on these properties. We\nfound that causal properties were reliably conveyed.\nSound identiﬁcation rates for Experiment 1 were reasonably\nhigh at 90%. This outcome was expected because small closed-set\ntasks produce better performance than tasks with more options.\nThe purpose of keeping this task relatively easy in Experiment\n1 was to compare to performance in Experiment 2 on spectrally\ndegraded sounds. We expected the spectrally degraded stimuli\nin Experiment 2 to impair identiﬁcation. It did, but average\nidentiﬁcation was still at 53%.\nThe spectral degradation introduced by vocoding does not\ninherently make sound more unpleasant. In fact, it seems to make\nsounds more neutral, for both Positive and Negative valence\ngroups. This result may be a consequence of the high rate\nof misidentiﬁcation and uncertainty about the sounds’ causes.\nThe misidentiﬁcations caused by vocoding helps to elucidate\nthe relationship between causal properties and unpleasantness\nand can provide a baseline for future studies on the eﬀects of\nhearing impairment.\nOur goal in causing misidentiﬁcations was to use a principled\napproach to provide additional evidence for the importance of\nsource identiﬁcation on a sound’s unpleasantness. Our result is\nconsistent with Edelstein et al. (2020) who showed an eﬀect\nof identiﬁcation on the emotional response to the sound of\neating an apple. We note that our methodology diﬀered from\nEdelstein et al. (2020) in a few ways. Our participants completed\na single rating of the pleasantness of our sounds before they\nbegan identifying any sounds (with closed-set labels). In contrast,\nthe participants in Edelstein et al. (2020) identiﬁed each sound’s\ncategory during two of the three trials in which they rated the\nsound’s valence. It is possible that diﬀerent trial structures could\nalter the response to the valence task. For instance, the temporal\nFrontiers in Psychology | www.frontiersin.org 13 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 14\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nproximity of the identiﬁcation and valence tasks could increase\nthe salience of a sound’s identity relative to when valence is the\nsole focus. It is also possible that rating the same sound three\ntimes in a row can have an eﬀect. Another diﬀerence is that\nour participants heard a greater variety of sounds, about half of\nwhich were potentially unpleasant or misophonic. Finally, we\nconducted a normative population study rather than recruiting\npeople with sound intolerance. Despite the methodological\ndiﬀerences, our two studies reached similar conclusions about the\nimportance of the relationship between sound identiﬁcation and\nthe emotional response to sound.\nBecause this was a normative study of a student population,\ncomparisons with studies targeting misophonic populations are\nventured with caution. We did seek to connect this study\nwith others by asking whether the observed variation in self-\nrated intolerance levels could account for variance in sound\npleasantness within our population, but no relationship was\nfound in our data. It is possible that a stronger relationship\nwould be seen with more severe intolerance; however, there\nwere not enough participants to reliably analyze such a\nsubpopulation. It is also possible that a more complete self-\nreport of sound intolerance would reveal something not found\nhere. The remaining questions about how the sound properties\nand pleasantness diﬀer between populations could be addressed\nin a future study that targets more participants with sound\nintolerance issues such as Misophonia.\nWithin our population there are informative patterns of\nvariation in sound properties and emotional categories across\nsounds. As a caveat, this study was not designed to test a\ncorrelation between causal properties and emotions. If such a\ncorrelation does exist in the natural world, we disrupted this\nregularity by setting up the paired sounds that had similar\nactions and materials but diﬀerent emotional categories. By this\nsame logic, if we do ﬁnd a relationship between certain causal\nproperties and their category, it cannot be viewed as causal.\nSurely, this study’s stimuli overrepresented certain properties in\nour selection process. Nonetheless, it should be informative to\nmention some perceptual patterns that did emerge. The Pleasant\nsounds, as a group, were rated relatively higher on blowing and\nﬂowing (i.e., compared to the other three categories). Conversely,\nPleasant sounds were rated relatively lower on “animate causal\nagent.” Ratings tended to be high on metal and scraping for\nunpleasant sounds. Finally, as expected, ratings for a human body\nas a material were especially high for the Misophonic category.\nObtaining a likelihood rating for a range of causal properties\nfor every sound is time-consuming in an experiment. This\napproach limited the number of questions and sounds that\ncould be heard by the same listener within a short time span.\nBut causal information is helpful when searching for a way to\ngenerate, predict, or even resolve sound confusions (e.g., Elizalde\net al., 2021). For example, there was a hint in the data that\nthe recording of Squeezing spray bottle was sometimes heard as\nbeing caused by scraping wood. This suggest that multiple actions\ncan be interpreted from the same acoustic stimulus. A better\nunderstanding of how causal properties of events are perceived\nthrough sound might lead to insights into how and why sounds\nproduce emotions. If scientists can decode the clues given bythe subset of sounds that are common misophonic triggers, this\nmay shed light on the root cause of why certain people develop\nMisophonia and could help lead to more eﬀective treatments.\nOur study looked at the impact of identiﬁcation on the\nemotional response to sounds, but it is also true that this\nemotional response to a sound is related to its perceptual\njudgments and sound discrimination (Bergman et al., 2016).\nVitale et al. (2020) noted that more than one type of measure\nis necessary to characterize the emotional response to sounds,\nand misophonic responses can also be triggered by non-auditory\nstimuli. By addressing these issues and beyond, future research\nmay extend to applications beyond Misophonia, such as ﬁnding\nways to make auditory environments more pleasant for everyone\n(DeLoach et al., 2015).\nDATA AVAILABILITY STATEMENT\nThe raw data supporting the conclusions of this article will be\nmade available by the authors, without undue reservation.\nETHICS STATEMENT\nThe studies involving human participants were reviewed and\napproved by Carnegie Mellon University Institutional Review\nBoard. Written informed consent for participation was not\nrequired for this study in accordance with the national legislation\nand the institutional requirements.\nAUTHOR CONTRIBUTIONS\nBoth authors listed have made a substantial, direct, and\nequal intellectual contribution to the work, and approved it\nfor publication.\nFUNDING\nFunding was provided by a grant to LH from the REAM\nFoundation’s Misophonia Research Fund.\nACKNOWLEDGMENTS\nWe would like to thank Seojun Jang, Urszula Oszczapinska,\nNicole Navolio, and Michael Tarr for helpful comments on\na preliminary version of this manuscript and Nathan Luzum,\nMichael Harris, and Valeriy Shaﬁro for their help with vocoded\nstimuli.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found online\nat: https://www.frontiersin.org/articles/10.3389/fpsyg.2022.\n894034/full#supplementary-material\nFrontiers in Psychology | www.frontiersin.org 14 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 15\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nREFERENCES\nAnders, S., Eippert, F., Weiskopf, N., and Veit, R. (2008). The human amygdala is\nsensitive to the valence of pictures and sounds irrespective of arousal: an fMRI\nstudy. Soc. Cogn. Aﬀect. Neurosci. 3, 233–243. doi: 10.1093/scan/nsn017\nArnott, S. R., Cant, J. S., Dutton, G. N., and Goodale, M. A. (2008). Crinkling\nand crumpling: an auditory fMRI study of material properties. NeuroImage 43,\n368–378. doi: 10.1016/j.neuroimage.2008.07.033\nBallas, J. A. (1993). Common factors in the identiﬁcation of an assortment of brief\neveryday sounds. J. Exper. Psychol. 19, 250–267. doi: 10.1037/0096-1523.19.\n2.250\nBarratt, E. L., and Davis, N. J. (2015). Autonomous Sensory Meridian Response\n(ASMR): a ﬂow-like mental state. PeerJ 3:e851. doi: 10.7717/peerj.851\nBergman, P., Västfjäll, D., Tajadura-Jiménez, A., and Asutay, E. (2016). Auditory-\nInduced Emotion Mediates Perceptual Categorization of Everyday Sounds.\nFront. Psychol. 7:1565 doi: 10.3389/fpsyg.2016.01565\nBlood, A. J., and Zatorre, R. J. (2001). Intensely pleasurable responses to music\ncorrelate with activity in brain regions implicated in reward and emotion. Proc.\nNatl. Acad. Sci. 98, 11818–11823. doi: 10.1073/pnas.191355898\nBrout, J., Edelstein, M., Erfanian, M., Mannino, M., Miller, L., Rouw, R., et al.\n(2018). Investigating misophonia: a review of the empirical literature, clinical\nimplications, and a research agenda | neuroscience. Front. Neurosci . 12:36.\ndoi: 10.3389/fnins.2018.00036\nCaramazza, A., and Shelton, J. R. (1998). Domain-speciﬁc knowledge systems\nin the brain: the animate-inanimate distinction. J. Cogn. Neurosci. 10, 1–34.\ndoi: 10.1162/089892998563752\nCassiello-Robbins, C., Anand, D., McMahon, K., Brout, J., Kelley, L., and\nRosenthal, M. Z. (2021). A Preliminary Investigation of the Association\nBetween Misophonia and Symptoms of Psychopathology and Personality\nDisorders. Front. Psychol. 11:519681. doi: 10.3389/fpsyg.2020.519681\nCassiello-Robbins, C., Anand, D., McMahon, K., Guetta, R., Trumbull, J.,\nKelley, L., et al. (2020). The Mediating Role of Emotion Regulation\nWithin the Relationship Between Neuroticism and Misophonia: a Preliminary\nInvestigation. Front. Psychiatr. 11:847. doi: 10.3389/fpsyt.2020.00847\nCavanna, A. E., and Seri, S. (2015). Misophonia: current perspectives.\nNeuropsychiatr. Dis. Treat. 11, 2117–2123. doi: 10.2147/NDT.S81438\nÇolak, B., Duman, B., Herdi, O., Ýlhan, R. S., and Sakarya, D. (2021). Misophonic\nsymptoms in non-psychotic psychiatric outpatients and its association with\ntrait psychological variables. J. Obsessive-Comp. Related Dis. 29:100644. doi:\n10.1016/j.jocrd.2021.100644\nCox, T. J. (2008). Scraping sounds and disgusting noises. Appl. Acoustics 69,\n1195–1204. doi: 10.1016/j.apacoust.2007.11.004\nCusack, S. E., Cash, T. V., and Vrana, S. R. (2018). An examination of the\nrelationship between misophonia, anxiety sensitivity, and obsessive-compulsive\nsymptoms. J. Obsessive-Comp. Relat. Dis. 18, 67–72. doi: 10.1016/j.jocrd.2018.\n06.004\nDaniels, E. C., Rodriguez, A., and Zabelina, D. L. (2020). Severity of misophonia\nsymptoms is associated with worse cognitive control when exposed to\nmisophonia trigger sounds. PLoS One 15:e0227118. doi: 10.1371/journal.pone.\n0227118\nDeLoach, A. G., Carter, J. P., and Braasch, J. (2015). Tuning the cognitive\nenvironment: sound masking with “natural” sounds in open-plan oﬃces.\nJ. Acoustical Soc. Am. 137, 2291–2291. doi: 10.1121/1.4920363\nEdelstein, M., Brang, D., Rouw, R., and Ramachandran, V. (2013). Misophonia:\nphysiological investigations and case descriptions. Front. Hum. Neurosci. 7:296.\ndoi: 10.3389/fnhum.2013.00296\nEdelstein, M., Monk, B., Ramachandran, V. S., and Rouw, R. (2020). Context\ninﬂuences how individuals with misophonia respond to sounds. biorxiv\n[preprint]. doi: 10.1101/2020.09.12.292391\nElizalde, B., Revutchi, R., Das, S., Raj, B., Lane, I., and Heller, L. M. (2021).\nIdentifying Actions for Sound Event Classiﬁcation. ArXiv .[preprint]. doi: 10.\n48550/arXiv.2104.12693\nEly, D. J. (1975). Aversiveness without pain: potentiation of imaginai and auditory\neﬀects of blackboard screeches. Bull. Psychonomic Soc. 6, 295–296. doi: 10.3758/\nBF03336667\nEngel, L. R., Frum, C., Puce, A., Walker, N. A., and Lewis, J. W. (2009). Diﬀerent\ncategories of living and non-living sound-sources activate distinct cortical\nnetworks. NeuroImage 47, 1778–1791. doi: 10.1016/j.neuroimage.2009.05.041Enzler, F., Loriot, C., Fournier, P., and NoreÑa, A. J. (2021). A psychoacoustic\ntest for misophonia assessment. Sci. Rep. 11:11044. doi: 10.1038/s41598-021-90\n355-8\nErfanian, M., Kartsonaki, C., and Keshavarz, A. (2019). Misophonia and comorbid\npsychiatric symptoms: a preliminary study of clinical ﬁndings. Nordic J.\nPsychiatr. 73, 219–228. doi: 10.1080/08039488.2019.1609086\nGrassi, M., Pastore, M., and Lemaitre, G. (2013). Looking at the world with your\nears: how do we get the size of an object from its sound? Acta Psychol. 143,\n96–104. doi: 10.1016/j.actpsy.2013.02.005\nGrewe, O., Katzur, B., Kopiez, R., and Altenmüller, E. (2011). Chills in diﬀerent\nsensory domains: frisson elicited by acoustical, visual, tactile and gustatory\nstimuli. Psychol. Music 39, 220–239. doi: 10.1177/0305735610362950\nGuastavino, C. (2007). Categorization of environmental sounds. Can. J. Exper.\nPsychol. 61, 54–63. doi: 10.1037/cjep2007006\nGygi, B., Kidd, G. R., and Watson, C. S. (2004). Spectral-temporal factors in the\nidentiﬁcation of environmental sounds. J. Acoustical Soc. Am. 115, 1252–1265.\ndoi: 10.1121/1.1635840\nHalpern, D. L., Blake, R., and Hillenbrand, J. (1986). Psychoacoustics of a chilling\nsound. Percep. Psychophys. 39, 77–80. doi: 10.3758/BF03211488\nHansen, H. A., Leber, A. B., and Saygin, Z. M. (2021). What sound sources trigger\nmisophonia? Not just chewing and breathing. J. Clin. Psychol. 77, 2609–2625.\ndoi: 10.1002/jclp.23196\nHeller, L., and Sheikh, A. (2019). “Acoustic features of environmental sounds that\nconvey actions, ” in Proceedings of the 18th Annual Meeting Auditory Perception,\nCognition, and Action, November 14, 2019 , Montreal, QC.\nJager, I., Koning, P., de, Bost, T., Denys, D., and Vulink, N. (2020). Misophonia:\nphenomenology, comorbidity and demographics in a large sample. PLoS One\n15:e0231390. doi: 10.1371/journal.pone.0231390\nJastreboﬀ, P. J., and Jastreboﬀ, M. M. (2001). Components of decreased\nsound tolerance: hyperacusis, misophonia, phonophobia. ITHS News Lett. 5,\n1–5.\nKeil, A., Bradley, M. M., Junghöfer, M., Russmann, T., Lowenthal, W., and Lang,\nP. J. (2007). Cross-modal attention capture by aﬀective stimuli: evidence from\nevent-related potentials. Cogn. Aﬀect. Behav. Neurosci. 7, 18–24. doi: 10.3758/\nCABN.7.1.18\nKumar, S., Tansley-Hancock, O., Sedley, W., Winston, J. S., Callaghan, M. F., Allen,\nM., et al. (2017). The Brain Basis for Misophonia. Curr. Biol. 27, 527–533.\ndoi: 10.1016/j.cub.2016.12.048\nKumar, S., von Kriegstein, K., Friston, K., and Griﬃths, T. D. (2012). Features\nversus feelings: dissociable representations of the acoustic features and valence\nof aversive sounds. J. Neurosci. 32, 14184–14192. doi: 10.1523/JNEUROSCI.\n1759-12.2012\nLemaitre, G., and Heller, L. M. (2012). Auditory perception of material is fragile\nwhile action is strikingly robust. J. Acoustical Soc. Am. 131, 1337–1348. doi:\n10.1121/1.3675946\nLemaitre, G., Pyles, J. A., Halpern, A. R., Navolio, N., Lehet, M., and Heller,\nL. M. (2018). Who’s that Knocking at My Door? Neural Bases of Sound Source\nIdentiﬁcation. Cereb. Cortex 28, 805–818. doi: 10.1093/cercor/bhw397\nMartín, R., Iseringhausen, J., Weinmann, M., and Hullin, M. B. (2015).\n“Multimodal perception of material properties”. Proceedings of the ACM\nSIGGRAPH Symposium on Applied Perception (Tübingen). doi: 10.1145/\n2804408.2804420\nMcDermott, J. H. (2012). “Chapter 10 - Auditory Preferences and Aesthetics:\nMusic, Voices, and Everyday Sounds, ” in Neuroscience of Preference and Choice ,\neds R. Dolan and T. Sharot (Cambridge:Academic Press), 227–256. doi: 10.\n1016/B978-0-12-381431-9.00020-6\nMilne, A. E., Bianco, R., Poole, K. C., Zhao, S., Oxenham, A. J., Billig, A. J., et al.\n(2021). An online headphone screening test based on dichotic pitch. Behav. Res.\nMethods 53, 1551–1562. doi: 10.3758/s13428-020-01514-0\nNavolio, N., Lemaitre, G., Forget, A., and Heller, L. M. (2016). The Egocentric\nNature of Action-Sound Associations. Front. Psychol. 7:231. doi: 10.3389/fpsyg.\n2016.00231\nNaylor, J., Caimino, C., Scutt, P., Hoare, D. J., and Baguley, D. M. (2021). The\nPrevalence and Severity of Misophonia in a UK Undergraduate Medical Student\nPopulation and Validation of the Amsterdam Misophonia Scale. The Psychiatric\nQuarterly 92, 609–619. doi: 10.1007/s11126-020-09825-3\nNeuhoﬀ, J. G., and Heller, L. M. (2015). “Applied Ecological Acoustics, ” in The\nCambridge Handbook of Applied Perception Research , eds J. L. Szalma, M. W.\nFrontiers in Psychology | www.frontiersin.org 15 July 2022 | Volume 13 | Article 894034"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "fpsyg-13-894034 July 20, 2022 Time: 10:30 # 16\nHeller and Smith Identiﬁcation Affects Sound Pleasantness\nScerbo, P. A. Hancock, R. Parasuraman, and R. R. Hoﬀman (Cambridge:\nCambridge University Press), 510–529. doi: 10.1017/CBO9780511973017.032\nPiczak, K. J. (2015). “ESC: Dataset for Environmental Sound Classiﬁcation, ”\ninProceedings of the 23rd ACM International Conference on Multimedia ,\n(Association for Computing Machinery) 1015–1018. doi: 10.1145/2733373.\n2806390\nPotgieter, I., MacDonald, C., Partridge, L., Cima, R., Sheldrake, J., and Hoare,\nD. J. (2019). Misophonia: a scoping review of research. J. Clin. Psychol. 75,\n1203–1218. doi: 10.1002/jclp.22771\nRo, T., Ellmore, T. M., and Beauchamp, M. S. (2013). A Neural Link Between\nFeeling and Hearing. Cereb. Cortex 23, 1724–1730. doi: 10.1093/cercor/bh\ns166\nRosenthal, M. Z., Anand, D., Cassiello-Robbins, C., Williams, Z. J., Guetta, R. E.,\nTrumbull, J., et al. (2021). Development and Initial Validation of the Duke\nMisophonia Questionnaire. Front. Psychol. 12:709928. doi: 10.3389/fpsyg.2021.\n709928\nRouw, R., and Erfanian, M. (2018). A Large-Scale Study of Misophonia. J. Clin.\nPsychol. 74, 453–479. doi: 10.1002/jclp.22500\nSchröder, A., Vulink, N., and Denys, D. (2013). Misophonia: diagnostic Criteria\nfor a New Psychiatric Disorder. PLoS One 8:e54706. doi: 10.1371/journal.pone.\n0054706\nSeaborne, A., and Fiorella, L. (2018). Eﬀects of background chewing sounds on\nlearning: the role of misophonia sensitivity. Appl. Cogn. Psychol. 32, 264–269.\ndoi: 10.1002/acp.3387\nShaﬁro, V., Gygi, B., Cheng, M.-Y., Vachhani, J., and Mulvey, M. (2011). Perception\nof Environmental Sounds by Experienced Cochlear Implant Patients. Ear Hear.\n32, 511–523. doi: 10.1097/AUD.0b013e3182064a87\nSiepsiak, M., ´Sliwerski, A., and Łukasz Dragan, W. (2020). Development and\nPsychometric Properties of MisoQuest—A New Self-Report Questionnaire\nfor Misophonia. Int. J. Environ. Res. Pub. Health 17:1797. doi: 10.3390/\nijerph17051797Swedo, S. E., Baguley, D. M., Denys, D., Dixon, L. J., Erfanian, M., and Fioretti,\nA. (2022). Consensus deﬁnition of misophonia: a delphi study. Front. Neurosci.\n16:841816. doi: 10.3389/fnins.2022.841816\nTaylor, S. (2017). Misophonia: a new mental disorder? Med. Hypoth. 103, 109–117.\ndoi: 10.1016/j.mehy.2017.05.003\nVitale, C., De Stefano, P., Lolatto, R., and Bianchi, A. M. (2020). “Physiological\nresponses related to pleasant and unpleasant sounds, ” in Proceedings of the 2020\nIEEE 20th Mediterranean Electrotechnical Conference (MELECON) ,16–18 June\n2020 , Palermo, 330–334. doi: 10.1109/MELECON48756.2020.9140579\nWu, M. S., Lewin, A. B., Murphy, T. K., and Storch, E. A. (2014). Misophonia:\nincidence, phenomenology, and clinical correlates in an undergraduate student\nsample. J. Clin. Psychol. 70, 994–1007. doi: 10.1002/jclp.22098\nZald, D. H., and Pardo, J. V. (2002). The Neural Correlates of Aversive Auditory\nStimulation. NeuroImage 16, 746–753. doi: 10.1006/nimg.2002.1115\nConﬂict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be construed as a\npotential conﬂict of interest.\nPublisher’s Note: All claims expressed in this article are solely those of the authors\nand do not necessarily represent those of their aﬃliated organizations, or those of\nthe publisher, the editors and the reviewers. Any product that may be evaluated in\nthis article, or claim that may be made by its manufacturer, is not guaranteed or\nendorsed by the publisher.\nCopyright © 2022 Heller and Smith. This is an open-access article distributed\nunder the terms of the Creative Commons Attribution License (CC BY). The use,\ndistribution or reproduction in other forums is permitted, provided the original\nauthor(s) and the copyright owner(s) are credited and that the original publication\nin this journal is cited, in accordance with accepted academic practice. No use,\ndistribution or reproduction is permitted which does not comply with these terms.\nFrontiers in Psychology | www.frontiersin.org 16 July 2022 | Volume 13 | Article 894034"
    }
  ]
}