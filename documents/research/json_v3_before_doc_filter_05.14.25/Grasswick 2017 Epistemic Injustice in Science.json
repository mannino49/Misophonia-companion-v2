{
  "doc_type": "scientific paper",
  "title": "Epistemic Injustice in Science",
  "authors": [
    "Heidi Grasswick"
  ],
  "year": 2017,
  "journal": "science",
  "doi": null,
  "abstract": null,
  "keywords": [
    "Epistemic injustice",
    "Science",
    "Testimonial injustice",
    "Hermeneutical injustice",
    "Participatory epistemic injustice",
    "Epistemic trust injustice",
    "Racism",
    "Sexism",
    "Philosophy of science",
    "Social epistemology"
  ],
  "research_topics": [
    "Epistemic injustice in scientific practices",
    "Impacts of racism and sexism on science",
    "Social context and knowledge production",
    "Testimonial and hermeneutical injustice in science",
    "Participatory epistemic injustices in scientific communities",
    "Epistemic trust and credibility in science",
    "Social biases and their epistemic effects",
    "Ethics and epistemology of science",
    "Cooperative epistemic inquiry",
    "Philosophy of science and social oppression"
  ],
  "created_at": "2025-05-05T01:45:15.539094Z",
  "source_pdf": "documents/research/Global/Grasswick 2017 Epistemic Injustice in Science.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Foranyissueswiththisdocument, pleasecontactyourlibrary.\n____________________________________________________________________________________\nTitle:TheRoutledge Handbook ofEpistemic Injustice\nAuthor:IanJamesKidd\nArticleTitle: Epistemic Injusticeinscience\nArticleAuthor: Grasswick, Heidi\nDescription: xviii,419pages\nPages:313-323\nISBN-9780367370633;\nPublisher: NewYork;London:Routledge 2017\nSource:TheRoutledge Handbook ofEpistemic Injustice\nCopyright: CCL\n____________________________________________________________________________________\nNOTICE CONCERNING COPYRIGHT RESTRICTIONS:\nThecopyright lawoftheUnitedStates[Title17,UnitedStatesCode] governsthemakingofphotocopies\norotherreproductions ofcopyrighted materials.\nUndercertainconditions specified inthelaw,librariesandarchivesareauthorized tofurnisha\nphotocopy orotherreproduction. Oneofthesespecificconditions isthatthephotocopy isnottobe\n\"usedforanypurposeotherthanprivatestudy,scholarship, orresearch.\" Ifausermakesarequestfor,or\nlateruses,aphotocopy orreproduction forpurposes inexcessof\"fairuse,\"thatusermaybeliablefor\ncopyright infringement.\nThisinstitution reservestherighttorefusetoacceptacopyingorderif,initsjudgment, fulfillment of\nthatorderwouldinvolveviolation ofcopyright law."
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "313 Science and epistemic injustice \n Scientiﬁc practices offer powerful forms of knowing, and there is no question that in the twenty- \nﬁrst century, they are a dominant force in knowledge production and circulation. Scientiﬁc practices are powerful both in the sense of producing immense amounts of knowledge that can be harnessed for use, and in the more basic sense of shaping contemporary life and material conditions of existence through resultant technologies, science- based policies, and science- based \ndecision- making. Though the speciﬁcs of how the practices of science shape life vary tremen-\ndously around the globe and across social positions, it would be difﬁcult to make the case that anyone remains untouched by their inﬂuence. Given their epistemic strength and political inﬂu-ence, scientiﬁc institutions and their practices need to be investigated as possible sites and sources of epistemic injustice. \n That racism and sexism, among other forms of oppression, have signiﬁcantly shaped the prac-\ntices and results of science is by now well documented by postcolonial science and technology \nstudies scholars, feminist theorists and philosophers of science, and critical race theorists alike. Historically, formal and informal barriers to the participation of women and racial minorities in scientiﬁc enterprises have had the effect of disproportionally favoring white males’ presence and inﬂuence in science (Gornick 1990; Harding 1991, 1993; Schiebinger 1989, 1999). Internal to scientiﬁc communities, cultural climates hostile to women and racial minorities have been identiﬁed as key factors in making the progression of careers more difﬁcult for members of these groups (Angier 1991; Fehr 2011; Harding 1993; Valian 1998). \n Additionally, the ways in which scientiﬁc research on humans has been done and how research \nsubjects have been treated have been inﬂuenced by racist attitudes and practices. Although proto-\ncols and regulations concerning the ethical treatment of human subjects in experimentation have evolved over time, some of the most egregious historical examples of the ethical abuse of research subjects have involved racial minorities or the poor. One of the most famous cases is the Tuske-gee syphilis experiment from 1932–1972 in which the progression of the disease was studied in African- American men. Long after penicillin was discovered and became the standard treatment \nfor syphilis, the Tuskegee study continued, with the men being denied treatment for their disease (Reverby 2009). Research directions themselves have also at times been motivated by racism and sexism. Long periods of scientiﬁc racism have been identiﬁed in which scientiﬁc research has  30 \n EPISTEMIC INJUSTICE IN \nSCIENCE \n Heidi Grasswick"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "Heidi Grasswick\n314been undertaken in order to justify whites’ ‘superior’ place in the social and natural order (Gould \n1996; Harding 1993). Research programs on behavioral links with biological sex differences have at times been developed and used to justify scientiﬁcally the underrepresentation of women in top positions in business, politics, and science (Fausto- Sterling 1992; Jordan- Y oung 2010). \n Though many racist and sexist- motivated research projects have been discredited and strongly \ncriticized for their use of poor methodologies, their place in the history of science makes it far \nfrom clear that scientiﬁc practices can be accurately characterized as generally aiming to beneﬁt all of humanity. Historically, some groups have driven and beneﬁtted from scientiﬁc research to a greater degree than others. As Shannon Sullivan and Nancy Tuana point out in the introduction to their collection,  Race and Epistemologies of Ignorance , “a lack of knowledge or an unlearning \nof something previously known often is actively produced for the purposes of domination and exploitation” (Sullivan and Tuana 2007: 1). \n More subtly, beyond the motivations and social applications of scientiﬁc research, background \nassumptions about social groups have shaped the generation of scientiﬁc knowledge. Because \nscience is a human practice that takes place in a social context (Rouse 1996), it is not surprising that background assumptions about the social order are reinscribed within speciﬁc scientiﬁc practices as scientists generate scientiﬁc hypotheses, employ scientiﬁc reasoning, and eventually produce scientiﬁc results. Feminist science studies scholars have pointed to numerous examples where androcentric assumptions have shaped research design, such as the case of heart disease research. For years heart disease was studied on male subjects only, working with the assumption that male bodies were the norm and that the disease would present similarly across the sexes. This led to the speciﬁc manifestation of heart disease in women being underfunded and understudied (Rosser 1994). Gendered and racialized assumptions also play a role in the analogies, metaphors, and even structures of reasoning that are used to understand scientiﬁc processes. For example, gendered stereotypes associating masculinity with activity and femininity with passivity led to a dominant yet inaccurate understanding of the comparative role of egg and sperm in human reproduction, casting the sperm as active and the egg as purely a passive receptacle (Martin 1996). \n Many of these intersections of scientiﬁc practices and the forces of oppression exemplify clear \nethical injustices. It is an ethical injustice to discriminate against women and racial minorities \nin the entry to and participation in science; it is an ethical injustice to mistreat research subjects and exercise lower standards of care for particular groups; it is an ethical injustice to ignore the needs of certain segments of the population in scientiﬁc research, directing it instead toward the interests of the dominant. Strikingly, in spite of such historical patterns of ethical injustices in science, philosophy of science itself has paid comparatively little attention to questions of the ethics of science when measured against the wealth of philosophical material generated on the metaphysics, epistemology, and logic of science. While such ethical issues are important to attend to for their own sake, they also have more epistemic signiﬁcance than traditional philosophers of science have supposed. \n Many of these noted intersections of science and ethical injustice either constitute or contrib-\nute to cases of  epistemic  injustice. Epistemic injustices are those injustices where a wrong is “done \nto someone speciﬁcally in their capacity as a knower” (Fricker 2007: 1). ‘Knowers’ needs to be \nunderstood in a broad sense here, encompassing those who seek to know and understand the world around them, not just those who already know or claim to know. Epistemic injustice, then, includes unjust impediments to one’s capacity as an  inquirer  (Anderson 2015). It involves obstacles \nto activities that are “distinctly epistemic” (Hookway 2010: 155). Appreciating the distinctively epistemic nature of such injustices is necessary if we are to have a thorough understanding of the social nature of our epistemic pursuits and correspondingly, the social conditions required in order to ﬂourish epistemically."
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "Epistemic injustice in science\n315  Injustices  deal in social relations and interactions.  Epistemic  injustices exist because large por-\ntions of our epistemic lives are social. Scientiﬁc inquiry in the twenty- ﬁrst century is one of the \nmost socially complex forms of knowing, due to its intense cognitive division of labor; this social complexity means that biases and stereotypes can inﬂuence epistemic interactions, just as they can any form of social interaction. Moreover, because scientiﬁc knowledge production is tightly intertwined with social needs and goals for its development and application, social injustices can push science in certain directions such that it creates new forms of understanding that can then serve as sources of further injustices. For example, research might be undertaken to legitimate certain gender or racial biases that in turn come to be relied upon both in the generation of further knowledge and in interactions with other knowers. Both science’s internal nature and its connections to the rest of society make it particularly vulnerable to epistemic injustices. \n The ﬁrst wave of extensive discussions of epistemic injustice focused on and further developed \nthe two forms of epistemic injustice – testimonial and hermeneutical – that were introduced and \nanalyzed in Miranda Fricker’s (2007) landmark,  Epistemic Injustice .  Testimonial injustices  concern \ncredibility deﬁcits that members of subordinated groups experience due to social prejudice. In the case of scientiﬁc practices, evidence of testimonial injustices can be found in the documented experiences of racial minorities and women within science who have had to confront a model of the ideal scientist as a white male in a white lab coat, and have had to struggle to have their claims heard and taken seriously in the classroom and the lab (Keller 2002; Sands 1993; Weisstein 2002). Or consider cases where medical researchers and physicians perceive female patients and research subjects as being overly emotional and unreliable observers of their embodied experiences, given cultural stereotypes regarding femininity, perceptions that lead to either a dismissal of their symp-toms or an increased likelihood of interpreting their medical complaints as having a psychological dimensions (Carel and Kidd 2017; Sherwin 1992; Wallen, Waitzkin and Stoeckle 1979). \n  Hermeneutical injustices  concern the inability of subordinated groups to adequately understand \ntheir experiences due to the poverty of conceptual resources available for such understanding. \nWhen scientiﬁc research programs are directed toward the needs of the privileged, as historically they have been, structural gaps in conceptual and empirical resources evolve resulting in herme-neutical injustices that disadvantage subordinated groups in their ability to come to understand their experiences and convey that understanding to others. \n Both testimonial and hermeneutical injustices play signiﬁcant roles in scientiﬁc practices. \nHowever, in what follows, I frame my discussion in terms of two broad forms of epistemic \ninjustice that scientiﬁc practices are especially prone to given the history of science’s evolution within a social context of racial and gender oppression:  participatory  and  epistemic trust injustices . \nThese injustices track two broad categories of epistemic encounters: engagement as participants in knowledge generation and as receivers of knowledge. I focus primarily on racial and gender oppression, but epistemic injustices threaten to emerge wherever there is oppression, and scientiﬁc practices can be examined for evidence of epistemic injustice along any axis of oppression and at the intersections of multiple axes of oppression. \n Participatory epistemic injustices in science \n T estimonial injustices are crucial to understanding the unjust impediments to the central epistemic \nactivities related to knowledge transmission, yet epistemic injustices can also afﬂict many other core epistemic activities concerning the generation of knowledge itself. Christopher Hookway makes this point when he emphasizes the central importance of cooperative epistemic endeavors and argues that there is a wide variety of types of participant contributions that lead to the suc-cess of cooperative epistemic pursuits, contributions well beyond offering or seeking testimony"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "Heidi Grasswick\n316(Hookway 2010). Discussion and deliberation about epistemic matters, such as asking relevant \nquestions or offering counterexamples to a proposal, are crucial to forwarding cooperative epis-temic inquiry (Hookway 2010: 160). Taking such activities as central to cooperative epistemic pursuits, Hookway argues that if someone fails to be taken seriously in their contributions to joint epistemic inquiry due to the forces of oppression (such as through the mechanisms of prejudices and stereotypes), an epistemic injustice occurs. He offers the example of a teacher who, although willing to take student’s informational questions seriously in their role as student, does not give a student uptake when they ask a question that is intended as a contribution to the inquiry itself. What happens in such cases is that someone who wishes “to be recognized as a member of a community of people collaborating in the attempt to improve understanding or advance knowl-edge” fails to be so recognized (Hookway 2010: 155). Their capacity to contribute to cooperative inquiry as an epistemic agent is stymied. When this happens as a result of systematic forces of oppression, a  participatory epistemic injustice  results. \n1  T estimonial injustices are key examples of this \nbroader category of epistemic injustice; suffering a credibility deﬁcit due to social prejudice when \nmaking a relevant knowledge claim within the context of a joint inquiry is one obvious way to have one’s participation in a joint epistemic endeavor stymied. But the category of participatory injustice is set out to include additional cooperative epistemic activities such as querying the assumptions, methods, and results at stake, being taken seriously in a brainstorming session, or being sought out by others to critique a novel theory or idea in its early form. None of these activities ﬁt under a narrower model of testimonial injustice where the focus is on credibility assigned when one is making an assertion of knowledge. Hookway also notes that there can be far- reaching consequences from participatory injustices, as they can affect additional epistemic \ncapacities of the recipient. When one is not taken seriously as a participant in inquiry, one can lose epistemic conﬁdence or self- trust, becoming too tentative in one’s contributions (Hookway 2010: 159). When one’s questions are ignored, one may develop a habit of silencing oneself, not asking relevant questions that might forward the investigation (Hookway 2010: 156). \n2  \n As is well recognized by many philosophers of science, scientiﬁc practices are paradigms of \ncooperative inquiry. Thomas Kuhn famously emphasized the shared theoretical structures and \nmethodological orientations that make collaboration and progress in periods of ‘normal science’ possible (Kuhn 1970). Karl Popper articulated the role of criticism in the collective endeavor of science (Popper 1962). Michael Polyani drew attention to the ‘tacit’ dimension of science with its shared sets of practices (Polyani 1958). Particularly in a contemporary context where scientiﬁc work is highly specialized, research progress depends upon a strong cognitive division of labor (Kitcher 1990). Scientists rely on the research activities and testimony of other scientists whose specialities differ from their own (Hardwig 1991). Even within small lab teams that may not require different specialists testifying on different topics, discussion and deliberation amongst team members is crucial to the development of theories, techniques, and ultimately, results and their interpretation. \n Classic work in the sociology of science has detailed many of the ways in which social \ninteractions amongst scientists and especially patterned dynamics within and across groups of \nscientists affect scientiﬁc outcomes and important decisions regarding the status of results (Gali-son 1987; Keller 1985; Latour and Woolgar 1986; Pickering 1984). The centrality of such social elements to the core activities of science make participatory epistemic injustices highly relevant to understanding scientiﬁc practices and the ways in which oppression can be implicated in them. Participatory epistemic injustices capture both obvious and not so obvious ways in which one’s capacity to contribute to scientiﬁc knowledge- making can be stiﬂed by the effects of oppression. \n The denial of equal educational opportunities of the kind required for participation in scien-\ntiﬁc communities offers a clear example of a participatory epistemic injustice (see Kotzee 2017)."
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "Epistemic injustice in science\n317This extends not only to speciﬁc training for careers in science, but also to skills acquired through \nquality education that serve as markers for credibility, such as standardized grammar. As Elizabeth Anderson notes, “in societies that systematically deprive disadvantaged social groups of access to a decent education, the use of such markers in assessing credibility will tend to exclude those groups from further participation in inquiry” (Anderson 2012: 169). In the case of science, the signiﬁcance of such participatory epistemic injustices is exacerbated because of the high degree of cognitive authority placed in the institutions of science. When society as a whole relies on and privileges the institutions of science to direct and produce knowledge that will have social relevance, the impact of participatory epistemic injustices that prevent or deter access to these communities of knowledge generation is more pronounced than in other areas of knowledge production. \n Participatory injustices are of course also experienced by members of subjugated groups who \nare a part of a formal scientiﬁc community – for example, a credentialed scientist or graduate \nstudent acting as a member of a research team, a member of a different research team working in a similar area, or a peer reviewer of others’ work. In any of these situations, the scientist’s potential to contribute to and inﬂuence the research process depends on how they and their contribu-tions to dialogue and deliberation are received by other scientists. Members of underrepresented groups who have managed to ‘make it’ into the formal scientiﬁc community are not necessarily always treated with the same respect and granted the same level of cognitive authority as other similarly talented members of the community. When members of underrepresented groups are taken less seriously and given less uptake in their intellectual interactions with their peers because of such biases, they suffer participatory epistemic injustices. Implicit biases of other researchers concerning race and gender in relation to ‘smartness’ and scientiﬁc creativity can affect how a wide variety of types of contributions of members of underrepresented groups are perceived, with cascading epistemic effects. Participatory injustices can occur when, due to such implicit biases, members of certain groups are not invited or encouraged to submit work to important conferences or publication venues to the same extent as others, or when their names are simply not thought of when members of the profession are soliciting peer reviewers. Furthermore, when members of certain groups are taken less seriously in the classroom, in the lab, at confer-ence venues, and in the grant proposal process, one effect can be that the researcher does not receive the level of rigorous criticism that might be required in order to strengthen their work or help them identify in what positive direction the work needs to be developed. This too is a participatory injustice. \n It is these types of dynamics that Helen Longino seeks to identify as problematic when she \narticulates communal requirements for objectivity and explicitly includes conditions of equality \nof intellectual authority \n3  and community responsiveness to criticism (uptake) (Longino 2002). \nThe goal of scientiﬁc objectivity as Longino understands it necessarily conﬂicts with participa-\ntory epistemic injustices. As she writes, “the social position or economic power of an individual or group in a community ought not determine who or what perspectives are taken seriously in that community” (Longino 2002: 131). \n It is also possible to experience a participatory epistemic injustice with respect to science with-\nout formally being a member of any scientiﬁc community or striving to become one. Speciﬁcally \nsituated laypersons can be in possession of local knowledge that is not directly accessible to pro-fessional scientists yet is highly relevant to a research project. \n4  Local knowledge comes in various \nforms. It could be additional data or observations that are gathered simply in the course of living \nin the particular environment of interest: scientists from southern Canada interested in wildlife management in Canada’s Arctic, whose ﬁeld season often consists of only a few summer weeks, may have much to learn from observations of Inuit who live in the vicinity of the wildlife ranges"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "Heidi Grasswick\n318through all seasons (Nunavut Wildlife Management Board 2000). Similarly, interviews with Iñupiat \nelders on the western Arctic Coastal Plain of northern Alaska have proved scientiﬁcally valuable in ﬁlling in historical information on local landscape change (predating aerial photographs and satel-lite imagery) (Eisner et al. 2009). Y et it is only relatively recently that such input from indigenous groups has been solicited, and the lack of such solicitation due to biases regarding what such groups could offer to the research process constitutes a participatory injustice. \n Local knowledge can also take the form of nuanced understandings of the environment of \nstudy and practical ‘know how’ that may be valuable for determining the most useful research \ntechniques and interpreting the research results of a study. For example, amongst post- Chernobyl \nconcerns of radio- active fall- out and the contamination of sheep in the United Kingdom, Cum-brian sheep farmers developed frustration with scientists, who were ignorant of the practical difﬁculties of gathering sheep from open fells for testing, and the nuances of successful hill- sheep \nfarming – ignorance that led to poorly formed policy regulations with severe ﬁnancial losses for the farmers (Wynne 1992). Local knowledge from those outside the scientiﬁc community is often required to understand fully a problem that science aims to address, as well as to craft a solution that will be viable within the local context (the details of which may only be understood by locals). \n Referencing archaeology and sociology in particular, Alison Wylie has stressed the importance \nof collaborative research with marginalized communities, arguing that in many contexts, such \ncommunities have valuable theoretical, methodological, and empirical insights to offer, as well as the possibility of a critical perspective on the assumptions of the scientiﬁc work (Wylie 2014). \n5  \nY et often, scientiﬁc communities do not seek such insights from the marginalized and commit participatory injustices in the process. It is all too easy for scientists’ biases concerning traits associated with a group to affect their willingness to engage with and ﬁnd value in the potential contributions of speciﬁc lay communities. The unjust inﬂuence of such stereotypes often ends up being coupled with the effects of an assumption of epistemic privilege (in comparison with ‘untrained laypersons’) that many scientists already carry. This can result in a collection of par-ticipatory injustices: testimonial injustices that dismiss attempts of lay communities to contribute knowledge relevant to the research, failures to take seriously the questions that these communities may be asking about the research, and failures to solicit input from such communities. \n Patient advocacy groups from the Women’s Health Movement (Tuana 2006) to AIDS advo-\ncacy groups (Epstein 1996) offer examples of resistance to such participatory injustices involving \nthose outside of scientiﬁc communities. Such advocacy groups have fought for the inclusion of relevant lay communities in decisions about the direction of research and the choice of research methodology. They have argued for not just the correction of testimonial injustices, but also the correction of broader participatory injustices that have prevented such groups from contributing to the shape of research agendas and priorities when their understandings of the epistemic needs may differ from the perspective of the scientists. For example, as the race for AIDS treatments was unfolding, AIDS advocacy groups fought for a place at the scientiﬁc table, arguing that they understood the needs of AIDS patients better than many of the researchers and had a right to contribute to decisions about experimental treatments and the kinds of trials that were most likely to serve AIDS patients well (Epstein 1996; Hood 2003). \n Epistemic trust injustices 6  \n Unjust obstacles to one’s abilities to directly or indirectly contribute to scientiﬁc practices and \nthe development of scientiﬁc knowledge do not exhaust the kinds of epistemic injustice that occur with respect to the sciences. All members of society, including scientists themselves, are"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "Epistemic injustice in science\n319positioned as non- experts with respect to most (and for some of us, all) scientiﬁc ﬁelds. Epis-\ntemic injustices can be inﬂicted upon non- experts who do not participate directly in the rele-vant inquiry but instead rely on others as sources of knowledge and understanding. In a social world, core epistemic activities extend not only to participation in the generation of knowledge and our communication of that knowledge, but also to our actions and judgments as potential  receivers  of knowledge and understanding. Social conditions have to be right for one to be able to \nreceive claims from scientists (or other inquirers) in an epistemically responsible way. While many \ncharacteristics of social institutions (from poor science education, to interest groups propagating poor quality science, to poor media coverage of science) can interfere with one’s capacity for epistemically responsible reception of scientiﬁc knowledge, conditions of oppression are signiﬁ-cant in their potential to unjustly impede this ability, placing a greater epistemic burden on the marginalized. \n For laypersons, the route to acquiring some degree of knowledge and understanding in an area \nin which they lack expertise lies in  trusting  the appropriate experts. T o not trust scientists is to do \nwithout the knowledge they might be able to convey and suffer an epistemic opportunity loss in \nthe process (Kitcher 2011). Laypersons need to trust scientiﬁc communities in order to beneﬁt from the very best and most relevant scientiﬁc results along with the scientists’ professional judg-ments of the status of scientiﬁc research, including its uncertainties. With this necessary epistemic role of trust comes the possibility of what I call  epistemic trust injustices . Epistemic trust injustices \noccur when, due to the forces of oppression, the conditions required to ground one’s trust in experts cannot be met for members of particular subordinated groups. \n7  \n The need for trust makes each of us vulnerable to others who claim expertise. It would be \nepistemically unwise to offer blanket trust to anyone and anything purporting to be scientiﬁc or \nthat one takes to be scientiﬁc. One can be too gullible and lack discernment in one’s placement of trust. For ideal epistemic success, the degree of trust one grants would always be balanced by the trustworthiness of the source. Problematically, however, one is never in a position to fully deter-mine the trustworthiness of one’s source. But it remains possible to distinguish  responsibly- placed \ntrust –  trust granted in cases in which one has a preponderance of evidence for the trustwor-\nthiness of the source – from irresponsibly- placed trust in which the preponderance of evidence should lead one instead toward an attitude of distrust (Grasswick 2014). \n  Responsibly- placed trust  is what is required in order for an agent to be able to receive knowledge \nand understanding from others in an epistemically virtuous way. Y et an epistemic communi-\nty’s trustworthiness, as well as the evidence available supporting that trustworthiness may vary, depending on the situation of the potential truster and their relationship with the knowledge provider. Trustworthiness is  situated . In the case of a subjugated group that has experienced a \nhistory of oppression, a preponderance of evidence against the epistemic trustworthiness of scien-tiﬁc communities (leading to responsibly- placed distrust rather than responsible trust) can result \nwhen those scientiﬁc communities have participated in and contributed to that very history of oppression. In such circumstances, an epistemic trust injustice occurs, wherein members of the group are unable to satisfy the conditions of responsible trust. \n One kind of evidence that speaks against the trustworthiness of a scientiﬁc community for \na particular group is a history of scientists having gotten things wrong, especially with respect \nto areas of knowledge that are of particular relevance for the group. For example, female sex-uality is of obvious interest to women, yet feminists have demonstrated how sexist biases and background assumptions have played a signiﬁcant role in the history of research on women’s sexuality, resulting in mistaken understandings and areas of ignorance that can be damaging to women (Lloyd 1993; Tuana 2006). Similarly, projects of scientiﬁc racism have purported to explain away economic disparities between those of European descent and those of African"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "Heidi Grasswick\n320descent, suggesting no changes in social policy need to be made, yet repeatedly these projects have \ncome to be discredited (Gould 1996; Harding 1993). Such evidence proves that scientists have repeatedly produced theories and results that turn out to be mistaken, a pattern that occurs more frequently with respect to particularly relevant knowledge for a speciﬁc group, offers reasons for the group’s distrust. \n8  \n But other kinds of evidence can also contribute to an attitude of responsible distrust in scien-\ntiﬁc communities and their results. Naomi Scheman has explicitly argued for the link between \nhistories of oppression and the epistemic untrustworthiness of scientiﬁc communities and insti-tutions without focusing on instances of ‘bad science’ that gets things wrong. Instead, Scheman emphasizes the “systematically trust- eroding effects of various forms of social, political, and \neconomic injustice” (Scheman 2001: 34), all of which can be identiﬁed in the institutions and practices of science. Histories of one’s group having suffered ethical abuses as research subjects, being discriminated against in the entry to and participation in the institutions of science, and having had one’s epistemic interests ignored while scientiﬁc institutions have appeared to serve the interests of the dominant, all contribute to the untrustworthiness of scientiﬁc institutions for members of such groups. Scheman writes, “the credibility of science suffers, and, importantly,  ought  to suffer . . . when its claims to trustworthiness are grounded in the workings of institutions \nthat are demonstrably unjust – even when those injustices cannot be shown to be responsible \nfor particular lapses in evidence gathering or reasoning” (Scheman 2001: 36). Her point is not that such ethical injustices imply that scientiﬁc institutions cannot serve as reliable truth trackers, but rather that what matters for grounding trust is whether or not variously situated laypersons outside of science can justiﬁably think they can serve as such (Scheman 2001: 35). Being at the receiving end of ethical injustices that are deeply connected to how these institutions and com-munities produce knowledge undermines reasons for trust in their knowledge claims. \n This is a somewhat controversial connection to draw. However, it rests on a recognition that \ntrust is a social relation, with an attitudinal dimension. Well- placed epistemic trust depends \non the sincerity of the testiﬁer toward a potential truster in a particular context, and a shared understanding of the goals of the particular epistemic enterprise that drive some of the decisions throughout inquiry (Wilholt 2013). Evidence of historical mistreatment by a scientiﬁc institu-tion, especially if coupled with a lack of evidence that the institution’s practices have changed signiﬁcantly, does not foster conﬁdence that the institution will be able to provide honest and meaningful knowledge for a member of a group that has suffered such mistreatment. \n Though her work is not framed in terms of epistemic injustice, Scheman’s arguments support \nthe claim that members of subordinated groups can suffer epistemic trust injustices with respect \nto science. This is not a blanket claim that applies to all subordinated groups with respect to all scientiﬁc communities and institutions. Rather, the occurrence of epistemic trust injustices depends on the speciﬁc history of relations between scientiﬁc institutions and subordinated groups. Anthropology, for example, is a ﬁeld whose origins were premised on the subordination of certain peoples and has a troubled history with many of these groups (Tsosie 2017). Where there is a poor track record of a particular scientiﬁc institution’s interactions with a subordinated group, often alongside a poor record of the institution’s ability and commitment to produce high quality knowledge that matters for the group, the conditions required to ground trust in the insti-tution for epistemic matters cannot be met, and the group’s epistemic abilities to gain knowledge and understanding through trust in scientiﬁc institutions are compromised. \n Additionally, there are participatory repercussions of epistemic trust injustices. If certain \ngroups do not trust an area of scientiﬁc research, they are unlikely to want to participate in it. For \nexample, in the attempt to diversify the pool of research subjects in medical research and correct some of the racist and androcentric assumptions of the past, it has at times been challenging for"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "Epistemic injustice in science\n321researchers to encourage increased participation amongst certain demographics due to historical \ndistrust (Epstein 2007). \n The signiﬁ  cance of epistemic injustice in science \n If science were just one among many equally inﬂuential ways of knowing in society, the epistemic \ninjustices perpetrated through them would be far less serious. This is because there would be other ways in which to exercise one’s epistemic agency (and have that agency recognized by oth-ers); so, although the epistemic injustices perpetrated through science would still interfere with one’s capacities as a knower, whether that be through direct participation in it or through one’s trust in it, the signiﬁcance of these interferences to one’s overall capacities as a knower would be less. However, the sheer dominance of scientiﬁc ways of knowing, and the cultural and cognitive authority that they carry, have worrisome effects (Feyerabend 1975, 1978). \n9  Among them, the \nepistemic injustices experienced through science and its dominance result in serious losses in \nepistemic agency for those who are subjected to them. This applies both to those who struggle against structural barriers and implicit biases within scientiﬁc communities to participate fully in the practices, as well as those who are in positions of simply trying to acquire knowledge through trust in those institutions that have produced scientiﬁc knowledge. \n Addressing epistemic injustices in science is no small task. Because these injustices deal with \ninstitutions – institutions that are intermeshed with and interact with a host of other cultural and \nsocial institutions including government agencies, educational institutions, corporations, and media outlets – structural remedies are required (Anderson 2012). More challenging still, the mechanisms of multiple institutions are not infrequently put to use by those who seek to actively generate distrust in science for their own purposes, such as through viciously generating doubt in climate change (Oreskes and Conway 2010). In the case of participatory injustices in science, the mech-anisms of implicit biases and stereotypes held by members of scientiﬁc communities play a major role, yet both the source of those mechanisms and their remedies lie outside the individuals involved; they are situated, within a long history of scientiﬁc practices evolving within a culture of oppression. In the case of epistemic trust injustices, remedies will only come when scientiﬁc institutions ﬁnd ways of becoming more accountable to those positioned outside of science, and begin the very dif-ﬁcult work of building better trust relations with those who arrive at the window of science with both histories of distrust and reasons for that distrust. The analysis of epistemic injustices in science provided here is a necessary ﬁrst step in being able to envision scientiﬁc practices that help foster people’s epistemic agency, both inside and out of formal scientiﬁc institutions. \n  Related chapters  6, 11, 20, 21, 26, 31, 32, 34, 35 \n Notes \n 1 Hookway does not explicitly name these as participatory epistemic injustices. He instead refers to epis-\ntemic injustices that can “only be detected from the participant perspective” (Hookway 2010). Kwong \n(commenting on Hookway) uses the phrase ‘participant- based injustices’ (Kwong 2015: 339). \n 2 Kristie Dotson makes a similar point concerning testimonial injustices, arguing that when testimonial \ninjustices occur, a coerced self- silencing can follow that she calls ‘testimonial smothering.’ In testimonial \nsmothering, the victim comes to testify only with respect to things that they think will be understood and taken seriously (Dotson 2011). \n 3 In her 2002 book, Longino notes this must be understood as a ‘tempered’ equality of intellectual authority, \nin order to allow for differences in native ability and schooling. \n 4 Harding has argued that rather than only considering modern western scientiﬁc practices as ‘science’, we \nneed to consider classifying a multiplicity of culturally speciﬁc yet reliable ways of knowing (traditional \nknowledges or local knowledges) as ‘sciences’ (Harding 2008)."
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "Heidi Grasswick\n322 5 This is not to say there are not challenges and limitations to the extent to which scientists are able to \nincorporate assumptions of lay communities that may severely challenge the basic premises of a scientiﬁc \napproach to their work and their commitments to certain standards of evidence. For a discussion of such limitations that face archeologists, see Cooper (2006). \n 6 Material in this section is based upon work supported by the National Science Foundation under Grant \nNo. 1230600. \n 7 The concept of ‘epistemic trust injustices’ that I am using should not be confused with the idea of ‘trust \ninjustices’ put forth by Gerald Marsh (Marsh 2011). Marsh’s trust injustices are ethical injustices that occur \nwhen one fails to trust another for prejudicial reasons. \n 8 Even beyond concerns of speciﬁc groups, arguments in contemporary philosophy of science have sug-\ngested that our current scientiﬁc theories may not be the best, given the problem of as yet unconceived \nalternative theories that would likely be adopted over our current theories if they were to be so conceived (Stanford 2006). \n 9 For a sympathetic and insightful reading of the development of Feyerabend’s thoughts on the relationship \nbetween science and society, see Kidd (2015). \n References \n Anderson, E. (2012) ‘Epistemic justice as a virtue of social institutions,’  Social Epistemology , 26: 163–173. \n Anderson, E. (2015) ‘Feminist Epistemology and Philosophy of Science,’  The Stanford Encyclopedia of Philos-\nophy  (Fall 2015 Edition), Edward N. Zalta (ed.), URL = <http://plato.stanford.edu/archives/fall2015/\nentries/feminism- epistemology/>. \n Angier, N. (1991) ‘Women join the ranks of science but remain invisible at the top,’  New York Times , May 21. \n Carel, H. and I.J. Kidd (2017) ‘Epistemic Injustice in Medicine and Healthcare,’ in I.J. Kidd, J. Medina, and \nG. Pohlhaus, Jr. (eds.)  Routledge Handbook of Epistemic Injustice , New Y ork: Routledge. \n Cooper, D.E. (2006) ‘Truthfulness and “Inclusion” in Archaeology,’ in C. Scarre and G. Scarre (eds.)  The \nEthics of Archaeology , Cambridge: Cambridge University Press, 131–145. \n Dotson, Kristie (2011) ‘Tracking epistemic violence, tracking practices of silencing,’  Hypatia , 26: 236–257. \n Eisner, W .R., C.J. Cuomo, K.M. Hinkel, B.M. Jones, and R.H. Brower, Sr. (2009) ‘Advancing landscape \nchange research through the incorporation of Iñupiaq knowledge,’  Arctic  62: 429–442. \n Epstein, S. (1996)  Impure Science: AIDS, Activism, and the Politics of Knowledge  , Berkeley: University of Cali-\nfornia Press. \n Epstein, S. (2007)  Inclusion: The Politics of Difference in Medical Research  , Chicago: University of Chicago Press. \n Fausto- Sterling, A. (1992)  Myths of Gender: Biological Theories about Women and Men , (2nd Ed.), New Y ork, \nNY: Basic Books. \n Fehr, C. (2011) ‘What’s in It for Me? The Beneﬁts of Diversity in Scientiﬁc Communities,’ in H.E. Grasswick \n(ed.)  Feminist Epistemology and Philosophy of Science: Power in Knowledge , Dordrecht: Springer, 133–155. \n Feyerabend, P . (1975)  Against Method , London: Verso. \n Feyerabend, P . (1978)  Science in a Free Society , London: New Left Books. \n Fricker, M. (2007)  Epistemic Injustice: Power and the Ethics of Knowing , Oxford: Oxford University Press. \n Galison, P . (1987)  How Experiments End , Chicago: University of Chicago Press. \n Gornick, V . (1990)  Women in Science , New Y ork: Simon & Schuster. \n Gould, S.J. (1996)  The Mismeasure of Man , New Y ork, NY: W .W . Norton and Company Inc. \n Grasswick, H. (2014) ‘Climate change science and responsible trust: A situated approach,’  Hypatia , 29: \n541–557. \n Harding, S. (1991)  Whose Science? Whose Knowledge? , Ithaca, NY: Cornell University Press. \n Harding, S. (1993)  The ‘Racial’ Economy of Science: Toward a Democratic Future , Bloomington: Indiana University \nPress. \n Harding, S. (2008)  Sciences from Below: Feminisms, Postcolonialities, and Modernities  , Durham, NC: Duke Uni-\nversity Press. \n Hardwig, J. (1991) ‘The role of trust in knowledge,’  The Journal of Philosophy , 88: 693–708. \n Hood,  Robert (2003) ‘AIDS ,\n Crisis, and Activist Science,’ in R. Figueroa and S. Harding (eds.),  Science and \nOther Cultures , New Y ork, NY: Routledge, 15–25. \n Hookway, C. (2010) ‘Some varieties of epistemic injustice: Reﬂections on Fricker,’  Episteme , 7: 151–163. \n Jordan- Y oung, R. (2010)  Brain Storm: The Flaws in the Science of Sex Differences , Cambridge, MA: Harvard \nUniversity Press."
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "Epistemic injustice in science\n323 Keller, E.F . (1985)  Reﬂections on Gender and Science , New Haven: Yale University Press. \n Keller, E.F . (2002) ‘The Anomaly of a Woman in Science,’ in J.A. Kourany (ed.),  The Gender of Science , Upper \nSaddle River, NJ: Pearson Education Inc., 66–74. \n Kidd, I.J. (2015) ‘Feyerabend on politics, education, and scientiﬁc culture,’  Studies in History and Philosophy \nof Science , 57: 121–128. \n Kitcher, P . (1990) ‘The division of cognitive labor,’  The Journal of Philosophy , 87: 5–22. \n Kitcher, P . (2011)  Science in a Democratic Society , Amherst NY: Prometheus Books. \n Kotzee, B. (2017) ‘Education and Epistemic Injustice,’ in I.J. Kidd, J. Medina, and G. Pohlhaus, Jr. (eds.) \n Routledge Handbook of Epistemic Injustice , New Y ork: Routledge. \n Kuhn, T.S. (1970)  The Structure of Scientiﬁc Revolutions , (2nd Ed.), Chicago: University of Chicago Press. \n Kwong, J. (2015) ‘Epistemic injustice and open- mindedness,’  Hypatia , 30: 337–351. \n Latour, B. and S. Woolgar (1986)  Laboratory Life: The Construction of Scientiﬁc Facts , Princeton, NJ: Princeton \nUniversity Press. \n Lloyd, E. (1993) ‘Pre- theoretical assumptions in evolutionary explanations of female sexuality,’  Philosophical \nStudies , 69: 139–153. \n Longino, H.E. (2002)  The Fate of Knowledge , Princeton: Princeton University Press. \n Marsh, M. (2011) ‘Trust, testimony, and prejudice in the credibility economy,’  Hypatia , 26: 280–293. \n Martin, E. (1996) ‘The Egg and the Sperm: How Science Has Constructed a Romance Based on Stereo-\ntypical Male- Female Roles,’ in E.F . Keller and H.E. Longino (eds.)  Feminism and Science , Oxford: Oxford \nUniversity Press, 103–117. \n Nunavut Wildlife Management Board (2000)  Final Report of the Bowhead Knowledge Study, Nunavut Canada , \nIqaluit: Nunavut Wildlife Management Board. \n Oreskes, N. and E. Conway (2010)  Merchants of Doubt , New Y ork: Bloomsbury. \n Pickering, A. (1984)  Constructing Quarks: A Sociological History of Particle Physics , Chicago: University of \nChicago Press. \n Polyani, M. (1958)  Personal Knowledge: Towards a Post- Critical Philosophy , Chicago: University of Chicago Press. \n Popper, K. (1962)  Conjectures and Refutations: The Growth of Scientiﬁc Knowledge , New Y ork: Basic Books. \n Reverby, S.M. (2009)  Examining Tuskegee: The Infamous Syphilis Study and Its Legacy  , Chapel Hill: The Uni-\nversity of North Carolina Press. \n Rosser, S. (1994)  Women’s Health – Missing from U.S. Medicine , Bloomington: Indiana University Press. \n Rouse, J. (1996)  Engaging Science: How to Understand Its Practices Philosophically  , Ithaca: Cornell University Press. \n Sands, A. (1993) ‘Never Meant to Survive: A Black Woman’s Journey,’ in S. Harding (ed.)  The ‘Racial’ Econ-\nomy of Science: Toward a Democratic Future ,  Bloomington: Indiana Univ er sity Press, 239–248. \n Scheman, N. (2001) ‘Epistemology Resuscitated: Objectivity as Trustworthiness,’ in N. Tuana and S. Morgen \n(eds.)  Engendering Rationalities , Albany: State University of New Y ork Press. \n Schiebinger, L. (1989)  The Mind Has No Sex , Cambridge, MA: Harvard University Press. \n Schiebinger, L. (1999)  Has Feminism Changed Science? , Cambridge, MA: Harvard University Press. \n Sherwin, S. (1992)  No Longer Patient: Feminist Ethics and Health Care , Philadelphia: T emple University Press. \n Stanford, P .K. (2006)  Exceeding Our Grasp: Science, History, and the Problem of Unconceived Alternatives  , Oxford: \nOxford University Press. \n Sullivan, S. and N. Tuana (eds.) (2007)  Race and Epistemologies of Ignorance , Albany: State University of New \nY ork Press. \n Tsosie, R. (2017) ‘Indigenous Peoples, Anthropology, and the Legacy of Epistemic Injustice,’ in I.J. Kidd, \nJ. Medina, and G. Pohlhaus, Jr. (eds.)  Routledge Handbook of Epistemic Injustice , New Y ork: Routledge. \n Tuana, N. (2006) ‘The speculum of ignorance: The Women’s Health Movement and epistemologies of \nignorance,’  Hypatia , 21: 1–19. \n Valian, V . (1998)  Why So Slow? Women’s Advancement , Massachusetts: Institute of T echnology, MIT Press. \n Wallen, J., H. Waitzkin and J.D. Stoeckle (1979) ‘Physician stereotypes about female health and illness: \nA study of patient’s sex and the informative process during medical interviews,’  Women and Health , 4: \n135–146. \n Weisstein, N. (2002) ‘How Can a Little Girl Like Y ou T each a Great Big Class of Men?,’ in J.A. Kourany \n(ed.)  The Gender of Science , Upper Saddle River, NJ: Pearson Education Inc., 60–65. \n Wilholt, T. (2013) ‘Epistemic trust in science,’  British Journal of Philosophy of Science , 64: 233–253. \n Wylie, A. (2014) ‘Community- Based Collaborative Archaeology,’ in N. Cartwright and E. Montuschi (eds.), \n Philosophy of Social Science: A New Introduction , Oxford: Oxford University Pres, 68–84s. \n Wynne, B. (1992) ‘Misunderstood misunderstanding: Social identities and public uptake of science,’  Public \nUnderstanding of Science , 1: 281–304."
    }
  ]
}