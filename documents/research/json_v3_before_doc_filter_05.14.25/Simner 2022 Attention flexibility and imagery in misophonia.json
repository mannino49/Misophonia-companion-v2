{
  "doc_type": "scientific paper",
  "title": "Attention, flexibility, and imagery in misophonia: Does attention exacerbate everyday disliking of sound?",
  "authors": [
    "J. Simner",
    "S. Koursarou",
    "L.J. Rinaldi",
    "J. Ward"
  ],
  "year": 2021,
  "journal": "Journal of Clinical and Experimental Neuropsychology",
  "doi": "10.1080/13803395.2022.2056581",
  "abstract": "Introduction: Misophonia is an unusually strong aversion to everyday sounds, such as chewing, crunching, or breathing. Here, we ask whether misophonia might be tied to an unusual profile of attention (and related traits), which serves to substantially heighten an otherwise everyday disliking of sounds. Methods: In Study 1, we tested 136 misophonics and 203 non-misophonics on self-report measures of attention to detail, cognitive inflexibility, and auditory imagery, as well as collecting details about their misophonia. In Study 2, we administered the Embedded Figures task to 20 misophonics and 36 non-misophonics. Results: We first showed that the degree to which sounds trigger misophonia reflects the pattern by which they are (more mildly) disliked by everyone. This suggests that misophonia is scaffolded onto existing mechanisms rather than qualitatively different ones. Compared to non-misophonics, we also found that misophonics self-reported greater attention to detail, cognitive inflexibility, and auditory imagery. As their symptoms worsen, they also become more accurate in an attentional task (Embedded Figures). Conclusions: Our findings provide a better understanding of misophonia and support the hypothesis that dispositional traits of attention to detail may be key to elevating everyday disliking of sound into the more troubling aversions of misophonia.",
  "keywords": [
    "Misophonia",
    "soundsensitivity",
    "sensory sensitivity",
    "aversion",
    "attention"
  ],
  "research_topics": [
    "misophonia",
    "attention to detail",
    "cognitive inflexibility",
    "auditory imagery",
    "sensory processing",
    "sound sensitivity",
    "neuropsychology",
    "behavioral task performance",
    "attention mechanisms",
    "sensory aversion"
  ],
  "created_at": "2025-05-05T01:32:06.112570Z",
  "source_pdf": "documents/research/Global/Simner 2022 Attention flexibility and imagery in misophonia.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "Full Terms & Conditions of access and use can be found at\nhttps://www.tandfonline.com/action/journalInformation?journalCode=ncen20\nJournal of Clinical and Experimental Neuropsychology\nISSN: (Print) (Online) Journal homepage: www.tandfonline.com/journals/ncen20\nAttention, flexibility, and imagery in misophonia:\nDoes attention exacerbate everyday disliking of\nsound?\nJ. Simner, S. Koursarou, L.J. Rinaldi & J. Ward\nTo cite this article:  J. Simner, S. Koursarou, L.J. Rinaldi & J. Ward (2021) Attention,\nflexibility, and imagery in misophonia: Does attention exacerbate everyday disliking of\nsound?, Journal of Clinical and Experimental Neuropsychology, 43:10, 1006-1017, DOI:\n10.1080/13803395.2022.2056581\nTo link to this article:  https://doi.org/10.1080/13803395.2022.2056581\n© 2022 The Author(s). Published by Informa\nUK Limited, trading as Taylor & Francis\nGroup.\nPublished online: 24 Mar 2022.\nSubmit your article to this journal \nArticle views: 2653\nView related articles \nView Crossmark data\nCiting articles: 4 View citing articles"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "Attention, flexibility, and imagery in misophonia: Does attention exacerbate \neveryday disliking of sound?\nJ. Simner, S. Koursarou, L.J. Rinaldi and J. Ward\nSchool of Psychology, University of Sussex, England\nABSTRACT\nIntroduction: Misophonia is an unusually strong aversion to everyday sounds, such as chewing, \ncrunching, or breathing. Here, we ask whether misophonia might be tied to an unusual profile of \nattention (and related traits), which serves to substantially heighten an otherwise everyday dislik -\ning of sounds.\nMethods: In Study 1, we tested 136 misophonics and 203 non-misophonics on self-report mea -\nsures of attention to detail, cognitive inflexibility, and auditory imagery, as well as collecting details \nabout their misophonia. In Study 2, we administered the Embedded Figures task to 20 misophonics \nand 36 non-misophonics.\nResults: We first showed that the degree to which sounds trigger misophonia reflects the pattern \nby which they are (more mildly) disliked by everyone. This suggests that misophonia is scaffolded \nonto existing mechanisms rather than qualitatively different ones. Compared to non-misophonics, \nwe also found that misophonics self-reported greater attention to detail, cognitive inflexibility, and \nauditory imagery. As their symptoms worsen, they also become more accurate in an attentional \ntask (Embedded Figures).\nConclusions: Our findings provide a better understanding of misophonia and support the hypoth -\nesis that dispositional traits of attention to detail may be key to elevating everyday disliking of \nsound into the more troubling aversions of misophonia.ARTICLE HISTORY \nReceived 20 August 2021  \nAccepted 17 March 2022 \nKEYWORDS \nMisophonia; sound- \nsensitivity; sensory \nsensitivity; aversion; \nattention\nDoes attention mediate between misophonia \nand everyday disliking of sound?\nMisophonia is a sound sensitivity characterized by \nunusually strong aversions to everyday sounds, \nwhich can cause anger, disgust, panic, or rage. \nTriggers are often human sounds originating from \nthe mouth (e.g., chewing, crunching, breathing, and \nlip smacking) or can be repetitive noises like tap-\nping and clicking. Most people can easily ignore \nthese sounds but people with misophonia experience \nstrong emotional reactions, which can have \na profound impact on daily life (negatively impacting \nschool, family, workplace etc.; Wu et al., 2014 ). In \nthis study, we investigate what traits might contri -\nbute to the profile of people with misophonia, look -\ning particularly at heightened attention, as well as \nrelated characteristics of cognitive inflexibility and \nunusually high auditory imagery. Establishing \nwhether misophonics show unusual profiles beyond \nsound aversions themselves can provide valuable \ninsight into potential underlying mechanisms for \nthis condition.Misophonia is relatively poorly understood, having \nbeen first recognized only recently (Jastreboff & \nJastreboff, 2001 ). Symptoms tend to emerge in childhood \nor adolescence (Rouw & Erfanian, 2018 ), but see also \nCavanna & Seri (2015 ), and are related to subtle organi -\nzational differences in the brain, including increased \nfunctional and structural connectivity in regions \nrelated to threat, emotion, and salience (Kumar \net al., 2017 ; Schröder et al., 2019 ). This suggests \nsounds may have a larger salient and emotional \nimpact on people with misophonia, compared to \nmost other people. Here we examine this unusual \nsalience, by looking at potential psychological \nmechanisms underlying it. Our hypothesis here is \nthat heightened attention to detail (and related traits, \nsee below) might escalate mild everyday disliking \ninto more problematic sound aversions.\nAttention to detail is the ability to allocate cognitive \nresources to all details of a task or environment, no \nmatter how small (Young et al., 1989 ). If people with \nmisophonia had superior attention to detail, they might \noverly attend to sounds that would otherwise be only \nCONTACT J. Simner \n j.simner@sussex.ac.uk \n School of Psychology, University of SussexJOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY \n2021, VOL. 43, NO. 10, 1006–1017 \nhttps://doi.org/10.1080/13803395.2022.2056581\n© 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.  \nThis is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial-NoDerivatives License (http://creativecommons.org/licenses/by-nc- \nnd/4.0/ ), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited, and is not altered, transformed, or built \nupon in any way."
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "mildly disturbing and easily ignored by other people. \nThere are two key components to this hypothesis: the \nfirst is that people with misophonia may have atten -\ntional differences, and the second is that misophonic \ntriggers may be sounds that are already mildly bother -\nsome for other people (albeit to a far lesser degree).\nWith respect to the nature of misophonia trigger \nsounds, early data from Edelstein et al. (2013 ) suggested \nthat misophonics and non-misophonics do indeed find \nthe same stimuli to be aversive versus non-aversive. \nTheir participants rated 31 sound-clips for discomfort \non a scale 0–4. There was a moderate by-item correla -\ntion across misophonics and non-misophonics (r = .4). \nHowever, many items were not misophonic triggers at \nall (e.g., rainfall, whale song, and bird singing), and the \nstudy tested just six misophonic participants. Hence, \nalthough these results are important and intriguing, \nthere are questions remaining about misophonic trig-\ngers themselves, and the extent to which they might be \naversive for both misophonics and non-misophonics \nalike. We therefore address this question by testing \na large group of people with and without misophonia, \npresenting a large number of known triggers of miso -\nphonia (see Methods ).\nThe second component to our hypothesis is that \nmildly aversive sounds may become heightened from \na priori traits of heightened attention. To begin, it is \ncertainly true that people with misophonia find their \naversive sounds hard to ignore. In a dichotic listening \ntask, Silva & Sanchez (2019 ) showed that people with \nmisophonia were significantly worse at attending to \nsentences compared with non-misophonics, if sentences \nwere played in the presence of a misophonic sound (e.g., \nchewing; but no difference for other sounds). Frank \net al. (2020 ) found similarly for misophonics attending \nto on-screen (visual) stimuli, both during and after \nhearing aversive sounds. Hence, people with misopho -\nnia are especially attentive to misophonic triggers, even \nat the expense of attention to other stimuli. Here, we \npropose that people with misophonia may also be more \nwidely attentive, as a dispositional trait. In other words, \nwe suggest that people with misophonia may have more \ngeneral differences in attention to detail – beyond mis-\nophonic triggers. If true, this trait difference might act as \na precursor to the emergence of misophonia, causing \npeople with misophonia to overly attend to sounds that \nothers can ignore.\nSurprisingly little is known about dispositional traits of \nattention in misophonia. However, one study of auditory- \nevoked EEG potentials found significant differences \nbetween misophonics and non-misophonics during an \n“oddball task” (Schröder et al., 2014 ). Participants listened \nto a stream of regular beeps of 1000 Hz interspersed with oddball beeps. Data showed that misophonics had signifi -\ncant differences in the mean amplitudes of their N1 peak, \nan EEG feature linked to early attentional processing \n(Näätänen, 1992 ; Rinne et al., 2006 ). Another study, of \npeople with misophonia performing a “stop signal task” \n(which measures response inhibition), found that miso -\nphonics favored accuracy rather than speed, and \nemployed more attentional resources to this end (Eijsker \net al., 2019 ); i.e., activating posterior cingulate cortices less \nthan non-misophonics during successful inhibition, \nwhere similar deactivation suggests increasing attentional \nloads). More recently, Eijsker et al. (2021 ) have shown \ndifferences in white matter structure in regions control -\nling attention toward emotionally salient information. \nThese three studies suggest that there may be broader \nattentional differences associated with misophonia – \nbeyond being unable to ignore trigger sounds themselves.\nHowever, one further study has suggested that mis-\nophonics may be broadly inattentive. When Frank et al. \n(2020 ) found that aversive sounds distracted misopho -\nnics from an on-screen visual task (see above), they also \nfound a null effect suggesting they may be equally inat-\ntentive to the screen even before sounds were played. \nHowever, we suggest that participants may have been \ndistracted by the expectation of sounds (because the \nauthors based their methods on Panagopoulos et al., \n2013 , who did indeed forewarn participants before the \nstudy began.) Indeed, Frank et al. warn of caution when \ninterpreting their result, suggesting future studies war-\nrant a replication in the complete absence of sounds. In \nthe current study, we will test more directly whether \npeople with misophonia have heightened attention to \ndetail using a series of measures. In Study 1, we present \nthe Detail and Flexibility questionnaire (DFlex; Roberts \net al., 2011 ) a questionnaire developed specifically to \ndetect excessive attention to detail (and also the trait of \ncognitive inflexibility; see below). We will also use the \nAttention to detail the subscale of the Autism Spectrum \nQuotient (AQ; Baron-Cohen et al., 2001 ), a second mea-\nsure of focused attention, and one that has successfully \nshown differences in other groups with heightened sen-\nsory sensitivities (e.g., synaesthetes; Ward et al., 2018 ). \nBoth scales measure attention-to-detail, but the Dflex \nadditionally taps the related trait of local processing (i.e., \na detail/local-focused approach at the relative expense of \nglobal context). It was also created to avoid a potential \nmale-bias of the AQ subscale, which (the authors sug-\ngest) had been written with the male profile of autism in \nmind, and may be less sensitive for female samples. We \ntherefore included both scales for their broader focus on \ntraits of attention (and we note the small but significant \ncorrelation across scales, r = .26, p < .001; Roberts et al., \n2011 ). Finally, in Study 2, we will present a behavioral JOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1007"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "task known to be sensitive to the local processing/atten -\ntion to detail (the Embedded Figures task; Witkin et al., \n1971 ; see Study 2).\nA second psychological trait of interest is Cognitive \nInflexibility (also known as a difficulty in set-shifting, or \ncognitive rigidity). Flexibility is a cognitive style related \nto the ability to shift selectively between thoughts in \nresponse to environmental demands (Dajani & Uddin, \n2015 ; Scott, 1962 ). Inflexibility is related to poorer self- \nregulation and can be involved in clinical vulnerabilities, \nsuch as for obsessive-compulsive disorder (Van Passel \net al., 2016 ) and anorexia nervosa (Maria et al., 2020 ). \nImportantly, it is also closely related to the trait of \nperfectionism (Ferrari & Mautz, 1997 ), a feature found \nin misophonia (Jager et al., 2020 ). Most importantly, \nmodels of perfectionism (Shafran et al., 2002 ) suggest \nthat perfectionists show an attentional bias, which allo-\ncates greater attention to negative information than to \npositive information. In the case of misophonia, this \nwould translate into an over-focusing on the negatively \nperceived sounds. Our use of the DFlex questionnaire to \nassess attention to detail (see above) also therefore offers \nthe opportunity to explore this relationship with perfec -\ntionism (Jager et al., 2020 ), since the DFlex measure has \nsubscales of both attention and (in)flexibility. We pre-\ndict greater inflexibility, linked to higher perfectionism \n(Jager et al., 2020 ), and increased attention (which in \ndaily life might include attention on the negatively per-\nceived sounds).\nThe final trait of interest is auditory imagery, which \nwe propose may also serve to enhance unwanted atten -\ntion toward sounds. Auditory imagery is the mental \nsimulation of sound in the absence of external auditory \nstimuli (Lima et al., 2015 ). An example of auditory \nimagery is hearing a familiar song in your head or \nhaving a mental internal dialog. Imagery is quasi- \niconic (i.e., it resembles real-world sounds, albeit \nwithin the mind) but its vividness varies widely \namong individuals (Lima et al., 2015 ). These differ -\nences are also reflected in brain structure: people scor-\ning higher on auditory imagery also show thicker gray \nmatter in regions, such as the superior temporal gyri \n(Halpern, 2015 ). Here, we ask whether auditory ima-\ngery is different in people with misophonia, given the \nknown relationship between imagery and attention. \nMoriya (2018 ) found that (visual) mental imagery \ninfluenced attentional guidance, so could direct atten -\ntion during a (visual) search task. We therefore ask \nwhether heightened auditory imagery may lead to \nsimilarly heightened auditory attention for sounds, \nthereby making it harder for people with misophonia \nto ignore them. To test this, we will administer an \nadaptation of the Clarity of Auditory Imagery Scale (CAIS; Willander & Baraldi, 2010 ), a self-report instru -\nment that allows participants to rate their imagery for \nsounds, such as someone laughing or people chatting. \nThis type of self-report questionnaire has been shown \nto tap imagery in a surprisingly robust way, correlating \nwith both behavioral measures of imagery (e.g., \nHalpern, 2015 ; Keogh & Pearson, 2018 ) and with dif-\nferences in brain structure (Halpern, 2015 ). We there -\nfore predict that people with misophonia may show \nheightened auditory imagery, elsewhere linked to \nheightened attention.\nIn summary, we propose to test a group of people \nwith and without misophonia (whom we will identify \nusing the Misophonia Questionnaire ; (Wu et al., 2014 ). \nWe will then examine two different components of our \ntheory that (a) heightened attention to detail, and \nrelated traits of increased auditory imagery and cogni -\ntive inflexibility, may lead to greater focus on (b) what \nwould otherwise be mildly aversive stimuli for every -\none else. We predict that people with misophonia will \nscore significantly higher on attention to detail sub-\nscales of the AQ (Baron-Cohen et al., 2001 ) and the \nDFlex (Roberts et al., 2011 ) while also showing greater \ncognitive rigidity (Flexibility subscale of the DFlex), \nand higher auditory imagery on the CAIS question -\nnaire (Willander & Baraldi, 2010 ). Additionally, we \npredict a strong positive correlation between misopho -\nnics and non-misophonics in how much they dislike \na large set of misophonic trigger sounds, suggesting \nthat misophonia may arise from an unusually heigh -\ntened manifestation of the everyday disliking of \nsounds.\nStudy 1\nMethod\nParticipants\nOur recruitment began with 149 self-declared misopho -\nnics and 344 members of the general population, 18 \n+ years. Self-declared misophonics were recruited via \nonline forums where misophonia is discussed (e.g., \nFacebook, Reddit; Twitter), whilst our general popula -\ntion were recruited from the University of Sussex com -\nmunity. All participants were screened using the \nMisophonia Questionnaire (Wu et al., 2014 ); see \nbelow). Those exceeding the diagnostic threshold \nentered our misophonia group (whether from our self- \ndeclared or general population streams), while those \nfalling below this threshold entered our non- \nmisophonics group (see Methods ). We excluded any \nself-declared misophonic (n = 38) who did not pass \nthe MQ, along with participants with incomplete data 1008\n J. SIMNER ET AL."
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "(n = 116; since our ethics allowed participants to skip \nany single question if they so wished). With these pro-\ncedures, n = 71 members of the general population \nmoved into our non-misophonics group, exactly in \nline with the published prevalence of misophonia (Wu \net al., 2014 ).\nOur final sample contained 136 misophonics (mean \nage = 27.60 years, SD = 13.62; 108 female/22 males/2 \nnon-binary/4 preferred not to say) and 203 non- \nmisophonics (mean age = 20.19 years, SD = 4.94; 161 \nfemale/37 male/4 non-binary/1 preferred not to say). \nEthical approval for both studies presented here was \nobtained from the Sussex University Science and \nTechnology Ethics Committee ethics board prior to \ntesting (approval number ER/lr290/3). Participants \ntook part without monetary incentive, but students \nwere offered course credit.\nMaterials and procedure\nParticipants completed our study online, using our in- \nhouse web application (www.misophonia-hub.org ). This \nonline platform is a one-stop resource containing all our \ntests and measures alongside advice and support for \nadults, children, parents, researchers, clinicians, and edu-\ncators. Participants were sent a URL via e-mail to take \npart, which led them directly to our testing page. The \nstudy began with a request for demographic information \non age, gender, etc. Participants then began our testing, \nwhich included our five measures presented in the order \ndescribed below (alongside other tests to be reported \nelsewhere). Our task took 25 minutes to complete.\nMisophonia Questionnaire (MQ; Wu et al., 2014 ). The \nMQ contains three sections (for Sections 1 and 2, see \nStudy 2). Section 3, our measure here, is used to identify \nindividuals with misophonia (Wu et al., 2014 ). It is a 15- \npoint severity scale, where participants indicate any \nsound sensitivity and its severity, by taking into account \ntheir number of triggers, degree of distress, and impair -\nment in their lives (Wu et al., 2014 ). Responses range \nfrom minimal to very severe, where scores ≥7 indicate at \nleast “moderate sound sensitivities . . . that cause signif -\nicant interference in my life and which I spend a great \ndeal of conscious energy resisting or being affected by” \n(St. Clare, 2003 ). Individuals reporting ≥7 on this \nSeverity Scale are considered to have clinically signifi -\ncant misophonia (Wu et al., 2014 ), since this mirrors \ncutoffs for other clinical conditions (e.g., National \nInstitute of Mental Health’s Global Obsessive- \nCompulsive Scale ; St. Clare, 2003 ). This was the thresh -\nold taken in the current study to classify our participants \ninto two groups (misophonics vs non-misophonics; see \nParticipants ). We found this measure to be reliable in \nour sample with a Cronbach's alpha of α = .92.Sussex Misophonia Scale – Triggers (SMS-Triggers; \nRinaldi et al., 2021 ). The Sussex Misophonia Scale \nincludes a section (Part 1) dedicated to misophonia \ntriggers. We included this measure to estimate how \naversive are misophonic trigger sounds, for both mis-\nophonics and non-misophonics. Here, participants were \npresented with 48 known triggers for misophonia (e.g., \nthe sound of people eating ) and asked Have you always \nhated these things? Or don’t you mind them? Within this \ntest, participants first saw eight broad categories of \ntriggers (e.g., People eating ; see, Table 1) to which they \nresponded individually Yes or No. If all eight responses \nwere No, the measure ended. However, any category \nthat responded positively revealed a full list of triggers \nwithin that category. For example, if the participant \nresponded Yes to I hate the sound of people eating , this \nrevealed further eight types of eating-sound (crunchy \nfoods (e.g., apples); crispy snacks; chewing; lip smacking; \nswallowing; slurping (a drink); wet mouth sounds (e.g., \nyogurt); other eating sound ; see, Table 1) along with the \nquestion Which do you hate hearing? Tick all that apply . \nIn total, participants saw 48 trigger items, which are \nshown in Table 1.\nDetail and Flexibility Questionnaire (DFlex; Roberts \net al., 2011 ). This self-report instrument contains 24 \nitems, which measure two aspects of neurocognitive \nfunctioning: cognitive rigidity (i.e., difficulty with flex-\nibility; e.g., “I like doing things in a particular order or \nroutine”) and attention to detail (e.g., “I tend to focus at \none thing at a time and get it out of proportion to the \ntotal situation”). Responses are given using a 6-point \nLikert scale (from 1 = “strongly disagree” to 6 = “strongly \nagree). A higher total score indicates more attentive or \ninflexible behaviors. Both subscales show high internal \nreliability, construct validity, and strong discriminant \nTable 1. Triggers for misophonia, and their superordinate \ncategory.\nCategory Trigger\nsound of people \neatingcrunchy foods (e.g., apples); crispy snacks; chewing; \nlip smacking; swallowing; slurping (a drink); wet \nmouth sounds (e.g., yogurt); other\nsound of repetitive \ntappingpen clicking; foot tapping/ foot on floor; repetitive \nbarking; tapping pen/ pencil; tapping finger; \ntyping on a computer; other\nsound of rustling rustling paper; rustling plastic; other\nthroat sounds throat clearing; hiccups; humming; other\nsounds from mouth \nand nosebreathing; snorting (e.g., when people laugh); nose \nsniffing; coughing; snoring; whistling; sneezing; \nburping; other\nvoice sounds certain accents; some people’s voices; certain letter \nsounds; certain vowels; certain consonants; other\nrepetitive visual \nmovementsrepetitive leg rocking; foot shuffling; people \nrocking back and forth on their chair; other\nbackground sounds clock ticking; car engines; refrigerator humming; \ndishwasher; washing machine/ dryer; fan; other\nNote that one category is non-auditory because people with misophonia can \nalso be triggered by repetitive visual movements such as leg-swayingJOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1009"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "validity (based originally on groups with and without \neating disorders; (Roberts et al., 2011 )). More recently, \nthe DFlex questionnaire was validated using a French \nclinical sample, where it again showed good psycho -\nmetric properties in distinguishing clinical groups \n(Maria et al., 2020 ). In our own sample, we found this \nmeasure to show excellent reliability with a Cronbach's \nalpha of α = .91.\nAttention to detail Subscale of the Autism Spectrum \nQuotient (AQ; (Baron-Cohen et al., 2001 ). The AQ is \na widely used measure for identifying autistic traits, \nincluding the trait of attention to detail. The full ques -\ntionnaire consists of 50 items rated using a 4-point \nLikert scale (definitely agree; slightly agree,” “slightly \ndisagree,” “definitely disagree”). Here we presented \none of its five subscales, attention to detail, which con-\ntains 10 items such as “I tend to notice details that \nothers do not” or the reverse coded “I don’t usually \nnotice small changes in a situation or a person’s \nappearance.”1 The total scores on this sub-scale range \nbetween 0 and 10, where higher total scores indicate \nstronger attention to detail. The AQ scale has previously \nshown acceptable internal consistency varying from \nα = .63 − .78 (Baron-Cohen et al., 2001 ; Kurita et al., \n2005 ) and in our own sample showed α = .84. Its sub- \nscale of attention to detail reliably predicts other sensory \nconditions such as synesthesia (Ward et al., 2018 ).\nThe Clarity of Auditory Imagery Scale (CAIS; \n(Willander & Baraldi, 2010 )– Adapted . The CAIS is \na self-report instrument measuring auditory imagery, \nwhich presents verbal descriptions of sounds (e.g., \na dog barking) and asks participants to rate their audi -\ntory imagery using a 5-point Likert Scale. Given our \ndetailed work in mental imagery (Dance, Jaquiery \net al., 2021 ) we adapted this scale in two ways. The \noriginal measure requires participants to rate how \nclearly they could “imagine the sounds”; however, \nrecent work shows that mental imagery and imagination \nare distinct (people without mental imagery can still \nimagine; e.g., Dance, Jaquiery et al., 2021 ). We therefore \nrephrased the instructions as follows: How clearly can \nyou HEAR these sounds in your head, as if they were real \nsounds? Likert labels were changed accordingly from \n1 = not at all to 6 = very clear (like a real sound) , these \nlast four words being our own addition. From the ori-\nginal item list of Willander and Baraldi (2010 ), we pre-\nsented the following: a clock ticking, a dog barking, \nsomeone sneezing, a person laughing, a group of people \nchatting. Higher scores on the CAIS scale indicate more \nvivid imagery and the scale has been previously shown \nto have a good internal consistency of α = .88. In our \nown sample, we found a yet higher internal reliability \nof α = .92.Analytic plan\nWe used R version 3.6.3 in RStudio, with the following \npackages (and uses in brackets): We conducted all \nanalyses in R version 3.6.3 using RStudio. We used \nthe following R packages to conduct our analyses: \ntidyverse (for general data wrangling), afex to perform \n(ANOVA), stats to perform (t-tests), and effsize to \ncalculate (effect sizes). Prior to each analysis, data \nwere checked for outliers by imposing cutoffs at 3 \nSDs above and below the mean; there were no outliers \nbeyond these points so all data was retained. Where \nappropriate, we describe our sample descriptively in \nterms of using means and standard deviations (SDs) \nwhere appropriate. We also confirmed the assumptions \nof normality by checking QQ plots and the Shapiro– \nWilk test, and we confirmed that homogeneity of var-\niance was checked using Levene’s test. We use inde -\npendent-samples t-tests to investigate groupwise \ndifferences between misophonics vs non-misophonics \nfor AQ-attention in detail and the CAIS. We used \nANOVA for the DFlex (which contains two subscales). \nWhere applicable, we applied Bonferroni correction \nfor multiple comparisons. There were no significant \ndifferences between our two groups in terms of gender \nratios (Fisher’s exact test p = .428), therefore gender \ndid not enter our modeling of dependent variables. In \ncontrast, age was significantly different across groups (t \n(337) = 7.09, p < .001, Hedges’ g = .79; see Participants \nfor means/SDs) so was entered into our initial models. \nHowever, it was a non-significant predictor and so was \nsubsequently dropped from our final models reported \nbelow.\nResults\nDo people with misophonia have greater attention \nto detail (AQ questionnaire)?\nWithin the AQ subscale of attention to detail, scores \nrange between 0 and 10, where higher scores indicate \ngreater attention to detail. We followed (Baron-Cohen \net al., 2001 ) in scoring 1 point for responses of “Slightly/ \nDefinitely agree” to positively worded items (i.e., from \nthe original AQ, items: 5, 6, 9, 12, 19, 23) and “Slightly/ \nDefinitely disagree” to negatively worded items (28, 29, \n30, 49). After confirming that there were no violations in \nassumptions (Levene’s test for homogeneity of variance. . \nF(1,337) = 1.06, p = .305), we compared attention to de-\ntail across groups (misophonics vs. non-misophonics). \nMisophonics scored a mean of 5.47 (SD = 1.95), while \nnon-misophonics scored 4.57 (SD = 2.08) and this dif-\nference was significant (t(302.64) = −4.05, p < .001), \nwith a small-to-medium effect size (d = −0.44).1010\n J. SIMNER ET AL."
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "Do people with misophonia have greater attention \nto detail and inflexibility (DFlex Questionnaire)\nWithin the DFlex (Roberts et al., 2011 ), total scores range \nbetween 24 and 144, while each subscale of 12 items ranges \nfrom 12 to 72. Higher scores indicate greater attention to \ndetail and inflexibility. We ran a 2 × 2 mixed ANOVA \ncrossing group (Misophonics, Non-misophonics) with \nsub-scale (Attention, Inflexibility). We found a significant \nmain effect of subscale (F(1,337) = 59.73, p < .001, \nη2G = 0.23) since scores were higher overall on Cognitive \nRigidity (M = 41.80, SE = 0.54) versus Attention to detail \nsubscale (M = 38.80, SE = 0.54). More importantly, we also \nfound a significant main effect of group (F (1,337) = 31.24, \np < .001, η2G = 0.75), indicating that misophonics \n(M = 43.10, SE = 0.71) scored significantly higher than \nthe non-misophonics (M = 37.40, SE = 0.71), with no \ninteraction (F(1,337) = 0.48, p = .487, η2G <.001). Our \ndata therefore indicate higher scores for misophonics on \nboth subscales of attention to detail and cognitive \ninflexibility.\nDo people with misophonia have higher auditory \nimagery (CAIS)?\nMisophonic participants scored overall higher in the \nCAIS (M = 18.99, SD = 5.42) than in non-misophonics \n(M = 17.04, SD = 5.42). An independent-samples t-test \nshowed this difference to be significant (t \n(289.48) = −3.22, p = .001) with a small effect size \n(Cohen’s d = −.34). Results therefore support our \nhypothesis that misophonic people have higher clarity \nand vividness of auditory imagery than non- \nmisophonics.\nAre misophonic trigger-sounds also (mildly) \naversive for Non-misophonics? (Sussex misophonia \nscale)\nOur aim here was to examine whether misophonia \nstems from an exaggeration of dislike felt by everyone \n(albeit shifted upward in severity) rather than qualita -\ntive differences in trigger-class. Our analysis began with \nthe 48 triggers of the Sussex Misophonia Scale, which \nwere rated individually by each participant, using check- \nboxes to indicate if they hated the sound (vs. did not \nmind it). We counted the number of “hate” responses \nfor each trigger and did this separately for misophonics \nversus non-misophonics. This gave us a ranking for \neach group, from the most-hated trigger to the least- \nhated trigger. We then compared the order of these \nrankings across participant group, using a Spearman’s \nrank correlation. This analysis revealed a highly significant correlation (r = .88, p < .001), suggesting \nthat the most aversive triggers for people with misopho -\nnia (e.g., chewing) were also those disliked most often \nby non-misophonics.\nIn addition to finding a strong correlation in the \nrankings of disliked triggers, we also found that the \nmean number of people disliking this set of triggers \nwas – as expected – significantly higher for misophonics \n(M = 41.02 SD = 28.74) than non-misophonics \n(M = 23.94 SD = 20.34; t(47) = −8.94, p < .001). For the \nfull-ordered list of triggers ranked by misophonics and \nnon-misophonics see Supplementary Information (SI).\nDiscssion\nHere, we tested a model of misophonia, which suggests \nthat the sound aversions are related in part to heigh -\ntened attention to detail, auditory imagery, and cogni -\ntive inflexibility. Our model produced four testable \nhypotheses: that results showed that misophonics \nwould score significantly higher on attention to detail, \nincluding the component of attention implicated in \nlocal (over global) processing. They also showed two \ndifferent scales ((a) from the AQ and (b) DFlex ques -\ntionnaires), as well as (c) greater cognitive inflexibility \non the DFlex, and (d) heightened auditory imagery on \nthe CAIS. Our hypotheses were supported. We also \npredicted that the sounds that trigger misophonia \nwould be somewhat aversive to all people (although far \nless), and this was also supported. We return to these \nresults in the General Discussion. Before then, we seek \nobjective validation of our self-report findings.\nStudy 2\nIn Study 1 we saw that people with misophonia reported \ngreater attention to detail and related traits (inflexibility, \nimagery) than people without misophonia. However, \nour measures were self-report questionnaires. In Study \n2, we provide behavioral support for these questionnaire \ndata. One way to measure attention to detail is via its \nrelationship with local processing. As noted above, this \nis the ability to focus on the fine-grained details of \na stimulus, or process information in a more detailed- \noriented way – for example, when locating a face in \na crowd (Jolliffe & Baron-Cohen, 1997 ; Koldewyn \net al., 2013 ). Previous studies have captured this by \nasking participants to scrutinize complex figures or pat-\nterns. The most widely known measure is the Embedded \nFigures Test (Witkin et al., 1971 ), where participants see \na complex and camouflaging gestalt, and their task is to \nspot a simple form within the complex figure. Clinical \ngroups with heightened attention to detail (e.g., people JOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1011"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "with autism) are found to have superior performance in \nthis task (e.g., Jolliffe & Baron-Cohen, 1997 ). We there -\nfore ask whether the Embedded Figures task can provide \nbehavioral support for the self-reports of greater atten -\ntion to detail in people with misophonia. We hypothe -\nsize greater accuracy and/or faster response times in \ndetecting embedded figures for people with misophonia.\nMethod\nParticipants\nWe tested 20 misophonics (mean age = 21.2 years, \nSD = 3.7; 18 female/2 non-binary), and 36 non- \nmisophonics (mean age = 19.9 years, SD = 1.3; 29 \nfemale/6 males/1 preferred not to say). As before, their \ngroup status was determined objectively using the \nSeverity Scale of the MQ (Wu et al., 2014 ; see above, \nand Methods below).\nParticipants were recruited from the same population \nas Study 1. The inclusion criteria for Study 2 were (a) \nthat participants had opted to complete the full MQ \n(rather than just the severity scale required for \nStudy 1), (b) they completed our second measure in \nfull (Embedded Figures , see below), and (c) they were \nusing a device with a trackpad to guide their pointer. \nOur task measures response times, which differ depend -\ning on device (e.g., mouse requires greater arm- \nmovement than trackpad). We therefore determined \nwhich device participants were using (via an on-screen \nquestion) and selected trackpad-users only because \nthese represented our largest group. (In general, we \nfind our test-participants are approximately 55–65% \ntrackpad, 20% mouse, 5–10% touchscreen, with 10– \n20% unknown). Hence, we excluded further 30 partici -\npants using non-trackpad pointers, and additional five \nparticipants who encountered a technical problem \n(which inadvertently repeated trials if the participant \nhit refresh).\nMaterials and procedure\nParticipants completed our study online as before (see \nStudy 1). Our task had the two components below, and \ntook 20–30 minutes to complete.\nMisophonia Questionnaire (MQ; Wu et al., 2014 ). \nThe MQ contains 21 questions across three sections. \nSection 3 is described in Study 1, while sections 1 \nand 2 contain questions about misophonia sound- \ntriggers (“Symptoms scale”: 8 items) and emotions/ \nbehaviors (“Emotions and behaviours Scale” 11 \nitems), respectively. Both are answered using a 5-point Likert Scale (0-Not at all true, to \n4-Always true) and show good internal consistency \n(α = .86; Wu et al., 2014 ). In Section 1, participants \nindicated how many different types of sound they \nare sensitive to in daily life (i.e., “In comparison to \nother people, I am sensitive to the sound of . . . ”). \nHere, they selected one or more from eight sound- \ncategories, which are the most commonly known \ntriggers of misophonia (Rinaldi et al., 2021 ). These \nsound-categories comprised: people eating, \nRepetitive tapping, rustling, people making nasal \nsounds, people making throat sounds, certain con-\nsonants and/or vowels, environmental sounds, and \nother. Each category was accompanied by examples \n(e.g., people eating: chewing, swallowing, lips smack -\ning, slurping, etc.). High scores on this scale repre -\nsent a greater aversion to sounds (i.e., a larger \nnumber of categories triggering misophonia). In \nSection 2, participants describe how they respond \nto their aversive sounds by selecting one or more \nemotions/behaviors (e.g., Become angry? Cover your \nears? ). Again, higher scores represent greater \nmisophonia.\nParticipants completed the MQ once only, with their \ndata from Section 3 cleaved off for Study 1 to determine \ngroup status, and with all three sections entering the \nanalysis for Study 2 (with a different statistical approach; \nsee Results ).\nEmbedded Figures Test (Witkin et al., 1971 ). This task \nhad 32 trials, including three practice items. Our mate -\nrials were taken from an adaptation of the Embedded \nFigures task (Ward et al., 2018 ). In each trial, partici -\npants were shown a line drawing (target shape) at the \ntop of the screen, and four complex shapes below \n(labeled 1, 2, 3, 4). Participants were required to select \nthe option (1–4) which contains the target shape within \nit (for example, see, Figure 1). Participants were told the \ntarget shape was embedded without rotating or chan -\nging in any way. Participants had 12 seconds to respond \nby selecting the correct answer on screen (i.e., hovering \ntheir pointer over 1, 2, 3, or 4 and clicking to select). \nParticipants began with practice trials providing feed-\nback, but there was no feedback during target trials. The \nEmbedded Figures task has been shown to be a reliable \nmeasure with an acceptable internal consistency of \nα = .76 (Mumma, 1993 ).\nAnalytic plan\nOur statistical tool and packages were identical to \nStudy 1, with the addition of Hmisc for correlations. \nData were treated as in Study 1, except that analyses \nwere independent-samples t-tests for groupwise 1012\n J. SIMNER ET AL."
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "differences in accuracy/response time, and correlations \nwithin groups. There were no significant differences \nbetween our two groups in terms of age (t(54) = 1.88, \np = .065, Hedges’ g = .53) or gender ratio (χ2 \n(1) = .850, p = .356, Cramér V = .123); see \nParticipants for descriptive statistics); therefore, age \nand gender did not enter our modeling of dependent \nvariables. (Here, gender was treated as female vs. non- \nfemale, given our small sample size and three zero- \ncells in our 2 × 4 contingency table of Group × \nGender; see Participants . However, applying Fisher’s \nexact test to the sparse 2 × 4 table shows a significant \ndifference of p = .030. So for added conservativeness, \nwe also ran initial models including gender but it was \na non-significant predictor, so was subsequently \ndropped from our final models below.)\nResults\nThe Embedded Figures task produces an accuracy score \nand a response time (RT) for correct items. The MQ \nproduces one datapoint for each of three subscales: number of triggers (aversive sounds, e.g., rustling; Section 1), the \nnumber of resultant emotions/behaviors (e.g., becoming \nangry; Section 2), and a severity score (Section 3; used to \ndivide our participants into groups; see above). In our \nanalysis, we first simply compare means in the Embedded \nFigures task across participant groups, asking whether \npeople with misophonia are more accurate and/or faster \nthan non-misophonics. Next, we examined how speed and \naccuracy are predicted by fine-grained information from \nthe MQ sub-scales.\nWe first compared means groupwise. An indepen -\ndent samples t-test showed no significant difference \nacross groups in either accuracy (misophonics \nM = 19.15, SD = 3.62; non-misophonics M = 20.64, \nSD = 4.02; t (42.99) = 1.42, p = .163; d = .38) or speed \n(misophonics M = 6665.55, SD = 1608.12; non- \nmisophonics M = 6580.67, SD = 1433.62; \nt (35.70) = 0.20, p = .845; d = .05) with negligible- \nsmall effect sizes.\nNext, we examined our data at a more fine-grained \nlevel, using all the information available across our \nthree subscales for misophonia – rather than a simple \nFigure 1. Example item from the Embedded Figures task. Participants must select the option (1–4) which contains the target shape \nwithin it. Here the correct answer is 2.JOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1013"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "categorical division of misophonics versus non- \nmisophonics. We hypothesized that people with mis-\nophonia may behave differently to non-misophonics in \nthe Embedded Figures task if we could include all the \ninformation across their full range of scores. For exam -\nple, on a scale relating to trigger-sounds, this could \nrange from just one or two types of sound (e.g., rus-\ntling) rarely experienced, to as many as eight sounds \nexperienced very often. We therefore separately corre -\nlated Sub-scales 1 and 2 of the MQ (trigger-sounds, \nemotions/behavior) with speed and accuracy in our \ntask.2 Table 2 shows the correlation coefficients for \nboth misophonics and non-misophonics. For people \nwith misophonia, there was a significant relationship \nbetween accuracy and the “Symptoms scale” of the MQ \n(relating to number and frequency of aversive sounds \n(r = .63, p = .002, which survives correction; see, \nTable 2). Specifically, the greater the number of trig-\nger-sounds symptoms for people with misophonia, the \nmore accurately they performed in our attention task. \nNo other effects were significant (see, Table 2). Finally, \nand importantly, MQ scores did not predict the speed \nof responding for either group (misophonia – all \nuncorrected p’s ≥ .2; non-misophonics – all uncor -\nrected p’s ≥ .07), suggesting that the superior accuracy \nof misophonics was not simply because they slowed \ndown.\nDiscussion\nWe tested groups of people with and without misopho -\nnia on the Embedded Figures task, a behavioral measure \nknown to tap into attention to detail. However, in our \nstudy, we found a relationship between accuracy in the \nEmbedded Figures task and the degree of misophonia. \nFor our misophonia group only, the greater the miso -\nphonia symptoms (i.e., the greater the number and \nfrequency of aversive sounds experienced in daily life), the higher the accuracy. This accuracy did not come \nwith any response time penalty, and provides behavioral \nsupport for our self-report findings in Study 1.\nGeneral discussion\nOur research centered around the idea that dispositional \ndifferences in attentional traits might lead people with \nmisophonia to over-attend to otherwise only mildly \naversive sounds. Our data supported this hypothesis. \nIn Study 1, we found a broad trait-profile of heightened \nattention to detail/local processing, as well as related \ntraits of cognitive inflexibility, and high auditory ima-\ngery. In Study 2 we found behavioral support from the \nEmbedded Figures task (which taps local processing/ \nattention to detail) in that misophonics with worse \nsymptoms (i.e., many frequent aversive trigger-sounds) \nperformed more accurately than those with fewer aver-\nsive trigger-sounds.\nOur behavioral results in Study 2 showed a specific \npattern of attention in misophonia. Attentional super -\niority was related to the number/frequency of misopho -\nnia triggers (i.e., our correlation was with Scale 1) rather \nthan the resultant behavior/emotions (no correlation \nwith Scale 2). Understanding this difference provides \na clearer interpretation of our results; i.e., attention-to- \ndetail is linked with how often someone encounters \nmisophonia triggers, and not with how much they are \nupset or impaired. This is a very intuitive finding: better \nattention relates to more easily spotting annoying \nsounds. Of course, this finding must be interpreted \nwithin our relatively small sample since we also found \na slight trend for Scale 2 (p = .06 uncorrected against an \nadjusted alpha of .006). Future studies might therefore \nseek to replicate this finding and/or use alternative \nscales with more items or subscales tapping behavior/ \nimpact (e.g., Rosenthal et al., 2021 ; Vitoratou et al., \n2021 ).\nOur findings on cognitive inflexibility and atten -\ntion to detail are particularly notable since they are \nalso seen in a number of conditions, such as obses -\nsive-compulsive disorder (Yovel et al., 2005 ), depres -\nsion (Kato, 2016 ), and perfectionism (Ferrari & \nMautz, 1997 ; Ong et al., 2019 ). Importantly, these \nsame traits have also been linked to misophonia \n(Cusack et al., 2018 ; Eijsker et al., 2019 ; Jager et al., \n2020 ). The perfectionist traits of people with miso -\nphonia can also be seen in behavioral tasks, such as \nthe stop signal task, which measures response inhibi -\ntion. Here, misophonics show longer stop-signal \ndelays, meaning they favor accuracy rather than \nspeed, implying traits of perfectionism (Eijsker \net al., 2019 ). Our findings of cognitive inflexibility Table 2. Correlation coefficients (and p values) for correlations \nbetween each of two MQ subscales (Symptoms, Emotions, and \nBehaviors) and accuracy (top) or response times (bottom) for \nboth misophonics and controls.\nAccuracy “Symptoms” Scale “Emotions and Behaviours” Scale\nMisophonic 0.63 (.002*) 0.21 (.382)\nNon- \nmisophonic−0.04 (.817) 0.25 (.146)\nResponse time “Symptoms” \nScale“Emotions and Behaviours” \nScale\nMisophonic 0.30 (.202) 0.17 (.472)\nNon- \nmisophonic0.03 (.855) 0.31 (.068)\nNote: P values are uncorrected; Bonferroni correction for multiple compar -\nisons sets the alpha level at .006; significant results at this new level are \nindicated with an asterisk1014\n J. SIMNER ET AL."
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "and heightened attention to detail also fit within this \ntrait profile, and may produce (or at the very least \ncorrelate with) an over-attending to sounds. In this \nrespect, misophonia may have similarities to phobias \n(e.g., fear of spiders) in that it elicits both behavioral \navoidance of triggering stimuli but also heightened \nattention toward those same stimuli (Lavy et al., \n1993 ; Thorpe & Salkovskis, 1997 ; Watts et al., \n1986 ), perhaps stemming from a trait disposition.\nRegarding misophonic triggers themselves, we also \nfound evidence to support our theory that these triggers \nare already mildly aversive for all people (Edelstein et al., \n2013 ). We therefore suggest that attention to detail could \nover-emphasize what are already (mildly) problematic \nsounds because the sounds disliked by misophonics were \nlargely similar to those disliked by non-misophonics. In \nother words, we found that misophonia triggers are aver-\nsive for all people, in a similar pattern that they become \nmore aversive for misophonics (i.e., a strong positive cor-\nrelation in disliking triggers across both misophonics and \nnon-misophonics). This suggests that the mechanisms \ndriving misophonia may stem – at least in part – from \nthe same underlying valence judgments in the general \npopulation, albeit with an overlay of more extreme \nemotions.\nWe now turn to our final hypothesis that miso -\nphonics may have more vivid experiences when \nmentally stimulating sounds are within their auditory \nimagery. Misophonics scored significantly higher in \nauditory imagery, showing that they “hear” sounds \ninternally (e.g., laughing) more clearly in their mind \nthan do non-misophonics. Imagery self-report ques -\ntionnaires have been shown to tap imagery in \na surprisingly robust way, correlating with behavioral \nmeasures of imagery (e.g., Halpern, 2015 ; Keogh & \nPearson, 2018 ) and brain structure (Halpern, 2015 ). \nWe hypothesized heightened auditory given the \nknown relationship between imagery and attention, \nin which imagery can encourage attentional guidance \n(Moriya, 2018 ). We therefore suggest that the heigh -\ntened auditory imagery attention may lead to simi -\nlarly heightened auditory attention for sounds, \nthereby making sounds harder to ignore.\nOur finding of superior scores in auditory imagery \nmight also be interpreted in light of Dance, Ward et al. \n(2021 ) who found that mental imagery is highest in \nthose with higher sensory sensitivities. Misophonia is \nitself a form of high sensory sensitivity, which means it \nmay be no surprise to find that imagery is also higher. \nImportantly, Baddeley & Andrade (2000 ) propose that \nfor increased vividness of imagery, more sensory infor -\nmation may be required to be available to appropriate systems in working memory. Hence, high attention to \nthe details of a sound may gather more information to \nbolster high auditory imagery. Alternatively, high ima-\ngery may itself cause higher attention to detail, and \nfuture research might profitably examine the relation -\nship and directionality of these two characteristics. \nFuture research might also consider differences across \ngenders, since our samples were predominantly female \n(a limitation of our study). This female-bias may reflect \nan as-yet-unknown gender bias in misophonia, \nalthough equally likely is the well-known participation \nbias in which women self-refer more often to studies \nthan men (Curtin et al., 2000 ; Singer et al., 2000 ) and are \nmore willing to self-disclose information (Dindia & \nAllen, 1992 ). This widely occurring bias has been \nknown to unhelpfully skew epidemiological estimates \non gender in other conditions (for discussion, see \nSimner & Carmichael, 2015 ). We therefore note this \nwith caution here and make no assumptions about \nwhether our sample reflects a wider female bias in \nmisophonia.\nIn summary, we have seen how misophonia is linked \nwith several key traits and characteristics beyond a mere \ndisliking of sounds. Our data show that people with \nmisophonia are more attentive to detail, cognitively \ninflexible, but superior at mentally imaging sounds. \nEstablishing these differences sets the stage for future \nresearch on the underlying mechanisms of misophonia \nand targeted interventions while adding a new dimen -\nsion to what we understand about the mental profiles of \npeople with misophonia.\nNotes\n1. Here we report only attention to detail questions, \nthese being items 5,6,9,12,19,23,28,29,30,49 from the \nfull scale. However, our tests were embedded in \na larger battery, which included the full AQ mea -\nsure. Results pertaining to autism per se are outside \nthe scope of this study and are to be reported \nelsewhere.\n2. We could not correlate speed/accuracy against the third \nsubscale (Severity subscale) because responses on this \nsubscale have a different range for misophonics (who \ncan score 7–15; i.e., a 9 point scale) versus non- \nmisophonics (who can score 1–6; i.e., a 6 point scale). \nCorrelations on a restricted range have a naturally smal -\nler coefficient, meaning we could not make a suitable \ncomparison across groups. Nonetheless, the concept \nrepresented by the Severity subscale (which asks readers \nto evaluate the number of triggers, their emotional con-\nsequences, and their impact in daily life) are also found \nwithin the remaining two scales (which ask about trig-\ngers-Scale 1, and emotions/behaviors-Scale 2).JOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1015"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "Disclosure statement\nNo potential conflict of interest was reported by the author(s).\nFunding\nThe authors received funding from the REAM foundation, \nMisophonia Research Fund initiative awarded to JS and JW.\nReferences\nBaddeley, A. D., & Andrade, J. (2000 ). Working memory and \nthe vividness of imagery. Journal of Experimental \nPsychology: General , 129(1), 126–145. https://doi.org/10. \n1037/0096-3445.129.1.126 \nBaron-Cohen, S., Wheelwright, S., Skinner, R., Martin, J., \n& Clubley, E. (2001 ). The autism-spectrum quotient \n(AQ): Evidence from Asperger syndrome/high-function -\ning autism, males and females, scientists and \nmathematicians. Journal of Autism and Developmental \nDisorders , 31(1), 5–17. https://doi.org/10.1023/ \nA:1005653411471 \nCavanna, A. E., & Seri, S. (2015 ). Misophonia: Current \nperspectives. Neuropsychiatric Disease and Treatment , 11 \n(August), 2117–2123. https://doi.org/10.2147/NDT.S81438 \nCurtin, R., Presser, S., & Singer, E. (2000 ). The effects of \nresponse rate changes on the index of consumer \nsentiment. Public Opinion Quarterly , 64(4), 413–428. \nhttps://doi.org/10.1086/318638 \nCusack, S. E., Cash, T. V., & Vrana, S. R. (2018 ). An examina -\ntion of the relationship between misophonia, anxiety sen-\nsitivity, and obsessive-compulsive symptoms. Journal of \nObsessive-Compulsive and Related Disorders , 18(July), \n67–72. https://doi.org/10.1016/j.jocrd.2018.06.004 \nDajani, D. R., & Uddin, L. Q. (2015 ). Demystifying cognitive \nflexibility: Implications for clinical and developmental neu-\nroscience. Trends in Neurosciences , 38(9), 571–578. https:// \ndoi.org/10.1016/j.tins.2015.07.003 \nDance, C. J., Jaquiery, M., Eagleman, D. M., Porteous, D., \nZeman, A., & Simner, J. (2021 ). What is the relationship \nbetween Aphantasia, Synaesthesia and Autism? \nConsciousness and Cognition , 89(March), 103087. https:// \ndoi.org/10.1016/j.concog.2021.103087 \nDance, C. J., Ward, J., & Simner, J. (2021 ). What is the Link \nBetween Mental Imagery and Sensory Sensitivity? Insights \nfrom Aphantasia. Perception , 50(9), 757–782. https://doi.org/ \n10.1177/03010066211042186 \nDindia, K., & Allen, M. (1992 ). Sex differences in \nself-disclosure: A meta-analysis. Psychological Bulletin , 112 \n(1), 106–124. https://doi.org/10.1037/0033-2909.112.1.106 \nEdelstein, M., Brang, D., Rouw, R., & Ramachandran, V. S. \n(2013 ). Misophonia: Physiological investigations and case \ndescriptions. Frontiers in Human Neuroscience , 7(JUN), \n296. https://doi.org/10.3389/fnhum.2013.00296 \nEijsker, N., Schröder, A., Liebrand, L. C., Smit, D. J. A., \nvan Wingen, G., & Denys, D. (2021 ). White \nmatter abnormalities in misophonia. NeuroImage: \nClinical , 32, 102787. https://doi.org/10.1016/j.nicl. \n2021.102787 Eijsker, N., Schröder, A., Smit, D. J. A., van Wingen, G., & \nDenys, D. (2019 ). Neural basis of response bias on the stop \nsignal task in misophonia. Frontiers in Psychiatry , 10. \nhttps://doi.org/10.3389/fpsyt.2019.00765 \nFerrari, J. R., & Mautz, W. T. (1997 ). Predicting perfectionism: \nApplying tests of rigidity. Journal of Clinical Psychology , 53 \n(1), 1–6. https://doi.org/10.1002/(SICI)1097-4679(199701) \n53:1<1::AID-JCLP1>3.0.CO;2-Y \nFrank, B., Roszyk, M., Hurley, L., Drejaj, L., & McKay, D. \n(2020 ). Inattention in misophonia: Difficulties achieving \nand maintaining alertness. Journal of Clinical and \nExperimental Neuropsychology , 42(1), 66–75. https://doi. \norg/10.1080/13803395.2019.1666801 \nHalpern, A. R. (2015 ). Differences in auditory imagery \nself-report predict neural and behavioral outcomes. \nPsychomusicology: Music, Mind, and Brain , 25(1), 37–47. \nhttps://doi.org/10.1037/pmu0000081 \nJager, I., de Koning, P., Bost, T., Denys, D., & Vulink, N. \n(2020 ). Misophonia: Phenomenology, comorbidity and \ndemographics in a large sample. PLoS ONE , 15(4), \ne0231390. https://doi.org/10.1371/journal.pone.0231390 \nJastreboff, M. M., & Jastreboff, P. J. (2001 ). Components of \ndecreased sound tolerance: Hyperacusis, misophonia, \nphonophobia. ITHS Newsletter , 1(July), 1–5. https://doi. \norg/10.1055/s-0034-1372527 \nJolliffe, T., & Baron-Cohen, S. (1997 ). Are people with autism \nand Asperger syndrome faster than normal on the \nEmbedded Figures Test? Journal of Child Psychology and \nPsychiatry, and Allied Disciplines , 38(5), 527–534. https:// \ndoi.org/10.1111/j.1469-7610.1997.tb01539.x \nKato, T. (2016 ). Impact of psychological inflexibility on \ndepressive symptoms and sleep difficulty in a Japanese \nsample. SpringerPlus , 5(1), 712. https://doi.org/10.1186/ \ns40064-016-2393-0 \nKeogh, R., & Pearson, J. (2018 ). The blind mind: No sensory \nvisual imagery in aphantasia. Cortex , 105(2015), 53–60. \nhttps://doi.org/10.1016/j.cortex.2017.10.012 \nKoldewyn, K., Jiang, Y. V., Weigelt, S., & Kanwisher, N. \n(2013 ). Global/local processing in autism: Not a disability, \nbut a disinclination. Journal of Autism and Developmental \nDisorders , 43(10), 2329–2340. https://doi.org/10.1007/ \ns10803-013-1777-z \nKumar, S., Tansley-Hancock, O., Sedley, W., Winston, J. S., \nCallaghan, M. F., Allen, M., Cope, T. E., Gander, P. E., \nBamiou, D. E., & Griffiths, T. D. (2017 ). The brain basis \nfor misophonia. Current Biology , 27(4), 527–533. https:// \ndoi.org/10.1016/j.cub.2016.12.048 \nKurita, H., Koyama, T., & Osada, H. (2005 ). Autism- \nSpectrum Quotient-Japanese version and its short \nforms for screening normally intelligent persons with \npervasive developmental disorders. Psychiatry and \nClinical Neurosciences , 59(4), 490–496. https://doi.org/ \n10.1111/j.1440-1819.2005.01403.x \nLavy, E., van den Hout, M., & Arntz, A. (1993 ). Attentional \nbias and spider phobia: Conceptual and clinical issues. \nBehaviour Research and Therapy , 31(1), 17–24. https:// \ndoi.org/10.1016/0005-7967(93)90038-V \nLima, C. F., Lavan, N., Evans, S., Agnew, Z., Halpern, A. R., \nShanmugalingam, P., Meekings, S., Boebinger, D., \nOstarek, M., McGettigan, C., Warren, J. E., & Scott, S. K. \n(2015 ). Feel the noise: Relating individual differences in 1016\n J. SIMNER ET AL."
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "auditory imagery to the structure and function of sensor -\nimotor systems. Cerebral Cortex , 25(11), 4638–4650. \nhttps://doi.org/10.1093/cercor/bhv134 \nMaria, A. S., Barry, C., Ringuenet, D., Falissard, B., Group, T., \n& Berthoz, S. (2020 ). Subjective cognitive rigidity and \nattention to detail: A cross-cultural validation of the \nDetail and Flexibility Questionnaire (DFlex) in a French \nclinical sample. Journal of Clinical and Experimental \nNeuropsychology , 42(10), 1059–1071. https://doi.org/10. \n1080/13803395.2020.1842333 \nMoriya, J. (2018 ). Visual mental imagery influences atten -\ntional guidance in a visual-search task. Attention, \nPerception, and Psychophysics , 80(5), 1127–1142. https:// \ndoi.org/10.3758/s13414-018-1520-0 \nMumma, G. H. (1993 ). The Embedded Figures Test: Internal \nstructure and development of a short form*. Personality \nand Individual Differences , 15(2), 221–224. https://doi.org/ \n10.1016/0191-8869(93)90029-3 \nNäätänen, R. (1992 ). Attention and brain function . Erlbaum.\nOng, C. W., Barney, J. L., Barrett, T. S., Lee, E. B., Levin, M. E., \n& Twohig, M. P. (2019 ). The role of psychological inflex -\nibility and self-compassion in acceptance and commitment \ntherapy for clinical perfectionism. Journal of Contextual \nBehavioral Science , 13(July), 7–16. https://doi.org/10.1016/ \nj.jcbs.2019.06.005 \nPanagopoulos, V. N., Greene, D. J., Campbell, M. C., & \nBlack, K. J. (2013 ). Towards objectively quantifying sensory \nhypersensitivity: A pilot study of the “Ariana effect. PeerJ , 2013 \n(1), e121. https://doi.org/10.7717/PEERJ.121 \nRinaldi, L. J., Ward, J., & Simner, J. (2021 , December 1). An \nAutomated Online Assessment for Misophonia: The Sussex \nMisophonia Scale for Adults. Psyarxiv. https://doi.org/10. \n31234/osf.io/5eb39 \nRinne, T., Särkkä, A., Degerman, A., Schröger, E., & Alho, K. \n(2006 ). Two separate mechanisms underlie auditory change \ndetection and involuntary control of attention. Brain \nResearch , 1077 (1), 135–143. https://doi.org/10.1016/j. \nbrainres.2006.01.043 \nRoberts, M. E., Barthel, F. M. S., Lopez, C., Tchanturia, K., & \nTreasure, J. L. (2011 ). Development and validation of the \ndetail and flexibility questionnaire (DFlex) in eating \ndisorders. Eating Behaviors , 12(3), 168–174. https://doi. \norg/10.1016/j.eatbeh.2011.04.001 \nRosenthal, M. Z., Anand, D., Cassiello-Robbins, C., \nWilliams, Z. J., Guetta, R. E., Trumbull, J., & Kelley, L. D. \n(2021 ). Development and initial validation of the duke mis-\nophonia questionnaire. Frontiers in Psychology , 12 \n(September), 4197. https://doi.org/10.3389/fpsyg.2021.709928 \nRouw, R., & Erfanian, M. (2018 ). A large-scale study of \nmisophonia. Journal of Clinical Psychology , 74(3), \n453–479. https://doi.org/10.1002/jclp.22500 \nSchröder, A., van Diepen, R., Mazaheri, A., Petropoulos-Petalas, \nD., Soto de Amesti, V., Vulink, N., Denys, D. (2014 ). \nDiminished N1 Auditory Evoked Potentials to Oddball \nStimuli in Misophonia Patients. Frontiers in Behavioral \nNeuroscience , 8(April), 1–6. https://doi.org/10.3389/fnbeh. \n2014.00123 \nSchröder, A., Wingen, G. V., Eijsker, N., San Giorgi, R., \nVulink, N. C., Turbyne, C., & Denys, D. (2019 ). Misophonia \nis associated with altered brain activity in the auditory cortex \nand salience network. Scientific Reports , 9(1), 1–9. https://doi. \norg/10.1038/s41598-019-44084-8 Scott, W. A. (1962 ). Cognitive complexity and cognitive \nflexibility. Sociometry , 25(4), 405. https://doi.org/10.2307/ \n2785779 \nShafran, R., Cooper, Z., & Fairburn, C. G. (2002 ). Clinical \nperfectionism: A cognitive-behavioural analysis. Behaviour \nResearch and Therapy , 40(7), 773–791. https://doi.org/10. \n1016/S0005-7967(01)00059-6 \nSilva, F. E. D., & Sanchez, T. G. (2019 ). Evaluation of selective \nattention in patients with misophonia. Brazilian Journal of \nOtorhinolaryngology , 85(3), 303–309. https://doi.org/10. \n1016/j.bjorl.2018.02.005 \nSimner, J., & Carmichael, D. A. (2015 ). Is synaesthesia \na dominantly female trait? Cognitive Neuroscience , 6(2–3), \n68. https://doi.org/10.1080/17588928.2015.1019441 \nSinger, E., van Hoewyk, J., & Maher, M. P. (2000 ). Experiments \nwith incentives in telephone surveys. Public Opinion \nQuarterly , 64(2), 171–188. https://doi.org/10.1086/317761 \nSt. Clare, T. (2003 ). Assessment Procedures. In R. Menzies & \nP. de Silva (Eds.), Obsessive compulsive disorder: Theory, \nresearch, and treatment (pp. 239–258). John Wiley & Sons Ltd.\nThorpe, S. J., & Salkovskis, P. M. (1997 ). The effect of one-session \ntreatment for spider phobia on attentional bias and beliefs. \nBritish Journal of Clinical Psychology , 36(2), 225–241. https:// \ndoi.org/10.1111/j.2044-8260.1997.tb01409.x \nvan Passel, B., Danner, U., Dingemans, A., van Furth, E., \nHendriks, G.-J., Hendriks, G.-J., Hendriks, G.-J., \nHendriks, G.-J., Cath, D., & Cath, D. (2016 ). Cognitive reme -\ndiation therapy (CRT) as a treatment enhancer of eating dis-\norders and obsessive compulsive disorders: Study protocol for \na randomized controlled trial. BMC Psychiatry , 16(1), 393– \nundefined. https://doi.org/10.1186/s12888-016-1109-x \nVitoratou, S., Uglik-Marucha, N., Hayes, C., & Gregory, J. (2021 ). \nListening to people with misophonia: Exploring the multiple \ndimensions of sound intolerance using a new psychometric \ntool, the S-five, in a large sample of individuals identifying with \nthe condition. Psych 2021 , 3(4), 639–662. https://doi.org/10. \n3390/PSYCH3040041 \nWard, J., Brown, P., Sherwood, J., & Simner, J. (2018 ). An \nautistic-like profile of attention and perception in \nsynaesthesia. Cortex , 107(October), 121–130. https://doi. \norg/10.1016/j.cortex.2017.10.008 \nWatts, F. N., Trezise, L., & Sharrock, R. (1986 ). Processing of \nphobic stimuli. British Journal of Clinical Psychology , 25(4), \n253–259. https://doi.org/10.1111/j.2044-8260.1986.tb00705.x \nWillander, J., & Baraldi, S. (2010 ). Development of a new clarity \nof auditory imagery scale. Behavior Research Methods , 42(3), \n785–790. https://doi.org/10.3758/BRM.42.3.785 \nWitkin, H. A., Oltman, P. K., Raskin, E., & Karp, S. A. (1971 ). \nA manual for the embedded figures test. Consulting \nPsychologist Press.\nWu, M. S., Lewin, A. B., Murphy, T. K., & Storch, E. A. (2014 ). \nMisophonia: Incidence, phenomenology, and clinical corre -\nlates in an undergraduate student sample. Journal of Clinical \nPsychology , 70(10), 994–1007. https://doi.org/10.1002/jclp. \n22098 \nYoung, M. P., Paterson, I. R., & Perrett, D. I. (1989 ). Attention to \ndetail? Behavioral and Brain Sciences , 12(3), 417–418. https:// \ndoi.org/10.1017/S0140525X00057022 \nYovel, I., Revelle, W., & Mineka, S. (2005 ). Who sees trees \nbefore forest?: The obsessive-compulsive style of visual \nattention. Psychological Science , 16(2), 123–129. https:// \ndoi.org/10.1111/j.0956-7976.2005.00792.xJOURNAL OF CLINICAL AND EXPERIMENTAL NEUROPSYCHOLOGY\n 1017"
    }
  ]
}