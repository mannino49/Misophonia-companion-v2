{
  "doc_type": "scientific paper",
  "title": "Recent advances in the application of predictive coding and active inference models within clinical neuroscience",
  "authors": [
    "Ryan Smith, PhD",
    "Paul Badcock, PhD",
    "Karl J. Friston, MRCPsych"
  ],
  "year": 2021,
  "journal": "Psychiatry and Clinical Neurosciences",
  "doi": "10.1111/pcn.13138/full",
  "abstract": "Research in clinical neuroscience is founded on the idea that a better understanding of brain (dys)function will improve our ability to diagnose and treat neurological and psychiatric disorders. In recent years, neuroscience has converged on the notion that the brain is a ‘prediction machine,’ in that it actively predicts the sensory input that it will receive if one or another course of action is chosen. These predictions are used to select actions that will (most often, and in the long run) maintain the body within the narrow range of physiological states consistent with survival. This insight has given rise to an area of clinical computational neuroscience research that focuses on characterizing neural circuit architectures that can accomplish these predictive functions, and on how the associated processes may break down or become aberrant within clinical conditions. Here, we provide a brief review of examples of recent work on the application of predictive processing models of brain function to study clinical (psychiatric) disorders, with the aim of highlighting current directions and their potential clinical utility. We offer examples of recent conceptual models, formal mathematical models, and applications of such models in empirical research in clinical populations, with a focus on making this material accessible to clinicians without expertise in computational neuroscience. In doing so, we aim to highlight the potential insights and opportunities that understanding the brain as a prediction machine may offer to clinical research and practice.",
  "keywords": [
    "active inference",
    "computational neuroscience",
    "computational psychiatry",
    "emotion",
    "predictive coding"
  ],
  "research_topics": [
    "clinical neuroscience",
    "predictive coding",
    "active inference",
    "computational neuroscience",
    "computational psychiatry",
    "brain function modeling",
    "psychiatric disorders",
    "neural circuit architecture",
    "decision-making",
    "perception"
  ],
  "created_at": "2025-05-05T02:29:48.956920Z",
  "source_pdf": "documents/research/Global/Psychiatry Clin NeurosciSmith 2020 Recent advances in the application of predictive coding and active inference.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "PCN FRONTIER REVIEWPCN\nRecent advances in the application of predictive coding\nand active inference models within clinical neuroscience\nRyan Smith, PhD ,1*Paul Badcock, PhD2,3,4and Karl J. Friston, MRCPsych5\nResearch in clinical neuroscience is founded on the idea that\na better understanding of brain (dys)function will improve\nour ability to diagnose and treat neurological and psychiatricdisorders. In recent years, neuroscience has converged onthe notion that the brain is a ‘prediction machine, ’in that it\nactively predicts the sensory input that it will receive if oneor another course of action is chosen. These predictions areused to select actions that will (most often, and in the longrun) maintain the body within the narrow range of physiologi-cal states consistent with survival. This insight has given riseto an area of clinical computational neuroscience researchthat focuses on characterizing neural circuit architecturesthat can accomplish these predictive functions, and on howthe associated processes may break down or become aber-rant within clinical conditions. Here, we provide a briefreview of examples of recent work on the application ofpredictive processing models of brain function to study clini-\ncal (psychiatric) disorders, with the aim of highlighting cur-\nrent directions and their potential clinical utility. We offerexamples of recent conceptual models, formal mathematicalmodels, and applications of such models in empiricalresearch in clinical populations, with a focus on making thismaterial accessible to clinicians without expertise in compu-tational neuroscience. In doing so, we aim to highlight thepotential insights and opportunities that understanding thebrain as a prediction machine may offer to clinical researchand practice.\nKeywords: active inference, computational neuroscience, computa-\ntional psychiatry, emotion, predictive coding.\nhttp://onlinelibrary.wiley.com/doi/10.1111/pcn.13138/full\nResearch in clinical neuroscience is founded on the premise that bet-\nter understanding of brain function –and, by extension, dysfunction –\nwill improve our ability to diagnose and treat disorders of the mind\nand brain. As the ﬁeld has moved forward, it has become increasingly\nclear that, to understand the brain, it must ﬁrst be characterized at\nmultiple spatiotemporal scales and levels of description. We then\nhave to understand how dynamics at each scale or level of description\nrelate to (or emerge from) the dynamics of others. At one end of thespectrum, a large body of work has emerged over the last century on\nthe microscale cellular and molecular functions of neurons and\nsupporting brain cells; at the other, the last few decades have pro-duced a growing body of work on large-scale human brain functionusing neuroimaging methods, which have uncovered regularities in\nthe relation between macroscale regional brain activity and complex\npsychological processes. However, to fully link micro- and macro-scale functioning, and biological and psychological levels of descrip-\ntion, it is widely recognized that we need to develop a better\nunderstanding of functional architectures at the intermediate meso-scale (see Fig. 1).\nThe mesoscale corresponds to circuits of interconnected neurons\nwith particular patterns of synaptic connections that allow for speci ﬁc\ntypes of information processing or ‘computation. ’For instance, one pat-\ntern of neural circuit connections may allow the brain to infer whatobjects are most likely giving rise to its current retinal input, whereas\nother patterns of connections may solve the problem of determining\nwhich action is more likely to generate preferred outcomes.\n2–4Thus,\nmesoscale circuits afford a computational level of description, whichoffers a bridge between biology and psychology by allowing researchers\nto characterize how neural circuit dynamics produce psychologicaloperations, such as object recognition and decision-making.4–8Unfortu-\nnately, the mesoscale is currently the most dif ﬁcult to study directly with\ncurrent neuroscience methods. However, a more recent body of work incomputational neuroscience –and its clinically focused sister discipline\nof computational psychiatry –has emerged over the last several years to\nbetter address this problem.9–11\nThe unique advantages offered by computational neuroscience\nand computational psychiatry follow from a speci ﬁc type of mathe-\nmatical modeling. This approach ﬁrst identi ﬁes a problem that the\nbrain can (or must) solve, such as object recognition or decision-mak-\ning, and then works backward to identify the requisite computational\nsteps –or algorithms –that the brain could use to solve this problem.\nAlthough many mathematical solutions may exist, only a subset will\nbe biologically plausible –that is, only some algorithms could be\nplausibly accomplished by connecting neurons together in particularpatterns. Once a set of biologically plausible algorithms has been\nidenti ﬁed, each algorithm in turn entails one or more testable hypoth-\neses about how the mesoscale function and structure of a particularbrain region (or connected set of regions) could implement that algo-\nrithm. Different algorithms and neural implementations typically have\ndifferent costs and bene ﬁts (e.g., different levels of ef ﬁciency vs accu-\nracy, and different metabolic demands) and, as such, they often make\ndistinct predictions about the patterns of brain activity and behavior\nthat should be observed under speci ﬁc conditions. Such predictions\ncan then be tested experimentally to provide evidence for one\n1Laureate Institute for Brain Research, Oklahoma, USA\n2Centre for Youth Mental Health, The University of Melbourne, Victoria, Australia\n3Orygen, Victoria, Australia\n4Melbourne School of Psychological Sciences, The University of Melbourne, Victoria, Australia\n5Wellcome Centre for Human Neuroimaging, Institute of Neurology, University College London, London, UK\n*Correspondence: Email: rsmith@laureateinstitute.org\n©2020 The Authors\nPsychiatry and Clinical Neurosciences ©2020 Japanese Society of Psychiatry and Neurology\nPsychiatry and Clinical Neurosciences 75: 3 –13, 20213PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "algorithm versus another and, in some cases, evidence for one neural\nimplementation (mesoscale circuit structure) over another. Therefore,the two primary advantages of computational neuroscience include:(i) building mathematical models that allow researchers to simulateneurocomputational processes –to con ﬁrm how the brain could solve\na particular problem; and (ii) making empirical predictions for testingwhich neurocomputational processes the brain in fact does use to\nsolve that problem.\nThere are many algorithms currently used for research in this\nﬁeld. In this article, we focus on a family of biologically plausible\nalgorithms that have emerged from the idea that brain processes are\npredictive . That is, they share the idea that the brain is a type of ‘pre-\ndiction machine, ’which allows it to solve dif ﬁcult problems in per-\nception, decision-making, and skeletomotor/visceromotor control in\nan approximately optimal manner. In perception, one widely studied\nalgorithm of this kind is ‘predictive coding, ’which rests on the idea\nthat a perceptual system continually predicts what it should observe\nnext if its current perceptual beliefs are correct.\n6,7,12Perceptual\nbeliefs are then updated when sensory input differs from predicted\ninput. In predictive coding, this difference affords the calculation of a\n‘prediction error, ’which can be used to guide belief updating and ﬁnd\nthe minimal change in perceptual beliefs necessary to minimize that\nerror signal. Technically, this is called Bayesian belief updating or\ninference. This process can also be iterated hierarchically, so that\nhigher brain circuits continuously update beliefs about (and predict)\nwhat will be represented in lower hierarchical levels that are closer tothe sensory periphery –allowing different levels of abstraction (e.g., a\nbelief that a white/round percept corresponds to a baseball2). Different\npredictions and prediction errors can also be considered more or less\nreliable (e.g., visual prediction errors may be more reliable during the\nday vs at night). As such, in predictive coding models, the brain canalso maintain (and update) estimates about the reliability (inverse var-\niance or ‘precision ’) of its various predictions and prediction errors,\nwhich modulate how easy or hard it is to change current beliefs when\nchallenged by strong prediction errors (i.e., by increasing or decreas-\ning the ‘weight ’assigned to those prediction errors).\nTo give the reader a sense of the dynamics of predictive coding\nmodels, and how they might be applied to solve a clinically relevantpsychological task, a very simple, four-neuron network, and simulated\nneuronal activity are shown in Figure 2a –e. The details of the exam-\nple are described in the ﬁgure legend; but, in short, the ﬁgure illus-\ntrates the simulated neuronal dynamics through which prediction\nerror is minimized to arrive at an estimate or ‘best guess ’about\nwhether another person is hostile or friendly. This is based on: (i) the\nperceived curvature of their lips (e.g., ﬂat curvature, most consistent\nwith a neutral facial expression); and (ii) prior expectations\n(i.e., initial predictions about how friendly or hostile the person is\nprior to seeing their facial expression). The simulations show how\nprior expectations can bias perception to favor a ‘hostile ’interpreta-\ntion, and how different relative precision weightings can amplify orattenuate this effect.\nFormally, and under certain simplifying assumptions, minimizing\nprediction error is equivalent to the minimization of a statistical quan-tity called ‘variational free energy, ’which is often used to solve opti-\nmization problems in machine learning.\n18In this context, free energy\nis a computationally tractable measure of the evidence that sensory\ninput provides for the brain ’s internal (generative) model of the world,\nsuch that minimizing free energy maximizes model evidence. Freeenergy is simultaneously a measure of complexity minus accuracy.\nThis means that, when the brain updates beliefs by minimizing (preci-\nsion-weighted) prediction errors (i.e., minimizing free energy), it does\nso by ﬁnding the simplest (i.e., least complex), most parsimonious\nchange in beliefs to account for new observations.\nIn decision-making and action selection, a related class of bio-\nlogically plausible algorithms comes from the ‘active inference ’\nframework.2,16,17,19Active inference models go a step beyond predic-\ntive coding to emphasize that the brain does not simply predict sen-\nsory input passively. Instead, it predicts what it will observe if itchooses to act in one way or another.20From this perspective,\ndecision-making involves predicting the outcomes one would observe\nifeach of several actions (or action sequences, called ‘policies ’) were\nchosen, and then selecting the actions expected to produce the obser-\nvations that are most preferred and/or that will provide the most newinformation. Upon re ﬂection, this is quite intuitive. For example, if I\nam hungry, then I am less likely to stay still and more likely to go\nandﬁnd food –precisely because being hungry is inconsistent with\nMacroscale\nMesoscale\nMicroscaleFig.1 Schematic of the multiscale archi-\ntecture of neural networks. At the macro-\nscale, the brain is most often studied in\nterms of activity within, or interactionsbetween, large-scale brain regions usingneuroimaging. These brain regions caninteract over large distances, mediated bylong-range axonal ﬁber bundles. At the\nmicroscale, the brain is studied in terms ofsingle-neuron activity and intra −/inter-\ncellular interactions at the molecular level.\nThe mesoscale links the micro- and mac-\nroscales, but it is currently the most dif ﬁ-\ncult to study. Computational neuroscienceis uniquely suited to address mesoscalefunction. Current work in this area sup-ports the idea that patterns of synapticconnectivity at this level implement thepredictive algorithms discussed in thetext. This algorithmic level of description\nbridges the neural and psychological\nlevels of description by showing how neu-ral structures can implement the computa-tional processes underlying psychologicalfunctions, such as perception, learning,and decision-making. Mesoscale compu-tational (algorithmic) modeling thereforeoffers a unique window into the neuralbasis of abnormal psychological pro-\ncesses within psychopathology. Adapted\nfrom Park and Friston.\n1\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 4The predictive brain in psychiatry PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "my preferences and I expect eating food will produce my more pre-\nferred feelings of satiety. However, if I am not con ﬁdent where to ﬁnd\nthe closest source of food, I will ﬁrst choose actions to gather infor-\nmation –such as checking in the fridge before deciding to go to the\nstore.\nIn active inference, preferences are formally modeled as a\nparticular type of prior expectation (over sensory observations or ‘out-\ncomes ’; often called ‘prior preferences ’), which means that non-\npreferred outcomes are ‘surprising ’in a technical sense (i.e., they\ndeviate from those prior preferences). During decision-making, this\ntype of expected ‘surprise ’(if one action were chosen vs another) is\nassociated with what might be thought of as an expected ‘preference\nprediction error ’(i.e., the expected difference [technically the\nKullback –Leibler divergence] between preferred outcomes and theoutcomes expected if one were to choose a particular course of action\n–a quantity also sometimes referred to as ‘risk ’). Preferred outcomes\nare then achieved by choosing actions expected to minimize this type\nof prediction error. However, it is important to distinguish this\npreference-based notion of ‘surprise ’and prediction error from other\nconstructs. First, prediction error is not equivalent to a conscious feel-ing of surprise or the conscious belief that something is surprising.\nConscious feelings and beliefs are higher-level states that must them-\nselves be inferred.21–23By contrast, in active inference (and in predic-\ntive coding), the terms ‘belief ’and ‘surprise ’are technical terms that\nrefer to probabilistic representations encoded by neuronal activity\n(and connectivity) in mesoscale neural circuitry (e.g., canonical\nmicrocircuits6). These neurocomputational processes occur at a sub-\npersonal level outside of conscious awareness and therefore need not\n(a) (b) (c)\n(e)(f)\nG1\n5\n423\nABsτ\nsπ,τ\nεπ,τ\nπ\nγ\nut(1)o1o2o3oπ,τ\nςπ,τ\n(d)Precision\nmodulation from\nhigher levels10 (Very friendly)\nTime 0 (Very hostile)\n10 (Very friendly)\n0 (Very hostile)Stable estimate\nPrFL= 1 (Low); πFL = πLC; LC = 5 PrFL= 9 (High); πFL = πLC; LC = 5\nPrFL= 1 (Low); πFL > πLC; LC = 5 PrFL= 1 (High); πFL < πLC; LC = 5Stable estimate Policies\nTime InhibitoryExcitatory\nModulator yStable estimateStable estimateFL activity (Friendliness level)\nLC activity (Neutral facial expression)\nPrecision\nmodulation from\nhigher levels\nSignal from\nlower levelsPrecision\nestimate\n(πFL)\nPrecision\nestimate\n(πLC)Linear mapping\nbetween levelsPEFL\nPELCFL\nLCPrediction from\nhigher level ( PrFL)\nFig.2 (a) An illustration of neuronal connectivity and dynamics within a very simple predictive coding model of ‘friendliness perception ’(i.e., estimating how friendly vs\nhostile someone is based on lip curvature as an indicator of facial expression). This example illustrates how the same input (i.e., ﬂat lip curvature, most consistent with\na neutral facial expression) can be interpreted as a sign of higher or lower levels of friendliness based on different learned prior expectations and p recision estimates.\nIn this model, blue triangles indicate cortical pyramidal neurons, and black lines indicate axons terminating in synaptic connections. Arrows indi cate excitatory synaptic\ninﬂuences, and circles indicate inhibitory synaptic in ﬂuences (dashed arrows are not modeled, but indicate additional context-speci ﬁc modulatory in ﬂuences that could\nalso be present in a more complete model). Activity of the FL neuron estimates ‘level of friendliness ’(from very hostile to very friendly; activity levels from 0 –10), and\nLC neuron activity represents ‘lip curvature ’(i.e., low activity indicates frown and high activity indicates smile). The two PE neurons re ﬂect ‘prediction-errors ’associated\nwith FL activation (higher level) and with LC activation (lower level). The strength of the two looping axons ’synapses (connecting each PE neuron to itself) estimates\nthe precision (reliability) of prior expectations ( πFL; higher level) and LC activity ( πLC; lower level). Expected friendliness (Pr FL) is conveyed through the strength of the\ntop-down inhibitory synapse on the higher-level PE neuron. Although not modeled here, predictive coding models also include quantitative synaptic learning mecha-\nnisms (i.e., update equations) allowing the strengths of the Pr FL,πFL, and πLCsynapses (i.e., prior expectations and precision estimates) to be altered over time to better\nmatch patterns in experience. Panels (b) –(e) illustrate changes in FL neuron activity (i.e., inferred friendliness level; black lines) over time when presented with a ﬂat lip\ncurvature (i.e., moderate LC activity, most consistent with a neutral level of friendliness, all else being equal; blue lines) under different model parameter values. These\ndifferent parameter values re ﬂect: prior expectations of (b) low versus (c) high levels of friendliness; and (d) high versus (e) low reliability/precision estimates for expecta-\ntions of low friendliness. As can be seen, after FL neuron activity converges onto a stable estimate (i.e., when activity ceases to oscillate once pred iction error is mini-\nmized), lower levels of friendliness are inferred in (b) compared to (c) (re ﬂecting the in ﬂuence of prior predictions), and in (d) compared to (e) (re ﬂecting the in ﬂuence of\nhigher reliability estimates for prior predictions of low friendliness). For the detailed mathematics on which this example is based, see Bogacz.13Panel (f) depicts the\nneural process theory proposed within active inference. Example simulations using this process theory are shown in Figure 3. In this theory, probabi lity estimates for a\ngiven phenomenon (e.g., being friendly or hostile) are associated with neuronal populations that are arranged to reproduce known intrinsic (within cortical area) connec-\ntions. Red connections are excitatory, blue connections are inhibitory, and green connections are modulatory (i.e., involve a multiplication or we ighting). Similar to pre-\ndictive coding, these connections convey different types of prediction and prediction error signals (labeled as signal types 1 –5), but in this case also incorporate action\nselection. Cyan units correspond to predictions about future sensory inputs ( o) and the causes of those inputs ( s) if one were to follow one sequence of actions versus\nanother (i.e., policies, π) at each time point ( t), while red units represent a type of ‘best guess ’about causes of sensory input when considering the probability of all pos-\nsible policies (i.e., a Bayesian model average). Pink units correspond to sensory prediction errors ( ε) and preference predictions errors ( ζ), which are used to evaluate\nexpected free energy (G) and compute subsequent policy probabilities ( π). When selecting an action ( u) at each time point, policy probabilities are also modulated by\nan expected precision term ( γ) that has been linked to dopamine.14Predictions are conveyed by one set of synaptic connections (denoted by the letter B), while predic-\ntion errors are encoded by a different set of synaptic connections (denoted by the letter A); these synaptic connection strengths are updated during a ssociative learn-\ning (i.e., long-term synaptic potentiation and depression15). Only exemplar connections are shown to avoid visual clutter. Furthermore, we have just shown neuronal\npopulations encoding beliefs under two possible policies over three time points. For an introduction to the associated mathematics describing neur onal interactions in\nthis theory, see Friston et al.,2, 16and Da Costa et al.17\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 5PCNPsychiatry and\nClinical Neurosciences The predictive brain in psychiatry\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "lead to conscious feelings of surprise. Second, ‘preference prediction\nerrors ’(also sometimes called ‘outcome prediction errors ’in the\nactive inference literature; e.g., see ﬁgure 2 within Smith et al.21) are\nnot the same as the ‘state prediction errors ’discussed above in rela-\ntion to predictive coding. There are also state prediction errors in\nactive inference (see Fig. 2f), which –as in predictive coding –occur\nwhen model beliefs (about one ’s current state or situation) are updated\nwith an unexpected new observation. In other words, state prediction\nerrors drive belief updating about states of the world that are encoun-\ntered, while preference prediction errors pertain to the (non)preferred\noutcomes expected if one were to choose different courses of action.\nIn this sense, it is possible for the brain to be ‘surprised ’by an unan-\nticipated outcome given its prior beliefs about states (i.e., large state\nprediction error), while yet anticipating a preferred outcome\n(i.e., small expected preference prediction errors). This speaks to thedifference between posterior beliefs about one ’s course of action (that\nare informed by state prediction errors) and prior beliefs before\nexperiencing the consequences of action (that are informed by\nexpected preference prediction errors).\nSimilar to state prediction errors in predictive coding, minimizing\nexpected preference prediction errors also corresponds to minimizing\nfree energy –but in this case it is the free energy associated with the\nfuture outcomes that are expected under different actions (i.e., expected\nfree energy). As with predictive coding, active inference comes\nequipped with a neural process theory that allows one to simulate pat-terns of neural activity that can be tested empirically.\n2,14,16,19,24An\nexample neural network implementation based on this process theory is\ndepicted in Figure 2f. Although the neural network architecture in this\ncase differs somewhat from the simpler predictive coding example in\nFigure 2a –e, similar prediction error minimizing dynamics emerge\n(example simulations using this architecture are shown in relation to a\nformal model of emotion in Fig. 3). In most cases, minimizing\n(expected) free energy in these theories is expected (on average, and in\nthe long run) to keep an organism within the narrow range of physio-\nlogical and environmental states consistent with its survival(i.e., preferred states34). However, it is important to highlight that\norganisms also plausibly inherit evolutionarily selected, adaptive prior\nexpectations (including preferences), which can favor genetic propaga-tion over individual survival (e.g., motivating risky reproductive behav-\nior or self-sacri ﬁce for genetic relatives35).\nSimilar to predictive coding, probabilistic beliefs in active infer-\nence models can also have different levels of precision that in ﬂuence\nbelief updating. However, in addition to the precision of sensory pre-diction errors and prior beliefs about states, there are a number of other\nvariables that have precisions in active inference. For example, prior\npreferences can have different precisions, which can affect the degree\nto which behavior is driven by seeking reward versus seeking informa-\ntion to resolve uncertainty. Beliefs about the probability (i.e., value) ofdifferent available sequences of actions ( ‘policies ’) can also have dif-\nferent expected precisions, which can affect how strongly decision-\nmaking is controlled by habits versus explicit planning. Beliefs about\ndistant future states can also be more or less precise (e.g., more or less\nconﬁdence in predicting the way one ’s life will be in 6 months if\nchoosing one or another course of action now), which can in ﬂuence\nwhether someone focuses more on short-term versus long-term conse-\nquences when making decisions. More generally, because precisionformally refers to the inverse dispersion (i.e., entropy) of a probability\ndistribution, every belief has the attribute of precision. In predictive\ncoding schemes, these probabilistic beliefs are over continuous vari-\nables (e.g., brightness, loudness) and precision corresponds to the\ninverse variance of those (typically Gaussian) distributions. In contrast,because decisions are categorical (i.e., a person can only choose one\ndiscrete option out of several available options), probabilistic beliefs in\nactive inference models are over categorical (discrete) variables. In this\ncase, precision can correspond to what are called ‘inverse temperature ’\nparameters that in ﬂuence the shape of discrete probability distribu-\ntions. For example, the beliefs (probabilities) over policies mentioned\nabove are controlled by an ‘expected precision ’parameter of this type.Physiologically, these types of precisions can be associated with lateral\ninhibition and excitation –inhibition balance, whereas in predictive\ncoding schemes, precision can be associated with postsynaptic gain or\nexcitability.\nAlthough considerable progress has been made in building and\ntesting computational models of simple problems in perception, cogni-\ntion, and action selection, applications of predictive coding and activeinference (as well as other related Bayesian) models to more complex\nclinical phenomena have thus far been limited. In this domain, the\nﬁelds of clinical computational neuroscience and computational psy-\nchiatry are still largely at the stage of building viable conceptual\nmodels –and identifying or simulating associated mathematical\nmodels of complex clinical phenomena. Thorough empirical tests of\nthese models are largely outstanding, although emerging empirical\nwork (discussed below) appears promising.\nIllustrative Examples\nIn what follows, we offer a number of illustrative examples of con-\nceptual and formal mathematical models in computational neurosci-\nence and psychiatry, with the aim of: (i) illustrating potentialempirical applications; and (ii) conveying the methodological\nresources available that can be applied to other cases. We then\ndescribe examples of recent empirical work that has applied suchmodels to clinical questions. These examples should not be seen as\nan exhaustive treatment of extant literature –they just exemplify ways\nin which understanding the brain as a ‘prediction machine ’can be\nused in psychiatry. It should also be noted that we do not address\nother areas of research in computational psychiatry, such as reinforce-ment learning. The primary focus of reinforcement learning is to\naccount for choice behavior in terms of rewards. This area of research\nhas been fruitful, but it has focused less on modeling the prediction-\nbased mesoscale brain processes we consider here (i.e., with some\nnotable exceptions related to dopamine and reward prediction errorsignals, and their interactions with corticostriatal circuits; e.g., see\nFrank,\n8Silvetti et al.,36and Schultz37).\nConceptual models\nThere is a growing body of theoretical work that affords potential clini-\ncal insights and new hypotheses for psychiatric disorders. This work\ntakes the general approach of synthesizing previous empirical ﬁndings\nand proposing ways in which computational concepts could help unifysuch ﬁndings under a single parsimonious theory. We consider these\ncontributions to be ‘conceptual ’because, although they qualitatively\ndescribe ways in which the predictive neurocomputational dynamics\nthat are illustrated in Figure 2 may shed light on clinical phenomena,\nthey do not offer quantitative mathematical models that afford precisesimulations of proposed mechanisms.\nAs one prominent example, depression has been the topic of a\nnumber of computational proposals. One recent model pertains to a\nproposed computational basis for mood.\n38The central idea here is\nthat neural systems not only maintain estimates in the con ﬁdence or\nprecision of their prior beliefs about outcomes, but also estimates of\nconﬁdence in their beliefs about that precision (i.e., the degree to\nwhich the unknowns are known). For example, if an individualexpects uncertain, unpredictable outcomes (low precision beliefs), but\nmakes those predictions con ﬁdently (high con ﬁdence in high uncer-\ntainty), it is proposed that this will result in a chronic, self-\nmaintaining negative emotional state that, in extreme cases, becomes\nresistant to change (as in depressive disorders). Neurobiologically, theset-points of neuromodulatory mechanisms are suggested to encode\nthese –statistically higher-order –conﬁdence estimates, potentially\naccounting for the neuromodulatory abnormalities observed in\ndepression (and the mechanisms of antidepressant drugs in targeting\nneuromodulatory systems\n39,40). In neural process theories (Fig. 2),\nthese neuromodulators would have the effect of dynamically tuning\nthe strengths of synapses that encode various types of precisions\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 6The predictive brain in psychiatry PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "(e.g., the estimated reliability of sensory signals, prior expectations,\nand expected action outcomes).\nThis model represents a nice example of how (sub-personal)\nbeliefs, computations, and mesoscale neuronal processes can be\nunderstood in terms of each other. That is, the precision corresponds\nto the statistical certainty of a probabilistic representation, where this\ncertainty is encoded by the patterns of synaptic ef ﬁcacy or gain (and\nresulting excitability) within a neuronal population (see Parr and\nFriston4and Friston et al .16). The required computation is then to\noptimize this encoding of uncertainty by adjusting synaptic connec-\ntion strengths through neuromodulatory mechanisms (e.g., serotoner-\ngic or dopaminergic neurotransmission). In this setting, ‘optimization ’\nmeans that neuronal dynamics will converge onto an internal estimate\n(a‘best guess ’based on past experience) that minimizes free energy.\nIn the case of psychopathology, early adversity (and perhaps genetic/epigenetic vulnerability factors) could lead an individual to converge\nonto poor or otherwise maladaptive estimates of uncertainty, as\nsuggested by the model described above.\nAnother predictive processing perspective has been offered by\nBarrett and colleagues,41who focus on the role of interoceptive predic-\ntive processing and the ways in which interoceptive predictions may\nbecome dysfunctional and result in a depressive phenotype. They pro-\npose that depression is due to one or more of the following: (i) an inter-\nnal model that is inef ﬁcient at managing energy regulation (e.g., due to\noverly precise expectations for large metabolic demand); (ii) impreciseinteroceptive signals from the body, creating dif ﬁculty in effective\nallostasis (i.e., dif ﬁculty adaptively generating anticipatory changes in\nvisceral states due to expected future demands); and (iii) maladaptive\ninternal estimates of the precision of afferent interoceptive signals\n(e.g., due to neuromodulatory system dysfunction). Each of thesepotential breakdowns would render the brain insensitive to updating its\nbeliefs about the body, and lead to dif ﬁculty keeping the body within\nhomeostatic ranges (i.e., ‘preferred states ’within active inference\nmodels). Under the assumption (put forward by the authors) that pleas-\nant/unpleasant feelings convey interoceptive information about themoment-to-moment energy conditions (i.e., immunological, in ﬂamma-\ntory, and physiological states) of the body, this could produce pervasive\nnegative affect (and sickness behaviors that reduce energy expenditureand promote fatigue), and lead to several motivational and neuro-\nvegetative symptoms of depression. In previous work, these authors\nhave also proposed an explicit mesoscale scheme in which cortical col-\numns within agranular cortical regions within the insula and anterior\ncingulate convey interoceptive prediction signals, while granular corti-cal regions (e.g., posterior insula) generate interoceptive prediction\nerror signals that update beliefs about the energy conditions of the\nbody\n42–offering additional predictions that could be tested empirically\nin future neuroimaging work.\nA further conceptual model of depression has been proposed by\nBadcock and colleagues43that highlights how computational processes\ncan interact with the various psychosocial processes that are implicated\nin depression (for another computational model of biopsychosocial pro-\ncesses, see Smith et al.44). Badcock et al. propose an evolutionary sys-\ntems theory of depressive mood states, which combines active inferencewith insights –drawn from psychology, psychiatry, and neuroscience –\non the role of social contexts in depressive phenomena. Under this\nmodel, normative levels of depressed mood can re ﬂect an adaptive,\nrisk-averse strategy that reduces uncertainty in interpersonal contexts\nwhen sensory cues evince an increased likelihood of unexpected or neg-\native social outcomes (e.g., rejection or loss). The depressive response\nthus functions as a ‘better safe than sorry ’strategy that minimizes inter-\npersonal interactions with unpredictable or non-preferred expected out-comes. It achieves this function by inducing changes in perception\n(e.g., a heightened sensitivity to social information), suppressing con ﬁ-\ndent reward-approach behaviors (e.g., anhedonia), and generating sig-\nnaling behaviors that either garner support (e.g., reassurance seeking) or\ndefuse con ﬂict (e.g., submissive behaviors). The authors suggest that,\nneurobiologically, depressed mood states are characterized by an\nincrease in the precision of (bottom-up) social prediction errors(i.e., prediction errors conveyed to neurons encoding social informa-\ntion), which facilitates perceptual inference and learning about thesocial world by increasing the in ﬂuence of ascending prediction errors\non belief updating. This idea is consistent with the active inference liter-\nature on emotion, which suggests that negatively valenced states\nincrease learning rate (see Jof ﬁly and Coricelli\n45). In depression, these\nampli ﬁed prediction errors are postulated to be selective to interpreta-\ntions of social stimuli, which most plausibly occur at higher levels in a\nhierarchical model (e.g., dorsomedial prefrontal cortices46–50). This\nincrease in precision ampli ﬁes an individual ’s sensitivity or attention to\ninterpersonal cues, while suppressing con ﬁdence in (top-down) social\npredictions (and thus con ﬁdence in associated social behaviors). Symp-\ntomatically, the authors suggest that this would produce a suspension of\ngoal-directed behavior (e.g., anhedonia and social withdrawal), rumina-\ntion about negative self –other relations, and an attentional bias toward\n(aversive) interpersonal cues during social inference. Here, it is espe-\ncially important to stress the role of attention. In this instance, attention\ncan be construed as affording precision to neuronal signals conveying\nvarious Bayesian beliefs or prediction errors,51–56such that they have\ngreater in ﬂuence on belief updating than other levels of the cortical\nhierarchy. This ﬁts comfortably with the role of neuromodulators in\nmediating attentional gain at the synaptic level.4\nIn most circumstances, the suggestion is that the depressive\nresponse functions adaptively by attracting interpersonal support and\nreducing social uncertainty through both risk-averse interpersonalbehaviors and faster belief updating in the presence of unexpected\noutcomes. However, psychopathology can emerge when there are\nongoing discrepancies between actual and preferred social outcomes\nover time (i.e., chronic prediction errors). Given the increased\nprecision-weighting assigned to social prediction errors, such chronicsocial stress can in turn engender precise higher-order expectations\nthat social rewards are unlikely (e.g., pessimism, low self-worth),\nwhich perpetuate risk-averse depressive behaviors (e.g., social with-\ndrawal) and ultimately lead to disorder (e.g., learned helplessness;\nalso see Chekroud\n57and Kube et al.58). As we discuss below, these\ndepressive beliefs can become increasingly entrenched and self-\nmaintaining, producing overly precise prior expectations about aver-\nsive (social) outcomes that are resistant to change. In other words,depressive disorders can be described as a maladaptive pattern of dys-\nregulated defenses: when depressive changes fail to resolve social\nstress, the individual is at risk of entering a self-perpetuating, dys-\nregulated state, leading to chronic illness behaviors that fail to\nrespond to any improvements in the social domain. Vulnerability topsychopathology is facilitated by early exposure to social stress\n(e.g., parental abuse or neglect), which promotes prior beliefs that\nsocial outcomes are uncontrollable and heightens the sensitivity of\nstress response systems to interpersonal stressors (e.g., in ﬂammatory\nimmune responses; see Slavich and Irwin\n59). Notably, the model\ndescribed here also lends itself to empirical scrutiny. For example, a\nsimple way to test this hypothesis would be to use neuroimaging or\nelectrophysiological methods that capture prediction error suppression\n(e.g., trial-by-trial ﬂuctuations in P300 amplitudes) in depressed ver-\nsus nondepressed participants when presented with unpredictablesocial stimuli. The model also has implications for prevention and\nintervention efforts by underscoring the importance of strategies that\naim to improve social environments or resolve interpersonal stress(e.g., interpersonal psychotherapy).\nNote that these are simply illustrative examples of recent con-\nceptual models. As we touched upon above, other authors have pro-\nposed that depression is maintained by overly precise prior\nexpectations for depressive schemas, such as strong expectations ofone ’s own worthlessness or that the world is uncontrollable.\n60The\nsuggestion here is that these prior expectations bias attention to\nschema-consistent information and also bias the interpretation of\nsensory input in a schema-consistent manner. This can then drive\nchronic stress, heightened in ﬂammation, and avoidance behaviors,\neach of which furnish future observations that selectively support\nand maintain depressive schemas in a vicious positive feedback loop\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 7PCNPsychiatry and\nClinical Neurosciences The predictive brain in psychiatry\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "(also see Kube et al.58). Further examples include recent conceptual\nmodels of autism61–63and schizophrenia.64,65In autism it is\nsuggested that, from childhood, low-level sensory prediction errors\nare overweighted generally, leading to (i) repetitive behaviors that\nreduce low-l evel prediction error; and (ii) a r educed ability to learn\nabstract and complex regularities in higher l evels of a hierarchical\nmodel (i.e., because all prediction errors are inappropriatelysuppressed before reaching these higher l evels). As social regulari-\nties are among the most complex to learn, social cognition thus\nremains poorly d eveloped. Interestingly, accounts of schizophrenia\nsuggest that a similar phenomenon occurs, in which low-l evel pre-\ndiction errors in some modalities are overweighted, but with adultonset.\n65This then leads the brain to treat random aspects of sensory\nobservations as ‘suspicious coincidences ’in need of explanation,\ndriving the development of overly complex models of the worldwith stranger and stranger (delusional) beliefs over time. For exam-\nple, when proprioceptive prediction errors (that carry information\nabout bodily movement) are overwei ghted, this can lead to delusions\nabout agency (e.g., that unexplained proprioceptive prediction errors\nindicate that one ’s body is being controlled by others). In contrast, it\nappears that auditory prediction errors are underweighted in psycho-\nsis, creating increased vulnerability to auditory illusions.64Although\nfurther conceptual models have been proposed for other clinical\nphenomena, the proposals on depression covered in detail here are\nrepresentative of the general explanatory strategies used in othercases.\nFormal models\nMoving beyond conceptual proposals, a few formal (i.e., quantitative\nmathematical) predictive processing models have also been presented\nfor a range of clinical phenomena; unlike conceptual models, these\nformal models afford explicit simulations of proposed neuro-computational mechanisms. In the case of depression, for example,\nStephan et al.\n66presented a mathematical model to capture homeo-\nstatic and allostatic regulation of visceral states and how meta-\ncognitive estimates of the ef ﬁcacy of allostasis could promote a\ndepression-like state of fatigue. In their proposal, homeostatic setpoints are modeled as ﬁxed probability distributions specifying\npredicted ranges (means and variances) of a given physiological vari-\nable (e.g., blood glucose levels, blood osmolality levels, and circulat-\ning hormone or in ﬂammatory cytokine levels); deviations from\nhomeostatic ranges lead to the generation of prediction errors (withrespect to those set points), which can then be minimized through\nclosed-loop control processes in an interoceptive re ﬂex arc (i.e., this\nis analogous to minimizing ‘preference prediction errors ’in active\ninference models where homeostatic set points represent preferred\nstates). Allostasis involves forecasting future deviations from homeo-stasis and adjusting physiological variables in advance to prevent\nthese deviations. In their model, the prior expectations for homeo-\nstatic ranges can be dynamically adjusted by higher-level predictions.\nFor example, if a cue indicated that blood glucose levels were about\nto drop, the predicted mean of the distribution could be temporarilyshifted upward, so that blood glucose levels would elevate before the\nanticipated drop, allowing them to always remain within acceptable\nvalues. Alternatively, if a cue indicated that blood glucose levels wereabout to change in an unexpected direction, the predicted precision of\nthe distribution could be tightened, endowing prediction errors with a\ngreater in ﬂuence on belief updating, and a faster return to homeostatic\nranges. They then discuss how, if attempts at allostasis repeatedly fail,\nsustained dyshomeostasis could lead to higher-level inferences favor-ing states of subjective fatigue associated with depression. Speci ﬁ-\ncally, they suggest that such states of depressive fatigue, and\nassociated sickness behaviors, could emerge as strategies for dealing\nwith conditions in which the brain continuously predicts that allostatic\nregulation will be ineffective. (To be clear, we use blood glucoselevels here only as an example physiological variable for illustration.\nThe authors focus on dyshomeostasis generally, consistent with theconceptual proposals regarding metabolic regulation in depression\nreviewed above.)\nCrucially, the quantitative prediction and prediction-error dynam-\nics that can be simulated using this model speak to the possibility of\ntesting which regions of the brain show patterns of activity consistent\nwith those simulated dynamics, and whether this differs in healthy\nversus depressed individuals. The authors hypothesize that a numberof subcortical and cortical regions (e.g., brainstem, amygdala, insula,\nanterior cingulate) may implement different levels of homeostatic and\nallostatic control, and that dorsal prefrontal regions may be involved\nin estimating allostatic ef ﬁcacy. Testing these predictions will be an\nimportant direction for future empirical work.\nAs an additional, more in-depth, example of recent formal\nmodeling, another series of papers has presented a formal active infer-\nence model of emotional state inference and emotional awareness(depicted in Fig. 3), and has used this model to simulate clinical phe-\nnomena arising from poor early learning and biased attentional mech-\nanisms\n21,25(for a related computational model of pleasant/unpleasant\naffective valence, see Hesp et al.22). This modeling effort aimed to\nexplain the common clinical observation that some individuals appearto have low awareness of their own emotions and can misinfer that\nemotion-related sensations are signs of medical illness.26,67,68It is\nalso inspired by the observation that psychotherapeutic interventions\nthat aim to improve emotional awareness have shown ef ﬁcacy.69,70To\nsimulate these phenomena, the model included examples of distinctinternal states that could be inferred, including emotional state cate-\ngories (sadness, panic) and somatic state categories (sickness, heart\nattack). The simulated decision-making ‘agent ’began with prior\nexpectations about its own internal state, and these expectations were\nthen updated (i.e., a new internal state was inferred) based on exam-ples of relevant lower-level beliefs about current experience, includ-\ning: valence (in this case, neutral/negative), arousal (high/low),\nmotivation (approach/avoid), and an interpretation of the current situ-\nation (neutral, socially threatening, or physically threatening; e.g., as\nin cases where one is ignored at a party, in a crowded space, or feel-ing chest pain). To allow for biases in attention, the agent could not\naccess all of this lower-level information at the same time. It instead\nhad to selectively attend to one or more of these pieces of informationsequentially (e.g., choose to attend to valence, then arousal, etc.) until\nit became con ﬁdent in its internal state. At this point it would choose\nto self-report its internal state beliefs (e.g., whether it was experienc-\ning sadness, panic, sickness, or a heart attack, or if it simply felt neu-\ntral, bad, or good). After making a report, the agent also received‘social feedback ’that was either positive (if its report was ‘correct ’;\ne.g., matched cultural expectation) or negative (if it was ‘incorrect ’).\nPositive social feedback was preferred. Thus, on each ‘trial, ’the agent\nwas presented with a newly generated ‘affective response ’(i.e., a pat-\ntern of valence, arousal, and motivation in a perceived context), andchose what to attend to and report in hopes of receiving the preferred\npositive feedback (i.e., to minimize preference prediction error). Each\naffective response pattern presented to the agent was generated by a\n‘true model, ’which held the different (probabilistic) patterns of\nlower-level information most consistent with each possible emotional/somatic state (e.g., ‘sadness ’best matched a pattern of negative\nvalence, low arousal, and avoidance motivation in the context of\nsocial threat [such as being socially rejected]).\nAside from this inference process, a variant of the model also\nimplemented emotion concept learning. Speci ﬁcally, the simulated\nagent could learn emotion categories (e.g., sadness, fear, anger, and\nhappiness) that predicted different patterns in experience through the\nsocial feedback mentioned above (e.g., as in early development, whencaregivers mirror and label a child ’s reactions with emotion terms\n71–73).\nMathematically, this learning process (i.e., a type of concept acquisi-\ntion) was implemented through learning probability distributions via a\ncoincidence-detection mechanism resembling Hebbian synaptic plastic-\nity.15,19,74This learning mechanism estimates how often different inter-\nnally represented states (e.g., sadness) are expected to generate\nparticular thoughts, feelings, and sensations (e.g., unpleasant feelings,\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 8The predictive brain in psychiatry PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "high arousal sensations, and avoidance drives while perceiving a preda-\ntor). The formal basis of this learning mechanism can be intuitively\nthought of as simply counting coincidences between states and observa-tions –that is, increasing the expected probability (i.e., synaptic con-\nnection strength) of a particular observation, given a particular state,\neach time one makes that observation when (they believe) they are in\nthat state –similar to long-term potentiation- and long-term depression-\nbased synaptic learning mechanisms widely studied in cellular/molecu-lar neuroscience.\n15,19\nThese simulations are based on the ‘three-process model ’of emo-\ntional awareness,26–32and supporting evidence,68,75 –83which empha-\nsizes that the mechanisms that generate affective responses can beseparated from the processes that infer the meaning of those responses.\nIt is also based on elements of ‘constructivist ’theories that stress the\nculture- and context-speci ﬁc nature of emotion-conceptualization pro-\ncesses.33Based on the evidence supporting these perspectives, the\nbroad theoretical assumptions of the simulations are that individuals\ngenerate multimodal affective responses in a ﬂexible (i.e., domain-gen-\neral) and context-sensitive manner, based on the predicted metabolic,\ncognitive, and behavioral demands of a perceived (or remembered/imagined) situation. These predicted demands are in turn based on a\nfast, largely unconscious evaluation of that situation (e.g., concerning\nwhether it is safe/threatening, goal-congruent/incongruent, consistent/inconsistent with norms/values, among other dimensions) and available\nDomain-general cognition\n(higher-level)\nEmotionally\nneutralPanic SickHeart\nattackNeutral\nSad\nPanic\nSick\nHeart attack\nTime 1 Time 2 Time 3SadINTERNAL STATE CONCEPTS\nNeutral High ApproachNeutral\nContextPhysical\nThreat\nValence Arousal Motivation\nLower-level representations\nBody Affective (interoceptive/behavioral) responseBeliefs\nabout contextNegative Low AvoidSocial\nThreatSimulated neural firing rates and local field potentials\nFig.3 Depiction of a formal (generative) model of emotional state inference, adapted from Smith et al.21, 25; also see Hesp et al.22On the left, a network of abstract\nneuron-like nodes (and select connections) is depicted, where the higher level represents different possible concept-level inferences about one ’s own internal state,\nincluding emotional and somatic interpretations. These representations send downward prediction signals, conveying the patterns of lower-level representations\nexpected under each higher-level representation. Prediction errors are conveyed upward, such that the higher level converges onto the representat ion that makes the\nmost accurate predictions (i.e., minimizes prediction error). The lower level in turn generates the affective (interoceptive/behavioral) respon ses themselves\n(e.g., generating elevated heart rate and avoidance behavior when inferring threat; shown in gray). Here it is assumed that the brain has previously g enerated a ( ﬂexible,\ncontext-speci ﬁc) affective response of this kind, based on the predicted metabolic, cognitive, and behavioral demands of a situation. This occurs upon perceiving a nd\ninterpreting that situation (i.e., based on a fast, largely unconscious, domain-general evaluation of a situation as being, for example, safe, thre atening, goal-incongruent,\nor inconsistent with norms/values; only interpretations of the situation as neutral, socially threatening, or physically threatening are explici tly depicted here). The brain ’s\njob is then to perceive how body states have changed based on this generated response, and to make sense of it in terms of various (self-report guiding) c oncept rep-\nresentations it has learned (i.e., this is based on the three-process model of emotional awareness,26–32as well as constructivist theories stressing the culture- and\ncontext-speci ﬁc, domain-general nature of emotion conceptualization33). To do so, the simulated decision-making ‘agent ’must ﬁrst choose selective attention policies\n(i.e., selectively attend to valence, arousal level, the surrounding context, etc.) and then choose self-report policies communicating which emot ion is being felt, based\non what it has attended to and observed (with the preference of receiving con ﬁrmatory social feedback, which also allows simulation of learning emotion concepts dur-\ning development25). In this example, activated lower-level representations are shown in red, leading to the inference of sadness at the higher level (also red) and the\nself-report that ‘I feel sad ’(not shown). This occurs gradually as the individual selectively attends to each lower-level modality (not shown) and accumulates evidence\nfor the sadness interpretation. After arriving at this interpretation, it can also be held in working memory and re ﬂected upon (i.e., gestured at with the ‘Domain-general\ncognition ’box in the top left; see Smith et al .21for explicit simulations). The top right corresponds to simulated neuronal ﬁring rates (darker = higher ﬁring rate;\ni.e., higher represented probability) and simulated local ﬁeld potentials (rates of change in ﬁring rates) for this model, based on the neural process theory proposed\nwithin the active inference framework,16which is depicted in Figure 2f. Here, the network starts with equally strong predictions across all possible interpretations, and\nslowly converges onto the belief that sadness is the best- ﬁt interpretation when successively integrating lower-level representations (via selective attention processes\nnot depicted here). By simulating different starting predictions and connection strengths, precise simulations of pathological emotional state i nference and learning can\nbe carried out and can be used to make empirical predictions.\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 9PCNPsychiatry and\nClinical Neurosciences The predictive brain in psychiatry\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "actions. Generated responses include the types of changes in motiva-\ntion, physiological arousal levels, and felt valence mentioned above.Once these bodily sensations and drives have been generated and per-\nceived, an individual must infer their meaning. Crucially, because map-\npings between emotion concepts and response patterns are both learned\n(within a culture and with context-speci ﬁcity) and probabilistic\n(e.g., sadness may typically be low-arousal but could be high-arousal),recognizing emotions can be a dif ﬁcult inference problem that can\nsometimes lead to poor understanding and awareness of one ’so w n\nemotions and their causes.\nNote that we have therefore moved from Bayesian beliefs to a\ncomputational description of feelings and emotions; namely, Bayesianbeliefs that provide the best explanation for both exteroceptive and\ninteroceptive signals. For example, a belief such as ‘I am anxious ’\nprovides the most parsimonious account of perceived threat and auto-nomic arousal that is itself in ﬂuenced (in part) by the predictions\nensuing from an expectation that one will feel anxious. This may\nsound rather abstract; however, this kind of belief updating is now\npossible to simulate in a neurobiologically plausible way and can, in\nprinciple, be used to produce symptoms of emotional pathology in sil-\nico. For example, the top right portion of Figure 3 depicts simulated\nneuronal ﬁring rates and local ﬁeld potentials during this emotional\nstate inference process, based on the neural process theory depicted\nin Figure 2f. Empirically, one can then take these mesoscale simula-\ntions and use neuroimaging (or other neuroscience methods) to iden-tify which brain regions most plausibly implement those mesoscale\ncomputations (e.g., by ﬁnding brain regions that show the predicted\npatterns of activity in simulations).\nSimulations in this model illustrated at least seven different\nmechanisms that could promote low emotional awareness. Becauseemotional awareness (i.e., the ability to recognize and understand\none ’s own emotions) plays a key role in many psychiatric\ndisorders,\n26,67and may act as either a vulnerability or maintenance\nfactor, understanding such mechanisms could represent an important\nstep in being able to identify which mechanisms are operative in dif-ferent individuals and how they might be targeted on an individual\nbasis within therapy. For instance, one mechanism involved having\noverly precise prior expectations for somatic threats, which led thesimulated agent to somatize (i.e., mistake sadness-related sensations\nas signs of sickness or mistake panic-related sensations as signs of a\nheart attack; e.g., as in high anxiety sensitivity\n84). In another example,\nif the agent ’s emotion concepts made highly imprecise predictions\n(e.g., as in poor emotion-concept acquisition due to social neglect inchildhood85,86), it remained uncon ﬁdent and only reported feeling\ngood or bad (i.e., it was unable to differentiate different types of\nunpleasant emotions; for clinical relevance, see Barrett et al .87and\nKashdan et al.88).\nA third mechanism involved selective attention biases, which led\nthe agent to selectively ignore either bodily signals or contextual cues\n(i.e., where such attention biases could have been reinforced in child-\nhood and prevented emotion concept learning; e.g., hypervigilant\nexternal attention, due to consistently high levels of threat or environ-\nmental unpredictability89,90). Importantly, these mechanisms produced\nsimilar behavioral phenotypes (i.e., self-report patterns), but might be\nbest targeted by different psychotherapeutic interventions. For exam-\nple, if low emotional awareness is due to an individual ’s emotion-\nconcept representations generating imprecise predictions, this would\nsuggest the need for psychoeducation interventions to help an individ-\nual mindfully attend to emotion and develop more precise emotion-\nconcept knowledge (e.g., mindfulness-based or emotion-focused\ntherapies91–93). In contrast, if an individual instead has overly precise\nprior expectations for somatic threats, interventions that focus on\nattenuating those strong expectations (e.g., exposure, cognitive\nrestructuring94) may be more appropriate. Finally, the model also\naffords quantitative simulations of, and makes distinct predictions\nabout, the neural responses and reaction time differences that wouldbe observed if different mechanisms were involved. For example,\nfaster reaction times ( ‘jumping to conclusions ’) are predicted withoverly precise prior expectations (e.g., for somatic threats). As another\nexample, weaker neural responses to affective stimuli are predicted inindividuals with less precise emotion-concept representations due to\nweaker changes in beliefs about emotional states upon the generation\nof a new affective response. Thus, these types of mathematical simu-\nlations afford important predictions to be tested in future experimental\nwork that could identify which brain regions implement the meso-scale neurocomputational processes captured in these simulations.\nWe stress here again that these are simply illustrative examples\nof relevant simulation work in this area and are not meant to be\nexhaustive. For example, other recent work in active inference has\nmathematically simulated the factors that in ﬂuence patients ’decisions\nto adhere to antidepressant medications\n95and the neurocomputational\nmechanisms of change during cognitive and behavioral therapies.96\nYet other studies have simulated predictive processing dynamics in\nneural network and robot models and have reproduced patterns of\nperception and behavior reminiscent of both schizophrenia97and\nautism.98,99However, the detailed examples above –which have\nselectively focused on depression and emotion –should offer the\nreader a foundational sense of current directions in this ﬁeld.\nEmpirical studies\nRecent neuroimaging studies have begun to support the hypothesis\nthat the brain engages in predictive processing, both in perceptionand decision-making. As might be intuited by the foregoing theoreti-\ncal review, many of these studies rest upon the relation between aber-\nrant precision-weighting and the consequent neuromodulation of\nbrain responses and connectivity (see references in Friston100). These\nstudies have been largely conducted with healthy participants. Forexample, a few studies have required participants to perform probabi-\nlistic perception and inference tasks, ﬁt computational models to task\nbehavior,101and then generated simulated sequences of precision-\nweighted prediction errors.102,103Using neuroimaging, these studies\nhave found patterns of brain activation that closely match the simu-\nlated pattern of prediction errors. The observed patterns of brain acti-\nvation support the roles of dopamine (midbrain activity) and\nacetylcholine (septum and basal forebrain) in encoding and precision-weighting distinct types of prediction errors associated with sensory\npredictions and uncertainty estimates, respectively. Another study14\nhas also ﬁt decision behavior to an active inference model and found\nevidence that activity within brain regions implicated in either send-\ning or receiving dopaminergic signals closely tracks the difference inexpected free energy before and after a new observation. This differ-\nence updates con ﬁdence estimates in the ability to select optimal\nactions (i.e., the expected certainty in achieving preferred outcomes),\nencoded by an ‘inverse temperature parameter ’reﬂecting the expected\nprecision of beliefs about the expected free energy of policies(i.e., possible sequences of actions). This parameter subsequently\ninﬂuences how goal-directed an individual ’s actions are; imprecise\nbeliefs about policies (i.e., low expected precision) will give way to\nmore random or habit-driven behavior. Note, however, that this type\nof (policy-related) precision is distinct from the types of precision dis-cussed above in predictive coding, which instead correspond to\nbeliefs about the reliability (inverse variance) of prior expectations\nand sensory prediction errors –and modulate how strongly beliefs are\nupdated by sensory prediction errors (i.e., based on those beliefs\nabout their reliability).\nThere are also some very recent predictive processing-based\nbehavioral and neuroimaging studies in psychiatric populations,\n104,105\nwhich have provided evidence, for example, of heightened prior beliefs\nthat the environment is unpredictable in schizophrenia patients and in\nthose with high risk for psychosis (associated with activation patterns\nwithin prefrontal and insula regions). While such neuroimaging studies\nare quite limited, purely behavioral studies have also found support for\ncomputational differences in patient populations. For example, onestudy asked individuals with and without auditory hallucinations to\nindicate when they heard a tone each time a light was presented, while\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 10The predictive brain in psychiatry PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "(unbeknownst to participants) the probability of the tone being pres-\nented changed over time.106Computational modeling revealed that\nindividuals with hallucinations overestimated the precision of auditory\npredictions, leading them to report false auditory percepts more often\nthan non-hallucinators (for related work linking aberrant prior expecta-\ntions and precision in psychosis, see Corlett et al .64and Adams\net al.107). Interestingly, studies combining pupillometry and probabilis-\ntic learning tasks have shown a distinct pattern in autism, where simi-\nlar modeling methods suggest that the precision of sensory predictions\nis underweighted.61,62,108\nLastly, a few recent studies have ﬁt active inference models to\ndata in transdiagnostic patient populations from tasks involvingexploratory decision-making, approach-avoidance con ﬂict, and inter-\noceptive awareness. One study found lower learning rates for losses\nversus wins and lower precision in action selection within individualswith substance-use disorders relative to healthy controls,\n109\nsuggesting a pattern in which actions that lead to negative outcomesfail to in ﬂuence future decisions –which could help explain contin-\nued substance use despite negative life consequences. A second\nstudy found that, during approach-avoidance con ﬂict, individuals\nwith depression, anxiety, and/or substance-use disorders each showed\nevidence of lower expected policy precision (greater uncertainty in\ndecision-making; associated with the γterm in Fig. 2f) in compari-\nson to healthy controls.110However, the clinical populations did not\nshow heightened aversion to negative stimuli, suggesting that deci-sion uncertainty may represent a more promising target for interven-\ntion/treatment. Finally, an active inference model of an interoceptive\nawareness task recently found evidence that individuals with depres-\nsion, anxiety, substance use, and/or eating disorders had lower intero-\nceptive sensory precision than healthy controls, but no difference inprior expectations.\n111This ﬁnding was speci ﬁc to an interoception-\nenhancing breath-hold manipulation, suggesting a transdiagnostic\ninability to update sensory precision estimates when there are\nchanges in afferent signals from the body. This might help to explain\nvisceral dysregulation and poor emotional awareness in these clinicalpopulations. A subsequent study in a new sample also recently repli-\ncated the ﬁnding that interoceptive precision estimates increase dur-\ning a breath-hold manipulation in healthy participants.112Such\nﬁndings are promising, but the observed effect in psychiatric patients\nwill still need to be replicated and extended in future work before\nbeing afforded high con ﬁdence.\nConclusion\nWe have reviewed illustrative examples of how modeling the brain\nas a prediction machine has begun to yield potential clinical\ninsights. Initially, this involves proposing conceptual models of how\na computational framework may offer explanatory power. Subse-quently, formal computational models can be written down,\naffording quantitative simulations and precise predictions. Finally,\nthose models can be translated into behavioral tasks that can be car-\nried out during neuroimaging. Models can then be ﬁt to behavior,\nallowing both: (i) identi ﬁcation of the neural correlates of model\nparameters; and (ii) identi ﬁcation of differences in model parameters\n(and associated neural responses) between individuals, which could\noffer either diagnostic or prognostic information and inform treat-ment selection –sometimes called computational phenotyping. This\ntherefore allows us to move from mesoscale neurocomputational\nprocesses that are very dif ﬁcult to study directly (e.g., through\nsingle-neuron recordings) all the way through to phenotyping indi-\nviduals within clinical populations with heterogeneous underlyingmechanisms. Further advances in the application of formal models\nof the predictive brain will require close collaboration between clini-\ncians, patients, and computational researchers to generate and for-\nmalize models of distinct clinical phenomena, and to design\ninformative behavioral tasks that, once validated, patients could per-form in the clinic to help mental health professionals better under-\nstand and treat their patients.Acknowledgments\nR.S. is funded by the William K. Warren Foundation. There is no\nother funding to report.\nDisclosure statement\nThe authors declare no con ﬂict of interest.\nAuthor contributions\nR.S. conceptualized and wrote the ﬁrst draft of the manuscript and\ncreated the ﬁgures. P.B. aided in generating ﬁgures and wrote/edited\nsections of the manuscript. K.J.F. contributed to conceptualization\nand also wrote/edited sections of the manuscript.\nReferences\n1. Park HJ, Friston K. Structural and functional brain networks: From con-\nnections to cognition. Science 2013; 342: 1238411.\n2. Friston K, Parr T, de Vries B. The graphical brain: Belief propagation\nand active inference. Network Neuroscience 2017; 1: 381 –414.\n3. Knill DC, Pouget A. The Bayesian brain: The role of uncertainty in\nneural coding and computation. Trends Neurosci. 2004; 27: 712 –719.\n4. Parr T, Friston K. The anatomy of inference: Generative models and\nbrain structure. Front. Comput. Neurosci. 2018; 12: 90.\n5. Marr D. Vision . MIT Press, Cambridge, MA, 1982.\n6. Bastos A, Usrey W, Adams R, Mangun G, Fries P, Friston K. Canoni-\ncal microcircuits for predictive coding. Neuron 2012; 76: 695 –711.\n7. Friston K. A theory of cortical responses. Philos. Trans. R. Soc. Lond.\nB Biol. Sci. 2005; 360: 815 –836.\n8. Frank M. Computational models of motivated action selection in cor-\nticostriatal circuits. Curr. Opin. Neurobiol. 2011; 21: 381 –386.\n9. Friston K, Stephan K, Montague R, Dolan R. Computational psychia-\ntry: The brain as a phantastic organ. Lancet Psychiatry 2014; 1:\n148 –158.\n10. Huys Q, Maia T, Frank M. Computational psychiatry as a bridge from\nneuroscience to clinical applications. Nat. Neurosci. 2016; 19: 404 –413.\n11. Montague P, Dolan R, Friston K, Dayan P. Computational psychiatry.\nTrends Cogn. Sci. 2012; 16:7 2 –80.\n12. Kiebel S, Daunizeau J, Friston K. A hierarchy of time-scales and the\nbrain. PLoS Comput. Biol. 2008; 4: e1000209.\n13. Bogacz R. A tutorial on the free-energy framework for modelling per-\nception and learning. J. Math. Psychol. 2017; 76: 198 –211.\n14. Schwartenbeck P, FitzGerald T, Mathys C, Dolan R, Friston K. The\ndopaminergic midbrain encodes the expected certainty about desired\noutcomes. Cereb. Cortex 2015; 25: 3434 –3445.\n15. Brown TH, Zhao Y, Leung V. Hebbian plasticity. In:Squire LR (ed.).\nEncyclopedia of Neuroscience . Academic Press, Cambridge, MA, 2009;\n1049 –1056.\n16. Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active\ninference: A process theory. Neural Comput. 2017; 29:1–49.\n17. Da Costa L, Parr T, Sajid N, Veselic S, Neacsu V, Friston K. Active\ninference on discrete state-spaces: A synthesis. arXiv . 20 January 2020.\nhttps://arxiv.org/abs/2001.07203v2\n18. Friston K. The free-energy principle: A uni ﬁed brain theory? Nat. Rev.\nNeurosci. 2010; 11: 127 –138.\n19. Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, O Doherty J,\nPezzulo G. Active inference and learning. Neurosci. Biobehav. Rev.\n2016; 68: 862 –879.\n20. Kaplan R, Friston KJ. Planning and navigation as active inference. Biol.\nCybern. 2018; 112: 323 –343.\n21. Smith R, Lane RD, Parr T, Friston KJ. Neurocomputational mecha-\nnisms underlying emotional awareness: Insights afforded by deep activeinference and their potential clinical relevance. Neurosci. Biobehav. Rev.\n2019; 107: 473 –491.\n22. Hesp C, Smith R, Allen M, Friston K, Ramstead M. Deeply felt affect:\nThe emergence of valence in deep active inference. Neural Comput.\n2020. https://doi.org/10.31234/osf.io/62pfd\n23. Whyte C, Smith R. The predictive global neuronal workspace: A formal\nactive inference model of visual consciousness. bioRxiv . 2020. https://\ndoi.org/10.1101/2020.02.11.944611\n24. Schwartenbeck P, Friston K. Computational phenotyping in psychiatry:\nA worked example. eNeuro 2016; 3: ENEURO.0049-16.2016.\n25. Smith R, Parr T, Friston KJ. Simulating emotions: An active inference\nmodel of emotional state inference and emotion concept learning. Front.\nPsychol. 2019; 10: 2844.\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 11PCNPsychiatry and\nClinical Neurosciences The predictive brain in psychiatry\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "26. Smith R, WDS K, Lane RD. The structure of emotional experience and\nits relation to trait emotional awareness: A theoretical review. Emotion\n2018; 18: 670 –692.\n27. Panksepp J, Lane RD, Solms M, Smith R. Reconciling cognitive and\naffective neuroscience perspectives on the brain basis of emotionalexperience. Neurosci. Biobehav. Rev. 2017; 76(Pt B): 187 –215.\n28. Smith R. The three-process model of implicit and explicit emotion. In:\nLane R, Nadel L (eds). Neuroscience of Enduring Change: Implications\nfor Psychotherapy . Oxford University Press, New York, NY, 2020.\n29. Smith R, Alkozei A, WDS K. How do emotions work? Front. Young\nMinds. 2017. https://doi.org/10.3389/frym.2017.00069\n30. Smith R, WDS K, Alkozei A, Lane RD. A neuro-cognitive process\nmodel of emotional intelligence. Biol. Psychol. 2018; 139: 131 –151.\n31. Smith R, Lane RD. Unconscious emotion: A cognitive neuroscienti ﬁc\nperspective. Neurosci. Biobehav. Rev. 2016; 69: 216 –238.\n32. Smith R, Lane RD. The neural basis of one ’s own conscious and uncon-\nscious emotional states. Neurosci. Biobehav. Rev. 2015; 57:1–29.\n33. Barrett L. How Emotions Are Made: The Secret Life of the Brain . Pan\nMacmillan, London, 2017.\n34. Badcock PB, Friston KJ, Ramstead MJD. The hierarchically mechanis-\ntic mind: A free-energy formulation of the human psyche. Phys. Life\nRev. 2019; 31: 104 –121.\n35. Badcock PB, Friston KJ, Ramstead MJD, Ploeger A, Hohwy J. The\nhierarchically mechanistic mind: An evolutionary systems theory of thehuman brain, cognition, and behavior. Cogn. Affect. Behav. Neurosci.\n2019; 19: 1319 –1351.\n36. Silvetti M, Alexander W, Verguts T, Brown J. From con ﬂict manage-\nment to reward-based decision making: Actors and critics in primatemedial frontal cortex. Neurosci. Biobehav. Rev. 2014; 46:4 4 –57.\n37. Schultz W. Dopamine reward prediction error coding. Dialogues Clin.\nNeurosci. 2016; 18:2 3 –32.\n38. Clark J, Watson S, Friston K. What is mood? A computational perspec-\ntive. Psychol. Med. 2018; 48: 2277 –2284.\n39. Cowen P, Browning M. What has serotonin to do with depression?\nWorld Psychiat. 2015; 14: 158 –160.\n40. Hieronymus F, Nilsson S, Eriksson E. A mega-analysis of ﬁxed-dose\ntrials reveals dose-dependency and a rapid onset of action for the anti-depressant effect of three selective serotonin reuptake inhibitors. Transl.\nPsychiatry 2016; 6: e834.\n41. Barrett LF, Quigley KS, Hamilton P. An active inference theory of\nallostasis and interoception in depression. Philos. Trans. R. Soc. Lond.\nB Biol. Sci. 2016; 371: 20160011.\n42. Barrett L, Simmons W. Interoceptive predictions in the brain. Nat. Rev.\nNeurosci. 2015; 16: 419 –429.\n43. Badcock PB, Davey CG, Whittle S, Allen NB, Friston KJ. The\ndepressed brain: An evolutionary systems theory. Trends Cogn. Sci.\n2017; 21: 182 –194.\n44. Smith R, Weihs KL, Alkozei A, Killgore WD, Lane RD. An embodied\nneurocomputational framework for organically integrating biopsycho-social processes: An application to the role of social support in health\nand disease. Psychosom. Med. 2019; 81: 125 –145.\n45. Jof ﬁly M, Coricelli G. Emotional valence and the free-energy principle.\nPLoS Comput. Biol. 2013; 9: e1003094.\n46. Adolphs R. The social brain: Neural basis of social knowledge. Annu.\nRev. Psychol. 2009; 60: 693 –716.\n47. Amodio DM, Frith CD. Meeting of minds: The medial frontal cortex\nand social cognition. Nat. Rev. Neurosci. 2006; 7: 268 –277.\n48. Meyer M, Lieberman M. Social working memory: Neurocognitive net-\nworks and directions for future research. Front. Psychol. 2012; 3:1–11.\n49. Meyer M, Spunt R, Berkman E, Taylor S, Lieberman M. Evidence for\nsocial working memory from a parametric functional MRI study. Proc.\nNatl. Acad. Sci. U. S. A. 2012; 109: 1883 –1888.\n50. Meyer M, Taylor S, Lieberman M. Social working memory and its dis-\ntinctive link to social cognitive ability: An fMRI study. Soc. Cogn.\nAffect. Neurosci. 2015; 10: nsv065.\n51. Parr T, Friston K. Working memory, attention, and salience in active\ninference. Sci. Rep. 2017; 7: 14678.\n52. Feldman H, Friston K. Attention, uncertainty, and free-energy. Front.\nHum. Neurosci. 2010; 4: 215.\n53. Parr T, Friston K. Uncertainty, epistemics and active inference. J. R.\nSoc. Interface 2017; 14: 20170376.\n54. Mirza MB, Adams RA, Friston K, Parr T. Introducing a Bayesian\nmodel of selective attention based on active inference. Sci. Rep. 2019;\n9: 13915.55. Parr T, Friston KJ. Attention or salience? Curr. Opin. Psychol. 2019;\n29:1–5.\n56. Parr T, Rikhye RV, Halassa MM, Friston KJ. Prefrontal computation as\nactive inference. Cereb. Cortex 2020; 30: 682 –695.\n57. Chekroud AM. Unifying treatments for depression: An application of\nthe free energy principle. Front. Psychol. 2015; 6: 153.\n58. Kube T, Schwarting R, Rozenkrantz L, Glombiewski JA, Rief W. Dis-\ntorted cognitive processes in major depression: A predictive processingperspective. Biol. Psychiatry 2020; 87: 388 –398.\n59. Slavich G, Irwin M. From stress to in ﬂammation and major depressive\ndisorder: A social signal transduction theory of depression. Psychol.\nBull. 2014; 140: 774 –815.\n60. Smith R, Alkozei A, Killgore WDS, Lane RD. Nested positive feed-\nback loops in the maintenance of major depression: An integration and\nextension of previous models. Brain Behav. Immun. 2018; 67: 374 –397.\n61. Haker H, Schneebeli M, Stephan K. Can Bayesian theories of autism\nspectrum disorder help improve clinical practice? Front. Psych. 2016;\n7: 107.\n62. Lawson R, Rees G, Friston K. An aberrant precision account of autism.\nFront. Hum. Neurosci. 2014; 8: 302.\n63. Van de Cruys S, Evers K, Van der Hallen R et al. Precise minds in\nuncertain worlds: Predictive coding in autism. Psychol. Rev. 2014; 121:\n649 –675.\n64. Corlett PR, Horga G, Fletcher PC, Alderson-Day B, Schmack K,\nPowers AR 3rd. Hallucinations and strong priors. Trends Cogn. Sci.\n2019; 23: 114 –127.\n65. Adams RA, Stephan KE, Brown HR, Frith CD, Friston KJ. The compu-\ntational anatomy of psychosis. Front. Psych. 2013;\n4: 47.\n66. Stephan K, Manjaly Z, Mathys C et al. Allostatic self-ef ﬁcacy: A meta-\ncognitive theory of dyshomeostasis-induced fatigue and depression.\nFront. Hum. Neurosci. 2016; 10: 550.\n67. Lane RD, Weihs KL, Herring A, Hishaw A, Smith R. Affective agno-\nsia: Expansion of the alexithymia construct and a new opportunity tointegrate and extend Freud ’s legacy. Neurosci. Biobehav. Rev. 2015; 55:\n594 –611.\n68. Smith R, Kaszniak AW, Katsanis J, Lane RD, Nielsen L. The impor-\ntance of identifying underlying process abnormalities in alexithymia:Implications of the three-process model and a single case study illustra-\ntion. Conscious. Cogn. 2019; 68:3 3 –46.\n69. Burger A, Lumley M, Carty J et al. The effects of a novel psychological\nattribution and emotional awareness and expression therapy for chronicmusculoskeletal pain: A preliminary, uncontrolled trial. J. Psychosomat.\nRes. 2016; 81:1–8.\n70. Thakur E, Holmes H, Lockhart N et al . Emotional awareness and\nexpression training improves irritable bowel syndrome: A randomizedcontrolled trial. Neurogastroenterol. Motil. 2017; 29: e13143.\n71. Ferry AL, Hespos SJ, Waxman SR. Categorization in 3- and 4-month-\nold infants: An advantage of words over tones. Child Dev. 2010; 81:\n472 –479.\n72. Widen S, Russell J. Children acquire emotion categories gradually.\nCogn. Develop. 2008; 23: 291 –312.\n73. Gergely G, Watson J. The social biofeedback theory of parental affect-\nmirroring: The development of emotional self-awareness and self-control in infancy. Int. J. Psychoanal. 1996; 77: 1181 –1212.\n74. Smith R, Schwartenbeck P, Parr T, Friston KJ. An active inference\napproach to modeling concept learning. bioRxiv . 13 April 2020. s\n75. Smith R, Alkozei A, Bao J, Smith C, Lane RD, Killgore WDS. Resting\nstate functional connectivity correlates of emotional awareness.\nNeuroImage 2017; 159:9 9 –106.\n76. Smith R, Alkozei A, Lane RD, Killgore WDS. Unwanted reminders:\nThe effects of emotional memory suppression on subsequent neuro-cognitive processing. Conscious. Cogn. 2016; 44: 103 –113.\n77. Smith R, Bajaj S, Dailey NS et al. Greater cortical thickness within the\nlimbic visceromotor network predicts higher levels of trait emotionalawareness. Conscious. Cogn. 2018;\n57:5 4 –61.\n78. Smith R, Braden BB, Chen K, Ponce FA, Lane RD, Baxter LC. The\nneural basis of attaining conscious awareness of sad mood. Brain Imag.\nBehav. 2015; 9: 574 –587.\n79. Smith R, Fass H, Lane RD. Role of medial prefrontal cortex in rep-\nresenting one ’s own subjective emotional responses: A preliminary\nstudy. Conscious. Cogn. 2014; 29: 117 –130.\n80. Smith R, Lane RD, Alkozei A et al. The role of medial prefrontal cor-\ntex in the working memory maintenance of one ’s own emotional\nresponses. Sci. Rep. 2018; 8: 3460.\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 12The predictive brain in psychiatry PCNPsychiatry and\nClinical Neurosciences\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "81. Smith R, Lane RD, Alkozei A et al. Maintaining the feelings of others\nin working memory is associated with activation of the left anterior\ninsula and left frontal-parietal control network. Soc. Cogn. Affect. Neu-\nrosci. 2017; 12: 848 –860.\n82. Smith R, Lane RD, Sanova A, Alkozei A, Smith C, Killgore WDS.\nCommon and unique neural systems underlying the working memory\nmaintenance of emotional vs. bodily reactions to affective stimuli: The\nmoderating role of trait emotional awareness. Front. Hum. Neurosci.\n2018; 12: 370.\n83. Smith R, Sanova A, Alkozei A, Lane RD, Killgore WDS. Higher levels\nof trait emotional awareness are associated with more ef ﬁcient global\ninformation integration throughout the brain: A graph-theoretic analysisof resting state functional connectivity. Soc. Cogn. Affect. Neurosci.\n2018; 13: 665 –675.\n84. Mueller J, Alpers GW. Two facets of being bothered by bodily sensa-\ntions: Anxiety sensitivity and alexithymia in psychosomatic patients.Compr. Psychiatry 2006; 47: 489 –495.\n85. Colvert E, Rutter M, Kreppner J et al. Do theory of mind and executive\nfunction de ﬁcits underlie the adverse outcomes associated with pro-\nfound early deprivation? Findings from the English and Romanianadoptees study. J. Abnorm. Child Psychol. 2008; 36: 1057 –1068.\n86. Fries AB, Pollak SD. Emotion understanding in postinstitutionalized\neastern European children. Dev. Psychopathol. 2004; 16: 355 –369.\n87. Barrett L, Gross J, Christensen T, Benvenuto M. Knowing what you ’re\nfeeling and knowing what to do about it: Mapping the relation betweenemotion differentiation and emotion regulation. Cognit. Emot. 2001; 15:\n713 –724.\n88. Kashdan T, Barrett L, McKnight P. Unpacking emotion differentiation:\nTransforming unpleasant experience by perceiving distinctions in nega-tivity. Curr. Dir. Psychol. Sci. 2015; 24:1 0 –16.\n89. Lane RD, Anderson FS, Smith R. Biased competition favoring physical\nover emotional pain: A possible explanation for the link between earlyadversity and chronic pain. Psychosom. Med. 2018; 80: 880 –890.\n90. Smith R, Steklis HD, Steklis NG, Weihs KL, Lane RD. The evolution\nand development of the uniquely human capacity for emotional aware-\nness: A synthesis of comparative anatomical, cognitive, neuro-computational, and evolutionary psychological perspectives. Biol.\nPsychol. 2020; 154: 107925.\n91. Hayes S, Strosahl K, Wilson K. Acceptance and Commitment Therapy:\nAn Experiential Approach to Behavior Change . Guilford Press,\nNew York, NY, 2003.\n92. Segal Z, Teasdale J, Williams J. Mindfulness-based cognitive therapy:\nTheoretical rationale and empirical status.\nIn:Hayes S, Follette V,\nLinehan M (eds). Mindfulness and Acceptance: Expanding the\nCognitive-Behavioral Tradition . Guilford Press, New York, NY,\n2004; 45 –65.\n93. Greenberg L. Emotion-Focused Therapy: Theory and Practice . Ameri-\ncan Psychological Association, Washington, DC, 2010.\n94. Barlow D, Allen L, Choate M. Toward a uni ﬁed treatment for emo-\ntional disorders –Republished article. Behav. Ther. 2016; 47: 838 –853.\n95. Smith R, Khalsa SS, Paulus MP. An active inference approach to dis-\nsecting reasons for nonadherence to antidepressants. Biol. Psychiatry\nCogn. Neurosci. Neuroimaging 2019. https://doi.org/10.1016/j.bpsc.\n2019.11.01296. Smith R, Moutoussis M, Bilek E. Simulating the computational mecha-\nnisms of cognitive and behavioral psychotherapeutic interventions:\nInsights from active inference. PsyArXiv . 4 July 2020. https://psyarxiv.\ncom/8m62p/\n97. Yamashita Y, Tani J. Spontaneous prediction error generation in\nschizophrenia. PLoS One 2012; 7: e37843.\n98. Idei H, Murata S, Chen Y, Yamashita Y, Tani J, Ogata TA. Neu-\nrorobotics simulation of autistic behavior induced by unusual sensoryprecision. Comput. Psychiat. 2018; 2: 164 –182.\n99. Idei H, Murata S, Yamashita Y, Ogata T. Homogeneous intrinsic neuro-\nnal excitability induces over ﬁtting to sensory noise: A robot model of\nneurodevelopmental disorder. PsyArXiv . 2 June 2020. https://psyarxiv.\ncom/ah89z/\n100. Friston KJ. Precision psychiatry. Biol. Psychiat. Cogn. Neurosci. Neuro-\nimaging 2017; 2: 640 –643.\n101. Mathys CD, Lomakina EI, Daunizeau J et al. Uncertainty in perception\nand the hierarchical Gaussian ﬁlter.Front. Hum. Neurosci. 2014; 8: 825.\n102. Diaconescu AO, Mathys C, Weber LAE, Kasper L, Mauer J,\nStephan KE. Hierarchical prediction errors in midbrain and septum dur-\ning social learning. Soc. Cogn. Affect. Neurosci. 2017; 12: 618 –634.\n103. Iglesias S, Mathys C, Brodersen KH et al. Hierarchical prediction errors\nin midbrain and basal forebrain during sensory learning. Neuron 2013;\n80: 519 –530.\n104. Deserno L, Boehme R, Mathys C et al . Volatility estimates increase\nchoice switching and relate to prefrontal activity in schizophrenia. Biol.\nPsychiatry Cogn. Neurosci. Neuroimaging 2020; 5: 173 –183.\n105. Cole DM, Diaconescu AO, Pfeiffer UJ et al . Atypical processing of\nuncertainty in individuals at risk for psychosis. Neuroimage Clin. 2020;\n26: 102239.\n106. Powers AR, Mathys C, Corlett PR. Pavlovian conditioning-induced hal-\nlucinations result from overweighting of perceptual priors. Science\n2017; 357: 596 –600.\n107. Adams R, Perrinet L, Friston K. Smooth pursuit and visual occlusion:\nActive inference and oculomotor control in schizophrenia. PLoS ONE\n2012; 7: e47502.\n108. Lawson R, Mathys C, Rees G. Adults with autism overestimate the vol-\natility of the sensory environment. Nat. Neurosci. 2017; 20: 1293 –1299.\n109. Smith R, Schwartenbeck P, Stewart JL et al. Imprecise action selection\nin substance use disorder: Evidence for active learning impairments\nwhen solving the explore-exploit dilemma. Drug Alcohol Depend.\n2020; 215: 108208.\n110. Smith R, Kirlic N, Touthang J et al. Greater decision uncertainty char-\nacterizes a transdiagnostic patient sample during approach-avoidance\nconﬂict: A computational modeling approach. J. Psychiatry Neurosci.\n2020. https://doi.org/10.31234/osf.io/t2dhn\n111. Smith R, Kuplicki R, Feinstein J, Forthman KL, Stewart JL,\nPaulus MP, et al. An active inference model reveals a failure to adapt\ninteroceptive precision estimates across depression, anxiety, eating, andsubstance use disorders. medRxiv . 2020. https://doi.org/10.1101/2020.\n06.03.20121343\n112. Smith R, Kuplicki R, Teed A, Upshaw V, Khalsa SS. Con ﬁrmatory evi-\ndence that healthy individuals can adaptively adjust prior expectationsand interoceptive precision estimates. bioRxiv . 2020. https://doi.org/10.\n1101/2020.08.31.275594\nPsychiatry and Clinical Neurosciences 75: 3 –13, 2021 13PCNPsychiatry and\nClinical Neurosciences The predictive brain in psychiatry\n 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License"
    }
  ]
}