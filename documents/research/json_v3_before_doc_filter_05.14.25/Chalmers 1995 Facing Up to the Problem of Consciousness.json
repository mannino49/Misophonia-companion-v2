{
  "doc_type": "scientific paper",
  "title": "Facing Up to the Problem of Consciousness",
  "authors": [
    "David J. Chalmers"
  ],
  "year": 1995,
  "journal": "Journal of Consciousness Studies",
  "doi": null,
  "abstract": "Consciousness poses the most baffling problems in the science of the mind. The paper isolates the hard problem of consciousness, distinguishing it from easier-to-explain cognitive functions. It critiques reductive explanatory approaches that only address the easy problems and argues for the necessity of nonreductive naturalistic explanations. The author proposes a nonreductive theory based on principles of structural coherence, organizational invariance, and a double-aspect view of information, aimed to better account for subjective experience.",
  "keywords": [
    "Consciousness",
    "Hard problem of consciousness",
    "Easy problems of consciousness",
    "Cognitive science",
    "Neuroscience",
    "Experience",
    "Functional explanation",
    "Neural correlates of consciousness",
    "Phenomenal consciousness",
    "Qualia",
    "Information integration",
    "Nonreductive explanation"
  ],
  "research_topics": [
    "Philosophy of mind",
    "Consciousness studies",
    "Cognitive science",
    "Neuroscience",
    "Philosophy of consciousness",
    "Functionalism",
    "Neural correlates of consciousness",
    "Subjective experience",
    "Information theory in consciousness",
    "Nonreductive theories of consciousness"
  ],
  "created_at": "2025-05-05T02:52:25.553893Z",
  "source_pdf": "documents/research/Global/Chalmers 1995 Facing Up to the Problem of Consciousness.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "FACING UP TO THE PROBLEM OF CONSCIOUSNESS*\nDavid J. Chalmers, Department of Philosophy, University of California\nSanta Cruz, CA 95064, USA. Email: chalmers@ling.ucsc.edu\nI: Introduction\nConsciousness poses the most baffling problems in the science of the mind. There is\nnothing that we know more intimately than conscious experience, but there is nothingthat is harder to explain. All sorts of mental phenomena have yielded to scientificinvestigation in recent years, but consciousness has stubbornly resisted. Many have triedto explain it, but the explanations always seem to fall short of the target. Some have beenled to suppose that the problem is intractable, and that no good explanation can be given. To make progress on the problem of consciousness, we have to confront it directly. Inthis paper, I first isolate the truly hard part of the problem, separating it from moretractable parts and giving an account of why it is so difficult to explain. I critique somerecent work that uses reductive methods to address consciousness, and argue that thesemethods inevitably fail to come to grips with the hardest part of the problem. Once thisfailure is recognized, the door to further progress is opened. In the second half of thepaper, I argue that if we move to a new kind of nonreductive explanation, a naturalisticaccount of consciousness can be given. I put forward my own candidate for such anaccount: a nonreductive theory based on principles of structural coherence and organiza-tional invariance and a double-aspect view of information.\nII: The Easy Problems and the Hard Problem\nThere is not just one problem of consciousness. Consciousness is an ambiguous term,\nreferring to many different phenomena. Each of these phenomena needs to be explained,but some are easier to explain than others. At the start, it is useful to divide the associatedproblems of consciousness into hard and easy problems. The easy problems ofconsciousness are those that seem directly susceptible to the standard methods of cogni-tive science, whereby a phenomenon is explained in terms of computational or neuralmechanisms. The hard problems are those that seem to resist those methods. The easy problems of consciousness include those of explaining the followingphenomena:\n•the ability to discriminate, categorize, and react to environmental stimuli;\n•the integration of information by a cognitive system;\n•the reportability of mental states;\n•the ability of a system to access its own internal states;\n•the focus of attention;\n•the deliberate control of behaviour;\n•the difference between wakefulness and sleep.\nAll of these phenomena are associated with the notion of consciousness. For example,\none sometimes says that a mental state is conscious when it is verbally reportable, orJournal of Consciousness Studies , 2, No.3, 1995, pp. 20019 \n* The arguments in this paper are presented in much greater depth in my book The Conscious Mind\n(Chalmers, 1996). Thanks to Francis Crick, Peggy DesAutels, Matthew Elton, Liane Gabora,Christof Koch, Paul Rhodes, Gregg Rosenberg, and Sharon Wahl for helpful comments.Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "when it is internally accessible. Sometimes a system is said to be conscious of some\ninformation when it has the ability to react on the basis of that information, or, morestrongly, when it attends to that information, or when it can integrate that information and\nexploit it in the sophisticated control of behaviour. We sometimes say that an action is\nconscious precisely when it is deliberate. Often, we say that an organism is conscious asanother way of saying that it is awake.\n There is no real issue about whether these  phenomena can be explained scientifically.\nAll of them are straightforwardly vulnerable to explanation in terms of computational orneural mechanisms. To explain access and reportability, for example, we need onlyspecify the mechanism by which information about internal states is retrieved and madeavailable for verbal report. To explain the integration of information, we need onlyexhibit mechanisms by which information is brought together and exploited by later\nprocesses. For an account of sleep and wakefulness, an appropriate neurophysiological\naccount of the processes responsible for organisms contrasting behaviour in those stateswill suffice. In each case, an appropriate cognitive or neurophysiological model canclearly do the explanatory work.\n If these phenomena were all there was to consciousness, then consciousness would not\nbe much of a problem. Although we do not yet have anything close to a completeexplanation of these phenomena, we have a clear idea of how we might go aboutexplaining them. This is why I call these problems the easy problems. Of course, easyis a relative term. Getting the details right will probably take a century or two of difficultempirical work. Still, there is every reason to believe that the methods of cognitive\nscience and neuroscience will succeed. The really hard problem of consciousness is the problem of experience . When we think\nand perceive, there is a whir of information-processing, but there is also a subjectiveaspect. As Nagel (1974) has put it, there is something it is like  to be a conscious organism.\nThis subjective aspect is experience. When we see, for example, we experience  visual\nsensations: the felt quality of redness, the experience of dark and light, the quality ofdepth in a visual field. Other experiences go along with perception in different modalities:the sound of a clarinet, the smell of mothballs. Then there are bodily sensations, frompains to orgasms; mental images that are conjured up internally; the felt quality of\nemotion, and the experience of a stream of conscious thought. What unites all of these\nstates is that there is something it is like to be in them. All of them are states of experience.\n It is undeniable that some organisms are subjects of experience. But the question of\nhow it is that these systems are subjects of experience is perplexing. Why is it that whenour cognitive systems engage in visual and auditory information-processing, we havevisual or auditory experience: the quality of deep blue, the sensation of middle C? Howcan we explain why there is something it is like to entertain a mental image, or toexperience an emotion? It is widely agreed that experience arises from a physical basis,but we have no good explanation of why and how it so arises. Why should physicalprocessing give rise to a rich inner life at all? It seems objectively unreasonable that it\nshould, and yet it does. If any problem qualifies as the problem of consciousness, it is this one. In this central\nsense of consciousness, an organism is conscious if there is something it is like to bethat organism, and a mental state is conscious if there is something it is like to be in thatstate. Sometimes terms such as phenomenal consciousness and qualia are also usedhere, but I find it more natural to speak of conscious experience or simply experience.Another useful way to avoid confusion (used by e.g. Newell 1990, Chalmers 1996) is toreserve the term consciousness for the phenomena of experience, using the less loadedFACING UP TO THE PROBLEM OF CONSCIOUSNESS 201Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "term awareness for the more straightforward phenomena described earlier. If such a\nconvention were widely adopted, communication would be much easier. As things stand,those who talk about consciousness are frequently talking past each other. The ambiguity of the term consciousness is often exploited by both philosophers andscientists writing on the subject. It is common to see a paper on consciousness begin withan invocation of the mystery of consciousness, noting the strange intangibility andineffability of subjectivity, and worrying that so far we have no theory of the phenome-non. Here, the topic is clearly the hard problem  the problem of experience. In thesecond half of the paper, the tone becomes more optimistic, and the authors own theoryof consciousness is outlined. Upon examination, this theory turns out to be a theory ofone of the more straightforward phenomena  of reportability, of introspective access,or whatever. At the close, the author declares that consciousness has turned out to betractable after all, but the reader is left feeling like the victim of a bait-and-switch. Thehard problem remains untouched.\nIII: Functional Explanation\nWhy are the easy problems easy, and why is the hard problem hard? The easy problems\nare easy precisely because they concern the explanation of cognitive abilities  and\nfunctions . To explain a cognitive function, we need only specify a mechanism that can\nperform the function. The methods of cognitive science are well-suited for this sort ofexplanation, and so are well-suited to the easy problems of consciousness. By contrast,the hard problem is hard precisely because it is not a problem about the performance offunctions. The problem persists even when the performance of all the relevant functionsis explained.\n1\n To explain reportability, for instance, is just to explain how a system could perform thefunction of producing reports on internal states. To explain internal access, we need toexplain how a system could be appropriately affected by its internal states and useinformation about those states in directing later processes. To explain integration andcontrol, we need to explain how a systems central processes can bring informationcontents together and use them in the facilitation of various behaviours. These are allproblems about the explanation of functions. How do we explain the performance of a function? By specifying a mechanism  that\nperforms the function. Here, neurophysiological and cognitive modelling are perfect forthe task. If we want a detailed low-level explanation, we can specify the neural mecha-nism that is responsible for the function. If we want a more abstract explanation, we canspecify a mechanism in computational terms. Either way, a full and satisfying explanationwill result. Once we have specified the neural or computational mechanism that performsthe function of verbal report, for example, the bulk of our work in explaining reportabilityis over. In a way, the point is trivial. It is a conceptual  fact about these phenomena that their\nexplanation only involves the explanation of various functions, as the phenomena arefunctionally definable . All it means  for reportability to be instantiated in a system is that\nthe system has the capacity for verbal reports of internal information. All it means for asystem to be awake is for it to be appropriately receptive to information from the\n1 Here function is not used in the narrow teleological sense of something that a system is designed to\ndo, but in the broader sense of any causal role in the production of behaviour that a system might perform.202 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "environment and for it to be able to use this information in directing behaviour in an\nappropriate way. To see that this sort of thing is a conceptual fact, note that someone whosays you have explained the performance of the verbal report function, but you have not\nexplained reportability is making a trivial conceptual mistake about reportability. All it\ncould possibly  take to explain reportability is an explanation of how the relevant function\nis performed; the same goes for the other phenomena in question.\n Throughout the higher-level sciences, reductive explanation works in just this way. To\nexplain the gene, for instance, we needed to specify the mechanism that stores andtransmits hereditary information from one generation to the next. It turns out that DNAperforms this function; once we explain how the function is performed, we have ex-plained the gene. To explain life, we ultimately need to explain how a system canreproduce, adapt to its environment, metabolize, and so on. All of these are questions\nabout the performance of functions, and so are well-suited to reductive explanation. The\nsame holds for most problems in cognitive science. To explain learning, we need toexplain the way in which a systems behavioural capacities are modified in light ofenvironmental information, and the way in which new information can be brought to bearin adapting a systems actions to its environment. If we show how a neural or computa-tional mechanism does the job, we have explained learning. We can say the same for othercognitive phenomena, such as perception, memory, and language. Sometimes the rele-vant functions need to be characterized quite subtly, but it is clear that insofar as cognitivescience explains these phenomena at all, it does so by explaining the performance of\nfunctions. When it comes to conscious experience, this sort of explanation fails. What makes the\nhard problem hard and almost unique is that it goes beyond  problems about the perform-\nance of functions. To see this, note that even when we have explained the performance ofall the cognitive and behavioural functions in the vicinity of experience  perceptualdiscrimination, categorization, internal access, verbal report  there may still remain afurther unanswered question: Why is the performance of these functions accompanied by\nexperience?  A simple explanation of the functions leaves this question open.\n There is no analogous further question in the explanation of genes, or of life, or of\nlearning. If someone says I can see that you have explained how DNA stores and\ntransmits hereditary information from one generation to the next, but you have not\nexplained how it is a gene , then they are making a conceptual mistake. All it means to\nbe a gene is to be an entity that performs the relevant storage and transmission function.But if someone says I can see that you have explained how information is discriminated,integrated, and reported, but you have not explained how it is experienced , they are not\nmaking a conceptual mistake. This is a nontrivial further question.\n This further question is the key question in the problem of consciousness. Why doesnt\nall this information-processing go on in the dark, free of any inner feel? Why is it thatwhen electromagnetic waveforms impinge on a retina and are discriminated and catego-rized by a visual system, this discrimination and categorization is experienced as a\nsensation of vivid red? We know that conscious experience does arise when these\nfunctions are performed, but the very fact that it arises is the central mystery. There is anexplanatory gap  (a term due to Levine 1983) between the functions and experience, and\nwe need an explanatory bridge to cross it. A mere account of the functions stays on oneside of the gap, so the materials for the bridge must be found elsewhere.\n This is not to say that experience has no function. Perhaps it will turn out to play an\nimportant cognitive role. But for any role it might play, there will be more to theexplanation of experience than a simple explanation of the function. Perhaps it will evenFACING UP TO THE PROBLEM OF CONSCIOUSNESS 203Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "turn out that in the course of explaining a function, we will be led to the key insight that\nallows an explanation of experience. If this happens, though, the discovery will be anextra  explanatory reward. There is no cognitive function such that we can say in advance\nthat explanation of that function will automatically  explain experience.\n To explain experience, we need a new approach. The usual explanatory methods ofcognitive science and neuroscience do not suffice. These methods have been developedprecisely to explain the performance of cognitive functions, and they do a good job of it.But as these methods stand, they are only equipped to explain the performance of\nfunctions. When it comes to the hard problem, the standard approach has nothing to say.\nIV: Some Case-Studies\nIn the last few years, a number of works have addressed the problems of consciousness\nwithin the framework of cognitive science and neuroscience. This might suggest that theanalysis above is faulty, but in fact a close examination of the relevant work only lendsthe analysis further support. When we investigate just which aspects of consciousnessthese studies are aimed at, and which aspects they end up explaining, we find that theultimate target of explanation is always one of the easy problems. I will illustrate this withtwo representative examples. The first is the neurobiological theory of consciousness outlined by Francis Crick andChristof Koch (1990; see also Crick 1994). This theory centers on certain 3575 hertzneural oscillations in the cerebral cortex; Crick and Koch hypothesize that these oscilla-tions are the basis of consciousness. This is partly because the oscillations seem to becorrelated with awareness in a number of different modalities  within the visual andolfactory systems, for example  and also because they suggest a mechanism by whichthe binding  of information contents might be achieved. Binding is the process whereby\nseparately represented pieces of information about a single entity are brought together tobe used by later processing, as when information about the colour and shape of aperceived object is integrated from separate visual pathways. Following others (e.g.Eckhorn et al.  1988), Crick and Koch hypothesize that binding may be achieved by the\nsynchronized oscillations of neuronal groups representing the relevant contents. Whentwo pieces of information are to be bound together, the relevant neural groups willoscillate with the same frequency and phase. The details of how this binding might be achieved are still poorly understood, butsuppose that they can be worked out. What might the resulting theory explain? Clearly itmight explain the binding of information contents, and perhaps it might yield a moregeneral account of the integration of information in the brain. Crick and Koch alsosuggest that these oscillations activate the mechanisms of working memory, so that theremay be an account of this and perhaps other forms of memory in the distance. The theorymight eventually lead to a general account of how perceived information is bound andstored in memory, for use by later processing. Such a theory would be valuable, but it would tell us nothing about why the relevantcontents are experienced. Crick and Koch suggest that these oscillations are the neuralcorrelates  of experience. This claim is arguable  does not binding also take place in the\nprocessing of unconscious information?  but even if it is accepted, the explanatory\nquestion remains: Why do the oscillations give rise to experience? The only basis for anexplanatory connection is the role they play in binding and storage, but the question ofwhy binding and storage should themselves be accompanied by experience is neveraddressed. If we do not know why binding and storage should give rise to experience,204 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "telling a story about the oscillations cannot help us. Conversely, if we knew  why binding\nand storage gave rise to experience, the neurophysiological details would be just the icing\non the cake. Crick and Kochs theory gains its purchase by assuming  a connection\nbetween binding and experience, and so can do nothing to explain that link.\n I do not think that Crick and Koch are ultimately claiming to address the hard problem,\nalthough some have interpreted them otherwise. A published interview with Koch gives\na clear statement of the limitations on the theorys ambitions.\nWell, lets first forget about the really difficult aspects, like subjective feelings, for\nthey may not have a scientific solution. The subjective state of play, of pain, of\npleasure, of seeing blue, of smelling a rose  there seems to be a huge jump between\nthe materialistic level, of explaining molecules and neurons, and the subjectivelevel. Lets focus on things that are easier to study  like visual awareness. Youre\nnow talking to me, but youre not looking at me, youre looking at the cappuccino,\nand so you are aware of it. You can say, Its a cup and theres some liquid in it. IfI give it to you, youll move your arm and youll take it  youll respond in ameaningful manner. Thats what I call awareness. (What is Consciousness?,\nDiscover , November 1992, p. 96.)\nThe second example is an approach at the level of cognitive psychology. This is Bernard\nBaars global workspace theory of consciousness, presented in his book A Cognitive\nTheory of Consciousness  (1988). According to this theory, the contents of consciousness\nare contained in a global workspace , a central processor used to mediate communication\nbetween a host of specialized nonconscious processors. When these specialized proces-\nsors need to broadcast information to the rest of the system, they do so by sending this\ninformation to the workspace, which acts as a kind of communal blackboard for the restof the system, accessible to all the other processors.\n Baars uses this model to address many aspects of human cognition, and to explain a\nnumber of contrasts between conscious and unconscious cognitive functioning. Ulti-\nmately, however, it is a theory of cognitive accessibility , explaining how it is that certain\ninformation contents are widely accessible within a system, as well as a theory ofinformational integration and reportability. The theory shows promise as a theory ofawareness, the functional correlate of conscious experience, but an explanation of expe-\nrience itself is not on offer.\n One might suppose that according to this theory, the contents of experience are\nprecisely the contents of the workspace. But even if this is so, nothing internal to thetheory explains  why the information within the global workspace is experienced. The best\nthe theory can do is to say that the information is experienced because it is globally\naccessible . But now the question arises in a different form: why should global accessibil-\nity give rise to conscious experience? As always, this bridging question is unanswered.\n Almost all work taking a cognitive or neuroscientific approach to consciousness in\nrecent years could be subjected to a similar critique. The Neural Darwinism model of\nEdelman (1989), for instance, addresses questions about perceptual awareness and the\nself-concept, but says nothing about why there should also be experience. The multipledrafts model of Dennett (1991) is largely directed at explaining the reportability ofcertain mental contents. The intermediate level theory of Jackendoff (1987) provides an\naccount of some computational processes that underlie consciousness, but Jackendoff\nstresses that the question of how these project into conscious experience remainsmysterious.FACING UP TO THE PROBLEM OF CONSCIOUSNESS 205Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "Researchers using these methods are often inexplicit about their attitudes to the\nproblem of conscious experience, although sometimes they take a clear stand. Evenamong those who are clear about it, attitudes differ widely. In placing this sort of work\nwith respect to the problem of experience, a number of different strategies are available.\nIt would be useful if these strategic choices were more often made explicit.\n The first strategy is simply to explain something else . Some researchers are explicit that\nthe problem of experience is too difficult for now, and perhaps even outside the domainof science altogether. These researchers instead choose to address one of the moretractable problems such as reportability or the self-concept. Although I have called theseproblems the easy problems, they are among the most interesting unsolved problems incognitive science, so this work is certainly worthwhile. The worst that can be said of thischoice is that in the context of research on consciousness it is relatively unambitious, and\nthe work can sometimes be misinterpreted. The second choice is to take a harder line and deny the phenomenon . (Variations on this\napproach are taken by Allport 1988; Dennett 1991; Wilkes 1988.) According to this line,once we have explained the functions such as accessibility, reportability, and the like,there is no further phenomenon called experience to explain. Some explicitly deny thephenomenon, holding for example that what is not externally verifiable cannot be real.Others achieve the same effect by allowing that experience exists, but only if we equateexperience with something like the capacity to discriminate and report. These ap-proaches lead to a simpler theory, but are ultimately unsatisfactory. Experience is themost central and manifest aspect of our mental lives, and indeed is perhaps the key\nexplanandum in the science of the mind. Because of this status as an explanandum,\nexperience cannot be discarded like the vital spirit when a new theory comes along.Rather, it is the central fact that any theory of consciousness must explain. A theory thatdenies the phenomenon solves the problem by ducking the question.\n In a third option, some researchers claim to be explaining experience  in the full sense.\nThese researchers (unlike those above) wish to take experience very seriously; they layout their functional model or theory, and claim that it explains the full subjective qualityof experience (e.g. Flohr 1992; Humphrey 1992). The relevant step in the explanation isusually passed over quickly, however, and usually ends up looking something like magic.\nAfter some details about information processing are given, experience suddenly enters\nthe picture, but it is left obscure how these processes should suddenly give rise to\nexperience. Perhaps it is simply taken for granted that it does, but then we have anincomplete explanation and a version of the fifth strategy below.\n A fourth, more promising approach appeals to these methods to explain the structure\nof experience . For example, it is arguable that an account of the discriminations made by\nthe visual system can account for the structural relations between different colourexperiences, as well as for the geometric structure of the visual field (see e.g. Clark 1992;Hardin 1992). In general, certain facts about structures found in processing will corre-spond to and arguably explain facts about the structure of experience. This strategy is\nplausible but limited. At best, it takes the existence of experience for granted and\naccounts for some facts about its structure, providing a sort of nonreductive explanationof the structural aspects of experience (I will say more on this later). This is useful formany purposes, but it tells us nothing about why there should be experience in the firstplace.\n A fifth and reasonable strategy is to isolate the substrate of experience . After all, almost\neveryone allows that experience arises  one way or another from brain processes, and it\nmakes sense to identify the sort of process from which it arises. Crick and Koch put their206 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "work forward as isolating the neural correlate of consciousness, for example, and Edel-\nman (1989) and Jackendoff (1987) make related claims. Justification of these claimsrequires a careful theoretical analysis, especially as experience is not directly observablein experimental contexts, but when applied judiciously this strategy can shed indirectlight on the problem of experience. Nevertheless, the strategy is clearly incomplete. Fora satisfactory theory, we need to know more than which  processes give rise to experience;\nwe need an account of why and how. A full theory of consciousness must build anexplanatory bridge.\nV: The Extra Ingredient\nWe have seen that there are systematic reasons why the usual methods of cognitive\nscience and neuroscience fail to account for conscious experience. These are simply thewrong sort of methods: nothing that they give to us can yield an explanation. To accountfor conscious experience, we need an extra ingredient  in the explanation. This makes for\na challenge to those who are serious about the hard problem of consciousness: What isyour extra ingredient, and why should that account for conscious experience?\n There is no shortage of extra ingredients to be had. Some propose an injection of chaosand nonlinear dynamics. Some think that the key lies in nonalgorithmic processing. Someappeal to future discoveries in neurophysiology. Some suppose that the key to themystery will lie at the level of quantum mechanics. It is easy to see why all thesesuggestions are put forward. None of the old methods work, so the solution must lie withsomething  new. Unfortunately, these suggestions all suffer from the same old problems.\n Nonalgorithmic processing, for example, is put forward by Penrose (1989; 1994)because of the role it might play in the process of conscious mathematical insight. Thearguments about mathematics are controversial, but even if they succeed and an accountof nonalgorithmic processing in the human brain is given, it will still only be an accountof the functions  involved in mathematical reasoning and the like. For a nonalgorithmic\nprocess as much as an algorithmic process, the question is left unanswered: why shouldthis process give rise to experience? In answering this question, there is no special role\nfor nonalgorithmic processing. The same goes for nonlinear and chaotic dynamics. These might provide a novelaccount of the dynamics of cognitive functioning, quite different from that given bystandard methods in cognitive science. But from dynamics, one only gets more dynamics.The question about experience here is as mysterious as ever. The point is even clearer fornew discoveries in neurophysiology. These new discoveries may help us make significantprogress in understanding brain function, but for any neural process we isolate, the samequestion will always arise. It is difficult to imagine what a proponent of new neurophysi-ology expects to happen, over and above the explanation of further cognitive functions.It is not as if we will suddenly discover a phenomenal glow inside a neuron! Perhaps the most popular extra ingredient of all is quantum mechanics (e.g. Hameroff1994). The attractiveness of quantum theories of consciousness may stem from a Law ofMinimization of Mystery: consciousness is mysterious and quantum mechanics is mys-terious, so maybe the two mysteries have a common source. Nevertheless, quantumtheories of consciousness suffer from the same difficulties as neural or computationaltheories. Quantum phenomena have some remarkable functional properties, such asnondeterminism and nonlocality. It is natural to speculate that these properties may playsome role in the explanation of cognitive functions, such as random choice and theFACING UP TO THE PROBLEM OF CONSCIOUSNESS 207Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "integration of information, and this hypothesis cannot be ruled out a priori . But when it\ncomes to the explanation of experience, quantum processes are in the same boat as any\nother. The question of why these processes should give rise to experience is entirelyunanswered.\n2\n At the end of the day, the same criticism applies to any purely physical account of\nconsciousness. For any physical process we specify there will be an unanswered question:\nWhy should this process give rise to experience? Given any such process, it is conceptu-\nally coherent that it could be instantiated in the absence of experience. It follows that nomere account of the physical process will tell us why experience arises. The emergenceof experience goes beyond what can be derived from physical theory.\n Purely physical explanation is well-suited to the explanation of physical structures ,\nexplaining macroscopic structures in terms of detailed microstructural constituents; and\nit provides a satisfying explanation of the performance of functions , accounting for these\nfunctions in terms of the physical mechanisms that perform them. This is because aphysical account can entail  the facts about structures and functions: once the internal\ndetails of the physical account are given, the structural and functional properties fall out\nas an automatic consequence. But the structure and dynamics of physical processes yieldonly more structure and dynamics, so structures and functions are all we can expect theseprocesses to explain. The facts about experience cannot be an automatic consequence of\nany physical account, as it is conceptually coherent that any given process could exist\nwithout experience. Experience may arise  from the physical, but it is not entailed  by the\nphysical.\n The moral of all this is that you cant explain conscious experience on the cheap . It is\na remarkable fact that reductive methods  methods that explain a high-level phenome-\nnon wholly in terms of more basic physical processes  work well in so many domains.\nIn a sense, one can explain most biological and cognitive phenomena on the cheap, in\nthat these phenomena are seen as automatic consequences of more fundamental proc-esses. It would be wonderful if reductive methods could explain experience, too; I hoped\nfor a long time that they might. Unfortunately, there are systematic reasons why these\nmethods must fail. Reductive methods are successful in most domains because whatneeds explaining in those domains are structures and functions, and these are the kind ofthing that a physical account can entail. When it comes to a problem over and above the\nexplanation of structures and functions, these methods are impotent. This might seem reminiscent of the vitalist claim that no physical account could\nexplain life, but the cases are disanalogous. What drove vitalist scepticism was doubtabout whether physical mechanisms could perform the many remarkable functionsassociated with life, such as complex adaptive behaviour and reproduction. The concep-\ntual claim that explanation of functions is what is needed was implicitly accepted, but\nlacking detailed knowledge of biochemical mechanisms, vitalists doubted whether anyphysical process could do the job and put forward the hypothesis of the vital spirit as analternative explanation. Once it turned out that physical processes could perform the\nrelevant functions, vitalist doubts melted away.\n2 One special attraction of quantum theories is the fact that on some interpretations of quantum\nmechanics, consciousness plays an active role in collapsing the quantum wave function. Such\ninterpretations are controversial, but in any case they offer no hope of explaining  consciousness in\nterms of quantum processes. Rather, these theories assume  the existence of consciousness, and use\nit in the explanation of quantum processes. At best, these theories tell us something about a physical\nrole that consciousness may play. They tell us nothing about how it arises.208 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "With experience, on the other hand, physical explanation of the functions is not in\nquestion. The key is instead the conceptual  point that the explanation of functions\ndoes not suffice for the explanation of experience. This basic conceptual point is notsomething that further neuroscientific investigation will affect. In a similar way,experience is disanalogous to the elan vital . The vital spirit was put forward as an\nexplanatory posit, in order to explain the relevant functions, and could therefore bediscarded when those functions were explained without it. Experience is not anexplanatory posit but an explanandum in its own right, and so is not a candidate forthis sort of elimination. It is tempting to note that all sorts of puzzling phenomena have eventually turned outto be explainable in physical terms. But each of these were problems about the observablebehaviour of physical objects, coming down to problems in the explanation of structuresand functions. Because of this, these phenomena have always been the kind of thing thata physical account might  explain, even if at some points there have been good reasons to\nsuspect that no such explanation would be forthcoming. The tempting induction fromthese cases fails in the case of consciousness, which is not a problem about physicalstructures and functions. The problem of consciousness is puzzling in an entirely differentway. An analysis of the problem shows us that conscious experience is just not the kindof thing that a wholly reductive account could succeed in explaining.\nVI: Nonreductive Explanation\nAt this point some are tempted to give up, holding that we will never have a theory of\nconscious experience. McGinn (1989), for example, argues that the problem is too hardfor our limited minds; we are cognitively closed with respect to the phenomenon.Others have argued that conscious experience lies outside the domain of scientific theoryaltogether. I think this pessimism is premature. This is not the place to give up; it is the place wherethings get interesting. When simple methods of explanation are ruled out, we need toinvestigate the alternatives. Given that reductive explanation fails, nonreductive  explana-\ntion is the natural choice. Although a remarkable number of phenomena have turned out to be explicable whollyin terms of entities simpler than themselves, this is not universal. In physics, it occasion-ally happens that an entity has to be taken as fundamental . Fundamental entities are not\nexplained in terms of anything simpler. Instead, one takes them as basic, and gives atheory of how they relate to everything else in the world. For example, in the nineteenthcentury it turned out that electromagnetic processes could not be explained in terms ofthe wholly mechanical processes that previous physical theories appealed to, so Maxwelland others introduced electromagnetic charge and electromagnetic forces as new funda-mental components of a physical theory. To explain electromagnetism, the ontology ofphysics had to be expanded. New basic properties and basic laws were needed to give asatisfactory account of the phenomena. Other features that physical theory takes as fundamental include mass and space-time.No attempt is made to explain these features in terms of anything simpler. But this doesnot rule out the possibility of a theory of mass or of space-time. There is an intricatetheory of how these features interrelate, and of the basic laws they enter into. These basicprinciples are used to explain many familiar phenomena concerning mass, space, andtime at a higher level.FACING UP TO THE PROBLEM OF CONSCIOUSNESS 209Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "I suggest that a theory of consciousness should take experience as fundamental. We\nknow that a theory of consciousness requires the addition of something  fundamental to\nour ontology, as everything in physical theory is compatible with the absence of con-\nsciousness. We might add some entirely new nonphysical feature, from which experience\ncan be derived, but it is hard to see what such a feature would be like. More likely, wewill take experience itself as a fundamental feature of the world, alongside mass, charge,and space-time. If we take experience as fundamental, then we can go about the businessof constructing a theory of experience.\n Where there is a fundamental property, there are fundamental laws. A nonreductive\ntheory of experience will add new principles to the furniture of the basic laws of nature.These basic principles will ultimately carry the explanatory burden in a theory ofconsciousness. Just as we explain familiar high-level phenomena involving mass in terms\nof more basic principles involving mass and other entities, we might explain familiar\nphenomena involving experience in terms of more basic principles involving experienceand other entities.\n In particular, a nonreductive theory of experience will specify basic principles telling\nus how experience depends on physical features of the world. These psychophysical\nprinciples will not interfere with physical laws, as it seems that physical laws alreadyform a closed system. Rather, they will be a supplement to a physical theory. A physicaltheory gives a theory of physical processes, and a psychophysical theory tells us howthose processes give rise to experience. We know that experience depends on physicalprocesses, but we also know that this dependence cannot be derived from physical laws\nalone. The new basic principles postulated by a nonreductive theory give us the extra\ningredient that we need to build an explanatory bridge.\n Of course, by taking experience as fundamental, there is a sense in which this approach\ndoes not tell us why there is experience in the first place. But this is the same for anyfundamental theory. Nothing in physics tells us why there is matter in the first place, butwe do not count this against theories of matter. Certain features of the world need to betaken as fundamental by any scientific theory. A theory of matter can still explain all sortsof facts about matter, by showing how they are consequences of the basic laws. The samegoes for a theory of experience.\n This position qualifies as a variety of dualism, as it postulates basic properties over andabove the properties invoked by physics. But it is an innocent version of dualism, entirely\ncompatible with the scientific view of the world. Nothing in this approach contradictsanything in physical theory; we simply need to add further bridging  principles to explain\nhow experience arises from physical processes. There is nothing particularly spiritual ormystical about this theory  its overall shape is like that of a physical theory, with a fewfundamental entities connected by fundamental laws. It expands the ontology slightly, tobe sure, but Maxwell did the same thing. Indeed, the overall structure of this position isentirely naturalistic, allowing that ultimately the universe comes down to a network ofbasic entities obeying simple laws, and allowing that there may ultimately be a theory of\nconsciousness cast in terms of such laws. If the position is to have a name, a good choice\nmight be naturalistic dualism .\n If this view is right, then in some ways a theory of consciousness will have more in\ncommon with a theory in physics than a theory in biology. Biological theories involve noprinciples that are fundamental in this way, so biological theory has a certain complexityand messiness to it; but theories in physics, insofar as they deal with fundamentalprinciples, aspire to simplicity and elegance. The fundamental laws of nature are part ofthe basic furniture of the world, and physical theories are telling us that this basic210 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "furniture is remarkably simple. If a theory of consciousness also involves fundamental\nprinciples, then we should expect the same. The principles of simplicity, elegance, andeven beauty that drive physicists search for a fundamental theory will also apply to atheory of consciousness.\n3\nVII: Toward of a Theory of Consciousness\nIt is not too soon to begin work on a theory. We are already in a position to understand\nsome key facts about the relationship between physical processes and experience, andabout the regularities that connect them. Once reductive explanation is set aside, we canlay those facts on the table so that they can play their proper role as the initial pieces in anonreductive theory of consciousness, and as constraints on the basic laws that constitutean ultimate theory. There is an obvious problem that plagues the development of a theory of conscious-ness, and that is the paucity of objective data. Conscious experience is not directlyobservable in an experimental context, so we cannot generate data about the relationshipbetween physical processes and experience at will. Nevertheless, we all have access to arich source of data in our own case. Many important regularities between experience andprocessing can be inferred from considerations about ones own experience. There arealso good indirect sources of data from observable cases, as when one relies on the verbalreport of a subject as an indication of experience. These methods have their limitations,but we have more than enough data to get a theory off the ground. Philosophical analysis is also useful in getting value for money out of the data we have.This sort of analysis can yield a number of principles relating consciousness and cogni-tion, thereby strongly constraining the shape of an ultimate theory. The method ofthought-experimentation can also yield significant rewards, as we will see. Finally, thefact that we are searching for a fundamental  theory means that we can appeal to such\nnonempirical constraints as simplicity, homogeneity, and the like in developing a theory.We must seek to systematize the information we have, to extend it as far as possible bycareful analysis, and then make the inference to the simplest possible theory that explainsthe data while remaining a plausible candidate to be part of the fundamental furniture ofthe world. Such theories will always retain an element of speculation that is not present in otherscientific theories, because of the impossibility of conclusive intersubjective experimen-tal tests. Still, we can certainly construct theories that are compatible with the data thatwe have, and evaluate them in comparison to each other. Even in the absence ofintersubjective observation, there are numerous criteria available for the evaluation ofsuch theories: simplicity, internal coherence, coherence with theories in other domains,the ability to reproduce the properties of experience that are familiar from our own case,\n3 Some philosophers argue that even though there is a conceptual  gap between physical processes\nand experience, there need be no metaphysical gap, so that experience might in a certain sense stillbephysical (e.g. Hill 1991; Levine 1983; Loar 1990). Usually this line of argument is supported byanappeal to the notion of a posteriori  necessity (Kripke 1980). I think that this position rests on a\nmisunderstanding of a posteriori  necessity, however, or else requires an entirely new sort of\nnecessity that we have no reason to believe in; see Chalmers 1996 (also Jackson 1994; Lewis 1994)for details. In any case, this position still concedes an explanatory  gap between physical processes\nand experience. For example, the principles connecting the physical and the experiential will not be\nderivable from the laws of physics, so such principles must be taken as explanatorily  fundamental.\nSo even on this sort of view, the explanatory structure of a theory of consciousness will be much as\nI have described.FACING UP TO THE PROBLEM OF CONSCIOUSNESS 211Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "and even an overall fit with the dictates of common sense. Perhaps there will be\nsignificant indeterminacies remaining even when all these constraints are applied, but wecan at least develop plausible candidates. Only when candidate theories have beendeveloped will we be able to evaluate them. A nonreductive theory of consciousness will consist of a number of psychophysical\nprinciples , principles connecting the properties of physical processes to the properties of\nexperience. We can think of these principles as encapsulating the way in which experi-ence arises from the physical. Ultimately, these principles should tell us what sort ofphysical systems will have associated experiences, and for the systems that do, theyshould tell us what sort of physical properties are relevant to the emergence of experience,and just what sort of experience we should expect any given physical system to yield.This is a tall order, but there is no reason why we should not get started. In what follows, I present my own candidates for the psychophysical principles thatmight go into a theory of consciousness. The first two of these are nonbasic principles  \nsystematic connections between processing and experience at a relatively high level.These principles can play a significant role in developing and constraining a theory ofconsciousness, but they are not cast at a sufficiently fundamental level to qualify as trulybasic laws. The final principle is a candidate for a basic principle  that might form the\ncornerstone of a fundamental theory of consciousness. This principle is particularlyspeculative, but it is the kind of speculation that is required if we are ever to have asatisfying theory of consciousness. I can present these principles only briefly here; I arguefor them at much greater length in Chalmers 1996.\n1. The principle of structural coherence\nThis is a principle of coherence between the structure of consciousness  and the structure\nof awareness . Recall that awareness was used earlier to refer to the various functional\nphenomena that are associated with consciousness. I am now using it to refer to asomewhat more specific process in the cognitive underpinnings of experience. In particu-lar, the contents of awareness are to be understood as those information contents that areaccessible to central systems, and brought to bear in a widespread way in the control ofbehaviour. Briefly put, we can think of awareness as direct availability for global control .\nTo a first approximation, the contents of awareness are the contents that are directlyaccessible and potentially reportable, at least in a language-using system. Awareness is a purely functional notion, but it is nevertheless intimately linked toconscious experience. In familiar cases, wherever we find consciousness, we find aware-ness. Wherever there is conscious experience, there is some corresponding informationin the cognitive system that is available in the control of behaviour, and available forverbal report. Conversely, it seems that whenever information is available for report andfor global control, there is a corresponding conscious experience. Thus, there is a directcorrespondence between consciousness and awareness. The correspondence can be taken further. It is a central fact about experience that it hasa complex structure. The visual field has a complex geometry, for instance. There are alsorelations of similarity and difference between experiences, and relations in such things asrelative intensity. Every subjects experience can be at least partly characterized anddecomposed in terms of these structural properties: similarity and difference relations,perceived location, relative intensity, geometric structure, and so on. It is also a centralfact that to each of these structural features, there is a corresponding feature in theinformation-processing structure of awareness.212 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "Take colour sensations as an example. For every distinction between colour experi-\nences, there is a corresponding distinction in processing. The different phenomenalcolours that we experience form a complex three-dimensional space, varying in hue,\nsaturation, and intensity. The properties of this space can be recovered from information-\nprocessing considerations: examination of the visual systems shows that waveforms oflight are discriminated and analysed along three different axes, and it is this three-dimen-sional information that is relevant to later processing. The three-dimensional structure ofphenomenal colour space therefore corresponds directly to the three dimensional struc-ture of visual awareness. This is precisely what we would expect. After all, every colourdistinction corresponds to some reportable information, and therefore to a distinction thatis represented in the structure of processing.\n In a more straightforward way, the geometric structure of the visual field is directlyreflected in a structure that can be recovered from visual processing. Every geometric\nrelation corresponds to something that can be reported and is therefore cognitivelyrepresented. If we were given only the story about information-processing in an agentsvisual and cognitive system, we could not directly  observe that agents visual experi-\nences, but we could nevertheless infer those experiences structural properties.\n In general, any information that is consciously experienced will also be cognitively\nrepresented. The fine-grained structure of the visual field will correspond to somefine-grained structure in visual processing. The same goes for experiences in othermodalities, and even for nonsensory experiences. Internal mental images have geometricproperties that are represented in processing. Even emotions have structural properties,\nsuch as relative intensity, that correspond directly to a structural property of processing;\nwhere there is greater intensity, we find a greater effect on later processes. In general,precisely because the structural properties of experience are accessible and reportable,those properties will be directly represented in the structure of awareness.\n It is this isomorphism between the structures of consciousness and awareness that\nconstitutes the principle of structural coherence. This principle reflects the central factthat even though cognitive processes do not conceptually entail facts about consciousexperience, consciousness and cognition do not float free of one another but cohere in anintimate way.\n This principle has its limits. It allows us to recover structural properties of experiencefrom information-processing properties, but not all properties of experience are structural\nproperties. There are properties of experience, such as the intrinsic nature of a sensationof red, that cannot be fully captured in a structural description. The very intelligibility ofinverted spectrum scenarios, where experiences of red and green are inverted but allstructural properties remain the same, show that structural properties constrain experi-ence without exhausting it. Nevertheless, the very fact that we feel compelled to leavestructural properties unaltered when we imagine experiences inverted between function-ally identical systems shows how central the principle of structural coherence is to ourconception of our mental lives. It is not a logically  necessary principle, as after all we can\nimagine all the information processing occurring without any experience at all, but it is\nnevertheless a strong and familiar constraint on the psychophysical connection.\n The principle of structural coherence allows for a very useful kind of indirect explana-\ntion of experience in terms of physical processes. For example, we can use facts aboutneural processing of visual information to indirectly explain the structure of colour space.The facts about neural processing can entail and explain the structure of awareness; if wetake the coherence principle for granted, the structure of experience will also be ex-plained. Empirical investigation might even lead us to better understand the structure ofFACING UP TO THE PROBLEM OF CONSCIOUSNESS 213Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "awareness within animals, shedding indirect light on Nagels vexing question of what it\nis like to be a bat. This principle provides a natural interpretation of much existing workon the explanation of consciousness (e.g. Clark 1992, Hardin 1992 on colours; Akins1993 on bats), although it is often appealed to inexplicitly. It is so familiar that it is takenfor granted by almost everybody, and is a central plank in the cognitive explanation ofconsciousness. The coherence between consciousness and awareness also allows a natural interpreta-tion of work in neuroscience directed at isolating the substrate  (or the neural correlate )\nof consciousness. Various specific hypotheses have been put forward. For example, Crickand Koch (1990) suggest that 40-hertz oscillations may be the neural correlate ofconsciousness, whereas Libet (1993) suggests that temporally-extended neural activity iscentral. If we accept the principle of coherence, the most direct  physical correlate of\nconsciousness is awareness: the process whereby information is made directly availablefor global control. The different specific hypotheses can be interpreted as empiricalsuggestions about how awareness might be achieved. For example, Crick and Kochsuggest that 40-Hz oscillations are the gateway by which information is integrated intoworking memory and thereby made available to later processes. Similarly, it is natural tosuppose that Libets temporally extended activity is relevant precisely because only thatsort of activity achieves global availability. The same applies to other suggested corre-lates such as the global workspace of Baars (1988), the high-quality representationsof Farah (1994), and the selector inputs to action systems of Shallice (1972). All thesecan be seen as hypotheses about the mechanisms of awareness : the mechanisms that\nperform the function of making information directly available for global control. Given the coherence between consciousness and awareness, it follows that a mecha-nism of awareness will itself be a correlate of conscious experience. The question of justwhich  mechanisms in the brain govern global availability is an empirical one; perhaps\nthere are many such mechanisms. But if we accept the coherence principle, we havereason to believe that the processes that explain  awareness will at the same time be part\nof the basis  of consciousness.\n2. The principle of organizational invariance\nThis principle states that any two systems with the same fine-grained functional organi-\nzation  will have qualitatively identical experiences. If the causal patterns of neural\norganization were duplicated in silicon, for example, with a silicon chip for every neuronand the same patterns of interaction, then the same experiences would arise. Accordingto this principle, what matters for the emergence of experience is not the specific physicalmakeup of a system, but the abstract pattern of causal interaction between its components.This principle is controversial, of course. Some (e.g. Searle 1980) have thought thatconsciousness is tied to a specific biology, so that a silicon isomorph of a human need notbe conscious. I believe that the principle can be given significant support by the analysisof thought-experiments, however. Very briefly: suppose (for the purposes of a reductio ad absurdum ) that the principle is\nfalse, and that there could be two functionally isomorphic systems with different experi-ences. Perhaps only one of the systems is conscious, or perhaps both are conscious butthey have different experiences. For the purposes of illustration, let us say that one systemis made of neurons and the other of silicon, and that one experiences red where the otherexperiences blue. The two systems have the same organization, so we can imaginegradually transforming one into the other, perhaps replacing neurons one at a time by214 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "silicon chips with the same local function. We thus gain a spectrum of inter- mediate\ncases, each with the same organization, but with slightly different physical makeup andslightly different experiences. Along this spectrum, there must be two systems A and B\nbetween which we replace less than one tenth of the system, but whose experiences differ.These two systems are physically identical, except that a small neural circuit in A has been\nreplaced by a silicon circuit in B.\n The key step in the thought-experiment is to take the relevant neural circuit in A, and\ninstall alongside it a causally isomorphic silicon circuit, with a switch between the two.What happens when we flip the switch? By hypothesis, the systems conscious experi-ences will change; from red to blue, say, for the purposes of illustration. This followsfrom the fact that the system after the change is essentially a version of B, whereas before\nthe change it is just A.\n But given the assumptions, there is no way for the system to notice  the changes! Its\ncausal organization stays constant, so that all of its functional states and behaviouraldispositions stay fixed. As far as the system is concerned, nothing unusual has happened.There is no room for the thought, Hmm! Something strange just happened! In general,the structure of any such thought must be reflected in processing, but the structure ofprocessing remains constant here. If there were to be such a thought it must float entirelyfree of the system and would be utterly impotent to affect later processing. (If it affectedlater processing, the systems would be functionally distinct, contrary to hypothesis.) Wemight even flip the switch a number of times, so that experiences of red and blue danceback and forth before the systems inner eye. According to hypothesis, the system cannever notice these dancing qualia. This I take to be a reductio  of the original assumption. It is a central fact about\nexperience, very familiar from our own case, that whenever experiences change signifi-cantly and we are paying attention, we can notice the change; if this were not to be thecase, we would be led to the sceptical possibility that our experiences are dancing beforeour eyes all the time. This hypothesis has the same status as the possibility that the worldwas created five minutes ago: perhaps it is logically coherent, but it is not plausible.Given the extremely plausible assumption that changes in experience correspond tochanges in processing, we are led to the conclusion that the original hypothesis isimpossible, and that any two functionally isomorphic systems must have the same sort ofexperiences. To put it in technical terms, the philosophical hypotheses of absent qualiaand inverted qualia, while logically possible, are empirically and nomologically impos-sible.\n3\n There is more to be said here, but this gives the basic flavour. Once again, this thoughtexperiment draws on familiar facts about the coherence between consciousness andcognitive processing to yield a strong conclusion about the relation between physicalstructure and experience. If the argument goes through, we know that the only physicalproperties directly relevant to the emergence of experience are organizational  properties.\nThis acts as a further strong constraint on a theory of consciousness.\n3. The double-aspect theory of information\nThe two preceding principles have been nonbasic  principles. They involve high-level\nnotions such as awareness and organization, and therefore lie at the wrong level to\n3 Some may worry that a silicon isomorph of a neural system might be impossible for technical\nreasons. That question is open. The invariance principle says only that if an isomorph is possible,\nthen it will have the same sort of conscious experience.FACING UP TO THE PROBLEM OF CONSCIOUSNESS 215Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 17",
      "page_number": 17,
      "text": "constitute the fundamental laws in a theory of consciousness. Nevertheless, they act as\nstrong constraints. What is further needed are basic  principles that fit these constraints\nand that might ultimately explain them.\n The basic principle that I suggest centrally involves the notion of information . I\nunderstand information in more or less the sense of Shannon (1948). Where there is\ninformation, there are information states  embedded in an information space . An informa-\ntion space has a basic structure of difference  relations between its elements, charac-\nterizing the ways in which different elements in a space are similar or different, possiblyin complex ways. An information space is an abstract object, but following Shannon wecan see information as physically embodied  when there is a space of distinct physical\nstates, the differences between which can be transmitted down some causal pathway. Thestates that are transmitted can be seen as themselves constituting an information space.\nTo borrow a phrase from Bateson (1972), physical information is a difference that makes\na difference .\n The double-aspect principle stems from the observation that there is a direct isomor-\nphism between certain physically embodied information spaces and certain phenomenal\n(or experiential) information spaces. From the same sort of observations that went intothe principle of structural coherence, we can note that the differences between phenome-nal states have a structure that corresponds directly to the differences embedded inphysical processes; in particular, to those differences that make a difference down certaincausal pathways implicated in global availability and control. That is, we can find thesame  abstract information space embedded in physical processing and in conscious\nexperience. This leads to a natural hypothesis: that information (or at least some information) has\ntwo basic aspects, a physical aspect and a phenomenal aspect. This has the status of abasic principle that might underlie and explain the emergence of experience from thephysical. Experience arises by virtue of its status as one aspect of information, when theother aspect is found embodied in physical processing.\n This principle is lent support by a number of considerations, which I can only outline\nbriefly here. First, consideration of the sort of physical changes that correspond tochanges in conscious experience suggests that such changes are always relevant by virtueof their role in constituting informational changes   differences within an abstract space\nof states that are divided up precisely according to their causal differences along certain\ncausal pathways. Second, if the principle of organizational invariance is to hold, then weneed to find some fundamental organizational  property for experience to be linked to,\nand information is an organizational property par excellence . Third, this principle offers\nsome hope of explaining the principle of structural coherence in terms of the structurepresent within information spaces. Fourth, analysis of the cognitive explanation of ourjudgments  and claims  about conscious experience  judgments that are functionally\nexplainable but nevertheless deeply tied to experience itself  suggests that explanationcentrally involves the information states embedded in cognitive processing. It follows\nthat a theory based on information allows a deep coherence between the explanation of\nexperience and the explanation of our judgments and claims about it.\n Wheeler (1990) has suggested that information is fundamental to the physics of the\nuniverse. According to this it from bit doctrine, the laws of physics can be cast in termsof information, postulating different states that give rise to different effects withoutactually saying what those states are. It is only their position in an information space that\ncounts. If so, then information is a natural candidate to also play a role in a fundamentaltheory of consciousness. We are led to a conception of the world on which information216 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 18",
      "page_number": 18,
      "text": "is truly fundamental, and on which it has two basic aspects, corresponding to the physical\nand the phenomenal features of the world. Of course, the double-aspect principle is extremely speculative and is also underdeter-mined, leaving a number of key questions unanswered. An obvious question is whetherall information has a phenomenal aspect. One possibility is that we need a further\nconstraint on the fundamental theory, indicating just what sort of information has a\nphenomenal aspect. The other possibility is that there is no such constraint. If not, thenexperience is much more widespread than we might have believed, as information iseverywhere. This is counterintuitive at first, but on reflection I think the position gains acertain plausibility and elegance. Where there is simple information processing, there issimple experience, and where there is complex information processing, there is complexexperience. A mouse has a simpler information-processing structure than a human, andhas correspondingly simpler experience; perhaps a thermostat, a maximally simpleinformation processing structure, might have maximally simple experience? Indeed, ifexperience is truly a fundamental property, it would be surprising for it to arise only everynow and then; most fundamental properties are more evenly spread. In any case, this isvery much an open question, but I believe that the position is not as implausible as it isoften thought to be. Once a fundamental link between information and experience is on the table, the dooris opened to some grander metaphysical speculation concerning the nature of the world.For example, it is often noted that physics characterizes its basic entities only extrinsi-\ncally , in terms of their relations to other entities, which are themselves characterized\nextrinsically, and so on. The intrinsic nature of physical entities is left aside. Some arguethat no such intrinsic properties exist, but then one is left with a world that is pure causalflux (a pure flow of information) with no properties for the causation to relate. If oneallows that intrinsic properties exist, a natural speculation given the above is that theintrinsic properties of the physical  the properties that causation ultimately relates are themselves phenomenal properties. We might say that phenomenal properties are theinternal aspect of information. This could answer a concern about the causal relevance ofexperience  a natural worry, given a picture on which the physical domain is causallyclosed, and on which experience is supplementary to the physical. The informationalview allows us to understand how experience might have a subtle kind of causal relevancein virtue of its status as the intrinsic aspect of the physical. This metaphysical speculationis probably best ignored for the purposes of developing a scientific theory, but inaddressing some philosophical issues it is quite suggestive.\nVIII: Conclusion\nThe theory I have presented is speculative, but it is a candidate theory. I suspect that the\nprinciples of structural coherence and organizational invariance will be planks in anysatisfactory theory of consciousness; the status of the double-aspect theory of informationis much less certain. Indeed, right now it is more of an idea than a theory. To have anyhope of eventual explanatory success, it will have to be specified more fully and fleshedout into a more powerful form. Still, reflection on just what is plausible and implausibleabout it, on where it works and where it fails, can only lead to a better theory. Most existing theories of consciousness either deny the phenomenon, explain some-thing else, or elevate the problem to an eternal mystery. I hope to have shown that it ispossible to make progress on the problem even while taking it seriously. To make furtherprogress, we will need further investigation, more refined theories, and more carefulFACING UP TO THE PROBLEM OF CONSCIOUSNESS 217Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 19",
      "page_number": 19,
      "text": "analysis. The hard problem is a hard problem, but there is no reason to believe that it will\nremain permanently unsolved.\nReferences\nAkins, K. (1993), What is it like to be boring and myopic? in Dennett and his Critics , ed.\nB. Dahlbom (Oxford: Blackwell).\nAllport, A. (1988), What concept of consciousness? in ( eds.) Consciousness in Contemporary\nScience , ed. A. Marcel and E. Bisiach (Oxford: Oxford University Press).\nBaars, B.J. (1988), A Cognitive Theory of Consciousness  (Cambridge: Cambridge University Press).\nBateson, G. (1972), Steps to an Ecology of Mind  (Chandler Publishing).\nBlock, N. (1995), On a confusion about the function of consciousness, Behavioral and Brain\nSciences , in press.\nBlock, N, Flanagan, O. and Güzeldere, G. (eds. 1996), The Nature of Consciousness: Philosophical\nand Scientific Debates  (Cambridge, MA: MIT Press).\nChalmers, D.J. (1996), The Conscious Mind  (New York: Oxford University Press).\nChurchland, P.M. (1995), The Engine of Reason, The Seat of the Soul: A Philosophical Journey into\nthe Brain  (Cambridge, MA: MIT Press).\nClark, A. (1992), Sensory Qualities  (Oxford: Oxford University Press).\nCrick, F. and Koch, C. (1990), Toward a neurobiological theory of consciousness, Seminars in the\nNeurosciences , 2, pp. 26375.\nCrick, F. (1994), The Astonishing Hypothesis: The Scientific Search for the Soul  (New York:\nScribners).\nDennett, D.C. (1991), Consciousness Explained  (Boston: Little, Brown).\nDretske, F.I. (1995), Naturalizing the Mind  (Cambridge, MA: MIT Press).\nEdelman, G. (1989), The Remembered Present: A Biological Theory of Consciousness  (New York:\nBasic Books).\nFarah, M.J. (1994), Visual perception and visual awareness after brain damage: a tutorial overview,\nin Consciousness and Unconscious Information Processing: Attention and Perform- ance 15 , ed.\nC. Umilta and M. Moscovitch (Cambridge, MA: MIT Press).\nFlohr, H. (1992), Qualia and brain processes, in Emergence or Reduction?: Prospects for\nNonreductive Physicalism , ed. A. Beckermann, H. Flohr, and J. Kim (Berlin: De Gruyter).\nHameroff, S.R. (1994), Quantum coherence in microtubules: a neural basis for emergent\nconsciousness?, Journal of Consciousness Studies , 1, pp. 91118.\nHardin, C.L. (1992), Physiology, phenomenology, and Spinozas true colors, in Emergence or\nReduction?: Prospects for Nonreductive Physicalism , ed.  A. Beckermann, H. Flohr, and J. Kim\n(Berlin: De Gruyter).\nHill, C.S. (1991), Sensations: A Defense of Type Materialism  (Cambridge: Cambridge University\nPress).\nHodgson, D. (1988), The Mind Matters: Consciousness and Choice in a Quantum World  (Oxford:\nOxford University Press).Further Reading\nThe problems of consciousness have been widely discussed in the recent philosophi-\ncal literature. For some conceptual clarification of the various problems of con-sciousness, see Block 1995, Nelkin 1993 and Tye 1995. Those who have stressedthe difficulties of explaining experience in physical terms include Hodgson 1988,Jackson 1982, Levine 1983, Lockwood 1989, McGinn 1989, Nagel 1974, Seager1991, Searle 1992, Strawson 1994 and Velmans 1991, among others. Those whotake a reductive approach include Churchland 1995, Clark 1992, Dennett 1991,Dretske 1995, Kirk 1994, Rosenthal 1996 and Tye 1995. There have not been manyattempts to build detailed nonreductive theories in the literature, but see Hodgson1988 and Lockwood 1989 for some thoughts in that direction. Two excellentcollections of recent articles on consciousness are Block, Flanagan and Güzeldere1996 and Metzinger 1995.218 D.J. CHALMERSCopyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    },
    {
      "section": "Page 20",
      "page_number": 20,
      "text": "Humphrey, N. (1992), A History of the Mind  (New York: Simon and Schuster).\nJackendoff, R. (1987), Consciousness and the Computational Mind  (Cambridge, MA: MIT Press).\nJackson, F. (1982), Epiphenomenal qualia, Philosophical Quarterly , 32, pp. 12736.\nJackson, F. (1994), Finding the mind in the natural world, in Philosophy and the Cognitive\nSciences , ed. R. Casati, B. Smith, and S. White (Vienna: Hölder-Pichler-Tempsky).\nKirk, R. (1994), Raw Feeling: A Philosophical Account of the Essence of Consciousness  (Oxford:\nOxford University Press).\nKripke, S. (1980), Naming and Necessity  (Cambridge, MA: Harvard University Press).\nLevine, J. (1983), Materialism and qualia: the explanatory gap, Pacific Philosophical Quarterly ,\n64, pp. 35461.\nLewis, D. (1994), Reduction of mind, in A Companion to the Philosophy of Mind , ed.\nS. Guttenplan (Oxford: Blackwell).\nLibet, B. (1993), The neural time factor in conscious and unconscious events, in Experimental and\nTheoretical Studies of Consciousness  (Ciba Foundation Symposium 174), ed. G.R. Block and\nJ. Marsh (Chichester: John Wiley and Sons).\nLoar, B. (1990), Phenomenal states, Philosophical Perspectives , 4, pp. 81108.\nLockwood, M. (1989), Mind, Brai, and the Quantum  (Oxford: Blackwell).\nMcGinn, C. (1989), Can we solve the mindbody problem?, Mind , 98, pp. 34966.\nMetzinger, T. (ed. 1995), Conscious Experience  (Exeter: Imprint Academic).\nNagel, T. (1974), What is it like to be a bat?, Philosophical Review , 4, pp. 43550.\nNelkin, N. (1993), What is consciousness?, Philosophy of Science , 60, pp. 41934.\nNewell, A. (1990), Unified Theories of Cognition  (Cambridge, MA: Harvard University Press).\nPenrose, R. (1989), The Emperor s New Mind  (Oxford: Oxford University Press).\nPenrose, R. (1994), Shadows of the Mind  (Oxford: Oxford University Press).\nRosenthal, D.M. (1996), A theory of consciousness, in The Nature of Consciousness , ed. N. Block,\nO. Flanagan, and G. Güzeldere (Cambridge, MA: MIT Press).\nSeager, W.E. (1991), Metaphysics of Consciousness  (London: Routledge).\nSearle, J.R. (1980), Minds, brains and programs, Behavioral and Brain Sciences , 3, pp. 41757.\nSearle, J.R. (1992), The Rediscovery of the Mind  (Cambridge, MA: MIT Press).\nShallice, T. (1972), Dual functions of consciousness, Psychological Review , 79, pp. 38393.\nShannon, C.E. (1948), A mathematical theory of communication, Bell Systems Technical Journal ,\n27, pp. 379423.\nStrawson, G. (1994), Mental Reality  (Cambridge, MA: MIT Press).\nTye, M. (1995), Ten Problems of Consciousness  (Cambridge, MA: MIT Press).\nVelmans, M. (1991), Is human information-processing conscious? Behavioral and Brain Sciences ,\n14, pp. 65169.\nWheeler, J.A. (1990), Information, physics, quantum: the search for links, in Complexity, Entropy,\nand the Physics of Information , ed. W. Zurek (Redwood City, CA: Addison-Wesley).\nWilkes, K.V . (1988),  , Yishi, Duh, Um and consciousness, in Consciousness in Contemporary\nScience , ed. A. Marcel and E. Bisiach (Oxford: Oxford University Press).FACING UP TO THE PROBLEM OF CONSCIOUSNESS 219Copyright (c) Imprint Academic 2016\nFor personal use only -- not for reproduction"
    }
  ]
}