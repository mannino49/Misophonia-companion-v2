{
  "doc_type": "scientific paper",
  "title": "Does context matter in misophonia? A multi-method experimental investigation",
  "authors": [
    "Marta Siepsiak",
    "Scott R. Vrana",
    "Andrzej Rynkiewicz",
    "M. Zachary Rosenthal",
    "Wojciech Łukasz Dragan"
  ],
  "year": 2023,
  "journal": "Frontiers in Neuroscience",
  "doi": "10.3389/fnins.2022.880853",
  "abstract": "Introduction: Misophonia is a recently defined disorder in which certain aversive repetitive sounds and associated stimuli elicit distressing and impairing affective, behavioral, and physiological responses. The responses in misophonia may be stronger when the sound is produced by close friends and family, suggesting that the context in which a triggering cue occurs may have an important role in misophonia. As such, the goal of this study was to test experimentally whether the context of the sound source influences affective and psychophysiological responses to triggering stimuli in misophonia. Methods: Sixty one adults with misophonia and 45 controls listened to audio recordings (8 s) of human eating, animals eating, and human mouth smacking sounds (without eating). After a break, the same audio recordings were presented embedded within videos of human eating (congruent stimuli), animals eating (congruent stimuli), and, in the mouth smacking condition, with visually incongruent stimuli (hands playing in mud or in a bowl with a watery dough). Psychophysiological responses-skin conductance response (SCR) and heart rate (HR), and self-reported affective responses (valence, arousal, dominance) were gathered during the experiment in a laboratory. Results: Participants with misophonia assessed all the stimuli as more negative and arousing than the controls, and reported feeling less dominant with respect to the sounds. Animal and mouth smacking sounds were assessed by all the participants as less negative and arousing than human eating sounds, but only in the audio-video conditions. SCR data partially confirmed increased psychophysiological arousal in misophonia participants during an exposure to mouth sounds, but did not reflect the self-report changes in response to different contexts. Misophonia participants had deeper deceleration of HR than controls during human eating sound with congruent video stimuli, while there was no group difference during human mouth smacking with incongruent video stimuli. Conclusion: Results suggest that the context of mouth sounds influences affective experiences in adults with misophonia, but also in participants without misophonia. Presentation of animal eating sounds with congruent visual stimuli, or human mouth smacking sounds with incongruent stimuli, decreased self-report reaction to common misophonic triggers.",
  "keywords": [
    "misophonia",
    "decreased sound tolerance",
    "psychophysiology",
    "experiment",
    "SCR",
    "HR",
    "context"
  ],
  "research_topics": [
    "misophonia",
    "psychophysiological responses",
    "auditory cognitive neuroscience",
    "affective and behavioral responses to sound",
    "context effects on sound perception",
    "skin conductance response",
    "heart rate response",
    "experimental psychology"
  ],
  "created_at": "2025-05-05T02:07:20.775827Z",
  "source_pdf": "documents/research/Global/Siepsiak 2023 Does context matter in misophonia a multi method experiemental investigation.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/366868278\nDoes context matter in misophonia? A multi-method experimental\ninvestigation\nArticle    in  Frontier s in Neur oscienc e · Januar y 2023\nDOI: 10.3389/fnins.2022.880853\nCITATIONS\n0READS\n31\n5 author s, including:\nSome o f the author s of this public ation ar e also w orking on these r elat ed pr ojects:\nGene tic and psy chosocial de terminants of male se xual orient ation and its neur al and c ognitiv e correlat es. View pr oject\nCreation and v alidation of a sc ale t o me asur e misophonia.  View pr oject\nMart a Siepsiak\nUniv ersity of W arsaw\n8 PUBLICA TIONS    82 CITATIONS    \nSEE PROFILE\nScott R V rana\nVirginia Commonw ealth Univ ersity\n113 PUBLICA TIONS    5,696  CITATIONS    \nSEE PROFILE\nWojciech Ł ukasz Dr agan\nJagiellonian Univ ersity\n54 PUBLICA TIONS    573 CITATIONS    \nSEE PROFILE\nAll c ontent f ollo wing this p age was uplo aded b y Mart a Siepsiak  on 05 Januar y 2023.\nThe user has r equest ed enhanc ement of the do wnlo aded file."
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 1\nTYPE Original Research\nPUBLISHED 04 January 2023\nDOI10.3389/fnins.2022.880853\nOPEN ACCESS\nEDITED BY\nChristian Füllgrabe,\nEar Institute, Faculty of Brain Sciences,\nUniversity College London,\nUnited Kingdom\nREVIEWED BY\nFalco Enzler,\nIndependent Researcher, Lausanne,\nSwitzerland\nNicolas Davidenko,\nUniversity of California, Santa Cruz,\nUnited States\nPhilippe Fournier,\nLaval University, Canada\n*CORRESPONDENCE\nMarta Siepsiak\nmarta.siepsiak@psych.uw.edu.pl\nSPECIALTY SECTION\nThis article was submitted to\nAuditory Cognitive Neuroscience,\na section of the journal\nFrontiers in Neuroscience\nRECEIVED 21 February 2022\nACCEPTED 30 November 2022\nPUBLISHED 04 January 2023\nCITATION\nSiepsiak M, Vrana SR, Rynkiewicz A,\nRosenthal MZ and Dragan WŁ (2023)\nDoes context matter in misophonia?\nA multi-method experimental\ninvestigation.\nFront. Neurosci. 16:880853.\ndoi: 10.3389/fnins.2022.880853\nCOPYRIGHT\n© 2023 Siepsiak, Vrana, Rynkiewicz,\nRosenthal and Dragan. This is an\nopen-access article distributed under\nthe terms of the Creative Commons\nAttribution License (CC BY). The use,\ndistribution or reproduction in other\nforums is permitted, provided the\noriginal author(s) and the copyright\nowner(s) are credited and that the\noriginal publication in this journal is\ncited, in accordance with accepted\nacademic practice. No use, distribution\nor reproduction is permitted which\ndoes not comply with these terms.Does context matter in\nmisophonia? A multi-method\nexperimental investigation\nMarta Siepsiak1*, Scott R. Vrana2, Andrzej Rynkiewicz1,\nM. Zachary Rosenthal3and Wojciech Łukasz Dragan4\n1Faculty of Psychology, University of Warsaw, Warsaw, Poland,2Virginia Commonwealth University,\nRichmond, VA, United States,3Department of Psychiatry and Behavioral Sciences, School\nof Medicine, Duke University, Durham, NC, United States,4Institute of Psychology, Jagiellonian\nUniversity, Kraków, Poland\nIntroduction: Misophonia is a recently deﬁned disorder in which certain\naversive repetitive sounds and associated stimuli elicit distressing and\nimpairing affective, behavioral, and physiological responses. The responses in\nmisophonia may be stronger when the sound is produced by close friends and\nfamily, suggesting that the context in which a triggering cue occurs may have\nan important role in misophonia. As such, the goal of this study was to test\nexperimentally whether the context of the sound source inﬂuences affective\nand psychophysiological responses to triggering stimuli in misophonia.\nMethods: Sixty one adults with misophonia and 45 controls listened to\naudio recordings (8 s) of human eating, animals eating, and human mouth\nsmacking sounds (without eating). After a break, the same audio recordings\nwere presented embedded within videos of human eating (congruent stimuli),\nanimals eating (congruent stimuli), and, in the mouth smacking condition, with\nvisually incongruent stimuli (hands playing in mud or in a bowl with a watery\ndough). Psychophysiological responses—skin conductance response (SCR)\nand heart rate (HR), and self-reported affective responses (valence, arousal,\ndominance) were gathered during the experiment in a laboratory.\nResults: Participants with misophonia assessed all the stimuli as more negative\nand arousing than the controls, and reported feeling less dominant with\nrespect to the sounds. Animal and mouth smacking sounds were assessed by\nall the participants as less negative and arousing than human eating sounds,\nbut only in the audio-video conditions. SCR data partially conﬁrmed increased\npsychophysiological arousal in misophonia participants during an exposure\nto mouth sounds, but did not reﬂect the self-report changes in response\nto different contexts. Misophonia participants had deeper deceleration of\nHR than controls during human eating sound with congruent video stimuli,\nwhile there was no group difference during human mouth smacking with\nincongruent video stimuli.\nConclusion: Results suggest that the context of mouth sounds inﬂuences\naffective experiences in adults with misophonia, but also in participants\nwithout misophonia. Presentation of animal eating sounds with congruent\nFrontiers in Neuroscience 01 frontiersin.org"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 2\nSiepsiak et al. 10.3389/fnins.2022.880853\nvisual stimuli, or human mouth smacking sounds with incongruent stimuli,\ndecreased self-report reaction to common misophonic triggers.\nKEYWORDS\nmisophonia, decreased sound tolerance, psychophysiology, experiment, SCR, HR,\ncontext\nIntroduction\nMisophonia is a newly deﬁned disorder in which selective\nrepetitive sounds or other associated stimuli elicit unpleasant\naﬀective, physiological, and behavioral responses that are\naccompanied by psychological distress and, over time, adversely\nimpact one’s quality of life (Brout et al., 2018; Jager et al.,\n2020; Swedo et al., 2022). Misophonic responses are triggered\nusually, but not exclusively, by oral or nasal human-made\nsounds (Schröder et al., 2013; Enzler et al., 2021; Vitoratou et al.,\n2021; Swedo et al., 2022). Findings across studies indicate that\nthe aﬀective responses most commonly are irritation, anger,\ndisgust, feeling trapped, anxiety, or rage (Schröder et al., 2013;\nRouw and Erfanian, 2018; Jager et al., 2020).\nSince misophonia was named and ﬁrst described by\nJastreboﬀ and Jastreboﬀ (2001), an unanswered empirical\nquestion is whether or to what extent misophonic responses are\nmoderated by the context in which the sound is experienced,\nsomething that has been observed in clinical settings (Jastreboﬀ\nand Jastreboﬀ, 2014). Researchers have called for studies to be\nconducted that help elucidate a comprehensive understanding\nof the mechanisms underlying responses to misophonic stimuli,\nsuch as the context of triggering sounds (Brout et al., 2018).\nAdditionally, the importance of context was identiﬁed in the\nrecent and ﬁrst consensus deﬁnition of misophonia (Swedo\net al., 2022).\nThe context of the sound can be deﬁned by actual\nenvironmental factors, such as sounds made by animals\ncompared to humans, or sounds made by a close\nrelative vs. a stranger.\nFor example, in Edelstein et al. (2013), participants with\nmisophonia reported that their reaction to a trigger sound\nwas stronger or limited to particular close friends or family\nmembers. Moreover, the majority of the participants in this\nstudy were not bothered by eating sounds produced by animals\nor babies. Jager et al. (2020) also reported that aﬀective responses\nmay not occur when a triggering sound is made by toddlers,\nadults with intellectual disabilities, or dementia suﬀerers.\nHowever, the context of the sound can also be modiﬁed by\nthe way one interprets or identiﬁes the source of the sound,\nand this phenomenon has also been investigated in recent\nresearch studies. Edelstein et al. (2020) employed experimental\nmanipulation of the sound source awareness. The authorsreported that not only the actual context (i.e., assessment of\nhuman-made sounds as being more aversive than animal-\nmade sounds), but also the perception of the source of the\nsound (human-made sounds assessed as being less aversive\nwhen identiﬁed as non-human made sound) can inﬂuence the\nmisophonic reaction. These data seem to indicate preliminarily\nthat both the actual eating sounds, as well as the belief about\nthe source of the sound may inﬂuence the misophonic reaction.\nSeveral case studies also have highlighted the possible role of\ncontext in responses reported by patients with misophonia\n(Johnson et al., 2013; Alekri and Al Saif, 2019; Natalini et al.,\n2020; Cecilione et al., 2021).\nOne way the role of context has been clinically explored\ninvolves modiﬁcation of a misophonic trigger for therapeutic\npurposes, wherein a study participant associated an eating\nsound with the sound of running in the snow to mitigate\na misophonic reaction to this sound (Schröder et al., 2017).\nA similar manipulation was reported by Frank and McKay\n(2019), in which one of the participants was instructed to listen\nto the trigger sounds while imagining that similar sounds could\nbe made by something diﬀerent (e.g., a gorilla or a motor). The\neﬃcacy of these particular manipulations remains unknown (for\nexample, modiﬁcation of the sound’s context was one of many\ninterventions that were used and it is not known which one\nwas the most eﬀective, and to what extent), however, they raise\ninteresting hypotheses about the possible ways in which the role\nof context modiﬁed on a cognitive level may inﬂuence reactivity\nto misophonic sounds.\nMost recently, several studies investigated the role of context\nand inﬂuence of cognitive processing of typical misophonic\nsounds on emotional reactions. Heller and Smith (2022) showed\nthat misidentiﬁcation of the sounds’ context (e.g., chewing food\nmisidentiﬁed as stirring cereal) decreased their “aversiveness”\nrating among people with and without misophonia. Results\npointing to the signiﬁcance of the cognitive assessment of\ncommon trigger sounds were also found by Savard et al.\n(2022). In this study, the 20% with the most severe misophonia\nsymptoms and the 20% with the least severe misophonia\nsymptoms from a group of 300 individuals sampled from the\ngeneral population were asked to assess and recognize sounds\npresented against multi-talker babble at various levels of signal-\nto-noise ratio. Both groups evaluated potential trigger sounds\n(orofacial) and unpleasant sounds (e.g., a child crying, dentist\nFrontiers in Neuroscience 02 frontiersin.org"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 3\nSiepsiak et al. 10.3389/fnins.2022.880853\ndrill) as signiﬁcantly more unpleasant than neutral sounds.\nMoreover, in the case of more favorable signal-to-noise ratios\ncondition, when the sounds were more identiﬁable, they evoked\nmore anger, disgust, and anxiety in all the participants. The\ndiﬀerence in sounds’ rating was more pronounced in the highest\nmisophonia symptoms group than in the lowest misophonia\nsymptoms group, and in the case of the highest misophonia\nsymptoms group the eﬀect size was yet larger for trigger sounds\nthan for unpleasant sounds.\nFurthermore, Samermit et al. (2022) showed that the same\npotential trigger sounds are less unpleasant when paired with\na video that is incongruent with the actual sound source,\nsuch as chewing sounds paired with a video of stepping\non snow. Thus, the perception of the sound’s context was\nmodiﬁed by experimentally manipulating the congruency\nbetween visual contextual cues and sounds triggers, impacting\naﬀective responses. In addition, a positive moderate correlation\nwas found between the diﬀerence in the pleasure rating in these\ntwo conditions and misophonia symptoms.\nNotably, the three latter studies examined adults from the\ngeneral population, with low and high misophonia symptoms\nassessed using online questionnaires. As a result, it is possible\nthat participants in these studies were not signiﬁcantly impaired\nby misophonia symptoms in everyday life, or could have\nother sound intolerance conditions, such as hyperacusis or\nphonophobia. For example, in Savard et al. (2022) only 6\nout of 66 participants from the group with high misophonia\nsymptoms met the cut-oﬀ for misophonia on the MisoQuest\n(Siepsiak et al., 2020). Similarly, in Samermit et al. (2022), 14\nout of 101 participants met the cut-oﬀ for moderate or higher\nimpairment misophonia on the Misophonia Questionnaire (Wu\net al., 2014). Therefore, the results should be replicated in people\nwith misophonia symptoms signiﬁcantly aﬀecting their lives,\nideally using clinical interviews as an assessment method in lieu\nof questionnaires.\nResponses to trigger sounds in misophonia suﬀerers have\nalso been studied using psychophysiological measures. Changes\nin heart rate (HR) and skin conductance response (SCR) are\nassociated with autonomic nervous system response to aﬀective\nstimuli (Levenson, 1992, 2014; Cacioppo et al., 2000). In the\nstudy by Edelstein et al. (2013), students with misophonia\nhad greater mean SCR while listening to misophonic trigger\nsounds (chosen individually for each of the participants) than\nstudents without misophonia. In addition, Kumar et al. (2017)\nfound that only human-made sounds, but not other aversive\nand neutral sounds, evoked SCR and HR increases and in\nmisophonia suﬀerers more than in controls. Similarly, in a study\nby Schröder et al. (2019), misophonic sounds elicited higher\nHR than aversive and neutral sounds in the misophonia group.\nThese results demonstrate that speciﬁc, repetitive sounds evoke\nautonomic responses in people with misophonia, consistent\nwith their self-reports. They are also in line with ﬁndings of\nincreased HR responses to extremely aversive stimuli.Phasic HR to a discrete stimulus is usually characterized by\nan initial deceleration that indicates orienting and information\nintake, followed by HR acceleration responsive to arousal and\naction readiness (Bradley et al., 2001; Witvliet and Vrana,\n2007). Negatively valent stimuli are particularly signiﬁcant and\noften produce a larger orienting response than neutral stimuli\n(Bradley et al., 2001). Cardiac deceleration to negative visual\nstimuli is especially large and sustained without subsequent\nacceleration unless the stimulus is extremely aversive, such as a\nperson with a severe phobia viewing a picture of a phobic object,\nor prolonged in duration. For example, Acute Stress Disorder\nand PTSD patients showed (Elsesser et al., 2004) acceleration of\nHR while viewing trauma-related pictures (notably, those with\nPTSD had slight initial HR deceleration), while deceleration\nof HR was observed in controls, whereas during exposure to\naversive, but not trauma-related, pictures, HR in both groups\ndecelerated. A slight deceleration followed by acceleration of\nHR in response to pictures related to injuries was also observed\nin war or torture survivors diagnosed with PTSD, whereas the\nhealthy controls and trauma resilient survivors showed steep\nand deep HR deceleration, followed by slow return toward\nthe baseline level (Adenauer et al., 2010). In a study by\nRosenbaum et al. (2020), where the stimuli lasted longer, spider\nphobia patients had higher mean HR during a presentation of\nspider pictures than during pictures of domestic animals, while\nthis change was not observed in controls. In a similar study\n(Wannemüller et al., 2015), participants with dental phobia had\nacceleration of HR while being exposed to pictures and noises\nrelated to their phobia, and deceleration of HR during exposure\nto neutral stimuli, whereas deceleration of HR during exposure\nto all the stimuli was observed in controls. SCR, like initial HR\ndeceleration, is responsive to orienting and information intake,\nand is often observed in response to arousing stimuli, whether\nnegative or positive (e.g., dangerous or threatening stimuli, but\nalso erotic, sport-related, or funny stimuli; Bradley et al., 2001;\nBos et al., 2013; Nigbur and Ullsperger, 2020).\nThe primary goal of the present study was to investigate\nwhether the context, either set by environmental factors (human\nvs. animal-made sounds) or by manipulation of the sound’s\nsource (congruent vs. incongruent visual stimuli) inﬂuences\nself-report and psychophysiological responses to common\nmisophonic stimuli in a misophonia and a control group.\nMouth sounds were presented either as an auditory cue\nalone or, in audio-video condition, with a congruent video\n(human or animal eating sounds) or with an incongruent\nvideo (human mouth smacking sounds presented against videos\nof human hands).\nThe misophonic response was assessed via self-report\non the three primary dimensions of emotional evaluation\n(Mehrabian and Russell, 1974): valence (pleasure-displeasure),\narousal (arousal-relaxation), and control (dominance-\nsubmission). Physiological reaction was assessed with phasic\nHR and SCR.\nFrontiers in Neuroscience 03 frontiersin.org"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 4\nSiepsiak et al. 10.3389/fnins.2022.880853\nIt was hypothesized that:\n(1) Compared to a healthy control group of adults, the\nmisophonia group would assess all stimuli as more negative,\nmore arousing, and as feeling less dominant toward them than\nthe controls, regardless of context;\n(2) Higher SCR and less pronounced deceleration of HR\nwould be observed in people with misophonia in response to all\nstimuli, in comparison to the control group;\n(3) In the audio-video condition (but not in the audio\ncondition) the misophonia group would assess animal sounds\n(congruent) and human mouth smacking sounds (incongruent)\nas less negative, less arousing, and as feeling more dominant\ntoward them than toward humans eating sounds (congruent),\nwhereas this eﬀect would not be observed in the control group;\n(4) In the audio-video condition (but not in the audio\ncondition), the misophonia group would have reduced HR\nresponse (deeper or more sustained deceleration) and SCR (i.e.,\nSCR will be lower) in response to animal (congruent), and\nhuman mouth smacking sounds (incongruent) than in response\nto the human eating sounds (congruent), whereas this eﬀect\nwould not be observed in controls;\n(5) Presenting the sounds with videos will decrease the\nrating of negative valence, decrease arousal, and increase the\ndominance in the misophonia group in response to animal-\nmade sounds (congruent) and human mouth smacking sounds\n(incongruent), but not to human eating sounds (congruent).\nThis eﬀect will not be observed in the control group;\n(6) Presenting the sounds with videos will reduce HR\nreaction (deeper or more sustained deceleration) and SCR\nresponses (SCR will be lower) in comparison to the audio\ncondition in the misophonia group in response to animal-\nmade sounds (congruent) and human mouth smacking sounds\n(incongruent), but not to human eating sounds, whereas this\neﬀect will not be observed in controls.\nMaterials and methods\nThe Ethics Committee at the Faculty of Psychology,\nUniversity of Warsaw (no. 29/05/2018) approved this study.\nThis study was a part of a larger parent misophonia project\nconducted at this university.\nParticipants\nThe study was advertised in social media, radio, local\nand online news (the language included: Do certain sounds\ndrive you mad? Can you not stand some particular sounds?\nOr maybe you do not have any sound over-responsivities? ).\nIndividuals willing to take part in the study completed the\nonline recruitment questionnaire, indicated whether they had\nany sound sensitivities, completed a questionnaire to assessmisophonia (MisoQuest; Siepsiak et al., 2020), and provided\ndemographic and contact information for study scheduling.\nA total of 131 people participated in the experiment, and the\ndata of 106 participants who met the criteria for the group\ninclusion were analyzed: 61 participants with misophonia and\n45 healthy controls without any sound over-responsivity took\npart in the study. Individuals with heart disease, substance\naddiction, or facial hair (as we collected facial EMG data for\nanother study, not described here) were excluded from the\nstudy. Participants were asked to avoid caﬀeine or energy drinks\n3 h before the experiment. They signed an electronic version of\nconsent and were remunerated with 50 PLN (12.5 USD).\nBecause the age distribution in both groups was right-\nskewed, in order to compare whether there were age diﬀerences\nbetween the groups, a U Mann-Whitney test was conducted.\nThere was a signiﬁcant age diﬀerence between misophonia\n(Mdn1=30;range: 19–55) and controls ( Mdn =23; range: 19–\n45), U= 757.50, z=\u00003.468, p<0.001. In order to compare\nthe gender ratio between the groups, a Chi-Square test was\nconducted. There were signiﬁcantly [( x2= 1; N= 105) = 3.95;\np= 0.047] more females in the misophonia group (90%) than in\nthe control group (76%).\nMisophonia assessment and the\ncontrol group assignment\nEach of the invited participants was assessed by\npsychologists trained in assessment of misophonia to conduct\nface-to-face interviews. Misophonia assessment for group\ninclusion was based on criteria proposed by Schröder et al.\n(2013). Speciﬁc eligibility criteria included: (a) experiencing\nimmediate psychophysiological reaction in response to human\nproduced oral or nasal sounds, (b) recognizing anger as\na dominant (but not necessarily sole) emotion evoked by\nthese sounds, and not fear or anxiety, (c) perceiving these\nemotions as excessive and overwhelming (d) avoiding exposure\nto these sounds, and in case of being exposed—reporting a\nsigniﬁcant distress caused by these sounds, (e) reporting a\nsigniﬁcant decrease in quality of life due to this sound over-\nresponsivity. Eligibility for the control group was to report\nnot having any sound over-responsivity. Participants who\nduring the interview reported being occasionally bothered\nby sounds that are commonly perceived as unpleasant, (e.g.,\nstyrofoam sounds or sounds of sliding a fork over a plate)\nwere included in the control group. Furthermore, participants\nwho reported that they disliked eating sounds but never\nbelieved it was a problem for them were included in the\ncontrol group. Participants with a variety of auditory over-\nresponsivities (25 individuals) signiﬁcantly aﬀecting their\n1 Median.\nFrontiers in Neuroscience 04 frontiersin.org"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 5\nSiepsiak et al. 10.3389/fnins.2022.880853\nlives who did not meet the misophonia criteria were not\nconsidered misophonia participants, so their data were not\nanalyzed (e.g., participants with presumed hyperacusis or those\nwhose main triggers were neighbor sounds, snoring, siren or\nbarking sounds, or those whose main emotion when exposed\nto their trigger was fear or anxiety, not anger or extreme\nirritation).\nAdditionally, the validity of group inclusion was\nconﬁrmed with a questionnaire for assessing misophonia—\nMisoQuest, administered online at the time of participants’\nrecruitment, a 14-item questionnaire with good reliability\n(Cronbach’s alpha = 0.95) and stability (intraclass\ncorrelation coeﬃcient = 0.84; Siepsiak et al., 2020). The\nresults of Welch’s t-test indicated a signiﬁcant diﬀerence\n[t(53.122) = 13.554; p<0.001; Cohen’s d= 2.81] in the\nseverity of misophonia symptoms between misophonia\n(n= 61; M= 64.57; SD = 4.9; range: 44—70) and\ncontrols ( n= 45; M= 36.71; SD = 13.13; range: 14—\n59). Because the data from MisoQuest were not normally\ndistributed according to Shapiro-Wilk Test [ W(59) = 0.832,\np<0.001] but there was a normal distribution in the\ncontrol group [ W(43) = 0.960, p= 0.136], and the number\nof observations in each group was >20, it was decided\nto use a parametric test, with a correction for unequal\nvariances (Schmider et al., 2010; Blanca et al., 2017;\nGeorge and Mallery, 2019).\nBehavioral measurement\nSelf-reported aﬀective responses were assessed with the\nSelf-Assessment Manikin scales (Bradley and Lang, 1994).\nThese are pictorial scales for assessing aﬀective response to\nstimuli. It allows for measurement of three dimensions of\nemotions– valence, arousal, and dominance–each on a 1–5\nscale. Each scale is depicted in Figures 1 –3. The instruction\n(Imbir, 2016, p. 3) that was used in our study for the valence\nrating, was as follows: “The ﬁrst picture shows a person who\nis obviously elated—relevant experiences could include fun,\ndelight, happiness, relaxation, satisfaction, or repose. The last\npicture shows a person who is clearly distressed—relevant\nexperiences could include panic, irritation, disgust, despair,\ndefeat, or crisis. The remaining pictures depict intermediate\nstates.”\nFor the dominance (Imbir, 2016, p. 3): “The ﬁrst picture\nshows an individual who feels a lack of control and agency—\nrelevant states could include subordination, intimidation,\nsubjugation, withdrawal, submission, or resignation. The\nlast picture shows a person who is dominant and in\ncontrol of the situation—relevant states include control,\ninﬂuence, being important, dominant, recognized, or\ndecisive.” For arousal (Imbir, 2016, p. 3): “The ﬁr pictureshows an individual who is very calm, almost sleeping—\nrelevant states could include relaxation, tranquility, idleness,\nmeditation, boredom, or laziness. The last picture shows an\nindividual who is bursting in arousal—relevant states could\ninclude excitation, euphoria, excitement, rage, agitation, or\nanger.”\nPsychophysiological measurements\nGalvanic skin response (GSR) and electrocardiography\n(ECG) were recorded with the BIOPAC MP-150 system through\nAcqKnowledge software. For GSR measurement, the EDA100C\nampliﬁer was used. The Ag-AgCl electrodes ﬁlled with dedicated\ngel were placed on the distal phalanges of the index and middle\nﬁnger of the non-dominant hand. SCR level was measured with\n5 mikroS/V gain and recorded at the rate of 2,000 samples\nper second. We decided to use as weak hardware ﬁlters as\npossible (no high-pass and 10 Hz low-pass) and then after\nvisual inspection we noticed that oﬄine software ﬁlters were\nnot necessary. The SCL data were visually inspected for artifacts\nin AcqKnowledge, and then preprocessed in Matlab. Further\nstatistical analyses were made in IBM SPSS Statistics 28. The\nperiod of 1-s before the onset of the main stimuli served as\na baseline and was subtracted from eight 1-s periods after the\nonset of the stimuli—thus the SCR was obtained. Therefore, the\nnegative values in SCR indicate the decrease in skin conductance\nlevel (SCL) in relation to the baseline.\nFor ECG, we used the ECG100C and a 3-lead arrangement\nof electrodes, which provides a clear shape of the ECG waveform\nand does not require removing the upper part of clothing. Two\nactive electrodes were attached on the sides of the chest, and an\ninactive electrode was attached at the lower part of the sternum.\nSelf-adhesive Ag/AgCl electrodes and standard ECG gel were\nused. Similar to SCL measurement, we limited hardware ﬁlters\nto minimum (150 Hz low-pass and 0.05 Hz high-pass). Each\nof the HR data recordings was visually inspected for artifacts\nin Acqknowledge, followed by preprocessing in the Matlab\nenvironment—no additional software ﬁlters were necessary to\nidentify R-waves correctly. All statistical analyses were made\nin IBM SPSS Statistics 28. In order to check whether heart\nrate phasic response to stimuli diﬀers between the groups,\nthe average HR was calculated separately for 8 post-trigger 1-\ns periods using the standard method to derive HR from a\nmeasurement lasting less than a minute (Berntson et al., 2016).\nHR during the 1-s before the trigger was then subtracted from\nHR of each second after the trigger onset in order to create\nchange scores.\nStimuli and apparatus\nFive audio recordings and ﬁve audio-video recordings\nwith the same sounds—three movies from YouTube (ASMR\nFrontiers in Neuroscience 05 frontiersin.org"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 6\nSiepsiak et al. 10.3389/fnins.2022.880853\nFIGURE 1\nValence rating (mean values) of the stimuli in audio and audio-video conditions in misophonia and the control group, separately for the analysis\n(A)and the analysis (B). Higher valence ratings indicate greater negative emotions. The distances between the scale values were identical (it is a\nlinear scale).\nSuna, 2018; Mayapolarbear, 2019; SAS-ASMR, 2019) and two\nrecorded by the ﬁrst author of the study served as stimuli:\nhuman eating, animal eating, and human mouth smacking\nsounds, without involving food inside (these stimuli aimed\nto be equivalent to human eating sounds- not having food\ninside the mouth while recording the audio sounds was\nunintentional). In the ﬁrst condition only the audio cues were\nused. In the second condition, the sounds were presented\neither with a congruent video (animal eating videos and human\neating video) or with incongruent videos of hands playing\nin mud or in watery dough, synchronized with the sounds.\nThe incongruent video aimed to modify the context of the\nsound. Initially, 6 stimuli were planned, but due to technical\nissues, one of the two human eating stimuli was presented\nto fewer than half of the participants and was not analyzed.\nTherefore, in further analysis, average values from 2 animal-\neating stimuli and 2 human mouth smacking stimuli rating\nand responses were analyzed. The procedure was displayed\nin PsychoPy (Peirce et al., 2019) and programmed in Python\nlanguage (Van Rossum and Drake, 1995). The markers were\nsent to Acqknowledge software through a parallel port.Procedure\nThe participants sat on a chair in front of a computer with\nspeakers and a keyboard in an air-conditioned room. During\nthe experiment, they were alone. Before the experiment started,\nthe research assistants placed the electrodes and explained the\nprocedure. The participants were told that sounds or videos\nwith sounds would be presented to them. Participants were\ninformed that the sounds and videos could be neutral, aversive,\nor pleasant, depending on the individual’s preferences, and that\nthey could press a security button or switch oﬀ the sound to stop\nthe experiment immediately. They were asked to assess their\nfeelings in response to the sounds and videos on the pictorial\nscales (see “Behavioral measurement” section). The answers\nwere given after each single stimulus, by typing numbers, from\n1 to 5, on the computer keyboard. The description of the\npictorial scales was also displayed on the computer screen at\nthe beginning of the experiment. The stimuli were displayed\nafter the answers were given, so there was no time limit\nto give an answer.\nFrontiers in Neuroscience 06 frontiersin.org"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 7\nSiepsiak et al. 10.3389/fnins.2022.880853\nFIGURE 2\nArousal rating (mean values) of the stimuli in audio and audio-video conditions in misophonia and the control group, separately for the analysis\n(A)and the analysis (B). Lower arousal ratings indicate greater arousal. The distances between the scale values were identical (it is a linear scale).\nBefore the experiment began, there was a 5-min resting\nbaseline period. The participants were asked to relax in the chair\nin front of a blank screen, and the level of psychophysiological\nsignals was recorded and sent to Acqknowledge software\nthrough Biopac System. The sounds were presented under\nspeakers, at the volum similar to eating sounds in real\nlife, the same for each participant. During the ﬁrst part\nof the experiment (A), participants listened to the audio\nrecordings (animal eating sounds, human eating sound, and\nhuman mouth smacking sounds). They did not receive any\ninformation from the experimenter regarding the source\nof the sounds. In the second part (B), after a break for\nother tasks (a questionnaire for assessing temperamental\ntraits and another experiment with audio-video that are not\ndescribed in this paper), the participants were presented with\nthe same stimuli, but this time the audio recordings were\naccompanied by videos (congruent animals eating videos,\ncongruent human eating video, and incongruent to human\nmouth smacking sounds—video of hands). Each of the stimuli\n(of 8-s duration) was presented once, in a randomizedorder. Between each stimulus, there was an interstimulus\ninterval—a black ﬁxation cross displayed in the center of\nthe white screen, with a duration of 8, 10, and 12 s,\nselected randomly.\nResults\nBehavioral data\nThe data were analyzed in IBM SPSS Statistics 28. Visual\ninspection of box plots revealed one outlier (in the control group\nvalence assessments of the animal-eating sound in the audio-\nvisual condition), which did not impact the results, so was not\nremoved. Levene’s test was non-signiﬁcant in all cases, except for\nthe Arousal assessment in human eating sounds in the audio-\nvideo condition ( p= 0.007; Equality of Covariance Matrices\np= 0.002). In order to explore whether the type of visual\ninformation about source of the sounds has an inﬂuence on the\nFrontiers in Neuroscience 07 frontiersin.org"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 8\nSiepsiak et al. 10.3389/fnins.2022.880853\nFIGURE 3\nDominance rating (mean values) of the stimuli in audio and audio-video conditions in misophonia and the control group, separately for the\nanalysis (A)and the analysis (B). Higher dominance ratings indicate greater dominance. The distances between the scale values were identical (it\nis a linear scale).\nemotional reaction, separate mixed ANOV As2were conducted\non the participants’ ratings of valence, arousal, and dominance,\nwith (a) Group (misophonia, control), Stimuli (human, animal),\nand Presentation (audio, audio-video) as variables, with the\nlatter two being repeated measures to test the hypothesis\nof the eﬀect of adding congruent visual information on the\nactual sound’s sources and (b) Group (misophonia, control),\nStimuli (human eating, human mouth smacking sounds), and\nPresentation (audio, audio-video) to test the hypothesis of the\neﬀect of presenting an actual human mouth smacking sounds\nwith incongruent video.\n2 There are no non-parametric tests for interaction, and this procedure\nwas needed to test hypotheses in this study. Therefore, due to\nevidence for the adequacy and robustness of ANOVA in case of non-\nnormally distributed data (Schmider et al., 2010; Blanca et al., 2017;\nGeorge and Mallery, 2019), ANOVAs are presented despite non-normal\ndistributions of the data. However, when the data from parametric and\nnon-parametric tests differed, additionally, non-parametric results are\npresented for the speciﬁc comparisons.When the sphericity assumption was not met, Greenhouse-\nGeisser corrected degrees of freedom and epsilon values were\nreported. Bonferroni post-hoc tests with correction for multiple\ncomparisons were conducted.\nValence\nIn the analysis involved human eating congruent stimuli and\nanimal eating congruent stimuli, participants with misophonia\nreported the sounds (an average across conditions) overall\nas more negative ( M= 3.85, SE= 0.09) than did controls\n(M= 3.00, SE= 0.11), Group F(1, 104) = 38.41, p<0.001;\n!2p= 0.27. There was no interaction between the Group\nand other variables.3There was an interaction of Stimuli\n\u0002Presentation F(1, 104) = 17,95, p<0.001; !2p= 0.15.\nPairwise comparison showed that while there was no diﬀerence\n3 Due to an exploratory character of the study, even when no Group\ninteractions were found, in case of all the analyses the interactions with\nStimuli and Presentations were tested, in order to check in what way the\ncontext of the sounds impacted both of the groups.\nFrontiers in Neuroscience 08 frontiersin.org"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 9\nSiepsiak et al. 10.3389/fnins.2022.880853\nbetween the stimuli in the audio condition ( p= 0.777),\nin audio-video condition, and human eating ( M= 3.64,\nSE= 0.074) was assessed as signiﬁcantly more negative than\nanimal eating ( M= 2.86, SE= 0.11), p<0.001. Moreover,\nwhile there was no diﬀerence in the human eating rating\nbetween audio and audio-video conditions ( M= 3.65, SE= 0.09\nvs.M= 3.48, SE= 0.1, p= 0.088), animal-made sounds\nwere assessed as more positive in the audio-video condition\n(M= 2.86, SE= 0.11, p<0.001) than in the audio condition\n(M= 3.64, SE= 0.07), p<0.001. The data are illustrated in\nFigure 1A .\nIn the analysis of human eating congruent stimuli and\nhuman mouth smacking incongruent stimuli, participants with\nmisophonia also reported the sounds overall as more negative\n(M= 3.9, SE= 0.09) than did controls ( M= 3.1, SE= 0.10),\nGroup F(1, 104) = 35.18, p<0.001; !2p= 0.25. There was\nno interaction between the Group status and other variables.\nThere was an interaction of Stimuli \u0002Presentation F(1,\n104) = 5,831, p= 0.017; !2p= 0.053. Pairwise comparison\nshowed that while there was no diﬀerence between the stimuli\nin the audio condition ( p= 0.87), in the audio-video condition\nhuman eating congruent stimuli ( M= 3.67, SE= 0.08)\nwere assessed as signiﬁcantly more aversive than human\nmouth smacking incongruent stimuli ( M= 3.2, SE = 0.09),\np= 0.005. Moreover, while there was no diﬀerence in the\nhuman eating rating between audio and audio-video conditions\n(p= 0.09), human mouth smacking sounds were assessed\nas less negative in the incongruent audio-video condition\n(M= 3.2, SE= 0.09), compared to the audio condition\n(M= 3.67, SE= 0.08), p<0.001. The data are illustrated in\nFigure 1B .\nArousal\nIn the analysis examining human eating congruent\nstimuli and animal eating congruent stimuli, participants\nwith misophonia found the sounds overall as more arousing\n(M= 2.42, SE= 0.11) than did controls ( M= 3.18, SE= 0.13),\nGroup F(1, 104) = 20.918, p<0.001; !2p= 0.1 (lower value\nmeans higher arousal). There was no interaction between the\nGroup and other variables.\nThere was an interaction of Stimuli \u0002Presentation F(1,\n104) = 4.342, p= 0.04; !2p= 0.04. While there was no diﬀerence\nin arousal during the human eating rating between audio and\naudio-video conditions ( M= 2.7, SE= 0.12 vs. M= 2.81,\nSE= 0.12, p= 0.318), animal-eating sounds were assessed as\nless arousing in the audio-video condition ( M= 3.05, SE= 0.1,\np<0.001) than in the audio condition ( M= 2.64, SE= 0.1),\np<0.001. Nonetheless, there was neither a diﬀerence in\narousal self-report between the stimuli in the audio condition\n(p= 0.539), nor in audio-video condition ( p= 0.059). The data\nare illustrated in Figure 2A .\nIn the analysis examining human eating congruent stimuli\nand human mouth smacking incongruent stimuli, participantswith misophonia also reported the sounds overall as more\narousing ( M= 2.41, SE= 0.11) than did controls ( M= 3.2,\nSE= 0.13), Group F(1, 104) = 21.37, p<0.001; !2p= 0.17. There\nwas an interaction of Stimuli \u0002Presentation F(1, 104) = 7.08,\np<0.009; !2p= 0.06. Pairwise comparison showed that while\nthere was no diﬀerence between the stimuli in the audio\ncondition ( p= 0.35), in the audio-video condition, congruent\nhuman eating ( M= 2.81, SE= 0.12) was assessed as signiﬁcantly\nmore arousing than incongruent human mouth smacking\nsounds ( M= 3.09, SE= 0.11), p= 0.016.\nMoreover, while there was no diﬀerence in arousal during\nthe human eating rating between audio and audio-video\nconditions ( p= 0.318), human mouth smacking sounds were\nassessed as less arousing in the incongruent audio-video\ncondition ( M= 3.09, SE= 0.11), than in audio condition alone\n(M= 2.61, SE= 0.09), p<0.001. The data are illustrated in\nFigure 2B .\nDominance\nIn the analysis involved human eating congruent and\nanimal eating congruent stimuli, participants in the control\ngroup reported feeling more dominant with respect to the\nsounds ( M= 3.26, SE= 0.12) than participants in the\nmisophonia group ( M= 2.5, SE= 0.1), F(1, 104) = 24.119,\np<0.001, !2p= 0.19. There was neither an interaction\nbetween Stimuli \u0002Presentation nor an interaction between\nGroup status and other variables. The data are illustrated in\nFigure 3A .\nIn the analysis of human eating congruent and human\nmouth smacking incongruent stimuli, participants in the control\ngroup reported feeling more dominant with respect to the\nstimuli ( M= 3.26, SE= 0.12) than participants in the\nmisophonia group ( M= 2.45, SE= 0.1), F(1, 104) = 25.861,\np<0.001, !2p= 0.2. There was no interaction between\nStimuli \u0002Presentation, but there was an interaction of Group\nstatus, Stimuli, and Presentation F(1, 104) = 4,32, p<0.04,\n!2p= 0.04. Whereas in controls, there was no diﬀerence in\nfeelings of dominance between Stimuli in the audio nor in the\naudio-video condition ( p= 0.114; p= 0.77), participants with\nmisophonia reported the same level of feeling dominant toward\nthe sounds in the audio condition ( p= 0.33), but when the\nstimuli were presented with videos, they felt more dominant in\nthe case of incongruent mouth smacking sounds than during\ncongruent human eating sounds ( M= 2.33, SE= 0.13 vs.\nM= 2.8, SE= 0.12), p= 0.016. The data are illustrated in\nFigure 3B .\nPsychophysiological data\nAlthough the physiological data were not distributed\nnormally, a parametric mixed ANOV A was performed with\nGroup (misophonia vs. control) as a between-subjects factor\nFrontiers in Neuroscience 09 frontiersin.org"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 10\nSiepsiak et al. 10.3389/fnins.2022.880853\nand Time (eight 1-s periods), Presentation (audio, audio-\nvideo), and Stimuli (human eating, animal eating) as within\nsubjects’ factors, to test the eﬀect of adding visual information\nto the actual sound’s source (congruent stimuli) on the\npsychophysiological reaction. Additionally, a similar mixed\nANOV A was conducted with Group (misophonia vs. control)\nas a between-subjects factor and Time (eight 1-s periods),\nPresentation (audio, audio-video), and Stimuli (human eating,\nhuman mouth smacking) as within subjects’ factors, in order\nto examine whether presenting an actual human mouth\nsmacking with an incongruent cue had an inﬂuence on the\npsychophysiological reaction.\nWhen the sphericity assumption was not met, Greenhouse-\nGeisser corrected degrees of freedom and epsilon values\nwere reported. Bonferroni post hoc tests with correction for\nmultiple comparisons were conducted. These analyses were\nmade separately for HR and SCR data.\nHeart rate\nBecause the cardiac responses of 10 participants were of\nlow quality or not recorded due to technical errors, the data\ngathered from 55 participants with misophonia and 42 controls\nwere analyzed. There were no main group eﬀects in either\nof the two analyses described above as (a) and (b), which\nmeans that we could not conﬁrm the diﬀerence in the HR\nreaction to the stimuli between people with misophonia and\ncontrols. mean HR changes (bpm) separately for misophonia\nand controls, two kinds of presentations (audio and Audio-\nVideo), and for two separate analyses (a and b) can be seen in\nFigure 4 .\nIn the analysis with human eating (congruent), animal\neating (congruent), and Time as within subject’s factors,\nonly a Time eﬀect4was found F(3.26, 309.84) = 33.3,\np<0.001, !2= 0.26, += 0.47. Pairwise comparisons\nindicated a deceleratory HR response to the stimuli, with\nHR dropping ( M=\u00000.708, SE= 0.34) until the seventh\nsecond ( M=\u00004.21, SE= 0.489). There was a signiﬁcant\ndiﬀerence between 2 consecutive periods: 2nd vs. 3rd second\n(M=\u00001.54, SE = 0.387 vs. M=\u00002.52, SE = 0.41;\np= 0.006) and 3rd vs. 4th second ( M=\u00003.12, SE= 0.48;\np= 0.045).\nIn the analysis with human eating (congruent), human\nmouth smacking (incongruent), and Time as within subjects’\nfactors, the Time eﬀect also showed decelatory HR response\nF(2.67, 250.54) = 49, p<0.001, !2= 0.34, += 0.38. Pairwise\ncomparisons showed that HR was dropping ( M=\u00000.905,\nSE= 0.31) until 8 s ( M=\u00004.34, SE= 0.38). There was a\nsigniﬁcant diﬀerence between 3 consecutive periods:1st vs. 2nd\nsecond ( M=\u00000.905, SE= 0.31 vs. M=\u00001.37, SE= 0.31;\n4 Due to an exploratory character of this study, in spite of no Group\neffects, additional interactions were tested in order to check the direction\nof HR changes across Time.p= 0.005), 2nd vs. 3rd second ( M=\u00002.870, SE= 0.34;\np<0.001), and 3rd vs. 4th second ( M=\u00003.57, SE= 0.41;\np= 0.009).\nWe also found a signiﬁcant interaction of Group, Stimuli,\nPresentation, and Time F(2.95, 277.63) = 3.001, p= 0.032,\n!2p= 0.031, += 0.422. Pairwise comparisons showed\nthat misophonia participants had signiﬁcantly deeper HR\ndeceleration than controls in the audio-video human eating\ncondition in the 2nd ( M=\u00003.08, SE= 0.714 vs. M=\u00000.242,\nSE= 0.83, p= 0.011), the 3rd ( M=\u00004.28, SE= 0.78 vs.\nM=\u00001.19, SE= 0.9, p= 0.011), and the 4th second ( M=\u00005.28,\nSE= 0.84 vs. M=\u00001.95, SE= 0.97, p= 0.011), while there was\nno diﬀerence between the groups in the human mouth smacking\nincongruent stimuli in the audio-video condition. There was\nno Group diﬀerence in the audio condition. A non-parametric\nMann Whitney’s U-test conﬁrmed the group diﬀerence in the\n2nd second ( Mdn =\u00002.25, n= 55 vs. Mdn =\u00000.75, n= 42),\nU= 780.50, z=\u00002.73, p= 0.006, and in the 3rd second\n(Mdn =\u00003.67, n= 55 vs. Mdn =\u00001.33, n= 42), U= 869.5,\nz=\u00002.08, p= 0.038. Similar analysis showed only a statistical\ntendency in the 4th second ( p= 0.088).\nSkin conductance response\nAs data from several participants had to be excluded due\nto recording errors, the results from 54 participants with\nmisophonia and 41 controls were analyzed.\nThere was no Group main eﬀect in the analysis of human\neating (congruent) and animal-eating (congruent) stimuli\n(p= 0.344), nor in the analysis of human eating (congruent)\nand human mouth smacking (incongruent) stimuli ( p= 0.115).\nIn the analysis with human eating (congruent), animal eating\n(congruent), and Time as within subject’s factors, there was\nan interaction of Group, Time, and Presentation, F(2.66,\n255.28) = 2.81; p= 0.046, !2= 0.028, += 0.380, showing that\nmisophonia participants ( M= 0.04, SE= 01) had higher SCR\nthan controls ( M= 0.003, SE= 0.012; p= 0.023) in the 8th second\nin the audio condition. However, non-parametric tests, which\nwere additionally conducted due to non-normal distribution of\nthe data, did not conﬁrm this diﬀerence. A Mann Whitney’s\nU-test indicated that there was no signiﬁcant diﬀerence between\nmisophonia and controls, U= 930.00, z=\u00001.766; p= 0.077.\nIn the analysis of human eating (congruent) and human\nmouth smacking (incongruent) an interaction of Time and\nGroup was found F(1.89, 176.02) = 4.69; p= 0.012, !2= 0.048,\n+= 0.270, indicating that participants with misophonia had\nsigniﬁcantly higher SCR than controls in the 6th ( M= 0.022,\nSE= 0.007 vs. M= 0.002, SE= 0.008), 7th ( M= 0.017, SE= 0.007\nvs.M=\u00000.009, SE= 0.008) and 8th ( M= 0.012, SE= 0.007\nvs.M=\u00000.016, SE= 0.008) second, as can be seen in Figure 5 .\nA Mann Whitney’s U-test did not conﬁrm the diﬀerence in the\n6th second ( p= 0.162) and indicated only statistical tendency in\nthe 8th second ( p= 0.060) but conﬁrmed the diﬀerence in the\nFrontiers in Neuroscience 10 frontiersin.org"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 11\nSiepsiak et al. 10.3389/fnins.2022.880853\nFIGURE 4\nMean HR changes (bpm) separately for misophonia and controls and two kinds of presentations (audio and audio-video), and for two separate\nanalyses (A,B) .\nFrontiers in Neuroscience 11 frontiersin.org"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 12\nSiepsiak et al. 10.3389/fnins.2022.880853\nFIGURE 5\nSCR means separately for misophonia and controls, and for two separate analyses (A,B) .\n7th second ( Mdn = 0.0035, n= 54 vs. Mdn =\u00000.0007, n= 41),\nU= 815, z=\u00002.194, p= 0.028.\nDiscussion\nThis study aimed to examine whether the context of the\nsound will aﬀect the misophonic response. As hypothesized,\nthe manipulations of the context of the sounds inﬂuenced theself-reported misophonic reaction. Nonetheless, among non-\nmisophonic participants, similar eﬀects were observed (with an\nexception for dominance rating). Although such a result does\nnot support a part of our hypothesis which states that the eating\nsound’s context will not aﬀect the control group, it is in line\nwith three studies (Heller and Smith, 2022; Samermit et al., 2022;\nSavard et al., 2022) published after our study had begun, showing\nthat the same orofacial or unpleasant sounds are assessed more\npositively when perceived or presented as something else, in\nFrontiers in Neuroscience 12 frontiersin.org"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 13\nSiepsiak et al. 10.3389/fnins.2022.880853\nparticipants without misophonia as well. In our study, however,\ncontrols, on average, assessed stimuli as neutral to somewhat\npositive in the audio-video condition. It could be assumed that\na dog eating a watermelon or a pig eating from a human hand\ncould be viewed as humorous. Participants with misophonia\nrated all these sounds as negative, or slightly negative (in case of\nanimal eating and human mouth smacking sounds), even when\nthe sounds were presented with videos.\nNot surprisingly, participants with misophonia assessed\nall misophonic sounds as more negative and arousing, and\nassessed feeling less dominant with respect to sounds compared\nto healthy control participants without misophonia, which\nsupports the ﬁrst hypothesis and is consistent with previous\nstudies and descriptions of misophonia (e.g., Edelstein et al.,\n2013; Brout et al., 2018; Swedo et al., 2022). It also conﬁrms\nan adequate group assignment based on the face-to-face\nmisophonia interview. Additionally, proper group assignment\nwas conﬁrmed by the signiﬁcant diﬀerences in MisoQuest\noutcomes between the two groups.\nThe results of the study are consistent with the role of\ncontext of the sounds on evaluation of misophonia trigger\nsounds found in other studies (Frank and McKay, 2019;\nEdelstein et al., 2020; Natalini et al., 2020; Wiese et al., 2021;\nCowan et al., 2022; Heller and Smith, 2022; Samermit et al.,\n2022; Savard et al., 2022). Put simply, the misophonic reaction is\nreduced when it is perceived as something apart from a human\nmouth sound. In our study, when people with misophonia (and\ncontrols as well) were not told the source of the sounds they\nwere listening to (i.e., in the audio condition), there was no\ndiﬀerence between human eating, human mouth smacking and\nanimal eating sounds on the self-report valence rating. However,\nwhen exposed to the same sounds in the audio-video condition,\nsounds made by animals (congruent) and human smacking\nsounds shown as being made by human hands (incongruent)\nwere rated as signiﬁcantly less negative than human eating\nsounds (congruent). Moreover, while there was no diﬀerence in\nthe valence rating between the same (congruent) human eating\nsound in the audio and audio-video conditions, presenting\nthe human mouth smacking with incongruent visual stimuli\nsigniﬁcantly decreased negative aﬀect and arousal. Similarly, in\nthe case of animal-eating sounds, exactly the same sounds were\nassessed as less negative and less arousing when presented with\nvideo of congruent stimuli. Moreover, people with misophonia\nreported feeling more dominant toward the smacking mouth\nsounds with incongruent visual stimuli than toward human\neating sound presented with congruent stimuli, while this eﬀect\nwas not observed in controls. Thus, the third and the ﬁfth\nhypotheses were supported. Furthermore, in both of the groups,\npresenting the sounds with videos decreased reported arousal,\nin comparison to the audio condition, to congruent animal and\nincongruent human mouth smacking sounds, but not to the\ncongruent human eating sound. This supports a part of the ﬁfth\nhypothesis in this study.Although in our study the manipulation of context involved\ndiﬀerent stimuli (e.g., audio only vs. audio-visual), the results\nare similar when this manipulation is carried out by text (e.g.,\nverbally informing participants about the source of the sound;\nEdelstein et al., 2020). This suggests that perception of the\nsound’s context, rather than the speciﬁc acoustic characteristics,\nis a source of the evaluative diﬀerences in how people with\nmisophonia perceive triggering stimuli.\nWhile the self-assessment results were in line with previous\nstudies and consistent with the misophonia reaction being\naﬀected by the context of the sound, psychophysiological\ndata were less clear. Although parametric tests indicated\nseveral diﬀerences between participants with misophonia and\ncontrols in SCR, non-parametric test conﬁrmed only one\ndiﬀerence—participants with misophonia had higher SCR than\ncontrols in the 7th second in the average of audio and\naudio-video of human eating and mouth smacking eating\nstimuli. Therefore, the second hypothesis was supported only\npartially. The results were not as clear as in the previous\nstudies (Edelstein et al., 2013; Kumar et al., 2017) of greater\nskin conductance increases among people with misophonia\nwhile listening to misophonia trigger stimuli. Furthermore, the\ncontext modiﬁcation did not impact the SCR data in our study.\nFurther studies should verify whether these ﬁndings were a\nresult of lower statistical power of non-parametric tests, or\nrather in the ﬁrst seconds of the trigger duration diﬀerences\nin SCR between people with and without misophonia are\nless demonstrable.\nThe heart rate results were also more diﬃcult to explain\nand better interpreted as being related to the cognitive and\nattentional processing of the stimuli. In most of the analyses,\nno diﬀerences between the misophonia and control groups\nwere found in the HR responses. The only diﬀerence that was\nfound indicated more robust HR deceleration in misophonia\nparticipants than in controls during 2 s in congruent human\neating sound in audio-video condition. This result, however,\ncontradicts our hypothesis about less pronounced deceleration\nduring human eating sounds, and may rather suggest an\norienting response. The orienting response indicates attention\nand information intake, and is larger when stimuli are\nnovel, interesting, or signiﬁcant (Graham, 1992, 1979). These\noutcomes may indicate that the ﬁght or ﬂight response to\nmisophonic triggers is preceded by increased attentional focus\nto misophonic triggers. Overfocus on triggers, and diﬃculties\nwith attention shifting, was already described as a signiﬁcant\nsymptom of misophonia (Swedo et al., 2022). Nonetheless, this\nresult was observed only in 2 s, and only in the audio-video\ncondition, so should be treated as preliminary until replicated\nin further studies.\nTwo studies (Kumar et al., 2017; Schröder et al., 2019)\nhave found HR increases in people with misophonia (but not\nhealthy controls) while listening to misophonia trigger stimuli.\nSeveral diﬀerences between those studies and the current one\nFrontiers in Neuroscience 13 frontiersin.org"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 14\nSiepsiak et al. 10.3389/fnins.2022.880853\nmay explain the discrepant results. First, these earlier studies\nemployed longer stimulus presentation times (15 or 25 s) than\nthe current study. The typical HR response to an aversive\nstimulus is cardiac deceleration (orienting response) during\nstimulus intake followed by acceleration (defensive response) in\npreparation for action (Bradley et al., 2001; Witvliet and Vrana,\n2007), which was also observed in our data. Therefore, a longer\nstimulus presentation may have captured a defensive response\nthat might have discriminated between groups or the diﬀerent\ntrigger sounds. Further, in addition to the longer presentation\ntimes, the other studies (Kumar et al., 2017; Schröder et al., 2019)\nrepeated the stimuli multiple times, allowing for sensitization\nto the trigger sounds and more opportunity to observe a HR\ndiﬀerence between groups. This study aimed to examine the\nimmediate reactions in both groups, before it would habituate\nor sensitize in either of the groups. Another reason for this\nmethodological choice was that the main goal of the study was to\nevaluate the eﬀect of sounds’ source manipulation on emotional\nreaction. If the stimulus was repeated, there was a risk that\nthe participants would discover the experimental manipulation,\nwhich would aﬀect psychological assessment of the stimuli.\nAnother possible explanation of between-study HR\ndiﬀerences is that stimuli were processed diﬀerently. Subtle\ndiﬀerences in perceptual and cognitive processing can greatly\naﬀect HR response to stimuli (Vrana et al., 1986; Peasley-\nMiklus and Vrana, 2000). In this study, participants were given\nminimal instructions regarding how to process the stimuli,\nthough the potential aﬀective components of the stimuli were\nhighlighted (see “Procedure” section). Other studies have\nnot provided processing instructions, but after every trial,\nmisophonic participants in Kumar et al. (2017) were asked to\nrate how annoying the sound was and how eﬀective it was in\ntriggering misophonic reaction, so participants were oriented\ntoward evaluating it for a negative emotional reaction. It is\nrecommended that future studies exploring the physiological\nresponse to misophonia stimuli publish the instructions they\nprovide to participants about the stimuli, in order to facilitate\ninterpretation of results and comparison across studies.\nThis study has several limitations that must be noted.\nFirst, the groups were not completely equivalent; people in\nthe misophonia group were slightly older and more likely to\nbe female compared to participants in the control condition.\nSecond, there were no neutral, positive, or non-mouth negative\nstimuli to compare with the misophonia triggers. This made\nit diﬃcult to ﬁnd group diﬀerences or to deﬁnitively interpret\nthe control group ﬁndings. Third, because we wanted to\nprevent participants from guessing the goal of the study,\nparticipants’ interpretation of the sources of the sounds were\nnot controlled. This limitation, however, made it impossible\nto conclude about possible assumptions on the sound context\nmade by the participants. Moreover, the manipulation of sound\nsource was confounded with both sensory modality of the\nstimulus (audio-only and audio + visual) and with presentationorder (the audio condition was always presented ﬁrst). Future\nstudies of context and interpretation of sounds on misophonia\nresponse should be designed so that equivalent stimuli can\nbe used when awareness is manipulated, and so conditions\ncan be adequately counterbalanced. In addition, relatively few\ntriggers were presented, and they were presented for a short\nperiod of time because the main goal of the experiment was\nto evaluate immediate perception and cognitive evaluation of\nthe stimuli. However, this had some important consequences:\nthe methodological diﬀerences between this study and other\nstudies make it diﬃcult to compare the HR results. Furthermore,\nthe fact that mouth smacking sounds were recorded without\nfood inside the mouth, while these stimuli were supposed to\nbe human eating sounds, possibly could not be treated and\ndescribed as outright human eating sounds, which somewhat\nlimits the interpretation of the data related to these stimuli.\nMoreover, due to an error, one of the human eating stimuli\nwas presented incorrectly, so only the data from one of\nthe human eating sound was calculated, and the average of\ntwo animal-eating stimuli and of two human smacking was\ncalculated. A ﬁnal limitation is the ecological validity of the\nstudy. The misophonia sounds were presented for only 8 s\neach, a much shorter duration than is typical in real life, and\nseveral participants commented that the sounds were much less\nunpleasant than in a real-life because they knew that it was made\nby an “actor.”\nDespite these limitations, the study adds to the growing\nmisophonia literature by demonstrating that the same eating\nsounds are assessed by misophonia suﬀerers as being less\nnegative when embedded within videos of non-human eating.\nThese contextual eﬀects occurred quickly during sound\npresentations that were shorter than typically occur in real\nlife. In future studies, the duration and maintenance of these\neﬀects should be explored. A recently developed database of\npotential trigger sounds paired with neutral or pleasant videos\n(Samermit et al., 2022) could help further studies to replicate\nand extend those of the present study. Additionally, our study\nresults encourage the development of cognitive interventions for\nmisophonia (see also Edelstein et al., 2020; Savard et al., 2022), in\nwhich interpretation and attribution of the sound is addressed.\nImportantly, here we only suggest that the misophonic reaction\ncould potentially be modiﬁed by cognitive reappraisal, but we\ndo not believe that the misophonic reaction can be removed\nby cognitive restructuring, or that misophonia could simply be\ncured with cognitive therapies.\nIn this study, we focused only on the source of sounds.\nIn further studies, investigating other moderators of the\nmisophonic response to triggering cues, such as personal\nexperience, mental state, an attitude to speciﬁc behaviors related\nto the trigger sounds, etc., could extend the understanding\nof the context in misophonia. Empirical veriﬁcation of the\nrole of context in misophonic responses is fundamental for\nFrontiers in Neuroscience 14 frontiersin.org"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 15\nSiepsiak et al. 10.3389/fnins.2022.880853\nthe understanding of the misophonia mechanism, and can\ncontribute to developing adequate misophonia treatment.\nData availability statement\nThe raw data supporting the conclusions of this article will\nbe made available by the authors, without undue reservation.\nEthics statement\nThe studies involving human participants were reviewed\nand approved by the Ethics Committee at the Faculty of\nPsychology University of Warsaw (no. 29/05/2018). The\npatients/participants provided their written informed consent to\nparticipate in this study.\nAuthor contributions\nMS designed the study, led the experiment and data\ncollection, performed the statistical analysis, and wrote the\nﬁrst draft of the manuscript. AR and MS processed the\npsychophysiological data. SV , AR, and MR modiﬁed the ﬁrst\ndraft of the manuscript and wrote sections of the manuscript.\nSV , WD, and MR supervised the manuscript writing. All authors\ncontributed to manuscript revision, read, and approved the\nsubmitted version.\nFunding\nThis work was supported by the Polish National Science\nCenter (grant no. Preludium 15 2018/29/N/HS6/01108) and thePolish National Science Center scholarship (grant no. Etiuda 7\n2019/32/T/HS6/00219).\nAcknowledgments\nThe authors thank Małgorzata Siemia ¸tkowska, Anna\nOlichwer, Magdalena ˙Zukowska, Maksymilan Koc, and Karolina\nAdaszewska, for their signiﬁcant help with the organization\nof the study, and the psychophysiological data collection.\nWe also would like to thank Marta Grzes – for their help\nwith the participants’ recruitment and contact. We also thank\nPiotr Kałowski, Dominika Pruszczak, Małgorzata Han ´c, and\nMichał Lewandowski for their help with the misophonia\ninterviews.\nConﬂict of interest\nThe authors declare that the research was conducted\nin the absence of any commercial or ﬁnancial\nrelationships that could be construed as a potential\nconﬂict of interest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed\nor endorsed by the publisher.\nReferences\nAdenauer, H., Catani, C., Keil, J., Aichinger, H., and Neuner, F. (2010). Is\nfreezing an adaptive reaction to threat? Evidence from heart rate reactivity\nto emotional pictures in victims of war and torture. Psychophysiology 47,\n315–322.\nAlekri, J., and Al Saif, F. (2019). Suicidal misophonia: A case report.\nPsychiatry Clin. Psychopharmacol. 29, 232–237. doi: 10.1080/24750573.2019.159\n7585\nASMR Suna (2018).\n ASMR 4\n (mini pig’s\neating sounds) [\n ,\n , eating shows, pet, real sounds\n[video]. Youtube. Available online at: https://www.youtube.com/watch?v=\nxoS3oDzVzX0&t=2s (accessed August 12, 2022).\nBerntson, G., Quigley, K., Norman, G., and Lozano, D. (2016). “Cardiovascular\npsychophysiology, ” in Handbook of Psychophysiology , eds J. Cacioppo, L. Tassinary,\nand G. Berntson (Cambridge: Cambridge University Press), 183–216. doi: 10.\n1017/9781107415782.009\nBlanca, M. J., Alarcón, R., Arnau, J., Bono, R., and Bendayan, R.\n(2017). Non-normal data: Is ANOV A still a valid option? Psicothema 29,\n552–557.Bos, M. G. N., Jentgens, P., Beckers, T., and Kindt, M. (2013).\nPsychophysiological response patterns to aﬀective ﬁlm stimuli. PLoS One\n8:e62661. doi: 10.1371/journal.pone.0062661\nBradley, M. M., and Lang, P. J. (1994). Measuring emotion: The self-assessment\nmanikin and the semantic diﬀerential. J. Behav. Ther. Exp. Psychiatry 25, 49–59.\ndoi: 10.1016/0005-7916(94)90063-9\nBradley, M., Codispoti, M., Cuthbert, B., and Lang, P. (2001). Emotion and\nmotivation I: Defensive and appetitive reactions in picture processing. Emotion\n1, 276–298. doi: 10.1037/1528-3542.1.3.276\nBrout, J. J., Edelstein, M., Erfanian, M., Mannino, M., Miller, L. J., Rouw, R.,\net al. (2018). Investigating misophonia: A review of the empirical literature, clinical\nimplications, and a research agenda. Front. Neurosci. 12:36. doi: 10.3389/fnins.\n2018.00036\nCacioppo, J., Berntson, G., Larsen, J., Poehlmann, K., and Ito, T. (2000). “The\npsychophysiology of emotion, ” in The handbook of emotion , eds M. Lewis, J. M.\nHaviland-Jones, and L. F. Barrett (New York, NY: The Guilford Press), 173–191.\nCecilione, J. L., Hitti, S. A., and Vrana, S. R. (2021). Treating\nadolescent misophonia with cognitive behavioral therapy: Considerations\nFrontiers in Neuroscience 15 frontiersin.org"
    },
    {
      "section": "Page 17",
      "page_number": 17,
      "text": "fnins-16-880853 January 4, 2023 Time: 13:3 # 16\nSiepsiak et al. 10.3389/fnins.2022.880853\nfor including exposure. Clin. Case Stud. 21:15346501211045708. doi:\n10.1177/15346501211045707\nCowan, E. N., Marks, D. R., and Pinto, A. (2022). Misophonia: A psychological\nmodel and proposed treatment. J. Obsessive Compuls. Relat. Disorder. 32:100691.\ndoi: 10.1016/j.jocrd.2021.100691\nEdelstein, M., Brang, D., Rouw, R., and Ramachandran, V. S. (2013).\nMisophonia: Physiological investigations and case descriptions. Front. Hum.\nNeurosci. 7:296. doi: 10.3389/fnhum.2013.00296\nEdelstein, M., Monk, B., Ramachandran, V. S., and Rouw, R. (2020).\nContext inﬂuences how individuals with misophonia respond to sounds. BioRxiv\n[Preprint]. doi: 10.1101/2020.09.12.292391\nElsesser, K., Sartory, G., and Tackenberg, A. (2004). Attention, heart rate, and\nstartle response during exposure to trauma-relevant pictures: A comparison of\nrecent trauma victims and patients with posttraumatic stress disorder. J. Abnorm.\nPsychol. 113, 289–301. doi: 10.1037/0021-843X.113.2.289\nEnzler, F., Loriot, C., Fournier, P., and Noreña, A. J. (2021). A psychoacoustic\ntest for misophonia assessment. Sci. Rep. 11, 1–14. 90355-8 doi: 10.1038/s41598-\n021-\nFrank, B., and McKay, D. (2019). The suitability of an inhibitory learning\napproach in exposure when habituation fails: A clinical application to misophonia.\nCogn. Behav. Pract. 26, 130–142. doi: 10.1016/j.cbpra.2018.04.003\nGeorge, D., and Mallery, P. (2019). IBM SPSS statistics 26 step by step: A\nsimple guide and reference , 16th Edn. London: Routledge. doi: 10.4324/978042905\n6765\nGraham, F. K. (1979). “Distinguishing among orienting, defense, and startle\nreﬂexes, ” in The orienting reﬂex in humans. an international conference sponsored\nby the scientiﬁc aﬀairs division of the north atlantic treaty organization , eds H. D.\nKimmel, E. H. van Olst, and J. F. Orlebeke (Hillsdale, NJ: Lawrence Erlbaum\nAssociates), 137–167. doi: 10.4324/9781003171409-10\nGraham, F. K. (1992). “Attention: The heartbeat, the blink, and the brain, ”\ninAttention and information processing in infants and adults: Perspectives from\nhuman and animal research , (Mahwah, NJ: Lawrence Erlbaum Associates, Inc),\n3–29.\nHeller, L. M., and Smith, J. M. (2022). Identiﬁcation of everyday sounds aﬀects\ntheir pleasantness. Front. Psychol. 13:894034. doi: 10.3389/fpsyg.2022.894034\nImbir, K. K. (2016). Aﬀective norms for 718 Polish short texts (ANPST):\nDataset with aﬀective ratings for valence, arousal, dominance, origin, subjective\nsigniﬁcance and source dimensions. Front. Psychol. 7:1030. doi: 10.3389/fpsyg.\n2016.01030\nJager, I., de Koning, P., Bost, T., Denys, D., and Vulink, N. (2020). Misophonia:\nPhenomenology, comorbidity and demographics in a large sample. PLoS One\n15:e0231390. doi: 10.1371/journal.pone.0231390\nJastreboﬀ, M. M., and Jastreboﬀ, P. J. (2001). Components of decreased sound\ntolerance : Hyperacusis, misophonia, phonophobia . Available online at: https://\nwww.tinnitus.org/DST_NL2_PJMJ.pdf (accessed December 8, 2022).\nJastreboﬀ, P. J., and Jastreboﬀ, M. M. (2014). Treatments for decreased sound\ntolerance (Hyperacusis and Misophonia). Seminars Hear. 35, 105–120.\nJohnson, P. L., Webber, T. A., Wu, M. S., Lewin, A. B., Murphy, T. K., and Storch,\nE. A. (2013). When selective audiovisual stimuli become unbearable: A case series\non pediatric misophonia. Neuropsychiatry 3, 569–575. doi: 10.2217/npy.13.70\nKumar, S., Tansley-Hancock, O., Sedley, W., Winston, J. S., Callaghan, M. F.,\nAllen, M., et al. (2017). The brain basis for misophonia. Curr. Biol. 27, 527–533.\ndoi: 10.1016/j.cub.2016.12.048\nLevenson, R. W. (1992). Autonomic nervous system diﬀerences among\nemotions. Psychol. Sci. 3, 23–27. doi: 10.1111/j.1467-9280.1992.tb00251.x\nLevenson, R. W. (2014). The autonomic nervous system and emotion. Emot.\nRev. 6, 100–112. doi: 10.1177/1754073913512003\nMayapolarbear (2019). ). ASMR dog eating watermelon I MAYASMR\n[video]. Youtube . Available online at: https://www.youtube.com/watch?v=\nVRmksNNPua8&t=2s (accessed August 12, 2022).\nMehrabian, A., and Russell, J. A. (1974). The basic emotional impact of\nenvironments. Percept. Motor Skills 38, 283–301. doi: 10.2466/pms.1974.38.1.283\nNatalini, E., Dimaggio, G., Varakliotis, T., Fioretti, A., and Eibenstein, A. (2020).\nMisophonia, maladaptive schemas and personality disorders: A report of three\ncases. J. Contemp. Psychother. 50, 29–35. doi: 10.1007/s10879-019-09438-3Nigbur, R., and Ullsperger, M. (2020). Funny kittens: Positive mood induced\nvia short video-clips aﬀects error processing but not conﬂict control. Int. J.\nPsychophysiol. 147, 147–155. doi: 10.1016/j.ijpsycho.2019.11.007\nPeasley-Miklus, C., and Vrana, S. R. (2000). Eﬀect of worrisome and relaxing\nthinking on fearful emotional processing. Behav. Res. Ther. 38, 129–144. doi:\n10.1016/S0005-7967(99)00025-X\nPeirce, J. W., Gray, J. R., Simpson, S., MacAskill, M. R., Höchenberger, R.,\nSogo, H., et al. (2019). PsychoPy2: Experiments in behavior made easy. Behav. Res.\nMethods 51, 195–203. doi: 10.3758/s13428-018-01193-y\nRosenbaum, D., Leehr, E. J., Kroczek, A., Rubel, J. A., Int-Veen, I., Deutsch,\nK., et al. (2020). Neuronal correlates of spider phobia in a combined fNIRS-EEG\nstudy. Sci. Rep. 10:12597. doi: 10.1038/s41598-020-69127-3\nRouw, R., and Erfanian, M. (2018). A large-scale study of misophonia. J. Clin.\nPsychol. 74, 453–479. doi: 10.1002/jclp.22500\nSamermit, P., Young, M., Allen, A. K., Trillo, H., Shankar, S., Klein, A., et al.\n(2022). Development and evaluation of a sound-swapped video database for\nmisophonia. Front. Psychol. 13:890829. doi: 10.3389/fpsyg.2022.890829\nSAS-ASMR (2019). ASMR GIANT FRUIT PLATTER (EATING SOUNDS)\nNO TALKING | SAS-ASMR [video]. Youtube . Available online at: https://www.\nyoutube.com/watch?v=ubwEbyeswck&t=636s (accessed August 12, 2022).\nSavard, M.-A., Sares, A. G., Coﬀey, E. B. J., and Deroche, M. L. D. (2022).\nSpeciﬁcity of aﬀective responses in misophonia depends on trigger identiﬁcation.\nFront. Neurosci. 16:879583. doi: 10.3389/fnins.2022.879583\nSchmider, E., Ziegler, M., Danay, E., Beyer, L., and Bühner, M. (2010). Is it really\nrobust? Methodology 6, 147–151. doi: 10.1027/1614-2241/a000016\nSchröder, A. E., Vulink, N. C., van Loon, A. J., and Denys, D. A. (2017).\nCognitive behavioral therapy is eﬀective in misophonia: An open trial. J. Aﬀect.\nDisorder. 217, 289–294. doi: 10.1016/j.jad.2017.04.017\nSchröder, A., van Wingen, G., Eijsker, N., San Giorgi, R., Vulink, N. C., Turbyne,\nC., et al. (2019). Misophonia is associated with altered brain activity in the auditory\ncortex and salience network. Sci. Rep. 9:7542. doi: 10.1038/s41598-019-44084-8\nSchröder, A., Vulink, N., and Denys, D. (2013). Misophonia: Diagnostic criteria\nfor a new psychiatric disorder. PLoS One 8:e54706. doi: 10.1371/journal.pone.\n0054706\nSiepsiak, M., ´Sliwerski, A., and Dragan, W. (2020). Development and\npsychometric properties of MisoQuest—A new self-report questionnaire for\nmisophonia. Int. J. Environ. Res. Public Health 17:1797. doi: 10.3390/\nijerph17051797\nSwedo, S. E., Baguley, D. M., Denys, D., Dixon, L. J., Erfanian, M., Fioretti, A.,\net al. (2022). Consensus deﬁnition of misophonia: A delphi study. Front. Neurosci.\n16:841816. doi: 10.3389/FNINS.2022.841816\nVan Rossum, G., and Drake, F. L. Jr. (1995). Python reference manual .\nAmsterdam: Centrum voor Wiskunde en Informatica.\nVitoratou, S., Uglik-Marucha, N., Hayes, C., Erfanian, M., Pearson, O., and\nGregory, J. (2021). Item response theory investigation of misophonia auditory\ntriggers. Audiol. Res. 11, 567–581. doi: 10.3390/audiolres11040051\nVrana, S. R., Cuthbert, B. N., and Lang, P. J. (1986). Fear imagery and\ntext processing. Psychophysiology 23, 247–253. doi: 10.1111/j.1469-8986.1986.tb00\n626.x\nWannemüller, A., Sartory, G., Elsesser, K., Lohrmann, T., and Jöhren, H. P.\n(2015). Modality of fear cues aﬀects acoustic startle potentiation but not heart-\nrate response in patients with dental phobia. Front. Psychol. 6:170. doi: 10.3389/\nfpsyg.2015.00170\nWiese, A. D., Wojcik, K. D., and Storch, E. A. (2021). Assessment and\nIntervention for individuals with misophonia. J. Health Serv. Psychol. 47, 51–60.\ndoi: 10.1007/S42843-021-00025-6\nWitvliet, C. V. O., and Vrana, S. R. (2007). Play it again Sam: Repeated\nexposure to emotionally evocative music polarises liking and smiling responses,\nand inﬂuences other aﬀective reports, facial EMG, and heart rate. Cogn. Emot. 21,\n3–25. doi: 10.1080/02699930601000672\nWu, M. S., Lewin, A. B., Murphy, T. K., and Storch, E. A. (2014).\nMisophonia: Incidence, phenomenology, and clinical correlates in an\nundergraduate student sample. J. Clin. Psychol. 70, 994–1007 doi: 10.1002/jclp.\n22098\nFrontiers in Neuroscience 16 frontiersin.org\nView publication stats"
    }
  ]
}