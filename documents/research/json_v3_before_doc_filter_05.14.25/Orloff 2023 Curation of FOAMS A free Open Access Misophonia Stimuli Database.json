{
  "doc_type": "scientific paper",
  "title": "Curation of FOAMS: a Free Open-Access Misophonia Stimuli Database",
  "authors": [
    "Dean M. Orloff",
    "Danielle Benesch",
    "Heather A. Hansen"
  ],
  "year": 2023,
  "journal": "Journal of Open Psychology Data",
  "doi": "10.5334/jopd.94",
  "abstract": "Misophonia is a disorder of decreased tolerance to certain 'trigger' sounds (e.g., chewing, tapping, clicking). While misophonia research is scant in general, studies presenting sounds are especially rare and methodologically variable, likely due to the labor and time required to create stimuli. Thus, we introduce FOAMS: Free Open-Access Misophonia Stimuli, a sound bank publicly available on Zenodo, accompanied by pilot discomfort ratings for 32 of these sounds (4 exemplars of 8 classes). The FOAMS database aims to decrease the burden on researchers, facilitating reproducibility and the pursuit of nuanced research questions to better understand this perplexing disorder.",
  "keywords": [
    "Misophonia",
    "sound sensitivity",
    "stimulus set",
    "sound bank",
    "database"
  ],
  "research_topics": [
    "Misophonia disorder",
    "Sound stimuli for misophonia research",
    "Sound database creation and annotation",
    "Pilot study on discomfort ratings",
    "Standardization and reproducibility in misophonia research",
    "Acoustic properties of misophonic triggers",
    "Machine learning for sound detection",
    "Experimental methods in cognitive and social effects of misophonia"
  ],
  "created_at": "2025-05-05T00:33:17.715570Z",
  "source_pdf": "documents/research/Global/Orloff 2023 Curation of FOAMS A free Open Access Misophonia Stimuli Database.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "RSHQ\u0003SV\\FKRORJ\\\u0003G DWD-RXUQDO\u0003R IDATA PAPERCuration of FOAMS: a Free \nOpen-Access Misophonia Stimuli Database\nDEAN M. ORLOFF\nDANIELLE BENESCH \nHEATHER A. HANSEN \nABSTRACT\nMisophonia is a disorder of decreased tolerance to certain “trigger” sounds (e.g., \nchewing, tapping, clicking). While misophonia research is scant in general, studies presenting sounds are especially rare and methodologically variable, likely due to the labor and time required to create stimuli. Thus, we introduce FOAMS: Free Open-Access Misophonia Stimuli, a sound bank publicly available on Zenodo, accompanied by pilot discomfort ratings for 32 of these sounds (4 exemplars of 8 classes). The FOAMS database aims to decrease the burden on researchers, facilitating reproducibility and the pursuit of nuanced research questions to better understand this perplexing disorder.CORRESPONDING AUTHOR:\nHeather A. Hansen\nDepartment of Psychology, \nThe Ohio State University, Columbus, OH, USA\nhansen.508@osu.edu\nKEYWORDS:\nMisophonia; sound sensitivity; stimulus set; sound bank; database\nTO CITE THIS ARTICLE:\nOrloff, D. M., Benesch, D., & Hansen, H. A. (2023). Curation of FOAMS: a Free Open-Access Misophonia Stimuli Database. Journal of Open Psychology Data,  \n11: 15, pp.  1–8. DOI: https://doi.\norg/10.5334/jopd.94*Author affiliations can be found in the back matter of this article"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "2\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\n(1) BACKGROUND\nMisophonia is a disorder of decreased tolerance to \nspecific sounds or stimuli associated with those sounds \n(Swedo et al., 2022 ). Although often thought of as \nan aversion to oral/nasal sounds in particular (Jager \net al., 2020 ; Kumar et al., 2021 ; Schröder et al., 2013 ), \nlarge-scale surveys and experimental investigations of \nmisophonia have revealed a wide variety of reported \ntriggers: chewing, sniffling, keyboard typing, rustling \nplastic/paper, cutlery noises, etc. (Cavanna & Seri, 2015 ; \nHansen et al., 2021 ; Vitoratou et al., 2021 ). Misophonia \nis a prevalent disorder – population studies estimate \n5-20% of the general population is affected (Vitoratou \net al., 2023 ; Kılıç et al., 2021 ; Jakubovski et al., 2022 ) – \nand leads to significant impairment in daily life activities \nfor sufferers (Rouw & Erfanian, 2017 ; Swedo et al., 2022 ). \nConsequently, studying the disorder and its effects has \nbeen a focus of recent research.\nTo experimentally study a disorder of sound \nprocessing, one logical approach is to present sounds \nto participants; however, only about a dozen studies so \nfar have incorporated sound stimuli. We surmise this \nis true for a few reasons: First, except in rare instances \nof collaboration, each research team must start from \nscratch in compiling their own stimulus sets, which is \nboth time and labor intensive. Additionally, perhaps due \nto the overwhelming range of sounds that misophonic \nindividuals find bothersome, existing studies in the \nliterature vary widely in which sound stimuli are used in \ntheir “triggering” condition. For example, some studies \nuse primarily oral/nasal sounds, such as chewing or \nsniffling (Daniels et al., 2020 ; Edelstein et al., 2020 ; \nKumar et al., 2017 ; Savard et al., 2022 ; Siepsiak et al., \n2023 ), whereas others equally incorporate non-oral/\nnasal or nonhuman sounds as triggers (Enzler et al., \n2021 ; Grossini et al., 2022 ; Hansen et al., 2021 ). While \nuseful starting points, both approaches have drawbacks: \nThe latter is more time-consuming and may include \ntrigger sounds that not all misophonic individuals are \npersonally averse to, but the former may not sufficiently \ncapture the variation in misophonia and subsequently \nisolate individuals who experience triggers that are less \ncommon. Similarly, most experiments incorporating \nstimuli thus far have included single instances of each \ntrigger sound (e.g., Daniels et al., 2020 ; Enzler et al., 2021 ; \nGrossini et al., 2022 ; Hansen et al., 2021 ; Heller & Smith, \n2022 ; Kumar et al., 2017 ; Seaborne & Fiorella, 2018 ; \nSilva & Sanchez, 2018 ). While simpler methodologically, \nindividuals with misophonia often report varied reactions \nto the same sound produced by different sources (e.g., \nmore aversion to a loved one chewing than a stranger \nchewing (Edelstein et al., 2013 , 2020 )); thus, using a single \nexemplar introduces uncertainty regarding whether the \nparticular stimulus chosen will feel bothersome to a \nparticipant with that trigger.In addition to the differences in stimulus content, \nwide variability exists in other choices regarding how \nmisophonia stimuli are presented. For instance, previous \nmisophonia research has used sound stimuli that vary in \nduration from around 2 seconds (e.g., Enzler et al., 2021 ) \nto 30 seconds (e.g., Grossini et al., 2022 ) and in breadth \nfrom fewer than 5 trigger sounds (e.g., Heller & Smith, \n2022 ) to more than 100 potential triggers (e.g., Hansen et \nal., 2021 ). Thus, it is unclear whether any resultant effects \nare attributable to misophonia or merely a byproduct \nof how long (or how many) stimuli were listened to. \nSimilarly, low-level acoustic properties can also affect \nresponses, as stimuli played at excessively high volume \nlevels can be bothersome to most listeners (Kaernbach \net al., 2011 ; Skagerstrand et al., 2017 ), regardless of their \nmisophonia status. Additionally, stimuli played at low \nvolume levels may also affect participants’ responses if \nthey are inaudible enough to be recognized, since the \nmisophonic reaction has been shown to be dependent \nupon sound identification (Edelstein et al., 2020 ; Hansen \net al., 2021 ; Heller & Smith, 2022 ; Savard et al., 2022 ). \nThus, different recordings of the same trigger sound may \nevoke different experimental responses due to variations \nin acoustics and context. Without access to the original \nstimuli, replication of individual studies is challenging.\nTaken together, the field would benefit greatly from \nsome common ground on which to study misophonia. \nTo fill in this gap, we present the FOAMS database—Free, \nOpen-Access Misophonia Stimuli. The FOAMS database \nseeks to 1) increase the quantity of current, usable stimuli \nin the misophonia research field, 2) standardize the stimuli \nused in experimental research, and ultimately 3) establish \na free and open-access platform to aid in reproducibility \nof existing and future studies. This paper first presents \nthe development of the database, including how specific \ncategories of trigger stimuli were collected and labeled. \nThis process provides detailed information regarding the \nname, duration, salience, and category of each trigger \nsound. Additionally, this paper presents pilot aversiveness \nratings from a subset of categories in the database as \npart of a larger cognitive experiment, demonstrating the \nflexibility and utility of the database for specific research \nquestions. Importantly, while standardized aversiveness \nratings (e.g., valence, arousal) for all the sounds would \nmake FOAMS maximally useful, these ratings data and \nthe FOAMS sound bank function as a proof of concept, \nexemplifying how open-access sound stimuli may be \nutilized in future experimental research of misophonia.\n(2) METHODS\n2.1 MATERIALS\n2.1.1 FOAMS creation\nTo create the initial release of the FOAMS database, \nsound search terms were compiled using previous"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "3\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\nresearch and prioritized based on how well discomfort to \nthe sound correlated with misophonia severity (Hansen \net al., 2021 ). Specifically, we used the sound list provided \nby Figure S8-B of Hansen et al. (2021 ), which presents \na Misophonia Sensitivity Index depicting the correlation \nbetween participant discomfort ratings for each sound \nand participant misophonia levels. Higher correlations \nindicate sounds that better discriminate individuals \nwith misophonia from controls. Thus, sounds that were \nsignificantly correlated with misophonia severity after \ncorrecting for multiple comparisons were prioritized \nfor the FOAMS sound bank. Although 37 sounds met \nthis criterion and were considered, 10 unique low-level \nclasses of sounds were chosen for the initial release of \nFOAMS given the effort required to manually annotate \nthem (see below), as done by the UrbanSound8K \ndatabase (see Salamon et al., 2014 ).\nSound stimuli were then compiled from existing files \nvia freesound.org , with up to 1000 results for each search \nterm. Stimuli were further prioritized if the following \ncriteria were met: the sound lasted from four to 150 \nseconds, was released under a creative commons zero \nlicense, had a sampling frequency of at least 44100 Hz, \nand was the first submission from a unique Freesound \nuser after sorting by priority. For sounds in which the \nlabel from Hansen et al. (2021 ) did not return five \nusable instances from freesound.org  (e.g., fewer than \nfive instances in search results, or at least five instances \nin search results but fewer than five that met pre-\nestablished criteria), the term was removed. Of the search \nresults, each sound was further categorized following \npriority order: Each sound was listened to by a member \nof our research team, who determined if 1) either the \ndesired sound (or another relevant sound) was indeed \npresent in the audio file for at least four seconds, and 2) \nif the audio file contained interfering background noise. \nThis process continued until five sounds from ten unique \ncategories were found to have the desired search term \npresent without background noise. The ten categories \npresented in the initial release of FOAMS include chewing \ngum, flipping newspaper, typing, basketball dribbling, \nknife cutting, human breathing, plastic crumpling, water \ndrops, clearing throat, and swallowing.\nEach sound event for the audio file was annotated \nusing Audacity® (v3.1.3). The entire audio file was \nmanually labeled, marking every occurrence of the \ndesired primary sound as well as any additional secondary \nsounds, aiming to annotate the onset and offset of each \nsound event within 50 ms precision. Labels also denoted \nsalience, with “C1_sound” and “C2_sound” indicating \nforeground or background sounds, respectively. These \ntechniques were modeled after those used to construct \nthe existing UrbanSound8K database (Salamon et al., \n2014 ). Then, representative four-second instances of \neach sound were selected by a member of the research \nteam. During this process, the labeled audio file was listened to again and all previously-labeled instances \nof the target sound were considered for the segment \ncreation. Instances with minimal background noise and \nthe most isolated target sound were selected, aiming \nfor about four seconds long, with slight variation so as \nto not cut the sound off abruptly. A four second duration \nwas chosen because of its use in the UrbanSound8K \ndatabase, based on four seconds being sufficient for \nparticipants to identify the sound (Salamon et al., 2014 , \nChu et al., 2009 ); previous misophonia literature has \nshown the critical role of sound identification (Savard \net al., 2022 , Heller & Smith, 2022 ). One segment was \nchosen for each of the 50 stimulus files. The initial labels \nand final segmentation were both exported to TXT files \nfrom Audacity and are publicly available on Zenodo.\nFinally, a taxonomy was created based on the search \nterms and updated throughout the annotation process. \nAs with annotation, we modeled our taxonomy method \non UrbanSound8K, given a misophonia taxonomy does \nnot yet exist and UrbanSound8K’s categorization of \nenvironmental sounds is similar in content to misophonia \ntriggers. We started with the parent categories used \nin their taxonomy of urban sounds (e.g., “Human”, \n“Nature”, and “Mechanical”) then modified the taxonomy \nusing our search terms to adapt it for misophonia-\nrelevant sound categories (e.g., adding “oral/nasal” as a \nsubheading under “Human”). Each of the search terms \nwe considered as categories in the initial release of FOAMS \n(see description above, Hansen et al., 2021 ) was added \nto the taxonomy under the appropriate subheading. The \ntaxonomy was updated during the annotation process \nso that each label present in an audio file was included; \nfor example, “exhaling” was not a prioritized search term, \nbut was present in the audio files, so it was added to the \ntaxonomy. Each label was categorized under at least one \nparent sound that described the type of sound present in \nthe label; researcher discretion was used to determine \nrelevant parent categories. While this taxonomy is \nfar from exhaustive and may be rearranged as more \nsounds are added, we find this structure useful in further \ncategorizing sounds that have relatively broad labels. \nFor example, a parent term called “oral/nasal” might be \nrelevant to researchers who are studying the effects of \noral/nasal sounds more generally, but the parent term \ncould be further subdivided into more specific labels like \n“lip smacking,” “chewing,” or “swallowing” for researchers \nwho have a narrower focus. In this sense, the taxonomy \nand label files provided in FOAMS are useful for a plethora \nof research questions. We have supplied the taxonomy in \nJSON format on GitHub to facilitate use, extension, and \nreorganization by future research.\n2.1.2 Pilot stimuli\nPilot discomfort ratings were derived from a larger \nexperiment studying the cognitive and social effects of \nmisophonia via a face memory task (see Hansen et al., n.d. )."
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "4\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\nFor the purposes of that experiment, eight human-\nproduced classes from FOAMS were used (breathing, \nchewing gum, clearing throat, swallowing, knife cutting, \nbasketball dribbling, flipping newspaper, and typing). To \napproximately equate sound durations between classes, \nfour instances from each class were chosen by removing \nthe shortest or longest instance from the available five. \nTo control for sound exposure, these 32 sound stimuli \nfrom FOAMS were supplemented with four instances of \npink noise and four trials with no sound, resulting in 10 \ntotal classes with four instances each.\nThe FOAMS stimuli do not have sound level normalized, \nboth to give researchers flexibility and maintain variability \nwhen sound level is a factor of interest. However, for this \ncognitive experiment, sound level variability was not a \nfactor of interest. As such, sound levels were normalized \nusing Adobe Audition (v.14.4) by matching Total RMS to \nthe first chewing gum file; chewing gum was chosen \nfor its quieter starting volume and role as a classic \nmisophonia trigger. Total RMS was -50.03dB for each \nsound used in the pilot.\n2.2 SAMPLE\n21 participants (Mean Age = 18.5; 11 female, 8 male) were \nrecruited for the pilot. Participants were undergraduate \nstudents who were enrolled in an Introduction to \nPsychology course at The Ohio State University and \nreceived course credit for their participation.\nParticipants were assessed for misophonia using \nthe Duke Misophonia Questionnaire (DMQ; Rosenthal \net al., 2021 ) and Selective Sound Sensitivity Syndrome \nScale (S5; Vitoratou et al., 2021 ), of which misophonia \nis suggested to be present above scores of 87 out of \n250. Our 21 participants had a mean S5 score of 44.8 \n(range: 0-134); four participants scored above the 87 \ncriterion, matching prevalence estimates of misophonia \nin undergraduate samples (Wu et al., 2014 ; Zhou et \nal., 2017 ) and the general population (Vitoratou et al., \n2023 ).\n2.3 STUDY DESIGN\nThe experiment was run in a dimly lit, sound-attenuated \ntesting room using a Mac Mini computer with a 24-\nin. LCD monitor. Stimuli were presented using Python \n3.8 and PsychoPy (v2021.2.3). Before beginning the \nexperiment, participants were informed that they would \nbe presented faces and asked to make judgments about \nthe faces. Participants were made aware that sounds \nwould play concurrently with the faces, and that some \nsounds may feel unpleasant to them.\nThe experiment was broken down into two parts: \nPhase 1 (Learning) and Phase 2 (Memory). In Phase 1, \nparticipants were shown 40 faces one at a time while \ncompleting an incidental encoding task. During presen-\ntation of the face, a stimulus from one of 10 sound \nclasses played aloud through speakers. Afterwards, participants were shown a response screen on which they \nwere given two additional tasks: 1) judge the identity of \nthe sound they just heard by choosing one of the 10 \navailable class names, and 2) rate their discomfort during \nthe sound on a scale from 0 (no discomfort) to 5 (max \ndiscomfort). After clicking responses to both questions, \na “Continue” button appeared, after which participants \nstarted the next trial. Participants were given two practice \ntrials (one male face, one female face) accompanied \nby pink noise (labeled “white noise” on the screen for \nfamiliarity), then completed 80 experimental trials split \ninto 4 blocks, between which they were offered short \nbreaks. In Phase 2, participants made trait and memory \njudgments about the faces from Phase 1; results from \nthis phase are outside the scope of the present paper.\n2.4 ETHICAL ISSUES\nAll research was approved by the Institutional Review \nBoard at The Ohio State University. Participants provided \ninformed written consent prior to data collection and \nwere assigned an anonymous ID number for data storage.\n2.5 EXISTING USE OF DATA\nThe FOAMS database was used in a dissertation experiment \nconducted by a member of the research team, currently \nunder review for publication (Hansen et al., n.d. ).\n(3) DATASET DESCRIPTION AND ACCESS\n3.1 REPOSITORY LOCATIONS\nFOAMS DOI: 10.5281/zenodo.8170225\nPilot DOI: 10.5281/zenodo.8170180\n3.2 FILE NAMES\n3.2.1 FOAMS\n− FOAMS_documentation.pdf: details of audio labeling, \nsegmentation, and taxonomy creation\n− FOAMS_processed_audio.zip: all labeled stimuli \navailable in the database, in WAV format\n− FOAMS_processed_audio_flac.zip: all labeled stimuli \navailable in the database, in FLAC format\n− segmentation_info.csv: details of stimulus segments\n3.2.2 Pilot\n− Sub01.csv – Sub21.csv: raw experimental output of \ndiscomfort ratings and sound identifications for all 21 \nparticipants\n− MisoAssessments.csv: DMQ and S5 assessment \nscores for all 21 participants\n− Stim_reference_table.csv: reference table of the \nsound stimuli with their corresponding FOAMS IDs\n− FOAMS_analysis.m: analysis script for compiling raw \ndata and generating a summary table"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "5\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\n− discomfort_summary.csv: summary table of \ndiscomfort ratings for the 32 FOAMs sounds used in \nthe pilot\n− README.txt: explanation of the raw experimental \noutput files\n− Pilot_sound_stimuli.zip: all 33 sound stimuli used (32 \nfrom FOAMS + pink noise), in WAV format\n− Pilot_sound_stimuli_flac.zip: all 33 sound stimuli used \n(32 from FOAMS + pink noise), in FLAC format\n3.3 DATA TYPE\nPrimary data, processed data\n3.4 FORMAT NAMES\nSound files are available in both WAV and FLAC audio \nformats. Pilot data is available in CSV format. Analysis \nscripts of the pilot data are available for use in Matlab \n(version R2021a).\n3.5 LANGUAGE\nAmerican English\n3.6 LICENSE\nCreative Commons Attribution 4.0 International Public \nLicense\n3.7 PUBLICATION DATE\nSeptember 25, 2022\n(4) REUSE POTENTIAL\nThe FOAMS database and pilot discomfort ratings \nprovide numerous interdisciplinary benefits. Firstly, \nsince the FOAMS database has multiple exemplars \nof each sound with varied acoustic properties, this \ndatabase can enable more nuanced research \nquestions. For example, auditory researchers may \nuse the differential discomfort ratings assigned to \nthe four piloted chewing sounds to explore which \nacoustic properties (e.g., frequency, intensity) best \nexplain why some instances of the trigger sound are \nmore aversive than others. Furthermore, the FOAMS \ndatabase’s diverse collection of sound exemplars with \nvarying acoustic properties presents an opportunity for \nmachine learning research. With its diverse collection \nof sound exemplars, researchers could leverage this \nsound bank to develop robust machine learning \nmodels for automatic detection of misophonic triggers, \nopening avenues for personalized interventions and \nadvancements in managing misophonia (Benesch et al., \n2021 ). By modeling the FOAMS format to match that of \nUrbanSound8K, a popular dataset used in sound event \nclassification research, we hope to encourage the use \nof FOAMS in the machine learning community.More generally, an open-access database will \nbridge gaps in misophonia literature and make results \nmore interpretable. For instance, if neuropsychological \nstudies from different research groups present these \nsounds to participants and observe conflicting results, \nresearchers can be more confident the disparate \nfindings are not merely confounded by the particular \nstimuli each group presented. Additionally, given \nthe individual differences in misophonic experiences, \nresearchers could benefit from individually tailoring \ntheir experiments to each individual’s trigger sounds, \nan ideal put forth by Schröder et al. (2019 ). Importantly, \nall files used to create the final processed dataset have \nbeen made publicly available, including the sound \nsearch results, the original audio files, the annotation \nfiles, and the taxonomy, which provides transparency \nand facilitates replication. This information offers much \npotential for expansion or modification of the FOAMS \ndatabase if researchers need to include more sounds \nor tailor the preprocessing to their own specifications. \nThis is relevant given that the initial release of the \nFOAMS database contains 10 sound categories, and \nmisophonic individuals report a plethora of triggers; as \nsuch, not all trigger sounds are presently represented \nin the database, and further expansion would make it \nmaximally useful.\nAside from research purposes, sounds from this \ndatabase can be used in diagnosis, therapy, and a \nbroadened awareness of misophonia in the medical \ncommunity. Enzler et al. (2021 ) demonstrated an ability \nto assess misophonia by analyzing ratings of pre-selected \nsounds (see also Hansen et al., 2021 ). With a larger \nand more diverse sound bank, the success in capturing \ndifferent variations of misophonia improves. Moreover, \nalthough about 20% of undergraduate samples (Wu et \nal., 2014 ; Zhou et al., 2017 ) and the general population \n(Vitoratou et al., 2023 ) experience misophonia, not all \ntreatment providers are comfortable with the term; in a \nstudy of audiologists in India, only about 15% of them \nreported confidence in handling the condition (Aryal & \nPrabhu, 2023 ). Often a multidisciplinary treatment team \nis preferred (Aryal & Prabhu, 2023 ), with psychologists \nusing therapies that may incorporate stimulus \npresentation (see Mattson et al., 2023  for a review of \ntreatments). Freely accessible sound stimuli can thus be \nincorporated into training seminars or individual therapy \nplans to familiarize treatment providers with the disorder \nand improve treatment outcomes.\nThe FOAMS database is a compilation of existing \nsound files and is therefore intrinsically limited in \nits scope. That is, all categorized sounds come from \nexisting, user-uploaded audio files on freesound.org ; \nno sounds were recorded by the research team. This \nreliance on previously existing sound files presented \nlogistical challenges when analyzing certain sound"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "6\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\ncategories, since not all desired categories (e.g., \n“sipping hot liquid”) had search results on freesound.org, \nor search results contained multiple categories besides \nthe desired sound (e.g., “slurping” containing lip smacks \nand swallowing sounds, or “lip smacks” containing \naudio indistinguishable from chewing gum). Further, acoustic properties (e.g., due to the recording device, \nbackground noise) could not be controlled. The reliance \non freesound.org also necessitated the use of researcher \ndiscretion when annotating sounds to verify that the content matched the user-uploaded description and \nto choose representative segments of each audio clip. \nFinally, while offering five exemplars of each sound \ncategory is more ecologically valid than presenting \njust one sound, doing so cannot fully account for the \nidiosyncrasies of the misophonic experience, especially \nfor sufferers who are mainly bothered by sounds from \nselect individuals (e.g., family/friends, Edelstein et al., \n2013).\nDespite these limitations, this intrinsic structure \nof the FOAMS database fosters both flexibility and \nreproducibility in research; because FOAMS relies on \nexisting sound databases, the potential for expansion \nremains feasible via the aforementioned methods. \nFurther, the acoustic variations in sounds—though at \nfirst apparently confounding—enables researchers to \nexamine more specific issues and is not necessarily a \nlimitation of the FOAMS database. For example, a study \nusing only “swallowing” sounds could examine what \nspecific characteristics of each swallowing sound make \nit triggering; is it variation in background noise? Does \nthe sound quality affect trigger response? The reuse \npotential is wide, and more open-access resources like \nthe FOAMS database will benefit the misophonia field \nas a whole. This proof of concept lays the framework for \nsuch broad, reproducible, and collaborative future efforts \nin misophonia research.\nACKNOWLEDGEMENTS\nWe thank soQuiet for financially supporting this research \nproject, as well as the many users on freesound.org who \nuploaded sounds we could use in this database. We \nwould also like to thank our collaborators on the project, \nMarie-Anick Savard, Emily Coffey, and Mickael Deroche, \nfor their helpful suggestions. Lastly, we thank Andrew \nLeber and Zeynep Saygin for supervising data collection \nof the pilot.\nFUNDING INFORMATION\nFunding for the creation of this sound bank was provided \nby a 2022 soQuiet Misophonia Student Research Grant \nawarded to DB and HAH.COMPETING INTERESTS\nThe authors have no competing interests to declare.\nAUTHOR CONTRIBUTIONS\nDO curated the FOAMS database (including sound \nsearch, sound labeling, and sound segmentation) and \ndrafted the manuscript. DB developed software to automatically segment and process the FOAMS stimuli. \nHAH collected pilot discomfort ratings. Both DB and HAH \nconceptualized and supervised the project and edited \nthe manuscript.\nAUTHOR AFFILIATIONS\nDean M. Orloff \nDepartment of Psychology, The Ohio State University, \nColumbus, OH, USA\nDanielle Benesch  orcid.org/0000-0002-2002-2325 \nÉTS-EERS Industrial Research Chair in In-Ear Technologies, \nMontreal, QC, CA\nHeather A. Hansen  orcid.org/0000-0002-8917-2516 \nDepartment of Psychology, The Ohio State University, Columbus, OH, USA\nREFERENCES\nAryal, S., & Prabhu, P. (2023). Awareness and perspectives \nof audiologists on assessment and management of \nmisophonia in India. Journal of Otology, 18(2), 104–110. \nDOI: https://doi.org/10.1016/j.joto.2023.02.003\nBenesch, D., Raj, K. N., Bouserhal, R., & Voix, J. (2021). \nInterfacing the Tympan open-source hearing aid with \nan external computer for research on decreased sound \ntolerance. 181st Meeting of the Acoustical Society of \nAmerica, 45. DOI: https://doi.org/10.1121/2.0001616\nCavanna, A. E., & Seri, S. (2015). Misophonia: current \nperspectives. Neuropsychiatric Disease and Treatment, 11, \n2117–2123. DOI: https://doi.org/10.2147/NDT.S81438\nChu, S., Narayanan, S., & Kuo, C.-C. J. (2009). Environmental \nSound Recognition With Time – Frequency Audio Features. \nIEEE Transactions on Audio, Speech, and Language \nProcessing, 17(6), 1142–1158. http://ieeexplore.ieee.org/\nxpls/abs_all.jsp?arnumber=5109766. DOI: https://doi.\norg/10.2147/NDT.S81438\nDaniels, E. C., Rodriguez, A., & Zabelina, D. L. (2020). \nSeverity of misophonia symptoms is associated with \nworse cognitive control when exposed to misophonia \ntrigger sounds. PLoS ONE, 15(1), 1–12. DOI: https://doi.\norg/10.1371/journal.pone.0227118\nEdelstein, M., Brang, D., Rouw, R., & Ramachandran, V. S. \n(2013). Misophonia: physiological investigations and case \ndescriptions. Frontiers in Human Neuroscience, 7(296), \n1–11. DOI: https://doi.org/10.3389/fnhum.2013.00296"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "7\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\nEdelstein, M., Monk, B., Ramachandran, V. S., & Rouw, \nR. (2020). Context influences how individuals with \nmisophonia respond to sounds. BioRxiv. DOI: https://doi.\norg/10.1101/2020.09.12.292391\nEnzler, F., Loriot, C., Fournier, P., & Noreña, A. J. (2021). A \npsychoacoustic test for misophonia assessment. Scientific \nReports, 11(1), 1–14. DOI: https://doi.org/10.1038/s41598-\n021-90355-8\nGrossini, E., Stecco, A., Gramaglia, C., De Zanet, D., Cantello, \nR., Gori, B., Negroni, D., Azzolina, D., Ferrante, D., Feggi, \nA., Carriero, A., & Zeppegno, P. (2022). Misophonia: \nAnalysis of the neuroanatomic patterns at the \nbasis of psychiatric symptoms and changes of the \northosympathetic/ parasympathetic balance. Frontiers \nin Neuroscience, 16(827998), 1–21. DOI: https://doi.\norg/10.3389/fnins.2022.827998\nHansen, H. A., Leber, A. B., & Saygin, Z. M. (2021). What \nsound sources trigger misophonia? Not just chewing and \nbreathing. Journal of Clinical Psychology, 77(11), 2609–\n2625. DOI: https://doi.org/10.1002/jclp.23196\nHansen, H. A., Leber, A. B., & Saygin, Z. M. (n.d.). Effect of \nmisophonia on cognitive and social processing .\nHeller, L. M., & Smith, J. M. (2022). Identification of Everyday \nSounds Affects Their Pleasantness. Frontiers in Psychology, \n13(894034), 1–16. DOI: https://doi.org/10.3389/\nfpsyg.2022.894034\nJager, I., de Koning, P., Bost, T., Denys, D., & Vulink, N. \n(2020). Misophonia: Phenomenology, comorbidity and \ndemographics in a large sample. PLoS ONE, 15(4), 1–16. \nDOI: https://doi.org/10.1371/journal.pone.0231390\nJakubovski, E., Müller, A., Kley, H., de Zwaan, M., & Müller-\nVahl, K. (2022). Prevalence and clinical correlates of \nmisophonia symptoms in the general population of \nGermany. Frontiers in Psychiatry, 13. DOI: https://doi.\norg/10.3389/fpsyt.2022.1012424\nKaernbach, C., Hoeldtke, K., & Pfitzinger, H. R. (2011). \nEmotional responses to sounds depend mainly on sound \nlevel. Proceedings of Forum Acusticum, c, 1097–1102.\nKılıç, C., Öz, G., Avano ğlu, K. B., & Aksoy, S. (2021). The \nprevalence and characteristics of misophonia in Ankara, \nTurkey: population-based study. BJPsych Open, 7(5), 1–6. \nDOI: https://doi.org/10.1192/bjo.2021.978\nKumar, S., Dheerendra, P., Erfanian, M., Benzaquén, E., Sedley, \nW., Gander, P. E., Lad, M., Bamiou, D. E., & Griffiths, \nT. D. (2021). The motor basis for misophonia. Journal \nof Neuroscience, 41(26). DOI: https://doi.org/10.1523/\nJNEUROSCI.0261-21.2021\nKumar, S., Tansley-Hancock, O., Sedley, W., Winston, J. S., \nCallaghan, M. F., Allen, M., Cope, T. E., Gander, P. E., \nBamiou, D. E., & Griffiths, T. D. (2017). The Brain Basis for \nMisophonia. Current Biology, 27(4), 527–533. DOI: https://\ndoi.org/10.1016/j.cub.2016.12.048\nMattson, S. A., D’Souza, J., Wojcik, K. D., Guzick, A. G., \nGoodman, W. K., & Storch, E. A. (2023). A systematic \nreview of treatments for misophonia. Personalized Medicine in Psychiatry, 39–40(May), 100104. DOI: https://\ndoi.org/10.1016/j.pmip.2023.100104\nRosenthal, M. Z., Anand, D., Cassiello-Robbins, C., Williams, \nZ. J., Guetta, R. E., Trumbull, J., & Kelley, L. D. (2021). \nDevelopment and Initial Validation of the Duke Misophonia \nQuestionnaire. Frontiers in Psychology, 12(709928), 1–21. \nDOI: https://doi.org/10.3389/fpsyg.2021.709928\nRouw, R., & Erfanian, M. (2017). A Large-Scale Study of \nMisophonia. Journal of Clinical Psychology, 0(0), 1–27. DOI: \nhttps://doi.org/10.1002/jclp.22500\nSalamon, J., Jacoby, C., & Bello, J. P. (2014). A Dataset \nand Taxonomy for Urban Sound Research. MM ’14 \nProceedings of the 22nd ACM International Conference \non Multimedia, 3, 1041–1044. DOI: https://doi.\norg/10.1145/2647868.2655045\nSavard, M. A., Sares, A. G., Coffey, E. B. J., & Deroche, \nM. L. D. (2022). Specificity of Affective Responses in \nMisophonia Depends on Trigger Identification. Frontiers \nin Neuroscience, 16(879583), 1–17. DOI: https://doi.\norg/10.3389/fnins.2022.879583\nSchröder, A., van Wingen, G., Eijsker, N., San, R., Vulink, N. C., \nTurbyne, C., & Denys, D. (2019). Misophonia is associated \nwith altered brain activity in the auditory cortex and \nsalience network. Scientific Reports, 9(7542), 1–9. DOI: \nhttps://doi.org/10.1038/s41598-019-44084-8\nSchröder, A., Vulink, N., & Denys, D. (2013). Misophonia – \nDiagnostic Criteria for a New Psychiatric Disorder. PLoS ONE, \n8(1). DOI: https://doi.org/10.1371/journal.pone.0054706\nSeaborne, A., & Fiorella, L. (2018). Effects of background \nchewing sounds on learning: The role of misophonia \nsensitivity. Applied Cognitive Psychology, 32 (2), 264–269. \nDOI: https://doi.org/10.1002/acp.3387\nSiepsiak, M., Vrana, S. R., Rynkiewicz, A., Rosenthal, M. Z., & \nDragan, W. Ł. (2023). Does context matter in misophonia? \nA multi-method experimental investigation. Frontiers \nin Neuroscience, 16(880853), 1–16. DOI: https://doi.\norg/10.3389/fnins.2022.880853\nSilva, F. E., & Sanchez, T. G. (2018). Evaluation of selective \nattention in patients with misophonia. Brazilian Journal of \nOtorhinolaryngology, 1–7. DOI: https://doi.org/10.1016/j.\nbjorl.2018.02.005\nSkagerstrand, Å., Köbler, S., & Stenfelt, S. (2017). Loudness \nand annoyance of disturbing sounds–perception by \nnormal hearing subjects. International Journal of \nAudiology, 56(10), 775–783. DOI: https://doi.org/10.1080/1\n4992027.2017.1321790\nSwedo, S. E., Baguley, D. M., Denys, D., Dixon, L. J., Erfanian, \nM., Fioretti, A., Jastreboff, P. J., Kumar, S., Rosenthal, M. \nZ., Rouw, R., Schiller, D., Simner, J., Storch, E. A., Taylor, \nS., Werff, K. R. V., Altimus, C. M., & Raver, S. M. (2022). \nConsensus Definition of Misophonia: A Delphi Study. \nFrontiers in Neuroscience, 16(March), 1–16. DOI: https://doi.\norg/10.3389/fnins.2022.841816\nVitoratou, S., Hayes, C., Uglik-Marucha, N., Pearson, O., \nGraham, T., & Gregory, J. (2023). Misophonia in the"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "8\n Orloff et al. Journal of Open Psychology Data DOI: 10.5334/jopd.94\nTO CITE THIS ARTICLE:\nOrloff, D. M., Benesch, D., & Hansen, H. A. (2023). Curation of FOAMS: a Free Open-Access Misophonia Stimuli Database. Journal of \nOpen Psychology Data,  11: 15, pp.  1 –8. DOI: https://doi.org/10.5334/jopd.94\nSubmitted: 24 May 2023          Accepted: 26 July 2023          Published: 29 August 2023\nCOPYRIGHT:\n© 2023 The Author(s). This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.\nJournal of Open Psychology Data is a peer-reviewed open access journal published by Ubiquity Press.UK: Prevalence and norms from the S-Five in a UK \nrepresentative sample. PLoS ONE, 18(3 March), 1–18. DOI: \nhttps://doi.org/10.1371/journal.pone.0282777\nVitoratou, S., Uglik-Marucha, N., Hayes, C., Erfanian, M., \nPearson, O., & Gregory, J. (2021). Item Response Theory \nInvestigation of Misophonia Auditory Triggers. Audiology \nResearch, 11(4), 567–581. DOI: https://doi.org/10.3390/\naudiolres11040051\nVitoratou, S., Uglik-Marucha, N., Hayes, C., & Gregory, J. \n(2021). Listening to People with Misophonia: Exploring \nthe Multiple Dimensions of Sound Intolerance Using a \nNew Psychometric Tool, the S-Five, in a Large Sample of \nIndividuals Identifying with the Condition. Psych, 3(4), \n639–662. DOI: https://doi.org/10.3390/psych3040041\nWu, M. S., Lewin, A. B., Murphy, T. K., & Storch, E. A. (2014). \nMisophonia: Incidence, phenomenology, and clinical \ncorrelates in an undergraduate student sample. Journal of Clinical Psychology, 70(10), 994–1007. DOI: https://doi.\norg/10.1002/jclp.22098\nZhou, X., Wu, M. S., & Storch, E. A. (2017). Misophonia \nsymptoms among Chinese university students: Incidence, \nassociated impairment, and clinical correlates. Journal \nof Obsessive-Compulsive and Related Disorders, 14, 7–12. \nDOI: https://doi.org/10.1016/j.jocrd.2017.05.001\nPEER REVIEW COMMENTS\nJournal of Open Psychology Data has blind peer review, \nwhich is unblinded upon article acceptance. The editorial \nhistory of this article can be downloaded here:\n•\tPR File 1. Peer Review History. DOI: https://doi.org/10.  \n5334/jopd.94.pr1"
    }
  ]
}