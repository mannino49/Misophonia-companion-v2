{
  "doc_type": "scientific paper",
  "title": "Context influences how individuals with misophonia respond to sounds",
  "authors": [
    "Edelstein, M.",
    "Monk, B.",
    "Ramachandran, V.S.",
    "Rouw, R."
  ],
  "year": 2020,
  "journal": null,
  "doi": "10.1101/2020.09.12.292391doi:",
  "abstract": "Misophonia is a newly researched condition in which specific sounds cause an intense, aversive response in individuals, characterized by negative emotions and autonomic arousal. Although virtually any sound can become a misophonic “trigger,” the most common sounds appear to be bodily sounds related to chewing and eating as well as other repetitive sounds. An intriguing aspect of misophonia is the fact that many misophonic individuals report that they are triggered more, or even only, by sounds produced by specific individuals, and less, or not at all, by sounds produced by animals (although there are always exceptions). In general, anecdotal evidence suggests that misophonic triggers involve a combination of sound stimuli and contextual cues. The aversive stimulus is more than just a sound and can be thought of as a Gestalt of features which includes sound as a necessary component as well as additional contextual information. In this study, we explore how contextual information influences misophonic responses to human chewing, as well as sonically similar sounds produced by non-human sources. The current study revealed that the exact same sound can be perceived as being much more or less aversive depending on the contextual information presented alongside the auditory information. The results of this study provide a foundation for potential cognitive based therapies.",
  "keywords": [
    "misophonia",
    "trigger sounds",
    "contextual information",
    "human chewing sounds",
    "auditory stimuli",
    "aversive response",
    "autonomic arousal",
    "cognitive therapy"
  ],
  "research_topics": [
    "Misophonia and its characteristics",
    "Physiological and emotional responses to triggers",
    "Contextual influence on auditory perception",
    "Neural correlates of misophonia",
    "Prevalence and comorbidities of misophonia",
    "Treatment approaches for misophonia",
    "Comparison between misophonia and ASMR",
    "Experimental methodology on misophonia response"
  ],
  "created_at": "2025-05-05T03:10:10.994574Z",
  "source_pdf": "documents/research/Global/Edelstein 2020 context influences how individuals with misophonia respond to sounds.pdf",
  "sections": [
    {
      "section": "Page 1",
      "page_number": 1,
      "text": "1  \n \n \nContext influences how individuals with misophonia respond to sounds  \n \nEdelstein, M., Monk, B. , Ramachandran, V.S. , and Rouw, R . \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 2",
      "page_number": 2,
      "text": "2  \nABSTRACT  \nMisophonia is a newly researched condition in which specific sounds cause an intense, \naversive response in individuals, characterized by negative emotions and autonomic arousal. \nAlthough virtually any sound can become a misophonic “trigger,” the most common sounds \nappear to be bodily sounds related to chewing and eating as well as other rep etitive sounds. An \nintriguing aspect of misophonia is the fact that many misophonic individuals report that they are \ntriggered more, or even only, by sounds produced by specific individuals, and less, or not at all, \nby sounds produced by animals (although there are always exceptions) . \nIn general, anecdotal evidence suggests that misophonic triggers involve a combination \nof sound stimuli and contextual cues. The aversive stimulus is more than just a sound and can be \nthought of as a Gestalt of features which includes sound as a necessary component as well as \nadditional contextual information. In this study, we explore how contextual information \ninfluences misophonic responses to human chewing, as well as sonically similar sounds \nproduced by non -human sources. The current study revealed that the exact same sound can be \nperceived as being much more or less aversive depending on the contextual information \npresented alongside the auditory information. The results of this study provide a foundation for \npotential cog nitive based therapies.  \n \n  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 3",
      "page_number": 3,
      "text": "3  \nINTRODUCTION  \n  Misophonia is a newly researched condition in which specific sounds evoke an intensely \naversive reaction in sufferers. Misophonia was first described by Jastreboff and Jastreboff (2001) \nnearly two decades ago but has only recently become a topic of interest to researchers in \nscientific and clinical communities. Sounds that evoke an intensely aversive reaction in \nindividuals with misophonia are known as “triggers.” When exposed to these trigger sounds, \nindividuals w ith misophonia experience a variety of physiological and negative emotional \nresponses, resembling a fight -or-flight response (Edelstein et al., 2013; Brout et al., 2018; Kumar \net al., 2014). At its most severe, misophonia can be so debilitating that it wil l often dictate the \nlives of those who suffer from it, causing people to go to great lengths just to avoid being \nexposed to certain sounds. Misophonic trigger sounds are frequently sounds that are not regarded \nas traditionally aversive to most individuals (although they may be considered annoying), and \ninstead are commonly found to be human bodily noises (such as chewing, lip smacking, \nbreathing or sniffing), or other repetitive sounds (such as tapping or pen clicking) (Schröder et \nal., 2013, Edelstein et a l., 2013). While certain trigger sounds (such as chewing and mouthy \nsounds) appear to be far more common than others, it is important to note that each individual \nwith misophonia possesses their own unique set of trigger sounds and that seemingly any sound  \nhas the potential to become a trigger.  \n  When exposed to trigger sounds, misophonic individuals report experiencing intense \nfeelings of anger, anxiety, disgust or rage (Schröder et al., 2013) in addition to a variety of \nphysical sensations such as increa sed heart rate, tensing of muscles or perceived pressure \nbuilding up in the body (Edelstein et al., 2013). It has been shown that, in response to auditory . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 4",
      "page_number": 4,
      "text": "4 stimuli, including trigger sounds, misophonic individuals experience larger physiological \nresponses ( SCR and heart rate) indicative of autonomic nervous system arousal, than matched \ncontrol participants  (Edelstein et al., 2013; Kumar et al., 2017).  \nTo date, only two published studies have explored the neural correlates associated with \nmisophonia. Schröder et al. (2014) utilized electroencephalography (EEG) to measure auditory \nevent related potentials (ERPs) in misophonic and control participants duri ng an oddball task. \nThey found that in response to oddball tones, misophonic but not control participants exhibited a \ndecreased mean peak amplitude of the auditory N1 component, which is a component associated \nwith early attention and detecting sudden chan ges in sensory information. As a decreased N1 \ncomponent has been observed in individuals with a number of psychiatric conditions, the authors \nsuggest that it could be interpreted as a marker of pathology and that misophonic individuals \nmay be experiencing basic deficits in auditory processing. A groundbreaking study by Kumar et \nal. (2017) utilized neuroimaging techniques to highlight structural as well as functional \nneurological differences in those with and without misophonia. Findings revealed that in \nresponse to trigger sounds, misophonic participants showed increased activation in the bilateral \nanterior insular cortex (AIC) as well as increased functional connectivity between the AIC and \nregions of the brain associated with processing and regulating emot ions. As the AIC is thought to \nbe involved in the detection of important, salient stimuli, the increased activation found in \nmisophonic individuals in response to trigger sounds suggests that these sounds are processed as \nbeing highly salient. In terms of structural differences, misophonic but not control participants \nwere found to have increased myelination in the ventromedial prefrontal cortex (vmPFC), a \nregion of the brain also involved in regulating emotions.   . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 5",
      "page_number": 5,
      "text": "5 The prevalence of misophonia in the general  population is not well understood yet. In a \nsample of 483 undergraduate students from a North American university, Wu et al. (2014) found \nthat 20% reported experiencing symptoms of misophonia that were considered clinically \nsignificant. Additionally, a st udy by Zhou et al. (2017) which investigated the prevalence of \nmisophonia in 415 students at two Chinese universities, found that while 16.6% reported \nclinically significant symptoms, only 6% were classified as experiencing significant levels of \nimpairment . While these studies have made important contributions to our early understanding of \nmisophonia, additional large -scale studies that sample a variety of populations are needed in \norder to gain an accurate sense of the true prevalence of the condition.  \nMisophonia has been found to be comorbid with conditions such as obsessive compulsive \ndisorder (OCD) (Schröder et al., 2013; Wu et al., 2014; Ferreira et al., 2013), post -traumatic \nstress disorder (PTSD) (Rouw & Erfanian, 2017), depression (Wu et al., 2014),  generalized \nanxiety disorder (Ferreira et al., 2013), ADHD (Rouw & Erfanian, 2017), Tourette’s syndrome \n(Neal & Cavanna, 2013), eating disorders (Kluckow et al., 2014) as well as tinnitus and \nhyperacusis (Jastreboff & Jastreboff, 2014). However, a signifi cant number  of individuals with \nmisophonia report that they do not suffer from  any additional conditions (Rouw & Erfanian, \n2017). More research in this area is needed as there is currently no demonstrable evidence that a \nrelationship  exists between misopho nia and other  conditions (Potgieter et al., 2019).  \nA number of potential treatments for misophonia have been explored, including cognitive \nbehavioral therapy (CBT) (Schröder et al., 2017; Bernstein et al., 2013; McGuire et al., 2015), \ntinnitus retraining therapy (TRT) (Jastreboff & Jastreboff, 2014), counterconditioning (Dozier, \n2015), mindfulness and acceptance based approaches (Schneider & Arch, 2017) and \npharmacological treatment (Vidal et al., 2017; Tunç et al., 2017). However, in addition to . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 6",
      "page_number": 6,
      "text": "6 varying levels of effectiveness, there looms a significant problem in that these proposed \ntreatments for misophonia are extremely preliminary and have not yet been validated through \nrigorous scientific testing (Potgieter et al., 2019).  \nIn the last five years, mis ophonia has often been compared with another emerging \nsensory phenomenon called the autonomous sensory meridian response (ASMR) in which \nindividuals experience pleasant tingling sensations (usually centralized around  the scalp and \nneck) and feelings of rel axation in response to specific auditory and visual stimuli ( Barratt & \nDavis, 2015; Janik McErlean & Banissy, 2018; Cash et al., 2018) . ASMR inducing sounds (also \ntermed  “triggers”) often include whispering, quiet repetitive noises, crinkling, crisp sounds  and \nsounds indicative of receiving personal attention.  Interestingly, m any ASMR triggers share \nstriking similarities with misophonic t riggers. Additionally, n early half of the 300 misophonic \nparticipants in a study conducted by Rouw & Erfanian (2017) reported exper iencing ASMR to \ncertain sounds, suggesting  a potential overlap  between ASMR and misophonia  that should \nundoubtedly be investigated further.  \n  Despite a growing interest in misophoni a in recent years, there still remains a marked \nlack of empirical research studies investigating the condition. The current study investigates an \nintriguing characteristic of misophonia reported by Edelstein et al. (2013) that may have the \npotential to inf orm future therapies. Namely, many sufferers have reported that sounds produced \nby certain individuals (typically family members and friends) are particularly aversive, while the \nsame type of sound produced by another individual or a stranger may evoke les s of a negative \nresponse or none at all. Also, self -produced trigger sounds rarely appear to evoke an aversive \nresponse in misophonic individuals. Given that an individual’s misophonia often appears to be \nlocalized around specific individuals, it seems lik e the misophonic response could be context . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 7",
      "page_number": 7,
      "text": "7 sensitive. It has also been reported that the sounds of animals or babies are typically not found to \nbe as aversive as similar sounding trigger sounds produced by adult humans. Although there are \nalways exceptions , based on the aforementioned reports, it appears that an aversive stimulus \noften involves a highly nuanced formulation of sound and context, suggesting that a misophonic \ntrigger is more than just a sound and instead, a Gestalt of features which includes s ound (real or \nanticipated) as a necessary component. The idea that any singular feature of an aversive stimulus \ndoes not necessarily produce aversion on its own, is very interesting and warrants further \nexploration for both understanding misophonia on a fu ndamental level, and for its potential for \nclinically informative results.  \nThrough the use of self -repor ted aversiveness ratings , we assessed participant aversion to \na variety of classic trigger sounds in the presence and absence of contextual information.  Clips of \ncommon trigger sounds (crunchy/wet human eating sounds) as well as sounds that highly \nresembled trigger sounds (crunchy/wet animal eating sounds and various crunchy/wet non eating \nsounds) were presented to self -identified misophonic and age/gende r matched control \nparticipants in three experimental blocks. In each of the three experimental blocks, the type of \ncontextual information accompanying each sound differed slightly. In block 1, participants were \npresented with only the audio of the sounds, and not given any feedback about what they were \nlistening to. In block 2, participants were also presented with only the audio of the sounds, but \nprior to each sound, received a short text description about what they were potentially listening \nto. However,  participants were informed that this description was not always correct and it was \nup to them to decide if the description matched the sound presented. In block 3, participants were \npresented with both the audio and video of each sound, which ultimately r evealed the identity of \neach sound they had been listening to.  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 8",
      "page_number": 8,
      "text": "8 By utilizing deliberately ambiguous sounds and manipulating the type of contextual \ninformation provided about said sounds, our intention was to influence what participants \nbelieved they were li stening to, to the extent where they may be convinced that certain trigger \nsounds were actually non -trigger sounds and certain non -trigger sounds were actually trigger \nsounds , and observe if their beliefs influenced their reactions . We hypothesized that mi sophonic \nindividuals (but not controls) would find sounds that they perceived to be human eating sounds \n(regardless of whether they  actually  were or not) to be significantly more aversive than sounds \nthat they perceived to be animal  eating and non eating s ounds.  If successful, this study would \ndemonstrate that  contextual information that an individual associates with a sound can \nsignificantly influence their response to that sound, providing empirical evidence for the idea that \nthe physical properties of a  trigger sound are not the only factors driving the misophonic \nresponse.  \n \nMETHODS  \nParticipants:  \nTwenty self -identified misophonic participants  (5 males and 15 females; mean age = 30.4 \nyears; range = 20 -58) and twenty age and gender matched control participants  (5 males and 15 \nfemales; mean age = 31.24 years; range = 20 -58) were recruited from the student population at \nthe University of California, San Diego and the greater San Diego area. All participants  reported \nnormal vision and hearing and signe d a consent form approved by the UCSD Human Research \nProtections Program prior to participating. Participants  were reimbursed with either UCSD \ncourse credit or at a rate of $10/hour. The entire lab session lasted for approximately 2 hours.  \n . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 9",
      "page_number": 9,
      "text": "9 Questionnaires:  \nControl participants  filled out a short demographic form that also assessed any prior \nknowledge of misophonia and sought to determine whether they may suffer from the condition \nunknowingly.  No control participants were found to experience misophonic symptoms.  Self-\nidentified misophonic participants  were given a demographic form as well as several commonly \nused misophonia questionnaires that assessed their experiences with the condition and gauged \nthe severity of their symptoms. The question naires included were the Ams terdam Misophonia \nScale (A -MISO -S), which measures the severity of the symptoms and intensity of responses \nassociated with a parti cipant’s misophonia, the Misophonia Activation Scale (MAS -1) which \ncharacterizes eleven levels  (0-10) of mi sophonia severity, and the Miso phonia Assessment \nQuestionnaire (MAQ)  which assesses how frequently participants experience negative effects \nand disturbances associated with misophonia.   \nMisophonic participants scored an average of 11.7 (range = 7 -24) points out of a \nmaximum of 24 (most severe) points on the A -MISO -S and an average of 28 (range: 10 -63) \npoints out of a maximum of 63 points (most severe) on the MAQ. Of the eleven levels of \nmisophonia  severity detailed in the MAS -1 (0-10), the average level amongst participants was \nfound to be 5.475 (range = 3.5 -9).  \n \n \nExperimental Setup:  \nAs a general overview, each participant took part in a session that consisted of 3 \nexperimental blocks. Although it differed slightly from block -to-block, the general structure of a \nblock was as follows: participants were seated 20 inches away from a compu ter screen and wore . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 10",
      "page_number": 10,
      "text": "10 a pair of Sennheiser headphones. Through the use of MATLAB R2014B, visual stimuli were \npresented on the computer screen and auditory stimuli were presented through the headphones at \n50% of the computer’s volume. An individual trial cons isted of a 5 second ( pre-stimulus  period) \nfollowed by a 15 second clip (stimulus period), and finally a 10 second intertrial interval (ITI). \nDuring the ITI, participants were instructed to verbally make an aversiveness rating about the \nclip they were just presented with on a 1 -10 scale. Each block contained 36 clips, with each clip \nfalling into  one of three sound categories (Fig. 1) . \n Participants were informed beforehand that an aversiveness rating of “1” signified very \nlittle to no discomfort while a rati ng of “10” signified extreme discomfort and possibly a strong \ndesire to leave the room should the sound continue. Each aversiveness rating was recorded by the \nexperimenter. Between blocks, participants were instructed to take a short break.  \n \nStimuli:  \nThirty-six, 15 -second video clips were used in the study. All clips were either found on \nYoutube or created in the lab. Each clip was placed into one of three sound categories: human \neating, animal eating or non eating, with 12 clips in each category. Clips we re selected based on \nthe criteria that they either were or highly resembled classic misophonic trigger sounds (most \nwere crunchy or wet sounding in nature). Audio (sound only) and audio -visual (sound + video) \nversions of each clip were created.  \nClips were  selected based on results from a pilot study involving 21 participants that was \nconducted in the summer of 2016. The purpose of this pilot study was to identify a set of classic \nmisophonic sounds that could plausibly be interpreted as belonging to more th an one of the . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 11",
      "page_number": 11,
      "text": "11 aforementioned sound categories (when presented with only audio and no visuals). The most \ncategorically ambiguous clips were then selected to be used as stimuli in the current study.  \n \nExperimental Blocks:  \n For each block 1 trial, participan ts were presented with a 5 second pre-stimulus  period \nfollowed by a 15 second audio only clip, and then a 10 second ITI during which they made their \naversiveness rating on a 1 -10 scale. In addition to their aversiveness rating, participants were also \ninstructed to make a guess as to what they thought the sound source of each clip was (based on \nthe aforementioned 3 sound categories) during this ITI. The sounds in block 1 were presented in \na randomiz ed order for every participant (Fig. 1).  \nFor each block 2 tr ial, participants were presented with a 5 second pre-stimulus  period \nwhich included 1 second of blank, black screen, followed by 3 seconds of descriptive text, \nfollowed by 1 second of blank, black screen. Next came a 15 second audio only clip and then the \n10 second ITI during which participants made their aversiveness rating on a 1 -10 scale. Half of \nthe time the text presented during the pre-stimulus  period was a correct description of the sound \nthat would play immediately after it and half of the time it was an incorrect description (Fig. 1).  \nWhen it was incorrect, the text was a randomly selected description from one of the other two \nsound categories that the sound from that trial did not fall under. An incorrect description was \nnever from the same categor y as the sound presented. For each trial in block 2, participants \nresponded with a “yes” or “no” as to whether or not the text description they received sounded \nlike the sound they were presented with. Participants were instructed to make this judgment \nbased on general sound category and not the specifics of each description. The ordering of both \nthe textual descriptions and sounds were preselected for each participant and counterbalanced. . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 12",
      "page_number": 12,
      "text": "12 There were 6 possible sound and 6 possible text pseudo -random orderi ngs. Each misophonic \nparticipant was matched with a control participant who received the same sound and text \nordering in block 2 as they did.  \n For each block 3 trial, participants were presented with a 5 second pre-stimulus  period \nfollowed by a 15 second v ideo clip (audio and video) and then a 10 second ITI during which \nparticipants made their aversiveness rating on a 1 -10 scale. Video clips in block 3 were presented \nin a randomi zed order for each participant (Fig. 1).  \n \nRESULTS  \nWithin Blocks Results  \nBlock 1: Audio Only  | All Trials : \n As expected, we found that overall, aversiveness  ratings given by misophonics (M = \n4.92) were significantly higher  than rating s given by controls (M = 1.97) [F(1,38) = 49.764, p < \n.001]. There was also an observed within subject factor effect of Sound Category [F(2,76) = \n25.719, p  < .001], where aversion to sounds from the human eating category (M = 4.01) was \nsignificantly higher than aversion to sounds from the animal eating (M = 3.18) and non eating \n(M = 3.15) categories , across groups (Fig. 2A).  \nThis observed main effect of Sound Category was driven by a significant interaction \nbetween Group and Sound Category [F(2,76) = 21.406, p  < .001], where misophonic participants \nrated human eating sounds as particularly aversive compared with animal eating and non eating \nsounds (M = 5.98, 4.55, 4.25 respectively for misophonics; M = 2.05, 1.82, 2.06 respectively for \ncontrols). As a follow up to  the interaction, paired t -tests indicated that misophonic participants \nrated human eating sounds as significantly more a versive than both animal eating [t(19) = 6.36, p  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 13",
      "page_number": 13,
      "text": "13 < .001] and non eating [ t(19) = 5.27, p <  .001] sounds (there was no statistical diffe rence \nbetween animal eating vs non eating so unds [ t(19) = 1.563, p = .135 ]) (Fig. 2A).  \nFigure 4 depicts average misophonic and control rating s of each stimulus from block 1 in \nthe form of a sc atterplot, illustrating  the finding that misophonic participants found all stimuli to \nbe more  aversive  than controls did  as well as showing  which sounds were found to be most \naversive.  \n \nBlock 1: Audio Only  | Correct Trials : \n  For ratings of trials where participants c orrectly identified the soun d category, we found \nsignificant main effects of Group [F(1,38) = 48.109, p  < .001], with the misophonic group rating \nsounds as significantly more aversive overall (M = 4.91) than the control group (M = 1.97), and \nSound Cat egory [F(2,76) = 28.552, p  < .001], with human eating sounds rated as more aversive \n(M = 4.22) than a nimal eating (M = 3.26) and non eating sounds (M = 2.83) across groups. A \nsignificant interaction between Group and  Sound Cat egory [F(2,76) = 19.801, p  < .001] was also \nobserved, with human eating sounds rated as particularly aversive by the misophonic participants \n(M = 6.28), compared with a nimal eating (M = 4.75) and non eating sounds (M = 3.71)  (Fig. \n2C).  \nPaired t -tests confirmed that misophonics rated human eating sounds as signifi cantly \nmore aversive than animal eating sounds [t(19) = 5.09, p  < .001] and non eating sounds [t(19) = \n5.60, p <  .001]. Interestingly, misophonics also rated animal eating sounds as signi ficantly more \naversive than non eating sounds [t(19) = 3.79, p = .001 ]. Controls were found to rate human \neating sounds as significantly more aversive than animal eating sounds, [t(19) = 3.13, p = .006], \nbut not non e ating sounds [t(19) = 1.50, p =  .149]. Controls also found non eating sounds to be . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 14",
      "page_number": 14,
      "text": "14 marginally more aversive than animal eating sounds [t(19) = 1.826, p = .084].  \n \nBlock 1: Audio Only  | Incorrect Trials : \nFor ratings of trials where the participant incorrectly identified the sound category, we \nfound a significant main effect of Group [F(1,38) = 42.685, p < .001 ], with the misophonic group \nrating sounds as significantly more aversive overall (M = 4.59) than the control group (M = \n1.94), a marginally significant main effect of Sound Category [F(2,76) = 2.557, p  = .084], \n(human eating sounds (M = 3.21) , animal eating (M = 3.08), non eating sounds (M = 3.51) \nacross groups), but no signifi cant interaction between Group and  Sound Category [F(2,76) = \n.593, p  = .475], with human eating sounds not rated as particularly aversive by the misophonic \nparticipants (M = 4.65) when compared with a nimal eating (M = 4.28) and non eating sounds (M \n= 4.84) (Fig. 2B) .  \nPaired t -tests indicated that misophonics did not demonstrate any significant difference in \naversiveness ratings between incorrectly identified human eating sounds and inco rrectly \nidentified animal eating sounds [t(19) = .938, p  = .36] or incorrectly identified non e ating sounds \n[t(19) = -.59, p =  .562]. There was also no significant difference between the ratings of \nincorrectly identified animal eating sounds  and incorrectl y identified non eating sounds [t(19) = -\n1.67, p = .112] for misophonics. Controls did not demonstrate any significant difference in \naversiveness ratings between incorrectly identified human eating sounds and incorrectly \nidentified animal eating sounds  [t(19) = -.892, p = .384 ] or incorrectly identified non eating \nsounds [t(19) = -1.80, p = .088]. There was also no significant difference between the ratings of \nincorrectly identified animal eating sounds  and incorrectly identified non eating sounds [t(19) = -\n1.582, p = .130] for controls.  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 15",
      "page_number": 15,
      "text": "15  \nBlock 1: Audio Only  | Trial Comparisons:  \nAdditionally, the ratings of trials where the participant incorrectly identified the sound \ncategory were compared to trials where they correctly identified the sound category. Specif ically, \nwe were interested in comparing 1) ratings of trials where human eating sounds were \nmisidentified as either animal eating sounds or non  eating sounds to ratings trials where human \neating sounds were correctly identified as human eating sounds, 2) r atings of trials where animal \neating sounds were misidentified as human eating sounds to ratings of trials where animal eating \nsounds were correctly identified as animal eating sounds and 3) ratings of trials where non  eating \nsounds were misidentified as h uman eating sounds to ratings of trials where non  eating sounds \nwere correctly identified as non  eating sounds.  \nResults showed that misophonics rated human eating sounds incorrectly identified as \nanimal eating or non  eating  sounds (M = 4.64, SD = 2.26) as significantly less aversive than \nhuman eating sounds correctly identified as human eating sounds (M = 6.28, SD = 2.18), [t(19) = \n-4.46, p <  .001]. The same pattern was present for controls [t(19) = -2.2, p =  .04]. Although there \nwas no significant difference between misophonic ratings of animal eating sounds incorrectly \nidentified as human eating sounds (M = 5.04, SD = 1.7) and animal eating sounds correctly \nidentified as animal eating sounds (M = 4.75, SD = 1.97), [t(19) = -.865, p = .398]s , controls did \nshow a significant difference in ratings between these two groups of trials, [t(19) = -2.25, p = \n.036]. Lastly, misophonics rated non  eating sounds incorrectly identified as human eating sounds \n(M = 5.2, SD = 1.41) as signif icantly more aversive than non  eating sounds correctly identified \nas non  eating sounds (M = 3.7, SD = 1.91), [t(19) = 3.08, p = .006]. Controls also exhibited the \nsame pattern of results for non  eating  sounds [t(19) = 3.3, p = .004]  (Fig. 2C) .  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 16",
      "page_number": 16,
      "text": "16  \nBlock 1: Audio Only: Stimulus  Classification | Category Guess Propensity & Accuracy:  \nWe also investigated the level of accuracy for sound category identification (percentage \nof trials correct) with factors of Group (misophonics, controls) and Sound Category (human \neating, animal eating, non  eating). No significant main effect of Group [F(1,38) = .615, p = .438 ] \nwas observed, but there was a significant main effect of Sound Category [F(2,76) = 18 .156, p < \n.001] as well as a marginally signifi cant interaction between G roup and  Sound Category [F(2,76) \n= 3.353, p  = .04]. This interaction brings about a few interesting findings. The first finding \nrevealed that misophonic participants  (M = 79.175%, SD = 16.120%) were significantly more \naccurate than controls (M = 67.075%, S D = 12.8293%) when identifying human eating sounds in \nparticular [F(1,38) = 6.899 , p = .012] but not when identifying animal eating sounds [F (1,38) = \n.034, p = .854] or non eating sounds [F( 1,38) = 1.756, p = .193] (Fig. 3A) .  \nPaired t -tests indicated tha t misophonics were also significantly more accurate at \nidentifying human eating sounds than animal eating sounds [t(19) = 5.361, p  < .001], \nsignificantly m ore accurate at identifying non eating sounds than animal eating sounds [t(19) = \n2.482, p = .023] and  marginally more accurate at identifyi ng human eating sounds than non \neating sounds [t(19) = 1.885, p  = .075]. Additionally, controls were significantly more accurate \nat identifying human eating sounds than animal eating sounds, [t(19) = 4.708, p  < .001], \nsignificantly m ore accurate at identifying non eating sounds than animal eating sounds [t(19) = \n4.162, p  = .001] but not significantly m ore accurate at identifying non eating sounds than human \neating sounds [t(19) = 1.256, p = .224].  \nIn order to ad dress the possibility that participants  may have demonstrated a preference to \nmake guesses within a specific sound category (which could influence their accuracy), the . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 17",
      "page_number": 17,
      "text": "17 percentage of trials that were guessed to be in each sound category was investigated wit h factors \nof Group (misophonics, controls) and Sound Category (human eating, animal eating, non  eating). \nAlthough no significant main effects of Group [F(1,38) = .580, p = .451] or Sound Category \n[F(2,76) = 1.9, p  = .157] were observed, a signifi cant inter action between Group and  Sound \nCategory [F(2,76) = 5.472, p  = .006] was found. This interaction brings about a few interesting \nfindings. The first finding revealed that misophonic participants  were significantly more likely \nthan controls to guess that a so und was a human eating sound [F(1,38) = 9.37, p = .004] but not \nsignificantly more likely than controls to guess that a sound was an animal eating sound [F(1,38) \n= .233, p = .632]. Interestingly, controls were significantly more likely than misophonics to \nguess that a sound was a non eating sou nd [F(1,38) = 5.395, p = .026] (Fig. 3B) . \n  Paired t -tests indicated that misophonics were also significantly more likely to guess that \na sound was a human eating sound as opposed to an animal eating sound [t (19) = 2. 667, p  = \n.015], or a non eating sound [t(19) = 2.16, p = .044]. No significant difference in guessing rate \nwas foun d between animal eating and non eating sounds [t(19) = .164, p  =.871]. Additionally, \nalthough controls were not significantly more likely to guess that a sound was a human eating \nsound as opposed to an animal eating sound [t(19) = .202, p = .842], they were marginally more \nlikely to guess that a sound was a non eating sound as opposed to a human eating sound [t(19) = \n1.936, p  = .068], or an ani mal eating sound [t(19) = 2.011, p = .059].  \n \nBlock 2: Audio + Text | Agree  + Disagree Trials:  \n  First, we conducted a repeated measures mixed design ANOVA on factors of Group \n(misophonic, control) and Sound Category (human eating, animal eating, non  eating) for ratings \nof all b lock 2 trials (regardless of whether the participant received an accurate (target) or false . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 18",
      "page_number": 18,
      "text": "18 (foil) textual description and regardless of whether they got the trial right or wrong). Overall, we \nfound significant main effects of Group [F(1,38) = 51.1, p < .001 ] and Sound Category [F(2,76) \n= 34.7, p  < .001] as well as a signifi cant interaction between Group and  Sound Category [F(2,76) \n= 27.6, p <  .001].  \nFollow up paired t -tests revealed that misophonics rated human eating sounds (M = 6.14, \nSD = 2.03) as significantly more aversive than both animal eating (M = 5.00, SD = 2.01), [t(1 9) \n= 5.87, p < .001] and non  eating sounds (M = 4.45, SD = 1.8), [t(19) = 6.69, p <.001]. \nAdditionally, misophonics rated animal eating sounds as significantly more aversive than non  \neating sounds [t(19) = 3.37, p = .003]. Controls demonstrated a similar p attern of results and \nrated human eating sounds (M = 2.1, SD = .79) as significantly more aversive than animal eating \nsounds (M = 1.87, SD = .6), [t(19) = 3.301, p = .004] but not non  eating sounds (M = 2.05, SD = \n.719) [t(19) = .669, p = .512]. Additional ly, controls rated non  eating sounds as significantly \nmore aversive than animal eating sounds [ t(19) = 2.75, p = .013] (Fig. 5 A). \n \nBlock 2: Audio + Text | Agree Trials:  \nWe compared the ratings of trials where participants incorrectly believed false text (foil) \ndescriptions preceding the stimulus to trials where they correctly believed true text (target) \ndescriptions preceding the stimulus. Specifically, we were interested  in comparing 1) ratings of \ntrials where human eating sounds were incorrectly believed to be either animal eating sounds or \nnon eating sounds to ratings of trials where human eating sounds were correctly believed to be \nhuman eating sounds, 2) ratings of tr ials where animal eating sounds were incorrectly believed to \nbe human eating sounds to ratings of trials where animal eating sounds were correctly believed \nto be animal eating sounds and 3) ratings of trials where non  eating sounds were incorrectly . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 19",
      "page_number": 19,
      "text": "19 believe d to be human eating sounds to ratings of trials where non  eating sounds were correctly \nbelieved to be non  eating sounds.  \nSpecifically, misophonics rated human eating sounds incorrectly believed to be animal \neating or non  eating sounds (M = 4.83, SD = 1.8 1) as significantly less aversive than human \neating sounds correctly believed to be human eating sounds (M = 6.59, SD = 2.23), [t(19) = -\n4.344, p < .001]. Misophonics also rated animal eating sounds incorrectly believed to be human \neating sounds (M = 5.56,  SD = 2.00) as significantly more aversive than animal eating sounds \ncorrectly believed to be animal eating sounds (M = 4.79, SD = 2.21), [t(19) = 1.69, p = .05]. \nAdditionally, misophonics rated non  eating sounds incorrectly believed to be human eating \nsounds (M = 5.58, SD = 1.55) as significantly more aversive than non  eating sounds correctly \nbelieved to be eating sounds (M = 4.23, SD = 1.92), [t(19) = 3.03, p = .0035 ] (Fig. 5 B). \nControls did not rate animal eating sounds incorrectly believed to be human e ating \nsounds as significantly more aversive than animal eating sounds correctly belie ved to be animal \neating sounds [ p >.05 ]. They also did not rate non  eating sounds incorrectly believed to be \nhuman eating sounds as significantly more aversive than non  eating sounds correctl y believed to \nbe eating sounds [ p >.05 ]. However, controls did rate human eating sounds incorrectly believed \nto be animal eating or non  eating sounds (M = 1.78, SD = .76) as significantly less aversive than \nhuman eating sounds correctly  believed to be human eating sounds (M = 2.31, SD = 1.07), [t (19) \n= -2.13, p = .047]  (Fig. 5 B). \n \nBlock 3: Audio + Video  Trials : \n We conducted a repeated measures mixed design ANOVA on factors of Group \n(misophonic, control) and Sound Category (human eating, animal eating, non  eating) for ratings . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 20",
      "page_number": 20,
      "text": "20 of block 3 trials. Overall, we found significant main effects of Group [F(1,38) = 46.822,  p < \n.001] and Sound Categ ory [F(2,76) = 51.879, p < .001 ] as well as a signifi cant interaction \nbetween Group and  Sound Category [F(2, 76) = 21.081, p < .001 ].  \n  Follow up paired t -tests revealed that misophonics rated human eating sounds (M = 6.97, \nSD = 2 .01) as significantly more aversive than both animal eating (M = 3.99, SD = 2.28), [t(19) \n= 7.39, p < .001] and non  eating sounds (M = 6.57, SD = 2.08), [t(19) = 6.69, p <  .001]. \nMisophonics did not rate animal eating sounds as significantly more aversive than non  eating \nsounds [t(19) = -.186, p = .854]. Controls rated human eating sounds (M = 2.44, SD = .87) as \nsignificantly more aversive than animal eating sounds (M = 1.63, SD = .46), [t(19) = 5.134, p < . \n001] and non  eating sounds (M = 1.94, SD = .63) [ t(19) = 3.13, p = .006]. Additionally, controls \nrated non  eating sounds as significantly more aversive than animal eating sounds [t(19) = 3.29, p \n= .004]  (Fig. 6 ). \n \nBetween Blocks Results  \nIn addition to investigating how misophonic and control participants  responded to human \neating, animal eating and non  eating sounds within the differing contexts of blocks 1, 2 and 3, we \nalso examined how their responses to specific sounds changed across these blocks. In particular, \nwe were interested in observing how thei r ratings changed between all three blocks for  \n1) human eating sounds that were correctly identified as human eating sounds in block 1 \nbut were believed to be produced by nonhuman (animal eating and non  eating sounds) sources in \nblock 2.  \n2) nonhuman sounds  (animal eating and non  eating sounds) that were correctly identified \nas nonhuman sounds in block 1 but were believed to be human eating sounds in block 2.  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 21",
      "page_number": 21,
      "text": "21 3) human eating sounds that were correctly identified as human eating sounds in blocks 1 \nand 2.  \n4) nonhuman sounds (animal eating and non  eating sounds) that were correctly identified \nas nonhuman sounds in blocks 1 and 2.  \n         When considering human eating sounds that were correctly identified as human eating \nsounds in block 1 but were believed to be  produced by nonhuman sources in block 2, we find \nthat misophonics rated these sounds to be significantly more aversive in block 1 (M = 5.95, SD = \n1.69) than when they encountered them again in block 2 (M = 5.0, SD = 1.58), [t(13) = 1.892, p \n= .04 ]. Misoph onics additionally rated these sounds to be significantly more aversive in block 3 \n(M = 6.45, SD = 1.45) than block 2 (M = 5.0, SD = 1.58), [t(13) = 3.065, p  = .0045 ], but no \nsignificant difference in ratings for these sounds was  found between blocks 1 and  3, [p > .05]. \nControls did not exhibit significant differences in ratings for these  sounds between blocks 1 and \n2 [p > .05], blocks 2 and 3 [ p > .05] or blocks 1 and 3 [ p > .05] (Fig. 7 A). \n         When considering nonhuman sounds (animal eating and non  eating sounds) that were \ncorrectly identified as nonhuman sounds in block 1 but were believed to be human eating sounds \nin block 2, we find that misophonics rated these sounds to be significantly more  aversive in \nblock 2 (M = 5.7, SD = 2.32) than in block 1 (M = 4.14, SD = 2.5), [t(1 9) = 4.098, p < . 001 ]. \nMisophonics also rated these sounds as significantly more aversive in block 2 (M = 5.7, SD = \n2.32) than in block 3 (M = 3.53, SD = 2.26), [t( 19) = 4 .875, p < .001 ], but no significant \ndifference in ratings for these sounds was  found between blocks 1 and 3, [ p > .05]. Controls did \nnot exhibit significant differences in ratings for these  sounds between blocks 1 and 2 [p > .05] or \nblocks 1 and 3 [ p > .05], but a significant difference between blocks 2 and 3 was observed, with . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 22",
      "page_number": 22,
      "text": "22 these sounds being rated as significantly more aversive in block 2 (M = 2.08, SD = 1.03) than \nblock 3 (M = 1.59, SD = .712), [t (16) = 3.125, p = .007] (Fig. 7 B). \n         When compar ing human eating sounds that misophonics correctly identified as human \neating sounds in block 1 but were believed to be produced by nonhuman sources in block 2, with \nnonhuman sounds (animal eating and non  eating sounds) that misophonics correctly identifie d as \nnonhuman sounds in block 1 but were believed to be human eating sounds in block 2, we find a \nsignificant main effect of the between subject factor of Sound Type  [F(1,32) = 4.57, p = .04]  and \na significant interaction between Sound Type  and t he within subject factor Block [ F(2,64) = \n17.254, p  < .001]  (Fig. 7 C).  \nWhen considering human eating sounds that were correctly identified as human eating \nsounds in blocks 1 and 2, we find that misophonics rated these sounds to be marginally more \naversive in block 2 (M = 6.6, SD = 2.29) than when they encountered them in block 1 (M = 6.32, \nSD = 2.36), [ t(19) = 1.48, p = .08 ], significantly more aversive in block 3 (M = 7.07, SD = 2.15) \nthan block 2 (M = 6.6, SD = 2.29), [t (19) = 2.33, p = .015 ], and significantly mo re aversive in \nblock 3 (M = 7.07, SD = 2.15) than block 1 (M = 6.32, SD = 2.36), [ t(19) = 3.28, p =  .002]. \nControls did not exhibit significant differences in ratings for these  sounds between blocks 1 and \n2 [p > .05], blocks 2 and 3 [p > .05]  or blocks 1 and 3 [p > .05]  (Fig. 8 A). \n         When considering nonhuman sounds (animal eating and non  eating sounds) that were \ncorrectly identified as nonhuman sounds in blocks 1 and 2, we find that misophonics did not \nexhibit significant differences in rat ings for these  sounds between blocks 1 and 2 [p > .05], \nblocks 2 and 3 [ p > .05] or blocks 1 and 3 [ p > .05]. Controls also did not exhibit significant \ndifferences in ratings for these  sounds between blocks 1 and 2 [ p > .05], blocks 2 and 3 [ p > .05] \nor blocks 1 and 3 [ p > .05] (Fig. 8 B). . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 23",
      "page_number": 23,
      "text": "23          When comparing human eating sounds that misophonics  correctly identified as human \neating sounds in blocks 1 and 2 and nonhuman sounds (animal eating and non  eating sounds) that \nmisophonics correctly identified as nonhuman sounds in blocks 1 and 2, we find a significant \nmain effect of the between subject fa ctor of Sound Type  [F(1,56) = 14.53, p < .00 1] and a \nsignificant interaction between Sound Type  and t he within subject factor Block [ F(2,112) = 3.42, \np = .036]  (Fig. 8 C).  \n Lastly, when investigating differences in how individual stimuli were rated in bloc k 3 and \nblock 1, we find that misophonic participants had a larger range of difference scores overall than \ncontrols. Additionally, although both misophonic and control participants tended to rate human \neating sounds as more aversive in block 3 than block 1 , and animal eating sounds as less aversive \nin block 3 than block 1, misophonics demonstrated this t o a much greater  extent  (Fig. 9 ). \n \nDISCUSSION  \nOverall these results support our main hypothesis that context plays a role in how \naversive  misophonic participants  find certain sounds  to be . This is in line with previous reports \nthat suggest that a sound’s source is a crucial factor in determining what is considered a \nmisophonic trigger sound to an individual  (Edelstein et al., 2013; Schneider & Arch, 2017) . \nHowever, the findings from our experiment extend beyond this and show that while sound \nsource is indeed an important factor in the misophonic respon se, an individual’ s perception  of a \nsound’s source is enough to  influence how they respond to that sound.  \n Our hypothesis that misophonic participants would find human eating sounds as most \naversive when compared with animal eating and non  eating sounds w as confirmed by within \nblock analyses of ratings and skin conductance of blocks 1, 2 and 3.  In block 1, we showed that . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 24",
      "page_number": 24,
      "text": "24 in the absence of any contextual information (such as text description or video), whether or not a \nparticipant correctly guessed a sound ’s source (and specifically what they thought the sound was \nwhen they didn’t guess correctly), played a role in how aversive they rated that sound to be. \nBlock 2 showed a similar finding, where correct or incorrect text descriptions provided prior to \neach sound (and whether or not participants believed these descriptions), influenced how \naversive participants found those sounds to be. Block 3, which included video of the sound \nparticipants were listening to, left no room for interpretation and further solid ified the finding \nthat human eating sounds were considered by both misophonic and control participants to be \nsignificantly more aversive than animal eating and non  eating sounds. Although both groups \nfound human eating sounds to be the most aversive  sound category, misophonic individuals  \nalways showed much higher aversiveness ratings than controls overall.  \nIn addition to examining how participants responded to these three categories of sounds \nwithin blocks, we examined how responses to specific sounds with in these categories may \nchange across blocks. In particular, we found that the very same sound could be rated \nsignificantly differently from block to block when paired with different contextual information. \nSpecifically, we were interested in the rating ch ange across blocks of human eating and \nnonhuman sounds (animal eating and non  eating sounds were grouped together to form this \ncategory) that were identified correctly in block 1, but were believed to be nonhuman sounds and \nhuman eating sounds, respectivel y, when they were heard again in block 2. Indeed, we found that \nmisophonics, but not controls, rated the very same human eating sounds that were correctly \nidentified in block 1, as significantly less aversive when encountered again in block 2 when \nbelieved  to be nonhuman sounds. When misophonics encountered those same human eating \nsounds for a third time in block 3, with video, their ratings significantly increased from block 2. . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 25",
      "page_number": 25,
      "text": "25 Conversely, we found that misophonics, but not controls, rated the very same no nhuman sounds \nthat were correctly identified in block 1, as significantly more aversive when encountered again \nin block 2 when believed to be human eating sounds. When misophonics encountered those same \nnonhuman sounds for a third time in block 3, with vid eo, their ratings significantly decreased \nfrom block 2.  \nWe were also interested in the rating change across blocks of human eating and \nnonhuman sounds that were correctly identified as human eating and nonhuman sounds, \nrespectively, in both blocks 1 and 2 . While controls did not exhibit significant differences in \nratings between blocks for either of these groups of sounds, misophonics did, but only for human \neating sounds and not nonhuman sounds. Specifically, misophonics rated human eating sounds \nas incre asingly aversive from blocks 1 to 3. This suggests that for trigger sounds, such as human \neating sounds, the more contextual information misophonics are given about what they were \nlistening to, the more aversive the sound becomes.  \n In terms of future dire ctions, it would be worthwhile to develop  a reliable technique to \nassess physiological marker s of misophonia. It should be noted that w e collected  SCR and \nelectromyography (EMG)  data from the participants in this specific study in order to supplement \ntheir subjective aversiveness ratings , but unfortunately,  due t o a number of factors such as a low \nsignal to noise  ratio, outdated equipment  and the length of the study , not enough of the \nphysiological data  ended up being clean enough to be properly analyze d. However, with higher \nquality recordings, some of the observed main effects from this study would likely produce \nreliable physiological components.  \nUltimately, t he findings from this study demonstrate that sound source plays a large role \nin what are considered to be trigger sounds. The idea that two sounds could sonically sound very . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 26",
      "page_number": 26,
      "text": "26 similar to each other, but only one might trigger an individual with misophonia, s uggested that \nthere is much more that goes into a misophonic trigger than just the sound itself. Through the \nexclusive use of sonically similar sounds, this study not only showed that human eating sounds \nwere considered to be significantly more aversive th an animal eating and non  eating sounds to \nmisophonic individuals overall; it also showed that how one interprets these sounds can \nsignificantly influence how aversive they believe them to be. The findings from this study show \nthat, depending on the context ual information given, the very same sound could be considered \nsignificantly more or less aversive th e next time it was encountered. There is already preliminary \nevidence that cognitive behavioral therapy, which utilizes techniques to help patients reappra ise \nnegative thoughts and feelings, may be helpful for individuals with misophonia (Schröder et al., \n2017). The fact that there appears to be some degree of cognitive flexibility in terms of \nreassessing misophonic trigger sounds leads us to believe that th ere may be successful \ntherapeutic applications of this work in the future.  \n \nReferences  \n \nBarratt, E. L., & Davis, N. J. (2015). Autonomous Sensory Meridian Response (ASMR): a flow - \nlike mental state. PeerJ , 3, e851.  \n \nBernstein, R. E., Angell, K. L., & Dehle, C. M. (2013). A brief course of cognitive behavioural  \ntherapy for the treatment of Misophonia: A case example. The Cognitive Behaviour \nTherapist , 6, e10.  \n \nBrout, J. J., Edelstein, M., Erfanian, M., Mannino, M., Mi ller, L. J., Rouw, R., Kumar, S. &  \nRosenthal, M. Z. (2018). Investigating Misophonia: A Review of the Empirical \nLiterature, Clinical Implications, and a Research Agenda. Front. Neurosci . 12:36. doi: \n10.3389/fnins.2018.00036  \n \nBruxner, G. (2016). ‘Masticati on rage’: a review of misophonia –an under -recognised symptom   \nof psychiatric relevance?. Australasian Psychiatry , 24(2), 195 -197. \n \nCash, D. K., Heisick, L. L., & Papesh , M. H. (2018). Expectancy effects in the Autonomous  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 27",
      "page_number": 27,
      "text": "27 Sensory Meridian Response.  PeerJ , 6, e5229.  \n \nDozier, T. H. (2015). Counterconditioning treatment for Misophonia. Clinical Case Studies ,  \n14(5), 374 –387.  \n \nEdelstein, M., Brang, D., Rouw, R., & Ramachand ran, V. S. (2013). Misophonia: physiological  \ninvestigations and case descriptions. Front. Hum. Neurosci . 7:296. Doi: \n10.3389/fnhum.2013.00296  \n \nFerreira, G. M., Harrison, B. J., & Fontenelle, L. F. (2013). Hatred of sounds: misophonic  \ndisorder or just an underreported psychiatric symptom?. Annals of clinical psychiatry: \nofficial journal of the American Academy of Clinical Psychiatrists , 25(4), 271 -274. \n \nJanik McErlean, A. B. , & Banissy, M. J. (2018). Increased misophonia in self -reported   \nAutonomous Senso ry Meridian Response. PeerJ , 6, e5351.  \n \nJastreboff, M. M., & Jastreboff, P. J. (2001). Components of decreased sound tolerance:  \nhyperacusis, misophonia, phonophobia. ITHS News Lett.  2, 5–7.  \n \nJastreboff, P. J., & Jastreboff , M. M. (2014). Treatments for decreased sound tolerance  \n(hyperacusis and misophonia). Seminars in Hearing  (Vol. 35, No. 02, pp. 105 -120).  \n \nKluckow, H., Telfer, J., & Abraham, S. (2014). Should we screen for misophonia in patients with  \neating disorders?  A report of three cases. International Journal of Eating Disorders , \n47(5), 558 -561. \n \nKumar, S., Hancock, O., Cope, T., Sedley, W., Winston, J., & Griffiths, T. D. (2014).  \nMisophonia: A disorder of emotion processing of sounds. Journal of Neurology,  \nNeur osurgery & Psychiatry , 85(8), e3 –e3. \n \nKumar, S., Hancock, O. T., Sedley, W., Winston, J. S., C allaghan, M. F., Allen, M., Cope, T. E.,  \nGander, P. E., Bamiou, D. E., & Griffiths, T. D . (2017). The brain basis for misophonia. \nCurr. Biol . 27, 527 –533. doi: 1 0.1016/j.cub.2016.12.048  \n \nMcGuire, J. F., Wu, M. S., & Storch, E. A. (2015). Cognitive ‐behavioral therapy for 2 youths  \nwith misophonia. The Journal of Clinical Psychiatry , 76(5), 573 –574. \n \nNeal, M., & Cavanna, A. E. (2013). Selective sound sensitivity syn drome (misophonia) in a  \npatient with Tourette syndrome. The Journal of Neuropsychiatry and Clinical  \nNeurosciences , 25(1), E01.  \n \nPotgieter, I., MacDonald, C., Partridge, L., Cima , R., Sheldrake, J., & Hoare, D. J. (2019).  \nMisophonia: A scoping review of research. J. Clin. Psychol . doi: 10.1002/jclp.22771.  \n \nRouw, R., & Erfanian, M. (2017). A large -scale study of misophonia. J. Clin. Psychol . doi:  \n10.1002/jclp.22500.  . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 28",
      "page_number": 28,
      "text": "28  \nSchneider, R . L., & Arch, J. J. (2017). Case study: a novel application of mindfulness -and   \nacceptance -based components to treat misophonia. Journal of Contextual Behavioral \nScience , 6(2), 221 -225. \n \nSchröder, A.  E., van Diepen, R., Mazaheri, A., Petropoulos -Petalas, D., de Amesti, V., Vulink,  \nN. C., & Denys, D. A.  (2014). Diminished n1 auditory evoked potentials to oddball \nstimuli in misophonia patients. Front. Behav. Neurosc i. 8:123. doi: \n10.3389/fnbeh.2014.00123  \n \nSchröder, A.  E., Vulink, N.  C., & Denys, D . A. (2013 ). Misophonia: diagnostic criteria for a new  \npsychiatric disorder. PLoS ONE  8:e54706. doi: 10.1371/journal.pone.0054706  \n \nSchröder, A. E., Vulink, N. C., van Loon, A. J., & Denys, D. A. (2017). Cognitive  \nbehavioral therapy is effective in misophonia: an op en trial. J. Affect. Disord.  \n217, 289 -294. doi: 10.1016/j.jad.2017.04.017  \n \nTunç, S., & Başbuğ, H. S. (2017). An extreme physical reaction in misophonia: Stop smacking    \nyour mouth! Psychiatry and Clinical Psychopharmacology , 27(4), 416 –418. \n \nVidal, C., Vi dal, L. M., & Lage, M. A. (2017). Misophonia: Case report. European Psychiatry ,   \n41, S644.  \n \nWu, M. S., Lewin, A. B., Murphy, T. K., & Storch, E. A. (2014). Misophonia: incidence,  \nphenomenology, and clinical correlates in an undergraduate student sample. J. Clin.  \nPsychol . 70, 994 –1007. doi: 10.1002/jclp.22098  \n \nZhou, X., Wu, M. S., & Storch, E. A . (2017). Misophonia symptoms among Chinese university  \nstudents: Incidence, associated impairment, and clinical correlates. Journal of Obsessive ‐ \nCompulsive and Related Disorders , 14,7 –12. \n \n \n \n . CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 29",
      "page_number": 29,
      "text": "29  \nFigure 1. Experimental setup and procedure.  \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 30",
      "page_number": 30,
      "text": "30  \nFigur e 2. Block 1 aversiveness ratings.  A) Average aversiveness ratings of human eating, \nanimal eating and non  eating sounds for misophon ic and control participants in b lock 1, \nregardless of if the sound category was correctly identified. B) Average aversiveness ratings of \nincorrectly identified human eating, animal eating and non  eating sounds for misophon ic and \ncontrol participants in b lock 1. C) Average aversiveness ra tings of correctly and specific \nincorrectly identified human eating, animal eating and non eating sounds of misophon ic and \ncontrol participants in b lock 1. Error bars represent the standard error of the mean.  * p < 0.05, \n** p < 0.01  \n \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 31",
      "page_number": 31,
      "text": "31  \nFigure 3. Sound category guess accuracy and propensity. A) Ave rage percentage of correct \nhuman eating, animal eating and non  eating trials of misophon ic and control participants in b lock \n1. B) Depicts how frequently trials (shown as percent difference from chance (33.33%)) were \nguessed by misophonic and control parti cipants to be human eating, animal eating and non  eating \nsounds in b lock 1. Error bars represent the standard error of the mean. * p < 0.05, ** p < 0.01  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 32",
      "page_number": 32,
      "text": "32  \nFigure 4. Scatterplot of misophonic and con trol ratings of all stimuli in b lock 1 .   \n \n \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 33",
      "page_number": 33,
      "text": "33  \nFigure 5. Block 2 aversiveness ratings.  A) Average aversiveness ratings of human eating, \nanimal eating and non  eating sounds for misophon ic and control participants in b lock 2, \nregardless of whether participants received an accurate (t arget) or false (foil) textual description \nand whether the sound category was correctly identified. B) Misophonic and control participants \naverage aversiveness ratings of human eating, animal eating and non eating sounds that were \neither correctly identifi ed as their target description  (left)  or incorrectly identified as specific foil \ndescriptions  (right)  in block 2. Error bars represent the standard error of the mean. * p < 0.05, ** \np < 0.01  \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 34",
      "page_number": 34,
      "text": "34  \nFigure 6. Block 3 aversiveness ratings.  Average aversiveness ratings of human eating, animal \neating and non  eating sounds for misophon ic and control participants in b lock 3. Error bars \nrepresent the standard error of the mean. * p < 0.05, ** p < 0.01  \n \n \n \n \n \n \n \n \n \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 35",
      "page_number": 35,
      "text": "35  \nFigure 7. Rating change of human eating sou nds and nonhuman sounds (believed to be  the \nopposite type of sound in b lock 2) across blocks. A) Depicts the average misophonic and \ncontrol aversiveness ratings of human eating sounds that were correctly identi fied as human \neating sounds in b lock 1 but wer e believed to be p roduced by nonhuman sources in b lock 2. B) \nDepicts the average misophonic and control aversiveness ratings of nonhuman sounds that were \ncorrectly identi fied as nonhuman sounds in b lock 1 but were believe d to be human eating sounds \nin block 2. C) Combines figures 7A and 7 B into one graph but instead of displaying average \naversiveness ratings, displays the average change in rating of each sound ty pe in each block \nrelative to b lock 1.  \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 36",
      "page_number": 36,
      "text": "36  \nFigure 8. Rating change of human eating sounds and nonhuman sounds (that were \ncorrectly identified in all blocks) across blocks. A) Depicts the average misophonic and \ncontrol aversiveness ratings of human eating sounds that were correctly identified as human \neatin g sounds in blocks 1 and 2. B) Depicts the average misophonic and control aversiveness \nratings of nonhuman sounds that were correctly identified as nonhuman sounds in blocks  1 and \n2. C) Combines figures 8A and 8 B into one graph but instead of displaying av erage aversiveness \nratings, displays the average change in rating of each sound type in each block relative to b lock \n1.  \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    },
    {
      "section": "Page 37",
      "page_number": 37,
      "text": "37  \n \nFigure 9. Rating change  of individual stimuli between b locks 3 and 1. Shows the difference \nin rating of each stimulus f rom when it was encountered in b lock 1 (audio only) a nd block 3 \n(audio + video). Control rating differences are shown on the x axis and misophonic rating \ndifferences are shown on the y axis. Purple dots represent human eating sounds, turquoise dots \nrepresent animal eating sounds and yellow dots represent non  eating sounds.  \n \n \n. CC-BY-ND 4.0 International license available under a(which was not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint this version posted September 15, 2020. ; https://doi.org/10.1101/2020.09.12.292391doi: bioRxiv preprint"
    }
  ]
}