ORIGINAL RESEARCH
published: 26 May 2022
doi: 10.3389/fnins.2022.879583
Frontiers in Neuroscience | www.frontiersin.org 1 May 2022 | Volume 16 | Article 879583Editedby:
M.ZacharyRosenthal,
DukeUniversity,UnitedStates
Reviewedby:
MercedeErfanian,
UniversityCollegeLondon,
UnitedKingdom
AndradaNeacsiu,
DukeUniversity,UnitedStates
LauraDixon,
UniversityofMississippi,
UnitedStates
*Correspondence:
Marie-AnickSavard
marieanick.savard@concordia.ca
†ORCID:
Marie-AnickSavard
orcid.org/0000-0001-9332-9806
AnastasiaG.Sares
orcid.org/0000-0002-1440-2639
EmilyB.J.Coffey
orcid.org/0000-0001-8249-7396
MickaelL.D.Deroche
orcid.org/0000-0002-8698-2249
Specialtysection:
Thisarticlewassubmittedto
AuditoryCognitiveNeuroscience,
asectionofthejournal
FrontiersinNeuroscience
Received: 19February2022
Accepted: 26April2022
Published: 26May2022
Citation:
SavardM-A,SaresAG,CoffeyEBJ
andDerocheMLD(2022)Speciﬁcity
ofAffectiveResponsesinMisophonia
DependsonTriggerIdentiﬁcation.
Front.Neurosci.16:879583.
doi:10.3389/fnins.2022.879583Speciﬁcity of Affective Responses in
Misophonia Depends on Trigger
Identiﬁcation
Marie-AnickSavard1,2,3*†,AnastasiaG.Sares1,2,3†,EmilyB.J.Coffey1,2,3†and
MickaelL.D.Deroche1,2,3†
1DepartmentofPsychology,ConcordiaUniversity,Montreal ,QC,Canada,2LaboratoryforBrain,MusicandSoundResearch
(BRAMS),Montreal,QC,Canada,3CentreforResearchonBrain,Language,andMusic(CRBLM),M ontreal,QC,Canada
Individuals with misophonia, a disorder involving extreme sound sensitivity, report
signiﬁcantanger,disgust,andanxietyinresponsetoselec tbutusuallycommonsounds.
While estimates of prevalence within certain populations su ch as college students
have approached 20%, it is currently unknown what percentag e of people experience
misophonicresponsestosuch“trigger”sounds.Furthermor e,thereislittleunderstanding
of the fundamental processes involved. In this study, we aim ed to characterize the
distribution of misophonic symptoms in a general populatio n, as well as clarify whether
theaversiveemotionalresponsestotriggersoundsarepart lycausedbyacousticsalience
of the sound itself, or by recognition of the sound. Using mul ti-talker babble as masking
noise to decrease participants’ ability to identify sounds , we assessed how identiﬁcation
of common trigger sounds related to subjective emotional re sponses in 300 adults
who participated in an online study. Participants were aske d to listen to and identify
neutral, unpleasant and trigger sounds embedded in differe nt levels of the masking
noise (signal-to-noise ratios: −30,−20,−10, 0,+10 dB), and then to evaluate their
subjective judgment of the sounds (pleasantness) and emoti onal reactions to them
(anxiety,anger,anddisgust).Usingparticipants’scores onascalequantifyingmisophonia
sensitivity, we selected the top and bottom 20% scorers from the distribution to form a
Most-Misophonic subgroup ( N=66) and Least-Misophonic subgroup ( N=68). Both
groups were better at identifying triggers than unpleasant sounds, which themselves
wereidentiﬁedbetterthanneutralsounds.Bothgroupsalso recognizedtheaversiveness
of the unpleasant and trigger sounds, yet for the Most-Misop honic group, there was a
greater increase in subjective ratings of negative emotion s once the sounds became
identiﬁable, especially for trigger sounds. These results highlight the heightened salience
of trigger sounds, but furthermore suggest that learning an d higher-order evaluation of
sounds play an important role in misophonia.
Keywords: misophonia, auditory cognition, emotion regulati on, anxiety, anger, mental health, sound sensitivity
1. INTRODUCTION
Misophonia is a disorder ( Swedo et al., 2022 ) involving extreme sensitivity to common sounds
such as eating, smacking lips, or breathing ( Schröder et al., 2013; Jastreboﬀ and Jastreboﬀ, 2014 )
which trigger a strong negative emotional state. The misopho nic response typically involves
irritability,annoyance,anxiety,disgust,andangerwhen peopleareexposedtotheirtriggersounds

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
(Rouw and Erfanian, 2018 ). People with misophonia show
heightened trigger-speciﬁc physiological autonomic respons es,
experience a strong desire to escape from the environment
where they hear trigger sounds ( Kumar et al., 2014 ), and can
sometimes feel a desire to harm those producing the sounds
(Edelstein et al., 2013 ). As a consequence, they tend to avoid
situations where triggers are likely to be encountered (e.g .,
social gatherings, classrooms, family dinners, etc.) ( Schröder
et al., 2013 ). These avoidance behaviors can be detrimental
to wellbeing, education, and social relationships ( Neal and
Cavanna, 2013; Jager et al., 2020 ), which highlights the need
to better characterize misophonia, and explore the underlyin g
mechanisms by which sounds cause such strong reactions in
certainpeople.
1.1. Misophonia in a General Population
Misophoniawithingeneralpopulationshasonlyrecentlybecome
a focus of scientiﬁc inquiry. Studies in large samples ( N
>300) estimate that, when assessed with scales speciﬁcally
designed to target misophonia, about 12–20% of people suﬀer
frommoderateorseveremisophoniasymptoms,cross-culturally
(Turkey, United Kingdom, United States, China) ( Wu et al.,
2014; Zhou et al., 2017; Kılıç et al., 2021; Naylor et al., 202 1).
Moderate and severe symptoms tend to be grouped together,
and are characterized by the interference that they cause in
daily life at work, school, and home. Research on the prevalenc e
of misophonia labels subjects as having misophonia or not
based on cut-oﬀ points; however, it is unknown if those with
severe symptoms of misophonia are truly a categorically specia l
population or merely the tail end of a continuum of sound-
sensitivity symptoms. Adding to this incertitude, there is s till
littleknowledgeofhowprevalencemaydiﬀerbetweenbiologica l
sexes.Althoughsomeresearchsuggeststhatmisophoniaismo re
prevalent in females, the samples on which these observations
were based were primarily comprised of female university
students (67–84% female), which the authors highlight as a
limitation to the generalizability of their results ( Wu et al., 2014;
Zhou et al., 2017; Kılıç et al., 2021 ). As such, it is not yet clear
if the apparent imbalance is caused by sample bias, noting that
most studies recruit within psychology departments, or due to
a real diﬀerence in prevalence across sexes. In addition to sex ,
age is a factor of interest in the study of misophonia, as ﬁndin gs
tend to point toward younger age being associated with greate r
ratesofmisophonia.Indeed,researchersﬁndahigherproporti on
of individuals with misophonia in younger samples (mean age
19.8 inZhou et al., 2017 and 21.4 in Wu et al., 2014 ) than in
relatively older and more age-balanced samples. In a study wit h
participants who were more balanced in age (age range of 15–
88 inKılıç et al., 2021 , mean age of 43.5 years old), researchers
foundloweraverageprevalenceofmisophoniaandobservedtha t
younger age was related to higher rates of misophonia. Though
prevalence estimates are inﬂuenced by the measurement tools
anddegreeofseverityconsideredasacut-oﬀ,itiscleartha tthere
are a large number of suﬀerers globally. A better understandi ng
ofwhosuﬀersfrommisophoniaisneeded.1.2. Misophonia, a Sound-Speciﬁc or
Person-Speciﬁc Disorder?
To understand why certain sounds cause such strong reaction s
in people with misophonia, some researchers turned their
attention to the nature of trigger sounds. Although they ten d
to vary between individuals, there are commonalities in the
categories of sounds reported as triggers. Speciﬁcally, they
are often everyday sounds created by other individuals (and
occasionally animals), and sometimes repetitive environmen tal
sounds (Schröder et al., 2013, 2017; Kumar et al., 2014 ). One
study found that in a large misophonic sample ( N=575),
most participants were triggered by eating sounds (96% of the
sample), nasal and breathing sounds (85%), repetitive tapping
(74%), and mouth/throat sounds (60%) ( Jager et al., 2020 ). One
observation about the nature of trigger sounds is that they t end
to share some acoustic properties. Whether they are of organic
(e.g., eating) or non-organic (e.g., clock ticking) origin, triggers
still tend to be pattern-based and repetitive ( Vitoratou et al.,
2021). In general, sounds that are temporally modulated tend
to stand out from a noisy background ( Kayser et al., 2005 );
this seems particularly exacerbated in some modulation rate s
resultingina senseofroughness ( Arnaletal.,2019 ),while other
work showed an association between ratings of unpleasantnes s
and temporal modulation (i.e., 1–16 Hz) in naturalistic sound s
(Kumar et al., 2008 ). Such acoustic qualities make auditory
stimuli easier to detect, grab the listener’s attention, an d are
thought to be processed viabottom-up auditory mechanisms
(Duangudom and Anderson, 2007 ). Given that typical trigger
sounds seem to share these attention-grabbing properties, it is
possible that early-attentive processes are somehow involved i n
misophonia(anideadiscussedin Schröderetal.,2014 ,discussed
in Section 4.2). If it is true that misophonic triggers are easi er to
detect than other types of sounds, it may be that such bottom-
up cues are involved in the development of these sounds as
triggers. In other words, more acoustically salient stimul i would
be more likely to become triggers, because people are better at
detectingthem.
At higher levels of processing, the meaning of stimuli is
extracted as we recognize sounds, interpret them, and make
links with previous memories. Another line of research thus
investigates the common observation that individuals’ tri gger
sounds seem to relate primarily to contextual cues, and only
partially to physical characteristics of the sounds ( Jastreboﬀ
and Jastreboﬀ, 2001 ). Evidence from past studies points toward
the involvement of higher-level evaluation of sounds in the
misophonic response. Such features include the meaning, soci al
context, and interpretation of the sound ( Schröder et al., 2013;
Bruxner, 2016 ), the belief that the sound is a potential threat
or that exposure to it will be harmful ( Jastreboﬀ and Jastreboﬀ,
2014), and the inﬂuence of personality traits ( Daniels et al.,
2020). In addition, a majority of people with misophonia report
that their responses are exacerbated if the sounds are produce d
by certain people, often close friends, coworkers, and family
members; or that their misophonic responses may even be
isolated to these events ( Edelstein et al., 2013 ). This insight
about the importance of the person who produces the sound in
Frontiers in Neuroscience | www.frontiersin.org 2 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
the misophonic response supports the involvement of higher-
level cognitive appraisals (i.e., subjective interpretation ) in the
misophonicreaction.Furthermore,individualswithmisophon ia
report that they may react to a given sound in one setting (such
as in their home) but not react as strongly to the same sound
in another setting (such as in the home of a friend) ( Jastreboﬀ
and Jastreboﬀ, 2014 ). Considering that the sounds share similar
acoustic properties regardless of who or what produces them,
it is likely that a person’s appraisal of a sound and context
around it aﬀect whether a misophonic reaction is produced or
not. This involvement of top-down processes has been hinted
at by self-reports and case studies, and brieﬂy mentioned in
Hansen et al. (2021) , however it has yet to be supported by
behavioralassessments.
Withevidenceforbothbottom-upandtop-downmechanisms
being involved in misophonia, disentangling the factors
contributing to the misophonic response and their relative
importance in producing said response will lay essential
groundwork for devising eﬀective intervention strategies. If
evidence supports a greater importance of acoustic cues, then
solutions should turn toward modifying the acoustic properti es
of triggers. If evidence supports the importance of higher
order evaluations of sounds, then solutions must focus on th e
associative link with the speciﬁc triggers of each patient and
imaginewaysinwhichonecouldbreakthoseassociations.
1.3. Goal of the Present Study
The ﬁrst aim of this study was to characterize the distributi on
of misophonia symptoms in a general population. To do so,
we collected responses from an online community sample on
a scale assessing misophonia. We then examined the shape
of the distribution to determine whether people with severe
misophonia symptoms represent a diﬀerent group than those
with sub-clinical symptoms (binomial distribution) or if th ey
are simply the tail-end of a normal distribution of misophonia
sensitivity. This ﬁrst aim was descriptive in nature. In term s
of a potential diﬀerence between males and females, we tested
the hypothesis that scores on the measure designed to screen
for misophonia would diﬀer between sexes. Based on previous
research ( Wu et al., 2014; Zhou et al., 2017; Kılıç et al., 2021 ),
we expected that females would score higher than males, thus
reportingmoremisophoniasymptoms.
The second aim of this study was to determine whether
misophonia could be partly caused by a reaction to acoustic
salience of typical trigger sounds regardless of what the sou nd
is (bottom-up processing), or if a sound must be consciously
identiﬁed as a known trigger in order to cause a misophonic
response (top-down evaluation of sounds). To do this, we
selected subgroups of most- and least-misophonic participants
and measured identiﬁcation thresholds (i.e., the point at wh ich
soundsfromacategorywereidentiﬁedbyagivenparticipant)o f
both groups for diﬀerent categories of sounds (neutral sounds ,
unpleasant sounds, typical misophonic triggers). To establis h
if trigger sounds were indeed more acoustically salient (i. e.,
more attention-grabbing) than other categories of sounds, we
asked participants to identify sounds in the presence of maskin g
noise with diﬀerent signal-to-noise ratios (SNR). We thenexploredtheroleofsoundidentiﬁcationonsubjectiveemoti onal
responses (anger, anxiety, disgust) and perceived pleasantne ss
of the sounds, by comparing sub-threshold and supra-threshol d
responses. This second aim yielded three diﬀerent hypotheses.
The ﬁrst hypothesis, related to lower-level properties of trig ger
sounds, is that as SNR increases (and all sounds become easie r
to detect), there would be a diﬀerence in identiﬁcation of the
diﬀerent sound categories, such that trigger sounds would be
identiﬁed more easily than neutral and unpleasant sounds. Th e
second hypothesis, related to individuals’ diﬀering ability to
detect trigger sounds, was that the group of people most prone
tomisophoniawouldhavelowerdetectionthresholdsfortrig ger
sounds (i.e., they would be able to detect trigger sounds at a
lower SNR level). A third hypothesis, related to the potential
involvement of higher-order processes in subjective emotio nal
responses of most- and least-misophonic individuals, was that
the diﬀerences in subjective ratings of trigger sounds would
only appear after the sounds are identiﬁed. In other words, at
an SNR level where sounds are not identiﬁed, both least- and
most-misophonic groups would have similar subjective ratings
of sounds, and at an SNR level where the sounds are identiﬁed,
responseswoulddiﬀerbetweengroupsfortriggersounds.
Thisstudywillfurtherourunderstandingofwhosuﬀersfrom
misophonia, whether common trigger sounds diﬀer from other
environmentalsoundsintheirsalience,andifthispotentia leﬀect
of acoustic properties or higher order evaluation of sounds pla y
importantrolesinmisophonicresponses.
2. METHODS
2.1. Participants
A total of 300 adults participated in this study (149 males, 151
females; age range: 18–50 years, mean age: 24.6 SD=6.7) and
wererecruitedonlinethroughProliﬁc(https://www.proliﬁc. co/).
Proliﬁcisanonlineplatformwhichcombinesdecentrecruitm ent
standards with reasonable cost, and allows researchers to pre -
screen participants based on information provided when the
participants sign up to the platform, which is updated over
time (Palan and Schitter, 2018 ). Research comparing Proliﬁc
to other more widely used platforms (e.g., MTurk) showed
that Proliﬁc provides the highest quality data; participants o n
Proliﬁcgenerallydevotemoreattentiontothetasks,comprehe nd
instructions better, answer questionnaire items more care fully,
and behave more honestly than on comparable platforms ( Eyal
etal.,2021 ).
To ensure that participants had a level of English ﬂuency
that would allow them to understand and take part in the
study, recruitment was only open to residents of predominantl y
English-speaking countries (65% from Canada/USA, 32%
from the Ireland/UK, 3% from Australia/New-Zealand). The
participants came from 48 diﬀerent countries of origin, with
generalrepresentationasfollows:52%fromNorthAmerica,3 0%
from Europe, 13% from Asia, 2% from Africa, 1% from South
America,1%fromOceania(1%missingdata).Fromtheresulti ng
sample, 64% were English monolinguals, 28% were bilinguals,
and8%wereﬂuentinthreetoﬁvelanguages(includingEnglish ).
Furthermore, students and non-students were represented in
Frontiers in Neuroscience | www.frontiersin.org 3 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
our sample (students: 60%, non-students: 40%), in addition to
people with diﬀering employment status (full-time: 31%; part-
time: 22%; unemployed: 23%; other: 24%). Subgroups were
deﬁnedatthedataanalysisstagebasedontotalMisoQuestsco res
(Siepsiak et al., 2020a ). See Section 3.1 for details regarding the
groupingapproach.
All participants reported being in good neurological health
with normal hearing and were free of any diagnosed language
disorder.Giventhatcomorbidityofmisophoniawithpsychiat ric
symptoms could contribute to high levels of anxiety or anger,
we used the Proliﬁc pre-screeners to exclude all individuals
who were taking medication to treat symptoms of depression,
anxiety, or low mood. This was done to limit the number of
individuals experiencing severe psychiatric symptoms in our
sample.TheexclusioncriteriaalsoincludedadiagnosisofA utism
SpectrumDisorder(basedonparticipantself-reportonProliﬁc ),
as this disorder shows considerable overlap with misophonia in
terms of symptomatology related to sound sensitivity ( Stiegler
and Davis, 2010 ). As in other crowdsourcing platforms used
for behavioral experiments, Proliﬁc provides an approval rate
for each participant. All participants who completed our study
had an approval rate above 92% ( M=99.3,SD=1.8),
which we considered to be an acceptable range. No other
exclusion criteria were speciﬁed for this study. All participa nts
gave informed consent and were compensated with 2.95GBP
(equivalent to $5CAD) for their time through Proliﬁc. The
experimental protocol was approved by Concordia University’s
HumanResearchEthicsCommittee.
2.2. Protocol
Participants were recruited through Proliﬁc (www.proliﬁc.c o),
and redirected to an online behavioral platform (Pavlovia,
https://pavlovia.org/) running the experiment designed on
PsychoPy ( Peirce et al., 2019 ). The entire experiment took on
average28mintocomplete.
Before proceeding with the task, participants were asked to
complete a questionnaire designed to screen for misophonia
(see Section 2.4). They were also asked to specify the type of
audiooutputthattheywereusing(earbuds,headphones,defau lt
computer audio, speakers), and rate the quality of their audio
(from1=poorto5 =excellent).Notethatallparticipantsrated
theiraudioqualityasa3orhigher.
Participants were presented with written instructions on how
to complete the task and completed three practice trials. The
sounds in the practice trials were presented without masking
noise. After each sound, participants rated their subjective
responses to the sound presented and identiﬁed it as they would
in the task. This allowed participants to familiarize themsel ves
with the scales for subjective ratings and with the labels fo r
the forced-choice identiﬁcation task, which they were prompt ed
to closely examine. For the ﬁrst two practice trials, they hea rd
sounds of a Toddler Crying (1st trial) and a Washing Machine
(2nd trial) for 15 s with a prompt to take this time to adjust
the audio to be comfortably loud. In the third practice trial,
participants were informed that the sounds in the study would
be considerably shorter (3 s rather than 15) and proceeded to a
trial containing a 3-s version of an Eating sound (diﬀerent fr omtheEatingsoundusedinthetask).Feedbackquestionsatthe end
of the study revealed that all participants found the instruct ions
clearandhadnoproblemunderstandingthetask.
Thetaskitselfconsistedof75trials,whereneutral,unpleas ant,
and trigger sounds were embedded in multitalker babble (see
Section 2.3), with diﬀerent levels of signal-to-noise ratio ( SNR;
15 sounds ×5 SNR levels). For each trial, participants ﬁrst
listened to the stimuli (3 s), then were prompted to rate the
pleasantness of the sound (from 0 =unpleasant to 100 =
pleasant), as well as their subjective anger (from 0 =angry to
100=neutral), disgust (from 0 =disgusted to 100 =neutral),
andanxiety(from0 =anxiousto100 =neutral),usingsliderson
a continuous scale. In contrast with appraisal of the sound itse lf,
the person-centered metrics were unidirectional with a neut ral
state on one end and the negative aﬀect on the other, such that
negativetoneutralreactionswerecaptured.Finally,forea chtrial,
participants completed a 15-alternative forced-choice (15-AF C)
task, where they were presented with labels describing all th e
possiblesoundsandwereaskedtoidentifytheonethattheyhad
just heard. The experimental interface is presented in Figure1.
The participants completed all 75 trials in one single block, and
theorderofsoundswasfullyrandomizedwithintheblock.
After the experimental portion ended, participants were
also asked to describe what they thought the purpose of
the experiment was and whether they had noticed anything
particular about the sounds (open-ended response). Of the 300
participants, a total of 19 participants provided vague answers
to both these questions. We visually assessed the data for th ese
individuals to check that they had done the task correctly.
Becausetheyallshowedgoodidentiﬁcationofthesounds(ab ove
80% identiﬁcation) on trials where the sounds were louder
than the babble, we concluded that all participants were likely
to have been engaged throughout the experiment. Participants
were further asked whether they had experienced technical
diﬃculties; no participant reported diﬃculties preventing the m
fromcompletingthetask.
2.3. Stimuli
The neutral, unpleasant, and misophonic trigger sounds used in
thisstudywereborrowedfrom Kumaretal.(2017) .Thematerials
originally comprised 42 sounds (each category consisting of 14
stimuli) of 15 s in length, from which we selected a subset of 1 5
sounds (5 from each category). The triggers in this set of sou nds
are related to orofacial actions (eating, drinking, etc.), which is
in line with previous assessments of misophonia showing that
orofacial sounds are the most common misophonic triggers.
Indeed,Jager et al. (2020) found that all participants in their
large (N=575) sample had at least one oral or nasal sound
as a trigger, and Vitoratou et al. (2021) showed that people
with misophonia were more than 40 times more likely than
those without misophonia to be triggered by eating sounds, an d
more than 20 times more likely to be triggered by loud/unusual
breathing sounds. Though we understand that misophonia is
characterized by a wider range of trigger sounds (as shown in
Daniels et al., 2020 ), we used human-generated sounds related
to orofacial actions in the present study, given that they are the
mostcommontriggersamongindividualswithmisophonia.
Frontiers in Neuroscience | www.frontiersin.org 4 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
FIGURE 1 | (A) Subjective ratings. Participants had unlimited time to rat e the pleasantness of the sound (from unpleasant to pleasant ) and the subjective feelings of
anger, disgust, and anxiety after hearing the sound. (B)15-alternative forced-choice task. Participants had unli mited time to click on the label corresponding to the
sound that they just heard.
Because the study design involved a total of 75 trials (5
SNR levels for each of the 15 sounds), we decided to select a
representative 3 s clip from each, to reduce the length of the
experiment and avoid participant fatigue. The ﬁfteen sounds
were selected based on pilot testing. Sounds were eliminated
if they were frequently confused with another sound (e.g.,
Vacuum Cleaner and Hair Dryer), if they had highly similar
semantic meaning (e.g., Eating, Chewing, and Crunching), o r
if they were diﬃcult to identify in their 3-s form (e.g., Kett le
Boiling, the acoustic properties of which evolved over 15 s). T he
ﬁnal set of sounds comprised: Hair Dryer, Helicopter, Phone
Ringing,Shower,andWashingMachineasneutralsounds;Alar m
Clock,DentistDrill,FemaleScream,MultipleDogsBarking,a nd
ToddlerCryingasunpleasantsounds;Coughing,Sniﬃng,Eati ng,
PacketRustling,andCutleryastriggersounds.
Multi-talker babble is often used as a masker for speech
perception and hearing-in-noise experiments ( Coﬀey et al.,
2017). It is a type of noise that many listeners encounter on a
regular basis in everyday life, therefore it has a higher deg ree
of ecological validity than other types of maskers ( Silbert et al.,
2014). Because trigger sounds are frequently human-generated
andheardinsocialcontexts,wealsoadopteditasamasker.
Inthisstudy,weused10-talkedbabble,withdiﬀerentlevels of
SNR. The levels were chosen via piloting such that, at the lowes t
level, the target sound would be generally indistinguishabl e
among the babble, whereas at the highest level, the target so und
would be very easily detectable from the babble. Thus, the
chosenlevelswerecoveringmostoftheunderlyingpsychomet ric
functionfromwhichaninﬂectionpointcouldbewell-bracket ed.
TheresultingSNRlevelswere: −30,−20,−10,0,+10dB.
2.4. Questionnaires
TheMisoQuest( Siepsiaketal.,2020a )isa14-itemquestionnaire
designed to screen for misophonia as a disorder in which
a person is “triggered immediately by certain sounds, withanger as a core (but not exclusive) emotion”. The questionnai re
includes items assessing diﬀerent aspects of misophonia, from
basic phenomenology (e.g., “I ﬁnd some sounds made by the
humanbodyunbearable.”),toclinically-relevantquestion sabout
avoidance behavior and daily functioning (e.g., “If I can, I avoid
meeting with certain people because of the sounds they make.”).
Foreachitem,participantswererequiredtoanswerona5-point
Likert-scale (from 1 =completely disagree, to 5 =completely
agree). Misophonia symptomatology is indicated by summing
thescorestogether,foramaximumof70points.TheMisoQuest
was developed in Polish with an Exploratory Factor Analysis
(EFA), and showed excellent reliability (Cronbach’s alpha =
0.955) in a misophonic sample. The English translation was
provided by the team who developed the questionnaire, and (to
the best of our knowledge) has yet to be validated in an English -
speaking sample. The internal consistency (Cronbach’s alpha) of
theMisoQuestinoursampleof300participantswasof0.890.
2.5. Statistical Approach
The ﬁrst analysis concerned the prevalence of misophonia-like
symptoms in our online community sample. We characterized
thefourmomentsofthedistributionofMisoQuestscores(mea n,
standarddeviation,skewness,andkurtosis),andusedaShapir o–
Wilk test to examine the normality of this distribution. We
reiteratedthisanalysissplitbysex(maleorfemale),andreg ressed
theMisoQuestscoresbychronologicalage.Afurtherexplorat ion
of sex eﬀects on each item of this questionnaire was conducted
with non-parametric t-tests (given the ordinal nature of the DV
onanitembasis)andcorroboratedbyaBayesianapproach.This
helped isolate which aspects of the questionnaire were likely t o
depend on sex, and which were not. Finally, the distribution of
MisoQuestscoreswasdividedinthetopandbottom20%toform
twosub-groups:Most-andLeast-Misophonic.Notethatthiswas
a critical step to the rest of the analyses, which focused on t hese
twosubgroups.
Frontiers in Neuroscience | www.frontiersin.org 5 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
The second analysis concerned the performance in the
identiﬁcation of each sound with one of the 15 labels. A
sigmoidfunctionwasﬁttedtothepercentcorrectscore,aver aged
for each category (neutral, unpleasant, and trigger sounds)
across the ﬁve SNRs (from −30 to +10 dB). From these ﬁts,
a threshold was extracted at a ﬁxed level of performance of
60.5% (which corresponds to d’ of 2 in a 15-AFC task). This
threshold was then submitted to a mixed analysis of variance
(ANOVA) with one between-subject factor (most- vs. least-
misophonic group) and one within-subject factor (category:
neutral, unpleasant, trigger). Greenhouse-Geisser correc tions
were applied to eﬀects and interactions that violated the
assumption of sphericity. Post-hocpairwise comparisons further
explored the eﬀect of category, correcting the inﬂation of type I
errorwithBonferroniadjustments.
The third analysis concerned the subjective ratings, colle cted
for each of the ﬁve sounds in each of the three categories of
sound, at each of the ﬁve SNRs (like the performance data).
These ratings were ﬁtted with a second-degree polynomial as a
function of SNR. The position of the threshold divided the SNR
scaleinwindowswheresoundswereorwerenotidentiﬁable.T he
subjectiveratingswereaveragedfromtheﬁtsineachofthes etwo
windows, providing twovalues (sub-thresholdratingandsupr a-
thresholdrating).Thegoalofthisthirdanalysiswastodete rmine
whether the supra-threshold rating would depart substantiall y
fromthesub-thresholdrating,speciﬁcallyfortriggersoun dsand
speciﬁcally for the most-misophonic group. Thus, these rating s
were submitted to a mixed ANOVA with one between-subject
factor(group)andtwowithin-subjectfactors(SNRwindow:s ub-
vs.supra-threshold,andcategory:3levels).Tofurtherexpl orethe
3-wayinteraction,thechangeinrating(sub-vs.supra-thre shold)
was calculated and submitted to a 2-way ANOVA similar to that
described above (second analysis). With this reduced desig n, the
simple eﬀect of group separately for neutral, unpleasant, and
triggersoundsenabledustopointatthetypeofsoundthatcoul d
elicit a particularly aversive experience (induced by the sou nd
becoming identiﬁable) in the Most-Misophonic group. Finally,
note that this third approach was repeated in four diﬀerent
versions, for (1) unpleasantness, (2) anger, (3) disgust, an d (4)
anxiety,andweredescribedasidenticallyaspossible.
3. RESULTS
3.1. MisoQuest Scores
Scores on the MisoQuest were normally distributed (minimum:
14, maximum: 69, M=37.9SD=9.9), as evidenced by a
Shapiro–Wilk test supporting the normality of the distributio n
(p=0.560) and by indices of skewness (0.114) and kurtosis
(−0.017) approaching zero. Figure2 shows the distribution of
scores for the entire sample. Mean scores on the MisoQuest
did not diﬀer between males and females [ t(298)= −0.67,p
=0.506], and both male and female distributions of MisoQuest
scores were also respectively normal according to the Shapiro –
Wilk test (female: p=0.653; male: p=0.841). In addition, the
MisoQuest scores did not correlate with age ( r= −0.06,p=
0.321), which was also true for males and females separately
(female: p=0.151; male: p=0.984). In other words, the
FIGURE 2 | Distribution of MisoQuest scores ( N=300). Least-Misophonic
(LM) and Most-Misophonic (MM) groups represent the top and b ottom 20% of
the distribution. Actual scores are plotted below the curve (jittered for better
visualization).
data suggest that misophonia symptoms are present in people
regardlessofsexorage,andisbestconceptualizedasacontin uum
in a symmetric and mesokurtic distribution of sound sensitivi ty.
The distributions of MisoQuest scores by sex and by age are
presentedinAppendixA.
Based on the proposition that certain types of misophonic
responses may be more common in women than in men ( Kılıç
et al., 2021 ), we compared sexes on their responses to individual
items of the MisoQuest. For these additional analyses, given
the ordinal nature of the data, we used Mann–Whitney U-tests.
Results of the tests (using a Bayesian approach) on each item
are provided in Appendix B. We found that females scored
generallyhigheronitem14,whichassessesimpairmentsindai ly
functioning, and also scored higher on three items relating to
emotional control (item 1, 2, and 5). Of note, the evidence fo r
a sex diﬀerence was especially strong for item 5 (“When I hear
unpleasant sounds, I start sensing emotions in my body [e.g., I
sweat, feel pain, feel pressure, my muscles tense]”), which refe rs
speciﬁcallytothephysiologicalcomponentofemotions.
To compare people with and without severe misophonia
symptoms on our diﬀerent measures, we established two groups
based on participants’ total scores on the MisoQuest. The
groups of Most-Misophonic (MM) and Least-Misophonic (LM)
included respectively the top and bottom 20% scorers on the
MisoQuest,basedonaprevalenceof20%formoderate-to-severe
misophonia symptoms reported in past literature ( Wu et al.,
2014; Zhou et al., 2017 ). The resulting MM group ( N=66,
33 females, mean age: 24.0 SD=5.9) included participants
with a total score above 45 on the MisoQuest ( M=51.3; SD
=5.0), and the LM group ( N=68, 32 females, mean age:
25.1SD=7.6) included participants with total scores below 31
(M=25.1;SD=4.6).
Thegroupsdidnotshowstatisticallysigniﬁcantdiﬀerencesin
any of the demographic variables, including age [ t(132)=−0.88,
p=0.382], sex [ χ2(1)=0.12,p=0.733], number of ﬂuent
languages[ χ2(4)=1.09,p=0.895],continentofresidence[ χ2(2)
=2.69,p=0.261], employment status [ χ2(3)=2.69,p=0.261]
andstudentstatus[ χ2(1)=0.21,p=0.645].Thetwogroupsalso
did not diﬀer in the audio output they used [ χ2(3)=4.91,p=
Frontiers in Neuroscience | www.frontiersin.org 6 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
0.179], nor the audio quality they reported [ χ2(2)=4.18,p=
0.124].Inotherwords,exceptfromMisoQuestscores,thegrou ps
didnotdiﬀerfromoneanother.
3.2. Identiﬁcation Thresholds
As expected, performance on the identiﬁcation task averaged
over the entire sample (300 participants) increased with SNR,
suchthatwhensoundsweremoreeasilydetectable,performan ce
ontheidentiﬁcationtaskincreasedtoabout100%identiﬁca tion.
Percent correctness of sound identiﬁcation on the 15-AFC-
task was used to compute a sigmoidal model of psychometric
functions for each category of sound and individual listene r
(Figure3A ). Although average ﬁt of the models was lower for
trigger sounds ( R2
trigger=0.912) than for other types of sounds
(R2
unpleasant=0.933,R2
neutral=0.937), all goodness of ﬁt indices
wereabove0.9,andthemodelﬁtforeachcategorydidnotdiﬀer
betweengroups.
Foreachparticipant,anidentiﬁcationthresholdwasextract ed
from the psychometric function of each category of sound. Thi s
threshold would represent the SNR level required to attain an
arbitrary criterion of 60.5% performance on the identiﬁcati on
task for a given sound category. In other words, for each
participant, the identiﬁcation threshold represented the SNR
levelatwhichtheyreliablyidentiﬁedthesounds.
A 2×3 mixed ANOVA was conducted to assess diﬀerences
in identiﬁcation thresholds between the LM and MM groups
for the three sound categories (neutral, unpleasant, trigge r). The
assumptionofsphericityamongthethreecategoriesofsoundw as
notmet.Inthisanalysis,andforallothersetsofdatathatv iolated
this assumption, the degrees of freedom were adjusted with
Greenhouse-Geisser [here, χ2(2)=18.8,p<0.001, ǫ=0.882].
There was a main eﬀect of category [ F(1.8, 232.9) =362.8,p<
0.001], and post-hoccomparisons (with Bonferroni corrections)
revealed that thresholds were lower for triggers than unplea sant
sounds (by 2.3 dB, p<0.001) which themselves were lower
than neutral sounds (by 9.9 dB, p<0.001). However, there was
no main eﬀect of Group [ F(1, 132)=0.58,p=0.884] nor any
interaction of Group and Sound category [ F(1.8, 232.9) =0.3,p=
0.688].Figure3B illustratestheANOVAresults.
The trigger sounds were more salient in general than the
other categories of sounds, but this was true of all participan ts,
regardless of whether they were in the LM or MM group.
This provides evidence for the ﬁrst hypothesis, that as SNR
increases (and all sounds become easier to detect), there wo uld
be a diﬀerence in identiﬁcation of the sounds between sound
categories,suchthattriggerswillbeidentiﬁedpriortounpl easant
sounds and certainly prior to (at least 10 dB) neutral sounds. It
is also evidence against our second hypothesis; individuals m ost
prone to misophonia are not better at detecting trigger sounds
thanthosewhoareleastmisophonic.
3.3. Subjective Ratings Before and After
Identiﬁcation
Following a visual assessment of participants’ responses for e ach
type of subjective rating as a function of SNR, we observed tha t
the ratings for the aversive sound categories seemed to follo w acurvilineartrend.Thereforeweuseda2nd-degreepolynomial to
ﬁt the participant’s mean ratings at each level of SNR, for each
typeofratingandeachcategoryofsound( Figure4).
Toassesswhethersubjective ratingsdiﬀeredinsub-thresho ld
SNRs vs. supra-threshold SNRs, we averaged all points in the
subjective ﬁts below and above the threshold to provide only
2 values per category and per participant. For each type of
rating, this resulted in a total of six data points per participan t:
3 categories of sounds (neutral, unpleasant, trigger) ×2
SNR windows (below recognition threshold, above recogniti on
threshold).Ratingsfromtheself-reportscaleswereﬂipped,s uch
that high scores indicated a more aversive reaction. Increa ses in
agivenratingthereforeindicatedelevatedunpleasantness ,anger,
disgust,andanxiety.
For each type of rating, we conducted a 2 ×2×3 mixed
ANOVA, with the within-subject factors being Sound category
and SNR window, and the between-subjects factor being Group
(LM and MM). For each test, the assumption of sphericity
was assessed for Sound category and its interactions; when th e
assumption of sphericity was not met, degrees of freedom were
adjusted with the Greenhouse-Geisser correction. Statisti cs for
maineﬀectsandinteractions(includingeﬀectsizes)arerepor ted
inTable1. Note that, when re-computing these analyses with
type of audio output or quality of audio as a between-subjects
factor, we found that the main results were not aﬀected. The
LM and MM groups did not diﬀer in audio quality or output,
the main eﬀect of either of these variables was never signiﬁca nt,
and they did not interact with the group variable for any type
ofrating.
In addition, we reiterated a similar analysis looking at
the linear slope with which subjective ratings degraded as a
function of SNR. The results (reported in Appendix C) were
largely consistent with those presented here in Section 3.3. This
additionalanalysisreﬂectedthediﬀerentialtrendsinhowso unds
became more aversive as they progressively stood out from the
multitalkerbabble.
3.3.1. Unpleasantness
The ﬁrst ANOVA revealed a main eﬀect of Sound category
and of SNR window, but no main eﬀect of Group. All 2- and
3-way interactions were signiﬁcant (see Table1for statistics).
Post-hoc comparisons of the 3-way interaction (with Tukey
correction for multiple comparisons) revealed that, for each
sound category, there was no statistically signiﬁcant group
diﬀerence in unpleasantness ratings below threshold (all p>
0.999), suggesting that the ratings for the two groups did not
signiﬁcantlydiﬀerwhentheycouldnotdetectthesounds.
The average ﬁt of the second-degree polynomial was lower
for neutral sounds ( R2
neutral=0.656) than for trigger sounds
(R2
trigger=0.800), which was itself lower than for unpleasant
sounds (R2
unpleasant=0.870). The goodness of ﬁt did not diﬀer
betweengroups.
To assess the 3-way interaction, we tested speciﬁcally the
change in rating below and above threshold, across the two
groups and the three categories (reducing the design to a 2-wa y
mixed ANOVA). For the LM group, the increase in rating was
Frontiers in Neuroscience | www.frontiersin.org 7 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
FIGURE 3 | (A) Psychometric functions ( N=300) for the 15-AFC identiﬁcation task. Average percent iden tiﬁcation plotted at each (SNR) level, for each sound
category. Solid lines represent the mean of the ﬁts and shaded areas represent ±1 standard deviation. Dotted lines represent chance level a nd the performance level
chosen to deﬁne identiﬁcation thresholds of the 15-AFC task. (B)Mean identiﬁcation threshold for each sound category, for th e Least-Misophonic (LM) and
Most-Misophonic (MM) groups. Error bars represent ±1 standard deviation. Asterisk (*) indicates a statistical ly signiﬁcant difference ( p<0.01), “n.s.” indicates a
non-signiﬁcant difference.
considerably stronger for unpleasant and trigger sounds rel ative
to neutral sounds (by 24.9 and 17.7 points, p<0.001 in both
cases),buttheincreasewassmallerintriggersthaninunple asant
sounds(by7.3points, p=0.001).FortheMMgroup,theincrease
in rating was even stronger for unpleasant and trigger sounds
than neutral (by 33.2 and 27.7 points, p<0.001 in both cases)
and the increase was again smaller for triggers than unpleasa nt
sounds (by 7.3 points, p=0.050). Results of the Unpleasantness
ratings below and above the identiﬁcation threshold, for ea ch
sound category and group, are shown in Figure5. These results
illustrate how both groups recognized the unpleasantness of
the trigger and unpleasant sounds, but only when the sounds
wereidentiﬁed.
Perhaps most importantly, the simple eﬀect of Group on the
below/above change in rating was signiﬁcant for triggers ( p<
0.001) and unpleasant sounds ( p=0.006) but not for neutral
sounds (p=0.760). Trigger sounds were the category of sounds
where the MM group increased their rating considerably more
than the LM group (eﬀect size d=0.64), whereas this was true
to a smaller degree for unpleasant sounds ( d=0.48), and not
true for neutral sounds (i.e., same trend for the two groups). In
otherwords,theincreaseinunpleasantnessratingsforalla versive
sounds was more extreme for the MM group than for the LM
group,especiallyfortriggersounds.
3.3.2. Anger
There was a main eﬀect of Sound category, SNR window, and
Group, on ratings of Anger. Like for Unpleasantness, all 2- and
3-way interactions were signiﬁcant. Statistics (includin g eﬀectsizes)arereportedin Table1.Post-hoccomparisonsofthe3-way
interaction (with Tukey correction for multiple comparisons)
revealed that, for each sound category, there was no statisti cally
signiﬁcant group diﬀerence in anger ratings below threshold (all
p>0.271),suggestingthattheratingsforthetwogroupsdidnot
signiﬁcantlydiﬀerwhentheycouldnotdetectthesounds.
Theaverageﬁtofthesecond-degreepolynomialwaslowerfor
neutralsounds( R2
neutral=0.593)thanforunpleasantandtrigger
sounds (R2
unpleasant=0.768,R2
trigger=0.767), which themselves
didnotdiﬀerfromoneanother.Thegoodnessofﬁtdidnotdiﬀer
betweengroups.
To assess the 3-way interaction, we again reduced the design
to a 2-way mixed ANOVA assessing the change in rating below
and above threshold. For the LM group, the elevated anger was
considerably stronger for unpleasant and trigger sounds rel ative
to neutral sounds (by 17.97 and 14.65 points, p<0.001 in both
cases), but it was not signiﬁcantly diﬀerent between trigger s and
unpleasant sounds. For the MM group, the elevated anger was
evenstrongerforunpleasantandtriggersoundsthanforneut ral
sounds (by 26.59 and 29.17 points, p<0.001 in both cases) and
again not signiﬁcantly diﬀerent between triggers and unpleas ant
sounds, as illustrated in Figure5. These results illustrate how
both groups felt more anger in response to the unpleasant and
triggersoundswhentheywereidentiﬁed.
The simple eﬀect of Group on the elevated anger was
signiﬁcant for triggers ( p<0.001) and unpleasant sounds ( p=
0.005), but not for neutral sounds ( p=0.760). Trigger sounds
were the category of sounds where the MM group experienced
elevatedangerconsiderablymorethantheLMgroup( d=0.95),
Frontiers in Neuroscience | www.frontiersin.org 8 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
FIGURE 4 | Population results ( N=300) for subjective ratings of each sound category. Shaded a reas represent ±1 standard deviation from the mean ﬁt. The aversive
sounds (blue and red) show a curvilinear trend.
whichwasalsotruetoasmallerdegreeforunpleasantsounds( d
=0.57), but not true for neutral sounds (i.e., same trend arou nd
0% for the two groups). That is, the increase in anger ratings f or
all aversive sounds was more extreme for the MM group than
for the LM group, a pattern which was especially strong for the
triggersounds.
3.3.3. Disgust
There was a main eﬀect of Sound category, SNR window, and
Group, on ratings of Disgust. All 2- and 3-way interactions
were signiﬁcant. Statistics (including eﬀect sizes) are repo rted
inTable1.Post-hoccomparisons of the 3-way interaction (with
Tukey correction for multiple comparisons) revealed that, fo r
each sound category, there was no statistically signiﬁcant group
diﬀerence in disgust ratings below threshold (all p>0.143),
suggestingthattheratingsforthetwogroupsdidnotsigniﬁc antly
diﬀerwhentheycouldnotdetectthesounds.
The average ﬁt of the second-degree polynomial was lower
for neutral sounds ( R2
neutral= 0.581) than for unpleasant sounds
(R2
unpleasant=0.674),whichwerethemselveslowerthanfortriggersounds ( R2
trigger= 0.803). The goodness of ﬁt did not diﬀer
betweengroups.
To assess the 3-way interaction, we again reduced the design
to a 2-way mixed ANOVA assessing the change in rating below
andabovethreshold.FortheLMgroup,theelevateddisgustwa s
considerably stronger for unpleasant and trigger sounds rel ative
to neutral sounds (by 9.96 and 21.65 points, p<0.001 in both
cases), and stronger for trigger relative to unpleasant soun ds (by
11.69,p<0.001). For the MM group, the elevated disgust was
evenstrongerforunpleasantandtriggersoundsthanforneut ral
sounds (by 16.89and 32.92points, p<0.001inboth cases),and
stronger for triggers than unpleasant sounds (by 16.03 points, p
<0.001), as illustrated in Figure5. These results illustrate how
both groups felt more disgust toward the unpleasant and trigge r
sounds(especiallythetriggersounds)whentheywereidenti ﬁed.
The simple eﬀect of Group on the elevated disgust was
signiﬁcant for triggers ( p<0.001), but not for unpleasant ( p=
0.201) or neutral sounds ( p=1.000). Triggers were the category
of sounds where the MM group experienced elevated disgust
considerably more than the LM group ( d= 0.60), whereas this
Frontiers in Neuroscience | www.frontiersin.org 9 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic ResponsesTABLE 1 | ANOVA results for emotional ratings before and after recogn ition threshold.
Unpleasantness Anger Disgust Anxiety
Mauchly’s test of sphericitya
Sound category χ2(2)=12.4,p=0.002, ǫ= 0.917 χ2(2)= 2.8,p= 0.244 χ2(2)= 12.6,p= 0.002, ǫ= 0.916 χ2(2)= 2.5,p= 0.279
SNR×Sound category χ2(2)= 5.0,p= 0.081 χ2(2)= 3.2,p= 0.200 χ2(2)= 3.3,p= 0.196 χ2(2)= 2.9,p= 0.234
Main effects
Sound category F(1.84, 242.16) =272.18 F(2, 264)=135.74 F(1.83, 241.83) =151.49 F(2, 264)=201.91
p<0.001, η2=0.110, η2
p=0.673 p<0.001, η2=0.048, η2
p=0.507 p<0.001, η2=0.062, η2
p=0.534 p<0.001, η2=0.076, η2
p=0.605
SNR F(1, 132)=190.44, F(1, 132)=143.29 F(1, 132)=113.69 F(1, 132)=193.11
p<0.001, η2=0.116, η2
p=0.591 p<0.001, η2=0.068, η2
p=0.521 p<0.001, η2=0.046, η2
p=0.463 p<0.001, η2=0.107, η2
p=0.594
Group F(1, 132)=0.15 F(1, 132)=16.86 F(1, 132)=16.06 F(1, 132)=19.95
p=0.702 p<0.001, η2=0.113, η2
p=0.113 p<0.001, η2=0.073, η2
p=0.108 p<0.001, η2=0.074, η2
p=131
2-way interactions
SNR×Sound category F(2, 264)=274.5 F(2, 264)=150.44 F(2, 264)=170.25 F(2, 264)=234.79
p<0.001, η2=0.089, η2
p=0.675 p<0.001, η2=0.045, η2
p=0.533 p<0.001, η2=0.057, η2
p=0.563 p<0.001, η2=0.072, η2
p=0.640
SNR×Group F(1, 132)=6.64 F(1, 132)=17.76 F(1, 132)=8.414 F(1, 132)=17.18
p=0.011, η2=0.004, η2
p=0.048 p<0.001, η2=0.008, η2
p=0.119 p<0.001, η2=0.004, η2
p=0.060 p<0.001, η2=0.010, η2
p=0.115
Sound category ×Group F(1.84, 242.16) =4.95 F(2, 264)=11.36 F(1.83, 241.83) =6.41 F(2, 264)=8.93
p=0.010, η2=0.002, η2
p=0.036 p<0.001, η2=0.004, η2
p=0.079 p<0.003, η2=0.003, η2
p=0.046 p<0.001, η2=0.003, η2
p=0.063
3-way interaction
SNR×Sound category ×Group F(2, 264)=8.42 F(2, 264)=12.34 F(2, 264)=7.39 F(2, 264)=8.55
p<0.001, η2=0.003, η2
p=0.060 p<0.001, η2=0.004, η2
p=0.085 p<0.001, η2=0.002, η2
p=0.053 p<0.001, η2=0.003, η2
p=0.061
Eachcolumnrepresentsadifferentrating.Allratingsshowedasimil arpatternofresults.
aGreenhouse-Geissercorrection( ǫ)appliedwhensphericitywasviolated.
Frontiers in Neuroscience | www.frontiersin.org 10 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
was not true for unpleasant sounds and for neutral sounds
(i.e., same trend [10–15% increase] for the two groups). In
other words, the increase in disgust ratings was more extrem e
for the MM group than for the LM group, speciﬁcally for the
triggersounds.
3.3.4. Anxiety
There was a main eﬀect of Sound category, SNR window, and
Group, on ratings of Anxiety. Like for all other types of rating s,
all2-and3-wayinteractionsweresigniﬁcant.Statistics( including
eﬀect sizes) are reported in Table1.Post-hoc comparisons
of the 3-way interaction (with Tukey correction for multiple
comparisons) revealed that, for each sound category, there w as
no statistically signiﬁcant group diﬀerence in anxiety rati ngs
below threshold (all p>0.157), suggesting that the ratings for
the two groups did not signiﬁcantly diﬀer when they could not
detectthesounds.
Theaverageﬁtwaslowerforneutralsounds( R2
neutral=0.606)
than for trigger sounds ( R2
trigger=0.679), which was itself lower
than for unpleasant sounds ( R2
unpleasant=0.862). The goodness
ofﬁtdidnotdiﬀerbetweengroups.
To assess the 3-way interaction, we again reduced the design
to a 2-way mixed ANOVA assessing the change in rating below
andabovethreshold.FortheLMgroup,theelevatedanxietywa s
considerably stronger for unpleasant and trigger sounds rel ative
to neutral sounds (by 29.08 and 6.91 points, p<0.001 and p=
0.030), but was weaker for trigger than unpleasant sounds (by
22.17,p<0.001). For the MM group, the elevated anxiety was
evenstrongerforunpleasantandtriggersoundsthanneutral (by
38.79 and 19.33 points, p<0.001 in both cases), and stronger
for unpleasant than trigger sounds (by 19.46, p<0.001), as
illustrated in Figure5. These results illustrate how both groups
felt more anxiety toward the unpleasant and trigger sounds
(especiallytheunpleasantsounds)whentheywereidentiﬁed.
The simple eﬀect of Group on the elevated anxiety was
signiﬁcant for triggers ( p<0.001) and unpleasant sounds ( p=
0.005), but not neutral sounds ( p= 1.000). Trigger sounds were
thecategoryofsoundswheretheMMgroupexperiencedelevated
anxiety considerably more than the LM group ( d= 0.96), which
was also true to a smaller degree for unpleasant sounds ( d=
0.61),andnottrueforneutralsounds(i.e.,sametrendfort hetwo
groups). That is to say, the increase in anxiety ratings was mo re
extremefortheMMgroupthanfortheLMgroupforallaversive
sounds. Even though the unpleasant sounds generally induced
moreanxietyonceidentiﬁed,thispattern(theMMgrouphaving
a stronger increase in anxiety ratings than the LM group) was
moreextremeofthetriggerthanunpleasantsounds.
4. DISCUSSION
4.1. Distribution of Misophonia Symptoms
To characterize the distribution of misophonia symptoms in
a general population, we collected responses from an online
community sample of 300 participants on the MisoQuest
(Siepsiak et al., 2020a ). We found that MisoQuest scores were
normally distributed ( Figure2), in line with the idea that manypeople without clinically-signiﬁcant symptoms still experience
negative emotional and physiological reactions to sounds. So me
of the sounds that frequently bother people include ﬁngernails
scratching on a chalkboard, metal scraping glass, and even
some typical misophonic triggers such as chewing or sucking
noises (Zald and Pardo, 2002; Kumar et al., 2008 ). Previous
work found that, when using a misophonia-speciﬁc scale, a
relatively large proportion of the population (68%) reported
experiencing such sub-clinical misophonia symptoms ( Zhou
et al., 2017 ). In their study, people with sub-clinical symptoms
were deﬁned as individuals experiencing misophonia symptoms
which did not cause signiﬁcant distress in daily life. Taken
together with the distribution of MisoQuest scores found in t his
study,itappearsthatmildmisophoniaregularlyoccursinalarg e
number of people. This observation gives weight to the idea
that those who experience daily life impairments as a result of
misophoniasimplyrepresentthetailendofanormaldistributio n
ofmisophoniasymptoms.
In the development of the MisoQuest, a general cut-oﬀ of 61
outof70pointswasproposedtoscreenformisophonia( Siepsiak
et al., 2020a ), based on the mean score (minus the standard
deviation) of participants self-reporting as having misophonia .
ResearchassessingthepsychometricpropertiesoftheMisoQuest ,
found that the questionnaire had good speciﬁcity (ability to
correctly classify an individual as not having misophonia), b ut
had low sensitivity (ability to correctly classify an indivi dual
as having misophonia) ( Siepsiak et al., 2020a; Enzler et al.,
2021). In other words, using the suggested cutoﬀ point for
the MisoQuest introduces a risk of false negatives. In our
online community sample, which did not consist of people
recruited on the basis of having misophonia or other hearing
sensitivities, only 4 out of 300 participants (less than 2%) scor ed
above 61 on the MisoQuest. This result is considerably lower
than previous assessments of misophonia’s prevalence (i.e., 12 –
20%, using semi-structured interviews and other misophonia-
speciﬁc questionnaires), and illustrates the lack of speciﬁc ity of
the MisoQuest as a whole, which has not yet been validated
for use in the general population ( Siepsiak et al., 2020b ). See
SupplementaryMaterial for a data-driven grouping approach
which attempted to reﬁne this cutoﬀ, an optimization exercise
outsidethescopeofthispaper.
Although the 61-point MisoQuest cutoﬀ appears to capture
the most severe cases of misophonia, our observations suggest
that the distribution of symptom severity in the population lie s
onacontinuum,analogoustosomeotherdisorders(e.g.,Autis m
Spectrum Disorder). Previous works proposed that misophonia
represents one end of a speciﬁc sound sensitivity spectrum,
with on the other end Autonomous Sensory Meridian Response
(ASMR), a pleasurable tingling sensation in response to trigger
sounds (Barratt et al., 2017; McErlean and Banissy, 2018; Rouw
and Erfanian, 2018 ). The MisoQuest was only designed to assess
negativeemotions,andthereforecannotreﬂectbothendsof that
hypothetical ASMR-to-Misophonia continuum. Nonetheless, it
maybesuitabletomeasureanindividual’sseverityofsympto ms,
assimilartoolsareusedforotherdisordersthatvaryconside rably
in their presentation (e.g., the Autism Quotient in the ﬁeld o f
autism;Baron-Cohenetal.,2001 ).
Frontiers in Neuroscience | www.frontiersin.org 11 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
FIGURE 5 | Change in subjective ratings below and above identiﬁcation t hresholds, for each group and sound category. Unpleasantne ss ratings are from 0 (pleasant)
to 100 (unpleasant), with 50 being a neutral rating. For Ange r, Disgust, and Anxiety, ratings are from 0 (neutral) to 100. Error bars represent ±1 standard deviation.
Many diﬀerent measures have been developed and used in
past years—most notably the A-MISO-S ( Schröder et al., 2013 )
andMisophoniaQuestionnaire(MQ; Wuetal.,2014 )—andkeep
beingintroducedinthemisophonialiterature(e.g.,morere cently
the Duke Misophonia Questionnaire by Rosenthal et al., 2021 ).
We hope that our ﬁndings about how the MisoQuest behaves
in our online community sample can reveal how this measure
relates to other scales assessing misophonia. Given recent
consensus from clinical experts on a deﬁnition of misophonia
(Swedo et al., 2022 ), understanding how these scales behave
similarly or diﬀerently across multiple populations, and how
they correlate with behavioral and physiological responses t o
trigger sounds, is crucial to the reﬁnement and generalizati on of
misophoniascreeningtools.
In addition to understanding the prevalence of the disorder
(how many people suﬀer from misophonia), unequal sampling
in past research revealed a need for better understanding of
the patients’ identity (exactly who suﬀers from misophonia).
Unbalanced sex ratios have, so far, prevented researchers
from reaching generalizable conclusions on sex diﬀerences. In
our balanced data set, we found that both male and female
distributions of MisoQuest scores were normal, with averages
not statistically diﬀerent from one another. In addition, wh en
lookingatthetopandbottom20%ofthedistributionseparate ly,
we found no diﬀerence in the number of males and females in
eachgroup.Thiscontradictspreviousstatementsonthepossib le
roleofsexinmisophoniasensitivity( Wuetal.,2014;Zhouetal.,
2017).
While misophonia severity may not diﬀer between sexes
overall,Kılıç et al. (2021) noted the possibility that certain typesof responses may be more common in women than men. This
prompted us to assess sex diﬀerences for individual items on
the MisoQuest. The one item in particular which stood out as
interacting with sex referred to the physiological component
of emotions. However, this may not be speciﬁc to misophonia:
men and women tend to diﬀer in self-reported experiences to
negativeemotionalstimuli,withwomenreportinghigheraro usal
and negative valence ( Šolcová and La ˇcev, 2017 ). Yet, these self-
reports do not correlate with physiological measures of facial
electromyography(muscleactivity)andskinconductance,w hich
Šolcová and La ˇcev (2017) proposed to result from stereotypes
and emotional beliefs. Future research on misophonia should
include physiological metrics to adjudicate on a possible sex -
induced diﬀerence in physiology when attending to sounds that
are known to aﬀect emotions. Further, if this diﬀerence does not
appear in physiological measures but is present in self reports,
future work should attempt to reﬁne questionnaires or possibl y
weighitemsdiﬀerentlybasedonsex.
In this study, total MisoQuest score did not correlate with
age, which contrasts with Kılıç et al. (2021) ’s ﬁnding that
younger individuals were more likely to have misophonia. One
explanation for this discrepancy is likely about characterist ics
of the sample, as younger (less age-balanced) samples do not
generally exhibit an eﬀect of age on misophonia (no age
eﬀect found in undergraduate samples for Wu et al., 2014;
Zhou et al., 2017 ). Despite our eﬀorts to obtain a sample
representative of a general population, by opening the study
to all ages, our participants consisted mostly (80%) of adults
between 18 and 29 years-old. Note however that there could be
individual trajectories of symptoms improving and worsening
Frontiers in Neuroscience | www.frontiersin.org 12 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
over time. Early in misophonia research, Edelstein et al. (2013)
observedthatwhile5oftheir11participantsreportedsymptoms
worsening over time, the same number of people reported
symptomsstayingthesameorimproving,astheyhadlearnedto
bettercopewiththem.Iftherearecounteractingtrendssuch that
half of individuals with misophonia improve and the other half
worsen, this may be seen as a null eﬀect in population results.
We therefore do not rule out an eﬀect of age in misophonia,
eventhoughourresultsdonotsupportitatthepopulationlevel.
Future work could clarify how the evolution of symptoms over
thelifespanandthusadjudicateontheprevalenceofmisophoni a
acrossdiﬀerentagegroups.
Of note, although our results can be considered somewhat
more generalizable than past studies done with samples
consisting of undergraduate students, our sample may not be
representative of all populations. As outlined in the review by
Chandler and Shapiro (2016) , there are diﬀerences between the
general population and online convenience samples. Though
their review focused on the crowdsourcing platform MTurk,
which is suggested to provide data of a lesser quality than
Proliﬁc (Eyal et al., 2021 ), some of the considerations brought
up byChandler and Shapiro (2016) do apply to our sample.
For example, in addition to online samples being of younger
age than the general population, the review outlines how some
groups are often over- and under-represented in such samples.
Our sample is somewhat more diverse than in past research,
consideringthatparticipantscamefromavarietyofcountrie sof
origin (though currently residing in English-speaking coun tries)
and had diﬀering employment and student status. However,
the present context of an online community sample should be
considered when generalizing observations to the population a t
large, particularly as we did not obtain information regardi ng
ethnicity nor socioeconomic-status. In addition, the scre ening
questions available in the online platform did not allow for t he
speciﬁc exclusion of participants with a diagnosis of anxiety
or depression. As we were concerned that the available more
general mental health questions would screen out individua ls
withmisophonia,ourpopulationofinterest,weusedascreenin g
question concerning use of medication to treat symptoms of
depression,anxiety,orlowmood.Becausepsychiatricsymptom s
areoftenco-morbidwithmisophonia( RouwandErfanian,2018;
Erfanian et al., 2019 ), it is possible that some of the reported
misophonia symptoms or high ratings of anger and anxiety
in the most-misophonic group could be partially explained by
co-morbidaﬀectivedisorders.
4.2. Misophonia, a Sound-Speciﬁc or
Person-Speciﬁc Disorder?
As highlighted in McGeoch and Rouw (2020) , the often highly
speciﬁc nature of trigger sounds (i.e., repetitive, low frequ ency,
etc.) points to the involvement of bottom-up mechanisms,
while the complex behavioral and emotional responses suggest
involvementofhigher-level(top-down)processes.Here,weu sed
a masking paradigm to explore the nature of top-down and
bottom-upprocessing,andhowtheyinteractinmisophonia.When assessing identiﬁcation thresholds for diﬀerent sound
categories, we found that trigger sounds were better identi ﬁed
than unpleasant and neutral sounds. This observation provide s
evidence for our ﬁrst hypothesis, about a diﬀerence in the
acousticsalienceofdiﬀerentsoundcategories,andindicat esthat
trigger sounds are generally easier to detect than other types
of sounds. With the small number of stimuli in our study (5
examples of triggers), this ﬁnding is diﬃcult to generalize. The
sounds chosen for this study aimed at covering the most typica l
trigger sounds, which are usually orofacial (i.e., produced by
the mouth and face) in nature ( Jager et al., 2020 ). There are,
however, many diﬀerent types of trigger sounds and so, future
endeavorsmaycontinueexploringtheideathatcommontrigge rs
have distinctive acoustic properties that set them apart from
otherenvironmentalsounds.Alimitationofourstudy(alth ough
we found no eﬀect of this in our sample) involved participants
potentially having diﬀerent audio devices perhaps involving
sound quality diﬀerences. Future assessments of misophonia
taking place on online platforms could aim at standardizing the
type of listening device, perhaps through the use of screening
tools for headphone-users (e.g., Milne et al., 2021 ); however,
for use with rich, naturalistic stimuli such as those used in t his
study, minor spectral diﬀerences caused by output device are
less likely to have an eﬀect than overall diﬀerences in sound
level. A more fruitful approach might be to complement online
studies with relatively large sample sizes yet somewhat loos er
experimentalcontrolsuchasthisonewithsmaller,highlyfo cused
andcontrolledstudiesinthelaboratoryenvironment.
Contrary to what we had hypothesized, the least- and most-
misophonic participants did not diﬀer in their ability to detect
trigger sounds, suggesting that bottom-up processes (e.g., those
engaged in the salience of certain sounds) may in fact be
relatively independent of misophonia. Overall, this is eviden ce
against our second hypothesis. Early misophonia research had
previously shown some evidence for diﬀerences between people
with and without misophonia in low level auditory informatio n
processing ( Schröder et al., 2014 ) on auditory event-related
potentials (ERPs). During an oddball task using pure tones, the
authors observed a diminished N1 component to oddball tones
in misophonia patients. One of the reasons suggested for this
ﬁnding was a potential basic impairment in auditory processing
at a low level, given that the N1 peak is linked to early attenti on
to auditory stimuli ( Näätänen, 1992; Rinne et al., 2006 ). If
individualswhoaremostandleastpronetomisophoniadodiﬀer
in such basic auditory processes, then this is not reﬂected in our
behavioral data, for any type of sound. Our result, paired with
the observation that the misophonic reaction is not associate d
with absolute hearing threshold or hearing impairments in
general ( Tyler et al., 2014; Jastreboﬀ and Jastreboﬀ, 2015 ),
oﬀers evidence against misophonia being driven by abnormal
bottom-up auditory processes. This interpretation is largely
consistent with the work of Kumar et al. (2021) , who found
involvement of the anterior insula in misophonia, known to be
essential to top-down control of action mirroring. Yet, caut ion
should be exerted before completely negating the involvemen t
of (abnormal) bottom-up processes (certain acoustic properti es
of triggers might elicit a form of pain or aversion, see e.g.,
Frontiers in Neuroscience | www.frontiersin.org 13 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
Arnal et al., 2019 ). Nevertheless, our conclusions about bottom-
up auditory processes emphasize a departure from hyperacusis
(i.e., pain in response to environmental sounds, especially lo ud
sounds), even though it tends to be comorbid with misophonia
(Jastreboﬀ and Jastreboﬀ, 2014 ). In hyperacusis, the discomfort
is driven by abnormal responses to the sounds’ characteristi cs
while the meaning of the sound is irrelevant ( Jastreboﬀ and
Hazell, 2008 ); it therefore contrasts with misophonia, in which
the sounds’ physical characteristics do not appear to be the
main component of the response. Of note, the present study
did not assess hyperacusis, and as such it is unknown to what
extent it might have impacted our results. Still, our observa tions
may indicate that treatment options used in disorders such as
hyperacusis would be less eﬀective for misophonia, and that
misophonia may respond better to other approaches such as
regularcounseling( JastreboﬀandJastreboﬀ,2014 ).
Certain sounds are more aversive than others; this is true
regardless of whether a person has misophonia or not. Often,
aversivereactionstosoundsdependontheirphysicalpropertie s;
for example, generally aversive sounds are loud, rough, and
have strong representation of high frequencies ( Halpern et al.,
1986). However, certain reactions to aversive sounds are based
on emotional connections with the sound ( Reuter et al., 2014 ),
and thus involve learned associations (top-down processes).
In this study, we found that external evaluations of the
sounds (unpleasantness) and internal evaluations of emotio ns
(anger, disgust, anxiety) largely paralleled each other, an d
both appeared only after the sounds were recognized. This
parallel suggests that there is a common process to both sound
appraisal and personal experience that depends on higher-level
cognitive processes. The diﬀerence in ratings observed betwe en
groups, on trials where the sounds could be identiﬁed, thus
relates to a higher-level evaluation of the sounds, which is
evidence for our third hypothesis. These observations about
the involvement of top-down processes are in line with recent
ﬁndings by Hansen et al. (2021) who showed, using self-
report data, that knowledge of the sound identity contribute s
to the discomfort experienced by people with misophonia.
Using a similar design (participants identiﬁed sounds and
provided aversiveness ratings), they showed that participant s
who correctly identiﬁed oral-nasal sounds rated them as mor e
unpleasant and evoking more discomfort than those who could
notidentifythem.
In our study, on trials where the sounds were identiﬁed,
the most-misophonic group experienced a stronger increase
in aversiveness ratings than the least-misophonic group. Thi s
was true to some degree of unpleasant sounds, but it was
exacerbated for trigger sounds. For example, the elevated
anger and anxiety induced by recognizable trigger sounds wa s
almost 3 times larger for MM than LM individuals. Expressed
diﬀerently, all participants experienced some discomfort, but
participants with higher misophonia symptoms were bothered
to a more extreme degree, and with speciﬁcity with regard to
triggers as opposed to other unpleasant sounds. This ﬁnding of
exaggerated responses in the MM group when the sounds are
identiﬁed provides once again evidence for a strong cognitiv e
component in the nature of the misophonic response; theremustbesomethingaboutthemeaningofthesoundthattrigger s
the response. Diﬀerences at higher-level processing between
those with and without misophonia are evident from studies
using functional brain imaging ( Kumar et al., 2017; Schröder
et al., 2019 ). When listening to trigger sounds, participants with
misophonia showed abnormal functional connectivity betwee n
theanteriorinsularcortex,criticalinperceptionofintero ceptive
signals (i.e., signals originating from inside the body) an d the
default mode network, which includes regions responsible fo r
emotion processing and attending to behaviorally-relevant
stimuli. Such diﬀerences in brain networks between people with
and without misophonia support the idea that memories and
contextualassociationsarestronglytiedtotheaversivee motions
experienced in response to triggers. Together, ﬁndings about
top-down processing in misophonia call for more behavioral
experiments manipulating top-down processes (perhaps
manipulating the focus of attention, or instead, the presence of
distracting tasks or stimuli) while observing neural correl ates to
diﬀerentsoundcategories.
Here, we provided additional evidence for the idea that
cognitive processes, speciﬁcally learned associations with
identiﬁable triggers, are involved in misophonia. Treatment
options could therefore focus on breaking the associative
link with speciﬁc triggers. Such treatment options, aimed at
treating the cognitive element of the misophonic response,
have been anecdotally successful. Although this is often li mited
to case-studies, cognitive-behavioral therapy (CBT) seems to
be eﬀective in reducing misophonia symptoms ( Bernstein
et al., 2013; McGuire et al., 2015 ) and managing levels of
anger when exposed to triggers ( Roushani and Honarmand,
2021). Perhaps more convincingly, Schröder et al. (2017)
showed that 48% of patients ( N=90) reported a reduction of
misophonia symptoms following CBT, whereas the waiting-
list control group showed no reduction of misophonia.
These results were observed after 3 months of treatment
(short-term) and maintained a year later (long-term). The
present results, emphasizing a person-centered disorder with
a high speciﬁcity to certain triggers (not so much other
unpleasant sounds) that need to be presented at a suﬃciently
large SNR to be recognizable, are in full support of such
treatmentoptions.
To summarize, in a study involving 300 adults sampled from
an online community, two sub-groups of participants were
formed on the basis of their self reports in a questionnaire
designed for misophonia symptom assessment: a least-
misophonic group, largely immune to the impact of sound
on their life and wellbeing, and a most-misophonic group that
exhibited heightened sensitivity to sound. They all listen ed to
three categories of sounds: neutral sounds, unpleasant soun ds
(typicallyaversive),andsoundstypicallytriggeringtoind ividuals
with misophonia (often orofacially-generated). These sound s,
embedded in a multi-talker babble, were presented at diﬀerent
signal-to-noise ratios from very faint in the background (a nd
thus barely identiﬁable) to perceptually salient (and thus
clearly identiﬁable). Triggers were found to be recognized
at a lower SNR than unpleasant sounds and neutral sounds,
but this pattern was common in both the least-misophonic
Frontiers in Neuroscience | www.frontiersin.org 14 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
and most-misophonic groups. Listeners also rated each sound
(identiﬁed or not) on four scales: unpleasantness, anger, di sgust,
and anxiety. As SNR increased, unpleasant and trigger sounds
became more aversive (as expected), but this change was
more pronounced for triggers than unpleasant sounds, and
exacerbated in MM compared to LM individuals. These results
demonstrate that the heightened sensitivity of individuals most
prone to misophonia does not generalize to sound overall
(neutral sounds or sub-threshold unpleasant/trigger sound s).
In fact, it does not provide any detection or discrimination
advantage,andrelatesto(conscious)appraisalaswellasint ernal
experience of certain triggers, provided that they are suﬃcie ntly
salient. This pattern of ﬁndings strongly supports a role for
higher-order processes related to sound identity (and likel y its
associations with the people generating them, contexts, and
soon).
5. CONCLUSION
Misophonia is increasingly recognized as a problem that can
signiﬁcantly aﬀect the wellbeing, education, and careers of
suﬀerers. To devise eﬀective mitigation strategies and eﬀecti ve
treatments,wemustbetterunderstanditsprevalence,cause s,and
physiologicalbasis.Thisstudyaddsseveralpiecesofinform ation
to our knowledge of misophonia. Overall symptom severity was
found in a continuum, and was approximately equal in males
and females. Although females rated some questionnaire ite ms
concerning subjective experiences of physiological response s
higher, previous work showed that while males and females
might self-report their emotional experiences diﬀerently, the ir
physiological responses to negative emotional stimuli do not
generally diﬀer ( Šolcová and La ˇcev, 2017 ). These observations
suggests that the biological basis of misophonia is not stron gly
sex-related, and so eventual treatments might be predicted t o
work equally well for both males and females. In addition,
we demonstrate that while people detect negative and trigger
sounds better than neutral sounds in noise, suggesting that
those sounds are more salient, people with stronger misophonia
symptoms did not show an additional degree of sensitivity
for detecting sounds. Conversely, once they were able to
identify the aversive sounds, they had a stronger increase
of negative emotional reactions to them, particularly for th e
trigger sounds. Together, these results further emphasize t hat
consciouslylinkingsoundstopastexperienceplaysanimportan t
roleinmisophonia.
As described above, the present study has several limitation s,
oneofwhichbeingthatthequestionnaireused(MisoQuest)wa s
validatedinaPolish-speakingpopulation( Siepsiaketal.,2020a ).
While the original authors provided an English translation, and
the questionnaire (in English and translated in French) was
recently used in a French sample ( Enzler et al., 2021 ), it has
not yet been validated in an English-speaking population. To
our knowledge, this is the ﬁrst study that is using the Englis h
translation of the questionnaire on English-speakers. In ou r
sample, there was a relatively low proportion of participants
who reached the recommended screening score for severemisophonia in our sample, with only 4 participants scoring
above 61. This small number is diﬃcult to interpret; because w e
excludedindividualswhoweretakingpsychotropicmedication s,
our distribution may reﬂect the removal of some more severe
cases. This exclusion may reduce the generalizability of ou r
ﬁnding to more complex psychiatric patients. However, it
did allow us to focus on misophonia symptoms in people
whose physiology is not being modulated by pharmaceutics,
and to highlight the continuous nature of misophonia severity
in a sample more representative of a general population.
Given these limitations, we support the proposition by Enzler
et al. (2021) that the MisoQuest should be used with other
measures of misophonia, to determine potential cut-oﬀs for
mild, moderate, and severe symptoms, and to determine the
convergent validity of the MisoQuest with other misophonia
assessment tools. As regards our experimental design, we cho se
to use an existing set of stimuli that focuses on orofacial
trigger sounds and was used in previous research ( Kumar
et al., 2017, 2021 ). Misophonic trigger sounds are not all
orofacially generated (the importance of other sources is
highlighted in Hansen et al., 2021 ), although most people
with misophonia do have at least one orofacially generated
trigger sound ( Jager et al., 2020 ). While a reasonable starting
point for fundamental research, an exclusive focus on orofaci al
sounds across studies could lead to an incomplete mechanisti c
understanding of misophonia. Therefore, work is needed to
characterize the full range of misophonic trigger sounds
and produce a wider selection of high-quality stimuli for
further study. In addition, although previous research has
found similar experiences with misophonia in diﬀerent cultures
(Zhou et al., 2017 ), the lack of information on ethnicity and
socioeconomic-status in our sample should be considered when
generalizing our results. Finally, the online study design t rades
oﬀ the precise experimental control over listening contexts
and sound quality that are possible in the laboratory with the
advantages of being able to recruit a larger sample with an
even representation of males and females. While the design
appeared to be appropriate for the current questions, which
concern perception and recognition of sounds in noise, some
research questions such as those requiring ﬁne characteriz ation
ofindividuals’psychiatricproﬁlesandperceptualabilitiesre quire
anin-persondesign.
Our main goal was to explore one aspect of misophonia:
its relation to identiﬁcation and memory. Further work is
underway to explore physiological markers of these aversive
responses, and manipulate listeners’ attention to emphasize o r
deemphasize these sounds’ salience. These next studies will be
able to inform shorter-term attention-based coping strateg ies
for people living with misophonia. However, attention-based
strategies are likely to be eﬀortful and tiring to the user and
may represent only a partial solution. More work will be needed
to clarify the etiology of misophonia and its evolution across
the lifespan, to distinguish preexisting anatomical diﬀerence s
that might predispose people to misophonia from the eﬀects
of experience ( Kumar et al., 2021 ), and perhaps to use our
knowledge of neuroplasticity within the auditory and motor
systems to induce meaningful long-term changes in how people
Frontiers in Neuroscience | www.frontiersin.org 15 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
with misphonia process sound (e.g., Herholz and Zatorre,
2012).
DATA AVAILABILITY STATEMENT
The original contributions presented in the study are publicl y
available.Thisdatacanbefoundhere:https://osf.io/39dz b/.
ETHICS STATEMENT
The studies involving human participants were reviewed and
approvedbyResearchEthicsUnit(OﬃceofResearch)Concordia
University. The patients/participants provided their written
informedconsenttoparticipateinthisstudy.
AUTHOR CONTRIBUTIONS
M-AS,AS,MD,andECconceivedanddesignedtheexperiment.
M-ASandMDselectedandeditedstimuli.MDandAScodedthe
experiment.M-AS,MD,andECanalyzedthedata.M-ASdrafted
themanuscript.Allauthorsreviewedandeditedthedraftsof themanuscript. All authors contributed to the article and approve d
thesubmittedversion.
FUNDING
This research was supported by the Misophonia Research
Fund and REAM foundation, and the Natural Sciences and
Engineering Research Council of Canada (NSERC) award
toM-AS.
ACKNOWLEDGMENTS
TheauthorsthankSukhbinderKumarforsharingstimuli,asw ell
as the Misophonia Research Fund and REAM Foundation for
supportingourwork.
SUPPLEMENTARY MATERIAL
The Supplementary Material for this article can be found
online at: https://www.frontiersin.org/articles/10.338 9/fnins.
2022.879583/full#supplementary-material
REFERENCES
Arnal, L. H., Kleinschmidt, A., Spinelli, L., Giraud, A.-L., and Mégev and, P.
(2019). The rough sound of salience enhances aversion through n eural
synchronisation. Nat.Commun. 10,1–12.doi:10.1038/s41467-019-11626-7
Baron-Cohen, S., Wheelwright, S., Skinner, R., Martin, J., and C lubley, E. (2001).
TheAutism-SpectrumQuotient(AQ):evidencefromaspergersyndro me/high-
functioningautism,malesandfemales,scientistsandmathematici ans.J.Autism
Dev.Disord. 31,5–17.doi:10.1023/A:1005653411471
Barratt, E. L., Spence, C., and Davis, N. J. (2017). Sensory determi nants of the
autonomous sensory meridian response (ASMR): understanding the t riggers.
PeerJ5,e3846.doi:10.7717/peerj.3846
Bernstein,R.E.,Angell,K.L.,andDehle,C.M.(2013).Abriefcou rseofcognitive
behavioural therapy for the treatment of misophonia: a case example. Cogn.
Behav.Ther. 6,e10.doi:10.1017/S1754470X13000172
Bruxner, G. (2016). “Mastication rage”: a review of misophonia–a n under-
recognised symptom of psychiatric relevance? Austral. Psychiatry 24, 195–197.
doi:10.1177/1039856215613010
Chandler, J. and Shapiro, D. (2016). Conducting clinical researc h using
crowdsourced convenience samples. Annu. Rev. Clin. Psychol. 12, 53–81.
doi:10.1146/annurev-clinpsy-021815-093623
Coﬀey,E.B.,Mogilever,N.B.,andZatorre,R.J.(2017).Speech- in-noiseperception
inmusicians:areview. Hear.Res. 352,49–69.doi:10.1016/j.heares.2017.02.006
Daniels, E. C., Rodriguez, A., and Zabelina, D. L. (2020). Severi ty of
misophonia symptoms is associated with worse cognitive control
when exposed to misophonia trigger sounds. PLoS ONE 15, e0227118.
doi:10.1371/journal.pone.0227118
Duangudom, V., and Anderson, D. V. (2007). “Using auditory sali ency to
understand complex auditory scenes,”in 2007 15th European SignalProcessing
Conference (Poznan:IEEE),1206–1210.
Edelstein,M.,Brang,D.,Rouw,R.,andRamachandran,V.S.(2013 ).Misophonia:
physiologicalinvestigationsandcasedescriptions. Front.Hum.Neurosci. 7,296.
doi:10.3389/fnhum.2013.00296
Enzler, F., Loriot, C., Fournier, P., and Noreña, A. J. (2021). A
psychoacoustic test for misophonia assessment. Sci. Rep. 11, 1–14.
doi:10.1038/s41598-021-90355-8
Erfanian,M.,Kartsonaki,C.,andKeshavarz,A.(2019).Misoph oniaandcomorbid
psychiatric symptoms: a preliminary study of clinical ﬁndings. Nordic J.
Psychiatry 73,219–228.doi:10.1080/08039488.2019.1609086Eyal, P., David, R., Andrew, G., Zak, E., and Ekaterina, D. (2021 ). Data quality of
platforms and panels for online behavioral research. Behav. Res. Methods . 53,
1–20.doi:10.3758/s13428-021-01694-3
Halpern, D. L., Blake, R., and Hillenbrand, J. (1986). Psychoacousti cs of a chilling
sound.Percept.Psychophys. 39,77–80.doi:10.3758/BF03211488
Hansen,H.A.,Leber,A.B.,andSaygin,Z.M.(2021).Whatsoun dsourcestrigger
misophonia? Not just chewing and breathing. J. Clin. Psychol. 77, 2609–2625.
doi:10.1002/jclp.23196
Herholz, S. C., and Zatorre, R. J. (2012). Musical training as a frame work
for brain plasticity: behavior, function, and structure. Neuron76, 486–502.
doi:10.1016/j.neuron.2012.10.011
Jager, I., de Koning, P., Bost, T., Denys, D., and Vulink, N. (2 020). Misophonia:
phenomenology, comorbidity and demographics in a large sample. PLoS ONE
15,e0231390.doi:10.1371/journal.pone.0231390
Jastreboﬀ, M. M., and Jastreboﬀ, P. J. (2001). Components of decre ased sound
tolerance:hyperacusis,misophonia,phonophobia. ITHSNewsLett. 2,1–5.
Jastreboﬀ,P.J.,andHazell,J.W.(2008). TinnitusRetrainingTherapy:Implementing
theNeurophysiologicalModel .NewYork,NY:CambridgeUniversityPress.
Jastreboﬀ, P. J., and Jastreboﬀ, M. M. (2014). Treatments for dec reased
sound tolerance (hyperacusis and misophonia). Semin. Hear. 35, 105–120.
doi:10.1055/s-003401372527
Jastreboﬀ, P. J., and Jastreboﬀ, M. M. (2015). Decreased sound t olerance:
hyperacusis, misophonia, diplacousis, and polyacousis. Handb. Clin. Neurol.
129,375–387.doi:10.1016/B978-0-444-62630-1.00021-4
Kayser, C., Petkov, C. I., Lippert, M., and Logothetis, N. K. (20 05). Mechanisms
for allocating auditory attention: an auditory saliency map. Curr. Biol. 15,
1943–1947.doi:10.1016/j.cub.2005.09.040
Kılıç, C., Öz, G., Avano ˘glu, K. B., and Aksoy, S. (2021). The prevalence and
characteristics of misophonia in ankara, turkey: population-based s tudy.
BJPsychOpen 7,e144.doi:10.1192/bjo.2021.978
Kumar,S.,Dheerendra,P.,Erfanian,M.,Benzaquén,E.,Sedley, W.,Gander,P.E.,
et al. (2021). The motor basis for misophonia. J. Neurosci . 41, 5762–5770.
doi:10.1523/JNEUROSCI.0261-21.2021
Kumar, S., Forster, H. M., Bailey, P., and Griﬃths, T. D. (2008). M apping
unpleasantness of sounds to their auditory representation. J. Acoust. Soc. Am.
124,3810–3817.doi:10.1121/1.3006380
Kumar, S., Hancock, O., Cope, T., Sedley, W., Winston, J., and Gri ﬃths, T. D.
(2014). Misophonia: a disorder of emotion processing of sounds. J. Neurol.
Neurosurg.Psychiatry 85,e3.doi:10.1136/jnnp-2014-308883.38
Frontiers in Neuroscience | www.frontiersin.org 16 May 2022 | Volume 16 | Article 879583

Savard et al. Sound Identiﬁcation Affects Misophonic Responses
Kumar,S.,Tansley-Hancock,O.,Sedley,W.,Winston,J.S.,Calla ghan,M.F.,Allen,
M., et al. (2017). The brain basis for misophonia. Curr. Biol. 27, 527–533.
doi:10.1016/j.cub.2016.12.048
McErlean,A.B.J.,andBanissy,M.J.(2018).Increasedmisophoni ainself-reported
autonomoussensorymeridianresponse. PeerJ6,e5351.doi:10.7717/peerj.5351
McGeoch, P. D., and Rouw, R. (2020). How everyday sounds can trig ger strong
emotions: ASMR, misophonia and the feeling of wellbeing. Bioessays 42,
2000099.doi:10.1002/bies.202000099
McGuire, J. F., Wu, M. S., and Storch, E. A. (2015). Cognitive- behavioral
therapy for 2 youths with misophonia. J. Clin. Psychiatry 76, 3143.
doi:10.4088/JCP.14cr09343
Milne, A. E., Bianco, R., Poole, K. C., Zhao, S., Oxenham, A. J., B illig, A. J., and
Chait, M.(2021).Anonline headphone screeningtest basedondi chotic pitch.
Behav.Res.Methods 53,1551–1562.doi:10.3758/s13428-020-01514-0
Näätänen,R.(1992). AttentionandBrainFunction .PsychologyPress.
Naylor, J., Caimino, C., Scutt, P., Hoare, D. J., and Baguley, D. M. (2021). The
prevalence and severity of misophonia in a uk undergraduate medical s tudent
population and validation of the Amsterdam misophonia scale. Psychiatr. Q.
92,609–619.doi:10.1007/s11126-020-09825-3
Neal, M., and Cavanna, A. E. (2013). Selective sound sensitivi ty syndrome
(misophonia) in a patient with tourette syndrome. J. Neuropsychiatry Clin.
Neurosci. 25,E01.doi:10.1176/appi.neuropsych.11100235
Palan,S.,andSchitter,C.(2018).Proliﬁc.ac–Asubjectpoolfo ronlineexperiments.
J.Behav.Exp.Fin. 17,22–27.doi:10.1016/j.jbef.2017.12.004
Peirce,J.,Gray,J.R.,Simpson,S.,MacAskill,M.,Höchenberger, R.,Sogo,H.,etal.
(2019).Psychopy2:experimentsinbehaviormadeeasy. Behav.Res.Methods 51,
195–203.doi:10.3758/s13428-018-01193-y
Reuter, C., Oehler, M., and Mühlhans, J. (2014). “Physiologica l and acoustical
correlates of unpleasant sounds,” in Proceedings of the Joint Conference
ICMPC13-APSCOM5 (Seoul:YonseiUniversity),97.
Rinne, T., Särkkä, A., Degerman, A., Schröger, E., and Alho, K. (20 06).
Two separate mechanisms underlie auditory change detection
and involuntary control of attention. Brain Res. 1077, 135–143.
doi:10.1016/j.brainres.2006.01.043
Rosenthal, M. Z., Anand, D., Cassiello-Robbins, C., Williams, Z. J ., Guetta,
R. E., Trumbull, J., et al. (2021). Development and initial validation
of the Duke misophonia questionnaire. Front. Psychol. 12, 709928.
doi:10.3389/fpsyg.2021.709928
Roushani, K., and Honarmand, M. M. (2021). The eﬀectiveness of c ognitive-
behavioral therapy on anger in female students with misophonia: a si ngle-case
study.IranianJ.Med.Sci. 46,61.doi:10.30476/ijms.2019.82063
Rouw, R., and Erfanian, M. (2018). A large-scale study of misopho nia.J. Clin.
Psychol.74,453–479.doi:10.1002/jclp.22500
Schröder, A., van Diepen, R., Mazaheri, A., Petropoulos-Petalas, D ., Soto de
Amesti,V.,Vulink,N.,etal.(2014).DiminishedN1auditoryevok edpotentials
to oddball stimuli in misophonia patients. Front. Behav. Neurosci. 8, 123.
doi:10.3389/fnbeh.2014.00123
Schröder, A., van Wingen, G., Eijsker, N., San Giorgi, R., Vuli nk, N. C.,
Turbyne, C., and Denys, D. (2019). Misophonia is associated w ith altered
brain activity in the auditory cortex and salience network. Sci. Rep. 9, 1–9.
doi:10.1038/s41598-019-44084-8
Schröder, A., Vulink, N., and Denys, D. (2013). Misophonia: dia gnostic
criteria for a new psychiatric disorder. PLoS ONE 8, e54706.
doi:10.1371/journal.pone.0054706
Schröder,A.E.,Vulink,N.C.,vanLoon,A.J.,andDenys,D.A.( 2017).Cognitive
behavioral therapy is eﬀective in misophonia: an open trial. J. Aﬀect. Disord.
217,289–294.doi:10.1016/j.jad.2017.04.017Siepsiak, M., Sliwerski, A., and Lukasz Dragan, W. (2020a). Dev elopment and
psychometric properties of misoquest–a new self-report questionnaire
for misophonia. Int. J. Environ. Res. Public Health 17, 1797.
doi:10.3390/ijerph17051797
Siepsiak, M., Sobczak, A. M., Bohaterewicz, B., Cichocki, Ł., and Dragan, W. Ł.
(2020b). Prevalence of misophonia and correlates of its symptoms among
inpatients with depression. Int. J. Environ. Res. Public Health 17, 5464.
doi:10.3390/ijerph17155464
Silbert, N. H., de Jong, K., Regier, K., Albin, A., and Hao, Y.-C. ( 2014).
Acoustic properties of multi-talker babble. J. Acoust. Soc. Am. 135, 2227.
doi:10.1121/1.4877284
Šolcová, I. P., and La ˇcev, A. (2017). Diﬀerences in male and female
subjective experience and physiological reactions to emotional
stimuli. Int. J. Psychophysiol. 117, 75–82. doi: 10.1016/j.ijpsycho.2017.
04.009
Stiegler,L.N.,andDavis,R.(2010).Understandingsoundsen sitivityinindividuals
with autism spectrum disorders. Focus Autism Other Dev. Disabil. 25, 67–75.
doi:10.1177/1088357610364530
Swedo,S.E.,Baguley,D.M.,Denys,D.,Dixon,L.J.,Erfanian ,M.,Fioretti,A.,etal.
(2022). Consensus deﬁnition of misophonia: a Delphi study. Front. Neurosci.
16,841816.doi:10.3389/fnins.2022.841816
Tyler, R. S., Pienkowski, M., Roncancio, E. R., Jun, H. J., Brozo ski, T.,
Dauman, N., et al. (2014). A review of hyperacusis and future directi ons:
part I. deﬁnitions and manifestations. Am. J. Audiol. 23, 402–419.
doi:10.1044/2014_AJA-14-0010
Vitoratou, S., Uglik-Marucha, N., Hayes, C., Erfanian, M., Pea rson, O., and
Gregory, J. (2021). Item response theory investigation of misophon ia
auditory triggers. Audiol. Res. 11, 567–581. doi: 10.3390/audiolres110
40051
Wu, M. S., Lewin, A. B., Murphy, T. K., and Storch, E. A. (2014). M isophonia:
incidence,phenomenology,andclinicalcorrelatesinanundergradu atestudent
sample.J.Clin.Psychol. 70,994–1007.doi:10.1002/jclp.22098
Zald, D. H., and Pardo, J. V. (2002). The neural correlates of aversiv e auditory
stimulation. Neuroimage 16,746–753.doi:10.1006/nimg.2002.1115
Zhou, X., Wu, M. S., and Storch, E. A. (2017). Misophonia symptoms
among Chinese university students: incidence, associated i mpairment,
and clinical correlates. J. Obsessive Compuls. Relat. Disord. 14, 7–12.
doi:10.1016/j.jocrd.2017.05.001
Conﬂict of Interest: The authors declare that the research was conducted in the
absence of any commercial or ﬁnancial relationships that could be c onstrued as a
potentialconﬂictofinterest.
Publisher’sNote: Allclaimsexpressedinthisarticlearesolelythoseoftheauthors
and do not necessarily represent those oftheir aﬃliated organizat ions, or those of
thepublisher,theeditorsandthereviewers.Anyproductthatmayb eevaluatedin
this article, or claim that may be made by its manufacturer, is not gua ranteed or
endorsedbythepublisher.
Copyright © 2022 Savard, Sares, Coﬀey and Deroche. This is an open- access article
distributed under the terms of the Creative Commons Attribu tion License (CC BY).
The use, distribution or reproduction in other forums is perm itted, provided the
original author(s) and the copyright owner(s) are credited a nd that the original
publication in this journal is cited, in accordance with acc epted academic practice.
No use, distribution or reproduction is permitted which doe s not comply with these
terms.
Frontiers in Neuroscience | www.frontiersin.org 17 May 2022 | Volume 16 | Article 879583