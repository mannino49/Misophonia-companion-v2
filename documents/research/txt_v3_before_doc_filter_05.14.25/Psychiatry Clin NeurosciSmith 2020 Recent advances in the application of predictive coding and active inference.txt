PCN FRONTIER REVIEWPCN
Recent advances in the application of predictive coding
and active inference models within clinical neuroscience
Ryan Smith, PhD ,1*Paul Badcock, PhD2,3,4and Karl J. Friston, MRCPsych5
Research in clinical neuroscience is founded on the idea that
a better understanding of brain (dys)function will improve
our ability to diagnose and treat neurological and psychiatricdisorders. In recent years, neuroscience has converged onthe notion that the brain is a ‘prediction machine, ’in that it
actively predicts the sensory input that it will receive if oneor another course of action is chosen. These predictions areused to select actions that will (most often, and in the longrun) maintain the body within the narrow range of physiologi-cal states consistent with survival. This insight has given riseto an area of clinical computational neuroscience researchthat focuses on characterizing neural circuit architecturesthat can accomplish these predictive functions, and on howthe associated processes may break down or become aber-rant within clinical conditions. Here, we provide a briefreview of examples of recent work on the application ofpredictive processing models of brain function to study clini-
cal (psychiatric) disorders, with the aim of highlighting cur-
rent directions and their potential clinical utility. We offerexamples of recent conceptual models, formal mathematicalmodels, and applications of such models in empiricalresearch in clinical populations, with a focus on making thismaterial accessible to clinicians without expertise in compu-tational neuroscience. In doing so, we aim to highlight thepotential insights and opportunities that understanding thebrain as a prediction machine may offer to clinical researchand practice.
Keywords: active inference, computational neuroscience, computa-
tional psychiatry, emotion, predictive coding.
http://onlinelibrary.wiley.com/doi/10.1111/pcn.13138/full
Research in clinical neuroscience is founded on the premise that bet-
ter understanding of brain function –and, by extension, dysfunction –
will improve our ability to diagnose and treat disorders of the mind
and brain. As the ﬁeld has moved forward, it has become increasingly
clear that, to understand the brain, it must ﬁrst be characterized at
multiple spatiotemporal scales and levels of description. We then
have to understand how dynamics at each scale or level of description
relate to (or emerge from) the dynamics of others. At one end of thespectrum, a large body of work has emerged over the last century on
the microscale cellular and molecular functions of neurons and
supporting brain cells; at the other, the last few decades have pro-duced a growing body of work on large-scale human brain functionusing neuroimaging methods, which have uncovered regularities in
the relation between macroscale regional brain activity and complex
psychological processes. However, to fully link micro- and macro-scale functioning, and biological and psychological levels of descrip-
tion, it is widely recognized that we need to develop a better
understanding of functional architectures at the intermediate meso-scale (see Fig. 1).
The mesoscale corresponds to circuits of interconnected neurons
with particular patterns of synaptic connections that allow for speci ﬁc
types of information processing or ‘computation. ’For instance, one pat-
tern of neural circuit connections may allow the brain to infer whatobjects are most likely giving rise to its current retinal input, whereas
other patterns of connections may solve the problem of determining
which action is more likely to generate preferred outcomes.
2–4Thus,
mesoscale circuits afford a computational level of description, whichoffers a bridge between biology and psychology by allowing researchers
to characterize how neural circuit dynamics produce psychologicaloperations, such as object recognition and decision-making.4–8Unfortu-
nately, the mesoscale is currently the most dif ﬁcult to study directly with
current neuroscience methods. However, a more recent body of work incomputational neuroscience –and its clinically focused sister discipline
of computational psychiatry –has emerged over the last several years to
better address this problem.9–11
The unique advantages offered by computational neuroscience
and computational psychiatry follow from a speci ﬁc type of mathe-
matical modeling. This approach ﬁrst identi ﬁes a problem that the
brain can (or must) solve, such as object recognition or decision-mak-
ing, and then works backward to identify the requisite computational
steps –or algorithms –that the brain could use to solve this problem.
Although many mathematical solutions may exist, only a subset will
be biologically plausible –that is, only some algorithms could be
plausibly accomplished by connecting neurons together in particularpatterns. Once a set of biologically plausible algorithms has been
identi ﬁed, each algorithm in turn entails one or more testable hypoth-
eses about how the mesoscale function and structure of a particularbrain region (or connected set of regions) could implement that algo-
rithm. Different algorithms and neural implementations typically have
different costs and bene ﬁts (e.g., different levels of ef ﬁciency vs accu-
racy, and different metabolic demands) and, as such, they often make
distinct predictions about the patterns of brain activity and behavior
that should be observed under speci ﬁc conditions. Such predictions
can then be tested experimentally to provide evidence for one
1Laureate Institute for Brain Research, Oklahoma, USA
2Centre for Youth Mental Health, The University of Melbourne, Victoria, Australia
3Orygen, Victoria, Australia
4Melbourne School of Psychological Sciences, The University of Melbourne, Victoria, Australia
5Wellcome Centre for Human Neuroimaging, Institute of Neurology, University College London, London, UK
*Correspondence: Email: rsmith@laureateinstitute.org
©2020 The Authors
Psychiatry and Clinical Neurosciences ©2020 Japanese Society of Psychiatry and Neurology
Psychiatry and Clinical Neurosciences 75: 3 –13, 20213PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

algorithm versus another and, in some cases, evidence for one neural
implementation (mesoscale circuit structure) over another. Therefore,the two primary advantages of computational neuroscience include:(i) building mathematical models that allow researchers to simulateneurocomputational processes –to con ﬁrm how the brain could solve
a particular problem; and (ii) making empirical predictions for testingwhich neurocomputational processes the brain in fact does use to
solve that problem.
There are many algorithms currently used for research in this
ﬁeld. In this article, we focus on a family of biologically plausible
algorithms that have emerged from the idea that brain processes are
predictive . That is, they share the idea that the brain is a type of ‘pre-
diction machine, ’which allows it to solve dif ﬁcult problems in per-
ception, decision-making, and skeletomotor/visceromotor control in
an approximately optimal manner. In perception, one widely studied
algorithm of this kind is ‘predictive coding, ’which rests on the idea
that a perceptual system continually predicts what it should observe
next if its current perceptual beliefs are correct.
6,7,12Perceptual
beliefs are then updated when sensory input differs from predicted
input. In predictive coding, this difference affords the calculation of a
‘prediction error, ’which can be used to guide belief updating and ﬁnd
the minimal change in perceptual beliefs necessary to minimize that
error signal. Technically, this is called Bayesian belief updating or
inference. This process can also be iterated hierarchically, so that
higher brain circuits continuously update beliefs about (and predict)
what will be represented in lower hierarchical levels that are closer tothe sensory periphery –allowing different levels of abstraction (e.g., a
belief that a white/round percept corresponds to a baseball2). Different
predictions and prediction errors can also be considered more or less
reliable (e.g., visual prediction errors may be more reliable during the
day vs at night). As such, in predictive coding models, the brain canalso maintain (and update) estimates about the reliability (inverse var-
iance or ‘precision ’) of its various predictions and prediction errors,
which modulate how easy or hard it is to change current beliefs when
challenged by strong prediction errors (i.e., by increasing or decreas-
ing the ‘weight ’assigned to those prediction errors).
To give the reader a sense of the dynamics of predictive coding
models, and how they might be applied to solve a clinically relevantpsychological task, a very simple, four-neuron network, and simulated
neuronal activity are shown in Figure 2a –e. The details of the exam-
ple are described in the ﬁgure legend; but, in short, the ﬁgure illus-
trates the simulated neuronal dynamics through which prediction
error is minimized to arrive at an estimate or ‘best guess ’about
whether another person is hostile or friendly. This is based on: (i) the
perceived curvature of their lips (e.g., ﬂat curvature, most consistent
with a neutral facial expression); and (ii) prior expectations
(i.e., initial predictions about how friendly or hostile the person is
prior to seeing their facial expression). The simulations show how
prior expectations can bias perception to favor a ‘hostile ’interpreta-
tion, and how different relative precision weightings can amplify orattenuate this effect.
Formally, and under certain simplifying assumptions, minimizing
prediction error is equivalent to the minimization of a statistical quan-tity called ‘variational free energy, ’which is often used to solve opti-
mization problems in machine learning.
18In this context, free energy
is a computationally tractable measure of the evidence that sensory
input provides for the brain ’s internal (generative) model of the world,
such that minimizing free energy maximizes model evidence. Freeenergy is simultaneously a measure of complexity minus accuracy.
This means that, when the brain updates beliefs by minimizing (preci-
sion-weighted) prediction errors (i.e., minimizing free energy), it does
so by ﬁnding the simplest (i.e., least complex), most parsimonious
change in beliefs to account for new observations.
In decision-making and action selection, a related class of bio-
logically plausible algorithms comes from the ‘active inference ’
framework.2,16,17,19Active inference models go a step beyond predic-
tive coding to emphasize that the brain does not simply predict sen-
sory input passively. Instead, it predicts what it will observe if itchooses to act in one way or another.20From this perspective,
decision-making involves predicting the outcomes one would observe
ifeach of several actions (or action sequences, called ‘policies ’) were
chosen, and then selecting the actions expected to produce the obser-
vations that are most preferred and/or that will provide the most newinformation. Upon re ﬂection, this is quite intuitive. For example, if I
am hungry, then I am less likely to stay still and more likely to go
andﬁnd food –precisely because being hungry is inconsistent with
Macroscale
Mesoscale
MicroscaleFig.1 Schematic of the multiscale archi-
tecture of neural networks. At the macro-
scale, the brain is most often studied in
terms of activity within, or interactionsbetween, large-scale brain regions usingneuroimaging. These brain regions caninteract over large distances, mediated bylong-range axonal ﬁber bundles. At the
microscale, the brain is studied in terms ofsingle-neuron activity and intra −/inter-
cellular interactions at the molecular level.
The mesoscale links the micro- and mac-
roscales, but it is currently the most dif ﬁ-
cult to study. Computational neuroscienceis uniquely suited to address mesoscalefunction. Current work in this area sup-ports the idea that patterns of synapticconnectivity at this level implement thepredictive algorithms discussed in thetext. This algorithmic level of description
bridges the neural and psychological
levels of description by showing how neu-ral structures can implement the computa-tional processes underlying psychologicalfunctions, such as perception, learning,and decision-making. Mesoscale compu-tational (algorithmic) modeling thereforeoffers a unique window into the neuralbasis of abnormal psychological pro-
cesses within psychopathology. Adapted
from Park and Friston.
1
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 4The predictive brain in psychiatry PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

my preferences and I expect eating food will produce my more pre-
ferred feelings of satiety. However, if I am not con ﬁdent where to ﬁnd
the closest source of food, I will ﬁrst choose actions to gather infor-
mation –such as checking in the fridge before deciding to go to the
store.
In active inference, preferences are formally modeled as a
particular type of prior expectation (over sensory observations or ‘out-
comes ’; often called ‘prior preferences ’), which means that non-
preferred outcomes are ‘surprising ’in a technical sense (i.e., they
deviate from those prior preferences). During decision-making, this
type of expected ‘surprise ’(if one action were chosen vs another) is
associated with what might be thought of as an expected ‘preference
prediction error ’(i.e., the expected difference [technically the
Kullback –Leibler divergence] between preferred outcomes and theoutcomes expected if one were to choose a particular course of action
–a quantity also sometimes referred to as ‘risk ’). Preferred outcomes
are then achieved by choosing actions expected to minimize this type
of prediction error. However, it is important to distinguish this
preference-based notion of ‘surprise ’and prediction error from other
constructs. First, prediction error is not equivalent to a conscious feel-ing of surprise or the conscious belief that something is surprising.
Conscious feelings and beliefs are higher-level states that must them-
selves be inferred.21–23By contrast, in active inference (and in predic-
tive coding), the terms ‘belief ’and ‘surprise ’are technical terms that
refer to probabilistic representations encoded by neuronal activity
(and connectivity) in mesoscale neural circuitry (e.g., canonical
microcircuits6). These neurocomputational processes occur at a sub-
personal level outside of conscious awareness and therefore need not
(a) (b) (c)
(e)(f)
G1
5
423
ABsτ
sπ,τ
επ,τ
π
γ
ut(1)o1o2o3oπ,τ
ςπ,τ
(d)Precision
modulation from
higher levels10 (Very friendly)
Time 0 (Very hostile)
10 (Very friendly)
0 (Very hostile)Stable estimate
PrFL= 1 (Low); πFL = πLC; LC = 5 PrFL= 9 (High); πFL = πLC; LC = 5
PrFL= 1 (Low); πFL > πLC; LC = 5 PrFL= 1 (High); πFL < πLC; LC = 5Stable estimate Policies
Time InhibitoryExcitatory
Modulator yStable estimateStable estimateFL activity (Friendliness level)
LC activity (Neutral facial expression)
Precision
modulation from
higher levels
Signal from
lower levelsPrecision
estimate
(πFL)
Precision
estimate
(πLC)Linear mapping
between levelsPEFL
PELCFL
LCPrediction from
higher level ( PrFL)
Fig.2 (a) An illustration of neuronal connectivity and dynamics within a very simple predictive coding model of ‘friendliness perception ’(i.e., estimating how friendly vs
hostile someone is based on lip curvature as an indicator of facial expression). This example illustrates how the same input (i.e., ﬂat lip curvature, most consistent with
a neutral facial expression) can be interpreted as a sign of higher or lower levels of friendliness based on different learned prior expectations and p recision estimates.
In this model, blue triangles indicate cortical pyramidal neurons, and black lines indicate axons terminating in synaptic connections. Arrows indi cate excitatory synaptic
inﬂuences, and circles indicate inhibitory synaptic in ﬂuences (dashed arrows are not modeled, but indicate additional context-speci ﬁc modulatory in ﬂuences that could
also be present in a more complete model). Activity of the FL neuron estimates ‘level of friendliness ’(from very hostile to very friendly; activity levels from 0 –10), and
LC neuron activity represents ‘lip curvature ’(i.e., low activity indicates frown and high activity indicates smile). The two PE neurons re ﬂect ‘prediction-errors ’associated
with FL activation (higher level) and with LC activation (lower level). The strength of the two looping axons ’synapses (connecting each PE neuron to itself) estimates
the precision (reliability) of prior expectations ( πFL; higher level) and LC activity ( πLC; lower level). Expected friendliness (Pr FL) is conveyed through the strength of the
top-down inhibitory synapse on the higher-level PE neuron. Although not modeled here, predictive coding models also include quantitative synaptic learning mecha-
nisms (i.e., update equations) allowing the strengths of the Pr FL,πFL, and πLCsynapses (i.e., prior expectations and precision estimates) to be altered over time to better
match patterns in experience. Panels (b) –(e) illustrate changes in FL neuron activity (i.e., inferred friendliness level; black lines) over time when presented with a ﬂat lip
curvature (i.e., moderate LC activity, most consistent with a neutral level of friendliness, all else being equal; blue lines) under different model parameter values. These
different parameter values re ﬂect: prior expectations of (b) low versus (c) high levels of friendliness; and (d) high versus (e) low reliability/precision estimates for expecta-
tions of low friendliness. As can be seen, after FL neuron activity converges onto a stable estimate (i.e., when activity ceases to oscillate once pred iction error is mini-
mized), lower levels of friendliness are inferred in (b) compared to (c) (re ﬂecting the in ﬂuence of prior predictions), and in (d) compared to (e) (re ﬂecting the in ﬂuence of
higher reliability estimates for prior predictions of low friendliness). For the detailed mathematics on which this example is based, see Bogacz.13Panel (f) depicts the
neural process theory proposed within active inference. Example simulations using this process theory are shown in Figure 3. In this theory, probabi lity estimates for a
given phenomenon (e.g., being friendly or hostile) are associated with neuronal populations that are arranged to reproduce known intrinsic (within cortical area) connec-
tions. Red connections are excitatory, blue connections are inhibitory, and green connections are modulatory (i.e., involve a multiplication or we ighting). Similar to pre-
dictive coding, these connections convey different types of prediction and prediction error signals (labeled as signal types 1 –5), but in this case also incorporate action
selection. Cyan units correspond to predictions about future sensory inputs ( o) and the causes of those inputs ( s) if one were to follow one sequence of actions versus
another (i.e., policies, π) at each time point ( t), while red units represent a type of ‘best guess ’about causes of sensory input when considering the probability of all pos-
sible policies (i.e., a Bayesian model average). Pink units correspond to sensory prediction errors ( ε) and preference predictions errors ( ζ), which are used to evaluate
expected free energy (G) and compute subsequent policy probabilities ( π). When selecting an action ( u) at each time point, policy probabilities are also modulated by
an expected precision term ( γ) that has been linked to dopamine.14Predictions are conveyed by one set of synaptic connections (denoted by the letter B), while predic-
tion errors are encoded by a different set of synaptic connections (denoted by the letter A); these synaptic connection strengths are updated during a ssociative learn-
ing (i.e., long-term synaptic potentiation and depression15). Only exemplar connections are shown to avoid visual clutter. Furthermore, we have just shown neuronal
populations encoding beliefs under two possible policies over three time points. For an introduction to the associated mathematics describing neur onal interactions in
this theory, see Friston et al.,2, 16and Da Costa et al.17
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 5PCNPsychiatry and
Clinical Neurosciences The predictive brain in psychiatry
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

lead to conscious feelings of surprise. Second, ‘preference prediction
errors ’(also sometimes called ‘outcome prediction errors ’in the
active inference literature; e.g., see ﬁgure 2 within Smith et al.21) are
not the same as the ‘state prediction errors ’discussed above in rela-
tion to predictive coding. There are also state prediction errors in
active inference (see Fig. 2f), which –as in predictive coding –occur
when model beliefs (about one ’s current state or situation) are updated
with an unexpected new observation. In other words, state prediction
errors drive belief updating about states of the world that are encoun-
tered, while preference prediction errors pertain to the (non)preferred
outcomes expected if one were to choose different courses of action.
In this sense, it is possible for the brain to be ‘surprised ’by an unan-
ticipated outcome given its prior beliefs about states (i.e., large state
prediction error), while yet anticipating a preferred outcome
(i.e., small expected preference prediction errors). This speaks to thedifference between posterior beliefs about one ’s course of action (that
are informed by state prediction errors) and prior beliefs before
experiencing the consequences of action (that are informed by
expected preference prediction errors).
Similar to state prediction errors in predictive coding, minimizing
expected preference prediction errors also corresponds to minimizing
free energy –but in this case it is the free energy associated with the
future outcomes that are expected under different actions (i.e., expected
free energy). As with predictive coding, active inference comes
equipped with a neural process theory that allows one to simulate pat-terns of neural activity that can be tested empirically.
2,14,16,19,24An
example neural network implementation based on this process theory is
depicted in Figure 2f. Although the neural network architecture in this
case differs somewhat from the simpler predictive coding example in
Figure 2a –e, similar prediction error minimizing dynamics emerge
(example simulations using this architecture are shown in relation to a
formal model of emotion in Fig. 3). In most cases, minimizing
(expected) free energy in these theories is expected (on average, and in
the long run) to keep an organism within the narrow range of physio-
logical and environmental states consistent with its survival(i.e., preferred states34). However, it is important to highlight that
organisms also plausibly inherit evolutionarily selected, adaptive prior
expectations (including preferences), which can favor genetic propaga-tion over individual survival (e.g., motivating risky reproductive behav-
ior or self-sacri ﬁce for genetic relatives35).
Similar to predictive coding, probabilistic beliefs in active infer-
ence models can also have different levels of precision that in ﬂuence
belief updating. However, in addition to the precision of sensory pre-diction errors and prior beliefs about states, there are a number of other
variables that have precisions in active inference. For example, prior
preferences can have different precisions, which can affect the degree
to which behavior is driven by seeking reward versus seeking informa-
tion to resolve uncertainty. Beliefs about the probability (i.e., value) ofdifferent available sequences of actions ( ‘policies ’) can also have dif-
ferent expected precisions, which can affect how strongly decision-
making is controlled by habits versus explicit planning. Beliefs about
distant future states can also be more or less precise (e.g., more or less
conﬁdence in predicting the way one ’s life will be in 6 months if
choosing one or another course of action now), which can in ﬂuence
whether someone focuses more on short-term versus long-term conse-
quences when making decisions. More generally, because precisionformally refers to the inverse dispersion (i.e., entropy) of a probability
distribution, every belief has the attribute of precision. In predictive
coding schemes, these probabilistic beliefs are over continuous vari-
ables (e.g., brightness, loudness) and precision corresponds to the
inverse variance of those (typically Gaussian) distributions. In contrast,because decisions are categorical (i.e., a person can only choose one
discrete option out of several available options), probabilistic beliefs in
active inference models are over categorical (discrete) variables. In this
case, precision can correspond to what are called ‘inverse temperature ’
parameters that in ﬂuence the shape of discrete probability distribu-
tions. For example, the beliefs (probabilities) over policies mentioned
above are controlled by an ‘expected precision ’parameter of this type.Physiologically, these types of precisions can be associated with lateral
inhibition and excitation –inhibition balance, whereas in predictive
coding schemes, precision can be associated with postsynaptic gain or
excitability.
Although considerable progress has been made in building and
testing computational models of simple problems in perception, cogni-
tion, and action selection, applications of predictive coding and activeinference (as well as other related Bayesian) models to more complex
clinical phenomena have thus far been limited. In this domain, the
ﬁelds of clinical computational neuroscience and computational psy-
chiatry are still largely at the stage of building viable conceptual
models –and identifying or simulating associated mathematical
models of complex clinical phenomena. Thorough empirical tests of
these models are largely outstanding, although emerging empirical
work (discussed below) appears promising.
Illustrative Examples
In what follows, we offer a number of illustrative examples of con-
ceptual and formal mathematical models in computational neurosci-
ence and psychiatry, with the aim of: (i) illustrating potentialempirical applications; and (ii) conveying the methodological
resources available that can be applied to other cases. We then
describe examples of recent empirical work that has applied suchmodels to clinical questions. These examples should not be seen as
an exhaustive treatment of extant literature –they just exemplify ways
in which understanding the brain as a ‘prediction machine ’can be
used in psychiatry. It should also be noted that we do not address
other areas of research in computational psychiatry, such as reinforce-ment learning. The primary focus of reinforcement learning is to
account for choice behavior in terms of rewards. This area of research
has been fruitful, but it has focused less on modeling the prediction-
based mesoscale brain processes we consider here (i.e., with some
notable exceptions related to dopamine and reward prediction errorsignals, and their interactions with corticostriatal circuits; e.g., see
Frank,
8Silvetti et al.,36and Schultz37).
Conceptual models
There is a growing body of theoretical work that affords potential clini-
cal insights and new hypotheses for psychiatric disorders. This work
takes the general approach of synthesizing previous empirical ﬁndings
and proposing ways in which computational concepts could help unifysuch ﬁndings under a single parsimonious theory. We consider these
contributions to be ‘conceptual ’because, although they qualitatively
describe ways in which the predictive neurocomputational dynamics
that are illustrated in Figure 2 may shed light on clinical phenomena,
they do not offer quantitative mathematical models that afford precisesimulations of proposed mechanisms.
As one prominent example, depression has been the topic of a
number of computational proposals. One recent model pertains to a
proposed computational basis for mood.
38The central idea here is
that neural systems not only maintain estimates in the con ﬁdence or
precision of their prior beliefs about outcomes, but also estimates of
conﬁdence in their beliefs about that precision (i.e., the degree to
which the unknowns are known). For example, if an individualexpects uncertain, unpredictable outcomes (low precision beliefs), but
makes those predictions con ﬁdently (high con ﬁdence in high uncer-
tainty), it is proposed that this will result in a chronic, self-
maintaining negative emotional state that, in extreme cases, becomes
resistant to change (as in depressive disorders). Neurobiologically, theset-points of neuromodulatory mechanisms are suggested to encode
these –statistically higher-order –conﬁdence estimates, potentially
accounting for the neuromodulatory abnormalities observed in
depression (and the mechanisms of antidepressant drugs in targeting
neuromodulatory systems
39,40). In neural process theories (Fig. 2),
these neuromodulators would have the effect of dynamically tuning
the strengths of synapses that encode various types of precisions
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 6The predictive brain in psychiatry PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

(e.g., the estimated reliability of sensory signals, prior expectations,
and expected action outcomes).
This model represents a nice example of how (sub-personal)
beliefs, computations, and mesoscale neuronal processes can be
understood in terms of each other. That is, the precision corresponds
to the statistical certainty of a probabilistic representation, where this
certainty is encoded by the patterns of synaptic ef ﬁcacy or gain (and
resulting excitability) within a neuronal population (see Parr and
Friston4and Friston et al .16). The required computation is then to
optimize this encoding of uncertainty by adjusting synaptic connec-
tion strengths through neuromodulatory mechanisms (e.g., serotoner-
gic or dopaminergic neurotransmission). In this setting, ‘optimization ’
means that neuronal dynamics will converge onto an internal estimate
(a‘best guess ’based on past experience) that minimizes free energy.
In the case of psychopathology, early adversity (and perhaps genetic/epigenetic vulnerability factors) could lead an individual to converge
onto poor or otherwise maladaptive estimates of uncertainty, as
suggested by the model described above.
Another predictive processing perspective has been offered by
Barrett and colleagues,41who focus on the role of interoceptive predic-
tive processing and the ways in which interoceptive predictions may
become dysfunctional and result in a depressive phenotype. They pro-
pose that depression is due to one or more of the following: (i) an inter-
nal model that is inef ﬁcient at managing energy regulation (e.g., due to
overly precise expectations for large metabolic demand); (ii) impreciseinteroceptive signals from the body, creating dif ﬁculty in effective
allostasis (i.e., dif ﬁculty adaptively generating anticipatory changes in
visceral states due to expected future demands); and (iii) maladaptive
internal estimates of the precision of afferent interoceptive signals
(e.g., due to neuromodulatory system dysfunction). Each of thesepotential breakdowns would render the brain insensitive to updating its
beliefs about the body, and lead to dif ﬁculty keeping the body within
homeostatic ranges (i.e., ‘preferred states ’within active inference
models). Under the assumption (put forward by the authors) that pleas-
ant/unpleasant feelings convey interoceptive information about themoment-to-moment energy conditions (i.e., immunological, in ﬂamma-
tory, and physiological states) of the body, this could produce pervasive
negative affect (and sickness behaviors that reduce energy expenditureand promote fatigue), and lead to several motivational and neuro-
vegetative symptoms of depression. In previous work, these authors
have also proposed an explicit mesoscale scheme in which cortical col-
umns within agranular cortical regions within the insula and anterior
cingulate convey interoceptive prediction signals, while granular corti-cal regions (e.g., posterior insula) generate interoceptive prediction
error signals that update beliefs about the energy conditions of the
body
42–offering additional predictions that could be tested empirically
in future neuroimaging work.
A further conceptual model of depression has been proposed by
Badcock and colleagues43that highlights how computational processes
can interact with the various psychosocial processes that are implicated
in depression (for another computational model of biopsychosocial pro-
cesses, see Smith et al.44). Badcock et al. propose an evolutionary sys-
tems theory of depressive mood states, which combines active inferencewith insights –drawn from psychology, psychiatry, and neuroscience –
on the role of social contexts in depressive phenomena. Under this
model, normative levels of depressed mood can re ﬂect an adaptive,
risk-averse strategy that reduces uncertainty in interpersonal contexts
when sensory cues evince an increased likelihood of unexpected or neg-
ative social outcomes (e.g., rejection or loss). The depressive response
thus functions as a ‘better safe than sorry ’strategy that minimizes inter-
personal interactions with unpredictable or non-preferred expected out-comes. It achieves this function by inducing changes in perception
(e.g., a heightened sensitivity to social information), suppressing con ﬁ-
dent reward-approach behaviors (e.g., anhedonia), and generating sig-
naling behaviors that either garner support (e.g., reassurance seeking) or
defuse con ﬂict (e.g., submissive behaviors). The authors suggest that,
neurobiologically, depressed mood states are characterized by an
increase in the precision of (bottom-up) social prediction errors(i.e., prediction errors conveyed to neurons encoding social informa-
tion), which facilitates perceptual inference and learning about thesocial world by increasing the in ﬂuence of ascending prediction errors
on belief updating. This idea is consistent with the active inference liter-
ature on emotion, which suggests that negatively valenced states
increase learning rate (see Jof ﬁly and Coricelli
45). In depression, these
ampli ﬁed prediction errors are postulated to be selective to interpreta-
tions of social stimuli, which most plausibly occur at higher levels in a
hierarchical model (e.g., dorsomedial prefrontal cortices46–50). This
increase in precision ampli ﬁes an individual ’s sensitivity or attention to
interpersonal cues, while suppressing con ﬁdence in (top-down) social
predictions (and thus con ﬁdence in associated social behaviors). Symp-
tomatically, the authors suggest that this would produce a suspension of
goal-directed behavior (e.g., anhedonia and social withdrawal), rumina-
tion about negative self –other relations, and an attentional bias toward
(aversive) interpersonal cues during social inference. Here, it is espe-
cially important to stress the role of attention. In this instance, attention
can be construed as affording precision to neuronal signals conveying
various Bayesian beliefs or prediction errors,51–56such that they have
greater in ﬂuence on belief updating than other levels of the cortical
hierarchy. This ﬁts comfortably with the role of neuromodulators in
mediating attentional gain at the synaptic level.4
In most circumstances, the suggestion is that the depressive
response functions adaptively by attracting interpersonal support and
reducing social uncertainty through both risk-averse interpersonalbehaviors and faster belief updating in the presence of unexpected
outcomes. However, psychopathology can emerge when there are
ongoing discrepancies between actual and preferred social outcomes
over time (i.e., chronic prediction errors). Given the increased
precision-weighting assigned to social prediction errors, such chronicsocial stress can in turn engender precise higher-order expectations
that social rewards are unlikely (e.g., pessimism, low self-worth),
which perpetuate risk-averse depressive behaviors (e.g., social with-
drawal) and ultimately lead to disorder (e.g., learned helplessness;
also see Chekroud
57and Kube et al.58). As we discuss below, these
depressive beliefs can become increasingly entrenched and self-
maintaining, producing overly precise prior expectations about aver-
sive (social) outcomes that are resistant to change. In other words,depressive disorders can be described as a maladaptive pattern of dys-
regulated defenses: when depressive changes fail to resolve social
stress, the individual is at risk of entering a self-perpetuating, dys-
regulated state, leading to chronic illness behaviors that fail to
respond to any improvements in the social domain. Vulnerability topsychopathology is facilitated by early exposure to social stress
(e.g., parental abuse or neglect), which promotes prior beliefs that
social outcomes are uncontrollable and heightens the sensitivity of
stress response systems to interpersonal stressors (e.g., in ﬂammatory
immune responses; see Slavich and Irwin
59). Notably, the model
described here also lends itself to empirical scrutiny. For example, a
simple way to test this hypothesis would be to use neuroimaging or
electrophysiological methods that capture prediction error suppression
(e.g., trial-by-trial ﬂuctuations in P300 amplitudes) in depressed ver-
sus nondepressed participants when presented with unpredictablesocial stimuli. The model also has implications for prevention and
intervention efforts by underscoring the importance of strategies that
aim to improve social environments or resolve interpersonal stress(e.g., interpersonal psychotherapy).
Note that these are simply illustrative examples of recent con-
ceptual models. As we touched upon above, other authors have pro-
posed that depression is maintained by overly precise prior
expectations for depressive schemas, such as strong expectations ofone ’s own worthlessness or that the world is uncontrollable.
60The
suggestion here is that these prior expectations bias attention to
schema-consistent information and also bias the interpretation of
sensory input in a schema-consistent manner. This can then drive
chronic stress, heightened in ﬂammation, and avoidance behaviors,
each of which furnish future observations that selectively support
and maintain depressive schemas in a vicious positive feedback loop
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 7PCNPsychiatry and
Clinical Neurosciences The predictive brain in psychiatry
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

(also see Kube et al.58). Further examples include recent conceptual
models of autism61–63and schizophrenia.64,65In autism it is
suggested that, from childhood, low-level sensory prediction errors
are overweighted generally, leading to (i) repetitive behaviors that
reduce low-l evel prediction error; and (ii) a r educed ability to learn
abstract and complex regularities in higher l evels of a hierarchical
model (i.e., because all prediction errors are inappropriatelysuppressed before reaching these higher l evels). As social regulari-
ties are among the most complex to learn, social cognition thus
remains poorly d eveloped. Interestingly, accounts of schizophrenia
suggest that a similar phenomenon occurs, in which low-l evel pre-
diction errors in some modalities are overweighted, but with adultonset.
65This then leads the brain to treat random aspects of sensory
observations as ‘suspicious coincidences ’in need of explanation,
driving the development of overly complex models of the worldwith stranger and stranger (delusional) beliefs over time. For exam-
ple, when proprioceptive prediction errors (that carry information
about bodily movement) are overwei ghted, this can lead to delusions
about agency (e.g., that unexplained proprioceptive prediction errors
indicate that one ’s body is being controlled by others). In contrast, it
appears that auditory prediction errors are underweighted in psycho-
sis, creating increased vulnerability to auditory illusions.64Although
further conceptual models have been proposed for other clinical
phenomena, the proposals on depression covered in detail here are
representative of the general explanatory strategies used in othercases.
Formal models
Moving beyond conceptual proposals, a few formal (i.e., quantitative
mathematical) predictive processing models have also been presented
for a range of clinical phenomena; unlike conceptual models, these
formal models afford explicit simulations of proposed neuro-computational mechanisms. In the case of depression, for example,
Stephan et al.
66presented a mathematical model to capture homeo-
static and allostatic regulation of visceral states and how meta-
cognitive estimates of the ef ﬁcacy of allostasis could promote a
depression-like state of fatigue. In their proposal, homeostatic setpoints are modeled as ﬁxed probability distributions specifying
predicted ranges (means and variances) of a given physiological vari-
able (e.g., blood glucose levels, blood osmolality levels, and circulat-
ing hormone or in ﬂammatory cytokine levels); deviations from
homeostatic ranges lead to the generation of prediction errors (withrespect to those set points), which can then be minimized through
closed-loop control processes in an interoceptive re ﬂex arc (i.e., this
is analogous to minimizing ‘preference prediction errors ’in active
inference models where homeostatic set points represent preferred
states). Allostasis involves forecasting future deviations from homeo-stasis and adjusting physiological variables in advance to prevent
these deviations. In their model, the prior expectations for homeo-
static ranges can be dynamically adjusted by higher-level predictions.
For example, if a cue indicated that blood glucose levels were about
to drop, the predicted mean of the distribution could be temporarilyshifted upward, so that blood glucose levels would elevate before the
anticipated drop, allowing them to always remain within acceptable
values. Alternatively, if a cue indicated that blood glucose levels wereabout to change in an unexpected direction, the predicted precision of
the distribution could be tightened, endowing prediction errors with a
greater in ﬂuence on belief updating, and a faster return to homeostatic
ranges. They then discuss how, if attempts at allostasis repeatedly fail,
sustained dyshomeostasis could lead to higher-level inferences favor-ing states of subjective fatigue associated with depression. Speci ﬁ-
cally, they suggest that such states of depressive fatigue, and
associated sickness behaviors, could emerge as strategies for dealing
with conditions in which the brain continuously predicts that allostatic
regulation will be ineffective. (To be clear, we use blood glucoselevels here only as an example physiological variable for illustration.
The authors focus on dyshomeostasis generally, consistent with theconceptual proposals regarding metabolic regulation in depression
reviewed above.)
Crucially, the quantitative prediction and prediction-error dynam-
ics that can be simulated using this model speak to the possibility of
testing which regions of the brain show patterns of activity consistent
with those simulated dynamics, and whether this differs in healthy
versus depressed individuals. The authors hypothesize that a numberof subcortical and cortical regions (e.g., brainstem, amygdala, insula,
anterior cingulate) may implement different levels of homeostatic and
allostatic control, and that dorsal prefrontal regions may be involved
in estimating allostatic ef ﬁcacy. Testing these predictions will be an
important direction for future empirical work.
As an additional, more in-depth, example of recent formal
modeling, another series of papers has presented a formal active infer-
ence model of emotional state inference and emotional awareness(depicted in Fig. 3), and has used this model to simulate clinical phe-
nomena arising from poor early learning and biased attentional mech-
anisms
21,25(for a related computational model of pleasant/unpleasant
affective valence, see Hesp et al.22). This modeling effort aimed to
explain the common clinical observation that some individuals appearto have low awareness of their own emotions and can misinfer that
emotion-related sensations are signs of medical illness.26,67,68It is
also inspired by the observation that psychotherapeutic interventions
that aim to improve emotional awareness have shown ef ﬁcacy.69,70To
simulate these phenomena, the model included examples of distinctinternal states that could be inferred, including emotional state cate-
gories (sadness, panic) and somatic state categories (sickness, heart
attack). The simulated decision-making ‘agent ’began with prior
expectations about its own internal state, and these expectations were
then updated (i.e., a new internal state was inferred) based on exam-ples of relevant lower-level beliefs about current experience, includ-
ing: valence (in this case, neutral/negative), arousal (high/low),
motivation (approach/avoid), and an interpretation of the current situ-
ation (neutral, socially threatening, or physically threatening; e.g., as
in cases where one is ignored at a party, in a crowded space, or feel-ing chest pain). To allow for biases in attention, the agent could not
access all of this lower-level information at the same time. It instead
had to selectively attend to one or more of these pieces of informationsequentially (e.g., choose to attend to valence, then arousal, etc.) until
it became con ﬁdent in its internal state. At this point it would choose
to self-report its internal state beliefs (e.g., whether it was experienc-
ing sadness, panic, sickness, or a heart attack, or if it simply felt neu-
tral, bad, or good). After making a report, the agent also received‘social feedback ’that was either positive (if its report was ‘correct ’;
e.g., matched cultural expectation) or negative (if it was ‘incorrect ’).
Positive social feedback was preferred. Thus, on each ‘trial, ’the agent
was presented with a newly generated ‘affective response ’(i.e., a pat-
tern of valence, arousal, and motivation in a perceived context), andchose what to attend to and report in hopes of receiving the preferred
positive feedback (i.e., to minimize preference prediction error). Each
affective response pattern presented to the agent was generated by a
‘true model, ’which held the different (probabilistic) patterns of
lower-level information most consistent with each possible emotional/somatic state (e.g., ‘sadness ’best matched a pattern of negative
valence, low arousal, and avoidance motivation in the context of
social threat [such as being socially rejected]).
Aside from this inference process, a variant of the model also
implemented emotion concept learning. Speci ﬁcally, the simulated
agent could learn emotion categories (e.g., sadness, fear, anger, and
happiness) that predicted different patterns in experience through the
social feedback mentioned above (e.g., as in early development, whencaregivers mirror and label a child ’s reactions with emotion terms
71–73).
Mathematically, this learning process (i.e., a type of concept acquisi-
tion) was implemented through learning probability distributions via a
coincidence-detection mechanism resembling Hebbian synaptic plastic-
ity.15,19,74This learning mechanism estimates how often different inter-
nally represented states (e.g., sadness) are expected to generate
particular thoughts, feelings, and sensations (e.g., unpleasant feelings,
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 8The predictive brain in psychiatry PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

high arousal sensations, and avoidance drives while perceiving a preda-
tor). The formal basis of this learning mechanism can be intuitively
thought of as simply counting coincidences between states and observa-tions –that is, increasing the expected probability (i.e., synaptic con-
nection strength) of a particular observation, given a particular state,
each time one makes that observation when (they believe) they are in
that state –similar to long-term potentiation- and long-term depression-
based synaptic learning mechanisms widely studied in cellular/molecu-lar neuroscience.
15,19
These simulations are based on the ‘three-process model ’of emo-
tional awareness,26–32and supporting evidence,68,75 –83which empha-
sizes that the mechanisms that generate affective responses can beseparated from the processes that infer the meaning of those responses.
It is also based on elements of ‘constructivist ’theories that stress the
culture- and context-speci ﬁc nature of emotion-conceptualization pro-
cesses.33Based on the evidence supporting these perspectives, the
broad theoretical assumptions of the simulations are that individuals
generate multimodal affective responses in a ﬂexible (i.e., domain-gen-
eral) and context-sensitive manner, based on the predicted metabolic,
cognitive, and behavioral demands of a perceived (or remembered/imagined) situation. These predicted demands are in turn based on a
fast, largely unconscious evaluation of that situation (e.g., concerning
whether it is safe/threatening, goal-congruent/incongruent, consistent/inconsistent with norms/values, among other dimensions) and available
Domain-general cognition
(higher-level)
Emotionally
neutralPanic SickHeart
attackNeutral
Sad
Panic
Sick
Heart attack
Time 1 Time 2 Time 3SadINTERNAL STATE CONCEPTS
Neutral High ApproachNeutral
ContextPhysical
Threat
Valence Arousal Motivation
Lower-level representations
Body Affective (interoceptive/behavioral) responseBeliefs
about contextNegative Low AvoidSocial
ThreatSimulated neural firing rates and local field potentials
Fig.3 Depiction of a formal (generative) model of emotional state inference, adapted from Smith et al.21, 25; also see Hesp et al.22On the left, a network of abstract
neuron-like nodes (and select connections) is depicted, where the higher level represents different possible concept-level inferences about one ’s own internal state,
including emotional and somatic interpretations. These representations send downward prediction signals, conveying the patterns of lower-level representations
expected under each higher-level representation. Prediction errors are conveyed upward, such that the higher level converges onto the representat ion that makes the
most accurate predictions (i.e., minimizes prediction error). The lower level in turn generates the affective (interoceptive/behavioral) respon ses themselves
(e.g., generating elevated heart rate and avoidance behavior when inferring threat; shown in gray). Here it is assumed that the brain has previously g enerated a ( ﬂexible,
context-speci ﬁc) affective response of this kind, based on the predicted metabolic, cognitive, and behavioral demands of a situation. This occurs upon perceiving a nd
interpreting that situation (i.e., based on a fast, largely unconscious, domain-general evaluation of a situation as being, for example, safe, thre atening, goal-incongruent,
or inconsistent with norms/values; only interpretations of the situation as neutral, socially threatening, or physically threatening are explici tly depicted here). The brain ’s
job is then to perceive how body states have changed based on this generated response, and to make sense of it in terms of various (self-report guiding) c oncept rep-
resentations it has learned (i.e., this is based on the three-process model of emotional awareness,26–32as well as constructivist theories stressing the culture- and
context-speci ﬁc, domain-general nature of emotion conceptualization33). To do so, the simulated decision-making ‘agent ’must ﬁrst choose selective attention policies
(i.e., selectively attend to valence, arousal level, the surrounding context, etc.) and then choose self-report policies communicating which emot ion is being felt, based
on what it has attended to and observed (with the preference of receiving con ﬁrmatory social feedback, which also allows simulation of learning emotion concepts dur-
ing development25). In this example, activated lower-level representations are shown in red, leading to the inference of sadness at the higher level (also red) and the
self-report that ‘I feel sad ’(not shown). This occurs gradually as the individual selectively attends to each lower-level modality (not shown) and accumulates evidence
for the sadness interpretation. After arriving at this interpretation, it can also be held in working memory and re ﬂected upon (i.e., gestured at with the ‘Domain-general
cognition ’box in the top left; see Smith et al .21for explicit simulations). The top right corresponds to simulated neuronal ﬁring rates (darker = higher ﬁring rate;
i.e., higher represented probability) and simulated local ﬁeld potentials (rates of change in ﬁring rates) for this model, based on the neural process theory proposed
within the active inference framework,16which is depicted in Figure 2f. Here, the network starts with equally strong predictions across all possible interpretations, and
slowly converges onto the belief that sadness is the best- ﬁt interpretation when successively integrating lower-level representations (via selective attention processes
not depicted here). By simulating different starting predictions and connection strengths, precise simulations of pathological emotional state i nference and learning can
be carried out and can be used to make empirical predictions.
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 9PCNPsychiatry and
Clinical Neurosciences The predictive brain in psychiatry
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

actions. Generated responses include the types of changes in motiva-
tion, physiological arousal levels, and felt valence mentioned above.Once these bodily sensations and drives have been generated and per-
ceived, an individual must infer their meaning. Crucially, because map-
pings between emotion concepts and response patterns are both learned
(within a culture and with context-speci ﬁcity) and probabilistic
(e.g., sadness may typically be low-arousal but could be high-arousal),recognizing emotions can be a dif ﬁcult inference problem that can
sometimes lead to poor understanding and awareness of one ’so w n
emotions and their causes.
Note that we have therefore moved from Bayesian beliefs to a
computational description of feelings and emotions; namely, Bayesianbeliefs that provide the best explanation for both exteroceptive and
interoceptive signals. For example, a belief such as ‘I am anxious ’
provides the most parsimonious account of perceived threat and auto-nomic arousal that is itself in ﬂuenced (in part) by the predictions
ensuing from an expectation that one will feel anxious. This may
sound rather abstract; however, this kind of belief updating is now
possible to simulate in a neurobiologically plausible way and can, in
principle, be used to produce symptoms of emotional pathology in sil-
ico. For example, the top right portion of Figure 3 depicts simulated
neuronal ﬁring rates and local ﬁeld potentials during this emotional
state inference process, based on the neural process theory depicted
in Figure 2f. Empirically, one can then take these mesoscale simula-
tions and use neuroimaging (or other neuroscience methods) to iden-tify which brain regions most plausibly implement those mesoscale
computations (e.g., by ﬁnding brain regions that show the predicted
patterns of activity in simulations).
Simulations in this model illustrated at least seven different
mechanisms that could promote low emotional awareness. Becauseemotional awareness (i.e., the ability to recognize and understand
one ’s own emotions) plays a key role in many psychiatric
disorders,
26,67and may act as either a vulnerability or maintenance
factor, understanding such mechanisms could represent an important
step in being able to identify which mechanisms are operative in dif-ferent individuals and how they might be targeted on an individual
basis within therapy. For instance, one mechanism involved having
overly precise prior expectations for somatic threats, which led thesimulated agent to somatize (i.e., mistake sadness-related sensations
as signs of sickness or mistake panic-related sensations as signs of a
heart attack; e.g., as in high anxiety sensitivity
84). In another example,
if the agent ’s emotion concepts made highly imprecise predictions
(e.g., as in poor emotion-concept acquisition due to social neglect inchildhood85,86), it remained uncon ﬁdent and only reported feeling
good or bad (i.e., it was unable to differentiate different types of
unpleasant emotions; for clinical relevance, see Barrett et al .87and
Kashdan et al.88).
A third mechanism involved selective attention biases, which led
the agent to selectively ignore either bodily signals or contextual cues
(i.e., where such attention biases could have been reinforced in child-
hood and prevented emotion concept learning; e.g., hypervigilant
external attention, due to consistently high levels of threat or environ-
mental unpredictability89,90). Importantly, these mechanisms produced
similar behavioral phenotypes (i.e., self-report patterns), but might be
best targeted by different psychotherapeutic interventions. For exam-
ple, if low emotional awareness is due to an individual ’s emotion-
concept representations generating imprecise predictions, this would
suggest the need for psychoeducation interventions to help an individ-
ual mindfully attend to emotion and develop more precise emotion-
concept knowledge (e.g., mindfulness-based or emotion-focused
therapies91–93). In contrast, if an individual instead has overly precise
prior expectations for somatic threats, interventions that focus on
attenuating those strong expectations (e.g., exposure, cognitive
restructuring94) may be more appropriate. Finally, the model also
affords quantitative simulations of, and makes distinct predictions
about, the neural responses and reaction time differences that wouldbe observed if different mechanisms were involved. For example,
faster reaction times ( ‘jumping to conclusions ’) are predicted withoverly precise prior expectations (e.g., for somatic threats). As another
example, weaker neural responses to affective stimuli are predicted inindividuals with less precise emotion-concept representations due to
weaker changes in beliefs about emotional states upon the generation
of a new affective response. Thus, these types of mathematical simu-
lations afford important predictions to be tested in future experimental
work that could identify which brain regions implement the meso-scale neurocomputational processes captured in these simulations.
We stress here again that these are simply illustrative examples
of relevant simulation work in this area and are not meant to be
exhaustive. For example, other recent work in active inference has
mathematically simulated the factors that in ﬂuence patients ’decisions
to adhere to antidepressant medications
95and the neurocomputational
mechanisms of change during cognitive and behavioral therapies.96
Yet other studies have simulated predictive processing dynamics in
neural network and robot models and have reproduced patterns of
perception and behavior reminiscent of both schizophrenia97and
autism.98,99However, the detailed examples above –which have
selectively focused on depression and emotion –should offer the
reader a foundational sense of current directions in this ﬁeld.
Empirical studies
Recent neuroimaging studies have begun to support the hypothesis
that the brain engages in predictive processing, both in perceptionand decision-making. As might be intuited by the foregoing theoreti-
cal review, many of these studies rest upon the relation between aber-
rant precision-weighting and the consequent neuromodulation of
brain responses and connectivity (see references in Friston100). These
studies have been largely conducted with healthy participants. Forexample, a few studies have required participants to perform probabi-
listic perception and inference tasks, ﬁt computational models to task
behavior,101and then generated simulated sequences of precision-
weighted prediction errors.102,103Using neuroimaging, these studies
have found patterns of brain activation that closely match the simu-
lated pattern of prediction errors. The observed patterns of brain acti-
vation support the roles of dopamine (midbrain activity) and
acetylcholine (septum and basal forebrain) in encoding and precision-weighting distinct types of prediction errors associated with sensory
predictions and uncertainty estimates, respectively. Another study14
has also ﬁt decision behavior to an active inference model and found
evidence that activity within brain regions implicated in either send-
ing or receiving dopaminergic signals closely tracks the difference inexpected free energy before and after a new observation. This differ-
ence updates con ﬁdence estimates in the ability to select optimal
actions (i.e., the expected certainty in achieving preferred outcomes),
encoded by an ‘inverse temperature parameter ’reﬂecting the expected
precision of beliefs about the expected free energy of policies(i.e., possible sequences of actions). This parameter subsequently
inﬂuences how goal-directed an individual ’s actions are; imprecise
beliefs about policies (i.e., low expected precision) will give way to
more random or habit-driven behavior. Note, however, that this type
of (policy-related) precision is distinct from the types of precision dis-cussed above in predictive coding, which instead correspond to
beliefs about the reliability (inverse variance) of prior expectations
and sensory prediction errors –and modulate how strongly beliefs are
updated by sensory prediction errors (i.e., based on those beliefs
about their reliability).
There are also some very recent predictive processing-based
behavioral and neuroimaging studies in psychiatric populations,
104,105
which have provided evidence, for example, of heightened prior beliefs
that the environment is unpredictable in schizophrenia patients and in
those with high risk for psychosis (associated with activation patterns
within prefrontal and insula regions). While such neuroimaging studies
are quite limited, purely behavioral studies have also found support for
computational differences in patient populations. For example, onestudy asked individuals with and without auditory hallucinations to
indicate when they heard a tone each time a light was presented, while
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 10The predictive brain in psychiatry PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

(unbeknownst to participants) the probability of the tone being pres-
ented changed over time.106Computational modeling revealed that
individuals with hallucinations overestimated the precision of auditory
predictions, leading them to report false auditory percepts more often
than non-hallucinators (for related work linking aberrant prior expecta-
tions and precision in psychosis, see Corlett et al .64and Adams
et al.107). Interestingly, studies combining pupillometry and probabilis-
tic learning tasks have shown a distinct pattern in autism, where simi-
lar modeling methods suggest that the precision of sensory predictions
is underweighted.61,62,108
Lastly, a few recent studies have ﬁt active inference models to
data in transdiagnostic patient populations from tasks involvingexploratory decision-making, approach-avoidance con ﬂict, and inter-
oceptive awareness. One study found lower learning rates for losses
versus wins and lower precision in action selection within individualswith substance-use disorders relative to healthy controls,
109
suggesting a pattern in which actions that lead to negative outcomesfail to in ﬂuence future decisions –which could help explain contin-
ued substance use despite negative life consequences. A second
study found that, during approach-avoidance con ﬂict, individuals
with depression, anxiety, and/or substance-use disorders each showed
evidence of lower expected policy precision (greater uncertainty in
decision-making; associated with the γterm in Fig. 2f) in compari-
son to healthy controls.110However, the clinical populations did not
show heightened aversion to negative stimuli, suggesting that deci-sion uncertainty may represent a more promising target for interven-
tion/treatment. Finally, an active inference model of an interoceptive
awareness task recently found evidence that individuals with depres-
sion, anxiety, substance use, and/or eating disorders had lower intero-
ceptive sensory precision than healthy controls, but no difference inprior expectations.
111This ﬁnding was speci ﬁc to an interoception-
enhancing breath-hold manipulation, suggesting a transdiagnostic
inability to update sensory precision estimates when there are
changes in afferent signals from the body. This might help to explain
visceral dysregulation and poor emotional awareness in these clinicalpopulations. A subsequent study in a new sample also recently repli-
cated the ﬁnding that interoceptive precision estimates increase dur-
ing a breath-hold manipulation in healthy participants.112Such
ﬁndings are promising, but the observed effect in psychiatric patients
will still need to be replicated and extended in future work before
being afforded high con ﬁdence.
Conclusion
We have reviewed illustrative examples of how modeling the brain
as a prediction machine has begun to yield potential clinical
insights. Initially, this involves proposing conceptual models of how
a computational framework may offer explanatory power. Subse-quently, formal computational models can be written down,
affording quantitative simulations and precise predictions. Finally,
those models can be translated into behavioral tasks that can be car-
ried out during neuroimaging. Models can then be ﬁt to behavior,
allowing both: (i) identi ﬁcation of the neural correlates of model
parameters; and (ii) identi ﬁcation of differences in model parameters
(and associated neural responses) between individuals, which could
offer either diagnostic or prognostic information and inform treat-ment selection –sometimes called computational phenotyping. This
therefore allows us to move from mesoscale neurocomputational
processes that are very dif ﬁcult to study directly (e.g., through
single-neuron recordings) all the way through to phenotyping indi-
viduals within clinical populations with heterogeneous underlyingmechanisms. Further advances in the application of formal models
of the predictive brain will require close collaboration between clini-
cians, patients, and computational researchers to generate and for-
malize models of distinct clinical phenomena, and to design
informative behavioral tasks that, once validated, patients could per-form in the clinic to help mental health professionals better under-
stand and treat their patients.Acknowledgments
R.S. is funded by the William K. Warren Foundation. There is no
other funding to report.
Disclosure statement
The authors declare no con ﬂict of interest.
Author contributions
R.S. conceptualized and wrote the ﬁrst draft of the manuscript and
created the ﬁgures. P.B. aided in generating ﬁgures and wrote/edited
sections of the manuscript. K.J.F. contributed to conceptualization
and also wrote/edited sections of the manuscript.
References
1. Park HJ, Friston K. Structural and functional brain networks: From con-
nections to cognition. Science 2013; 342: 1238411.
2. Friston K, Parr T, de Vries B. The graphical brain: Belief propagation
and active inference. Network Neuroscience 2017; 1: 381 –414.
3. Knill DC, Pouget A. The Bayesian brain: The role of uncertainty in
neural coding and computation. Trends Neurosci. 2004; 27: 712 –719.
4. Parr T, Friston K. The anatomy of inference: Generative models and
brain structure. Front. Comput. Neurosci. 2018; 12: 90.
5. Marr D. Vision . MIT Press, Cambridge, MA, 1982.
6. Bastos A, Usrey W, Adams R, Mangun G, Fries P, Friston K. Canoni-
cal microcircuits for predictive coding. Neuron 2012; 76: 695 –711.
7. Friston K. A theory of cortical responses. Philos. Trans. R. Soc. Lond.
B Biol. Sci. 2005; 360: 815 –836.
8. Frank M. Computational models of motivated action selection in cor-
ticostriatal circuits. Curr. Opin. Neurobiol. 2011; 21: 381 –386.
9. Friston K, Stephan K, Montague R, Dolan R. Computational psychia-
try: The brain as a phantastic organ. Lancet Psychiatry 2014; 1:
148 –158.
10. Huys Q, Maia T, Frank M. Computational psychiatry as a bridge from
neuroscience to clinical applications. Nat. Neurosci. 2016; 19: 404 –413.
11. Montague P, Dolan R, Friston K, Dayan P. Computational psychiatry.
Trends Cogn. Sci. 2012; 16:7 2 –80.
12. Kiebel S, Daunizeau J, Friston K. A hierarchy of time-scales and the
brain. PLoS Comput. Biol. 2008; 4: e1000209.
13. Bogacz R. A tutorial on the free-energy framework for modelling per-
ception and learning. J. Math. Psychol. 2017; 76: 198 –211.
14. Schwartenbeck P, FitzGerald T, Mathys C, Dolan R, Friston K. The
dopaminergic midbrain encodes the expected certainty about desired
outcomes. Cereb. Cortex 2015; 25: 3434 –3445.
15. Brown TH, Zhao Y, Leung V. Hebbian plasticity. In:Squire LR (ed.).
Encyclopedia of Neuroscience . Academic Press, Cambridge, MA, 2009;
1049 –1056.
16. Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active
inference: A process theory. Neural Comput. 2017; 29:1–49.
17. Da Costa L, Parr T, Sajid N, Veselic S, Neacsu V, Friston K. Active
inference on discrete state-spaces: A synthesis. arXiv . 20 January 2020.
https://arxiv.org/abs/2001.07203v2
18. Friston K. The free-energy principle: A uni ﬁed brain theory? Nat. Rev.
Neurosci. 2010; 11: 127 –138.
19. Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, O Doherty J,
Pezzulo G. Active inference and learning. Neurosci. Biobehav. Rev.
2016; 68: 862 –879.
20. Kaplan R, Friston KJ. Planning and navigation as active inference. Biol.
Cybern. 2018; 112: 323 –343.
21. Smith R, Lane RD, Parr T, Friston KJ. Neurocomputational mecha-
nisms underlying emotional awareness: Insights afforded by deep activeinference and their potential clinical relevance. Neurosci. Biobehav. Rev.
2019; 107: 473 –491.
22. Hesp C, Smith R, Allen M, Friston K, Ramstead M. Deeply felt affect:
The emergence of valence in deep active inference. Neural Comput.
2020. https://doi.org/10.31234/osf.io/62pfd
23. Whyte C, Smith R. The predictive global neuronal workspace: A formal
active inference model of visual consciousness. bioRxiv . 2020. https://
doi.org/10.1101/2020.02.11.944611
24. Schwartenbeck P, Friston K. Computational phenotyping in psychiatry:
A worked example. eNeuro 2016; 3: ENEURO.0049-16.2016.
25. Smith R, Parr T, Friston KJ. Simulating emotions: An active inference
model of emotional state inference and emotion concept learning. Front.
Psychol. 2019; 10: 2844.
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 11PCNPsychiatry and
Clinical Neurosciences The predictive brain in psychiatry
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

26. Smith R, WDS K, Lane RD. The structure of emotional experience and
its relation to trait emotional awareness: A theoretical review. Emotion
2018; 18: 670 –692.
27. Panksepp J, Lane RD, Solms M, Smith R. Reconciling cognitive and
affective neuroscience perspectives on the brain basis of emotionalexperience. Neurosci. Biobehav. Rev. 2017; 76(Pt B): 187 –215.
28. Smith R. The three-process model of implicit and explicit emotion. In:
Lane R, Nadel L (eds). Neuroscience of Enduring Change: Implications
for Psychotherapy . Oxford University Press, New York, NY, 2020.
29. Smith R, Alkozei A, WDS K. How do emotions work? Front. Young
Minds. 2017. https://doi.org/10.3389/frym.2017.00069
30. Smith R, WDS K, Alkozei A, Lane RD. A neuro-cognitive process
model of emotional intelligence. Biol. Psychol. 2018; 139: 131 –151.
31. Smith R, Lane RD. Unconscious emotion: A cognitive neuroscienti ﬁc
perspective. Neurosci. Biobehav. Rev. 2016; 69: 216 –238.
32. Smith R, Lane RD. The neural basis of one ’s own conscious and uncon-
scious emotional states. Neurosci. Biobehav. Rev. 2015; 57:1–29.
33. Barrett L. How Emotions Are Made: The Secret Life of the Brain . Pan
Macmillan, London, 2017.
34. Badcock PB, Friston KJ, Ramstead MJD. The hierarchically mechanis-
tic mind: A free-energy formulation of the human psyche. Phys. Life
Rev. 2019; 31: 104 –121.
35. Badcock PB, Friston KJ, Ramstead MJD, Ploeger A, Hohwy J. The
hierarchically mechanistic mind: An evolutionary systems theory of thehuman brain, cognition, and behavior. Cogn. Affect. Behav. Neurosci.
2019; 19: 1319 –1351.
36. Silvetti M, Alexander W, Verguts T, Brown J. From con ﬂict manage-
ment to reward-based decision making: Actors and critics in primatemedial frontal cortex. Neurosci. Biobehav. Rev. 2014; 46:4 4 –57.
37. Schultz W. Dopamine reward prediction error coding. Dialogues Clin.
Neurosci. 2016; 18:2 3 –32.
38. Clark J, Watson S, Friston K. What is mood? A computational perspec-
tive. Psychol. Med. 2018; 48: 2277 –2284.
39. Cowen P, Browning M. What has serotonin to do with depression?
World Psychiat. 2015; 14: 158 –160.
40. Hieronymus F, Nilsson S, Eriksson E. A mega-analysis of ﬁxed-dose
trials reveals dose-dependency and a rapid onset of action for the anti-depressant effect of three selective serotonin reuptake inhibitors. Transl.
Psychiatry 2016; 6: e834.
41. Barrett LF, Quigley KS, Hamilton P. An active inference theory of
allostasis and interoception in depression. Philos. Trans. R. Soc. Lond.
B Biol. Sci. 2016; 371: 20160011.
42. Barrett L, Simmons W. Interoceptive predictions in the brain. Nat. Rev.
Neurosci. 2015; 16: 419 –429.
43. Badcock PB, Davey CG, Whittle S, Allen NB, Friston KJ. The
depressed brain: An evolutionary systems theory. Trends Cogn. Sci.
2017; 21: 182 –194.
44. Smith R, Weihs KL, Alkozei A, Killgore WD, Lane RD. An embodied
neurocomputational framework for organically integrating biopsycho-social processes: An application to the role of social support in health
and disease. Psychosom. Med. 2019; 81: 125 –145.
45. Jof ﬁly M, Coricelli G. Emotional valence and the free-energy principle.
PLoS Comput. Biol. 2013; 9: e1003094.
46. Adolphs R. The social brain: Neural basis of social knowledge. Annu.
Rev. Psychol. 2009; 60: 693 –716.
47. Amodio DM, Frith CD. Meeting of minds: The medial frontal cortex
and social cognition. Nat. Rev. Neurosci. 2006; 7: 268 –277.
48. Meyer M, Lieberman M. Social working memory: Neurocognitive net-
works and directions for future research. Front. Psychol. 2012; 3:1–11.
49. Meyer M, Spunt R, Berkman E, Taylor S, Lieberman M. Evidence for
social working memory from a parametric functional MRI study. Proc.
Natl. Acad. Sci. U. S. A. 2012; 109: 1883 –1888.
50. Meyer M, Taylor S, Lieberman M. Social working memory and its dis-
tinctive link to social cognitive ability: An fMRI study. Soc. Cogn.
Affect. Neurosci. 2015; 10: nsv065.
51. Parr T, Friston K. Working memory, attention, and salience in active
inference. Sci. Rep. 2017; 7: 14678.
52. Feldman H, Friston K. Attention, uncertainty, and free-energy. Front.
Hum. Neurosci. 2010; 4: 215.
53. Parr T, Friston K. Uncertainty, epistemics and active inference. J. R.
Soc. Interface 2017; 14: 20170376.
54. Mirza MB, Adams RA, Friston K, Parr T. Introducing a Bayesian
model of selective attention based on active inference. Sci. Rep. 2019;
9: 13915.55. Parr T, Friston KJ. Attention or salience? Curr. Opin. Psychol. 2019;
29:1–5.
56. Parr T, Rikhye RV, Halassa MM, Friston KJ. Prefrontal computation as
active inference. Cereb. Cortex 2020; 30: 682 –695.
57. Chekroud AM. Unifying treatments for depression: An application of
the free energy principle. Front. Psychol. 2015; 6: 153.
58. Kube T, Schwarting R, Rozenkrantz L, Glombiewski JA, Rief W. Dis-
torted cognitive processes in major depression: A predictive processingperspective. Biol. Psychiatry 2020; 87: 388 –398.
59. Slavich G, Irwin M. From stress to in ﬂammation and major depressive
disorder: A social signal transduction theory of depression. Psychol.
Bull. 2014; 140: 774 –815.
60. Smith R, Alkozei A, Killgore WDS, Lane RD. Nested positive feed-
back loops in the maintenance of major depression: An integration and
extension of previous models. Brain Behav. Immun. 2018; 67: 374 –397.
61. Haker H, Schneebeli M, Stephan K. Can Bayesian theories of autism
spectrum disorder help improve clinical practice? Front. Psych. 2016;
7: 107.
62. Lawson R, Rees G, Friston K. An aberrant precision account of autism.
Front. Hum. Neurosci. 2014; 8: 302.
63. Van de Cruys S, Evers K, Van der Hallen R et al. Precise minds in
uncertain worlds: Predictive coding in autism. Psychol. Rev. 2014; 121:
649 –675.
64. Corlett PR, Horga G, Fletcher PC, Alderson-Day B, Schmack K,
Powers AR 3rd. Hallucinations and strong priors. Trends Cogn. Sci.
2019; 23: 114 –127.
65. Adams RA, Stephan KE, Brown HR, Frith CD, Friston KJ. The compu-
tational anatomy of psychosis. Front. Psych. 2013;
4: 47.
66. Stephan K, Manjaly Z, Mathys C et al. Allostatic self-ef ﬁcacy: A meta-
cognitive theory of dyshomeostasis-induced fatigue and depression.
Front. Hum. Neurosci. 2016; 10: 550.
67. Lane RD, Weihs KL, Herring A, Hishaw A, Smith R. Affective agno-
sia: Expansion of the alexithymia construct and a new opportunity tointegrate and extend Freud ’s legacy. Neurosci. Biobehav. Rev. 2015; 55:
594 –611.
68. Smith R, Kaszniak AW, Katsanis J, Lane RD, Nielsen L. The impor-
tance of identifying underlying process abnormalities in alexithymia:Implications of the three-process model and a single case study illustra-
tion. Conscious. Cogn. 2019; 68:3 3 –46.
69. Burger A, Lumley M, Carty J et al. The effects of a novel psychological
attribution and emotional awareness and expression therapy for chronicmusculoskeletal pain: A preliminary, uncontrolled trial. J. Psychosomat.
Res. 2016; 81:1–8.
70. Thakur E, Holmes H, Lockhart N et al . Emotional awareness and
expression training improves irritable bowel syndrome: A randomizedcontrolled trial. Neurogastroenterol. Motil. 2017; 29: e13143.
71. Ferry AL, Hespos SJ, Waxman SR. Categorization in 3- and 4-month-
old infants: An advantage of words over tones. Child Dev. 2010; 81:
472 –479.
72. Widen S, Russell J. Children acquire emotion categories gradually.
Cogn. Develop. 2008; 23: 291 –312.
73. Gergely G, Watson J. The social biofeedback theory of parental affect-
mirroring: The development of emotional self-awareness and self-control in infancy. Int. J. Psychoanal. 1996; 77: 1181 –1212.
74. Smith R, Schwartenbeck P, Parr T, Friston KJ. An active inference
approach to modeling concept learning. bioRxiv . 13 April 2020. s
75. Smith R, Alkozei A, Bao J, Smith C, Lane RD, Killgore WDS. Resting
state functional connectivity correlates of emotional awareness.
NeuroImage 2017; 159:9 9 –106.
76. Smith R, Alkozei A, Lane RD, Killgore WDS. Unwanted reminders:
The effects of emotional memory suppression on subsequent neuro-cognitive processing. Conscious. Cogn. 2016; 44: 103 –113.
77. Smith R, Bajaj S, Dailey NS et al. Greater cortical thickness within the
limbic visceromotor network predicts higher levels of trait emotionalawareness. Conscious. Cogn. 2018;
57:5 4 –61.
78. Smith R, Braden BB, Chen K, Ponce FA, Lane RD, Baxter LC. The
neural basis of attaining conscious awareness of sad mood. Brain Imag.
Behav. 2015; 9: 574 –587.
79. Smith R, Fass H, Lane RD. Role of medial prefrontal cortex in rep-
resenting one ’s own subjective emotional responses: A preliminary
study. Conscious. Cogn. 2014; 29: 117 –130.
80. Smith R, Lane RD, Alkozei A et al. The role of medial prefrontal cor-
tex in the working memory maintenance of one ’s own emotional
responses. Sci. Rep. 2018; 8: 3460.
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 12The predictive brain in psychiatry PCNPsychiatry and
Clinical Neurosciences
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License

81. Smith R, Lane RD, Alkozei A et al. Maintaining the feelings of others
in working memory is associated with activation of the left anterior
insula and left frontal-parietal control network. Soc. Cogn. Affect. Neu-
rosci. 2017; 12: 848 –860.
82. Smith R, Lane RD, Sanova A, Alkozei A, Smith C, Killgore WDS.
Common and unique neural systems underlying the working memory
maintenance of emotional vs. bodily reactions to affective stimuli: The
moderating role of trait emotional awareness. Front. Hum. Neurosci.
2018; 12: 370.
83. Smith R, Sanova A, Alkozei A, Lane RD, Killgore WDS. Higher levels
of trait emotional awareness are associated with more ef ﬁcient global
information integration throughout the brain: A graph-theoretic analysisof resting state functional connectivity. Soc. Cogn. Affect. Neurosci.
2018; 13: 665 –675.
84. Mueller J, Alpers GW. Two facets of being bothered by bodily sensa-
tions: Anxiety sensitivity and alexithymia in psychosomatic patients.Compr. Psychiatry 2006; 47: 489 –495.
85. Colvert E, Rutter M, Kreppner J et al. Do theory of mind and executive
function de ﬁcits underlie the adverse outcomes associated with pro-
found early deprivation? Findings from the English and Romanianadoptees study. J. Abnorm. Child Psychol. 2008; 36: 1057 –1068.
86. Fries AB, Pollak SD. Emotion understanding in postinstitutionalized
eastern European children. Dev. Psychopathol. 2004; 16: 355 –369.
87. Barrett L, Gross J, Christensen T, Benvenuto M. Knowing what you ’re
feeling and knowing what to do about it: Mapping the relation betweenemotion differentiation and emotion regulation. Cognit. Emot. 2001; 15:
713 –724.
88. Kashdan T, Barrett L, McKnight P. Unpacking emotion differentiation:
Transforming unpleasant experience by perceiving distinctions in nega-tivity. Curr. Dir. Psychol. Sci. 2015; 24:1 0 –16.
89. Lane RD, Anderson FS, Smith R. Biased competition favoring physical
over emotional pain: A possible explanation for the link between earlyadversity and chronic pain. Psychosom. Med. 2018; 80: 880 –890.
90. Smith R, Steklis HD, Steklis NG, Weihs KL, Lane RD. The evolution
and development of the uniquely human capacity for emotional aware-
ness: A synthesis of comparative anatomical, cognitive, neuro-computational, and evolutionary psychological perspectives. Biol.
Psychol. 2020; 154: 107925.
91. Hayes S, Strosahl K, Wilson K. Acceptance and Commitment Therapy:
An Experiential Approach to Behavior Change . Guilford Press,
New York, NY, 2003.
92. Segal Z, Teasdale J, Williams J. Mindfulness-based cognitive therapy:
Theoretical rationale and empirical status.
In:Hayes S, Follette V,
Linehan M (eds). Mindfulness and Acceptance: Expanding the
Cognitive-Behavioral Tradition . Guilford Press, New York, NY,
2004; 45 –65.
93. Greenberg L. Emotion-Focused Therapy: Theory and Practice . Ameri-
can Psychological Association, Washington, DC, 2010.
94. Barlow D, Allen L, Choate M. Toward a uni ﬁed treatment for emo-
tional disorders –Republished article. Behav. Ther. 2016; 47: 838 –853.
95. Smith R, Khalsa SS, Paulus MP. An active inference approach to dis-
secting reasons for nonadherence to antidepressants. Biol. Psychiatry
Cogn. Neurosci. Neuroimaging 2019. https://doi.org/10.1016/j.bpsc.
2019.11.01296. Smith R, Moutoussis M, Bilek E. Simulating the computational mecha-
nisms of cognitive and behavioral psychotherapeutic interventions:
Insights from active inference. PsyArXiv . 4 July 2020. https://psyarxiv.
com/8m62p/
97. Yamashita Y, Tani J. Spontaneous prediction error generation in
schizophrenia. PLoS One 2012; 7: e37843.
98. Idei H, Murata S, Chen Y, Yamashita Y, Tani J, Ogata TA. Neu-
rorobotics simulation of autistic behavior induced by unusual sensoryprecision. Comput. Psychiat. 2018; 2: 164 –182.
99. Idei H, Murata S, Yamashita Y, Ogata T. Homogeneous intrinsic neuro-
nal excitability induces over ﬁtting to sensory noise: A robot model of
neurodevelopmental disorder. PsyArXiv . 2 June 2020. https://psyarxiv.
com/ah89z/
100. Friston KJ. Precision psychiatry. Biol. Psychiat. Cogn. Neurosci. Neuro-
imaging 2017; 2: 640 –643.
101. Mathys CD, Lomakina EI, Daunizeau J et al. Uncertainty in perception
and the hierarchical Gaussian ﬁlter.Front. Hum. Neurosci. 2014; 8: 825.
102. Diaconescu AO, Mathys C, Weber LAE, Kasper L, Mauer J,
Stephan KE. Hierarchical prediction errors in midbrain and septum dur-
ing social learning. Soc. Cogn. Affect. Neurosci. 2017; 12: 618 –634.
103. Iglesias S, Mathys C, Brodersen KH et al. Hierarchical prediction errors
in midbrain and basal forebrain during sensory learning. Neuron 2013;
80: 519 –530.
104. Deserno L, Boehme R, Mathys C et al . Volatility estimates increase
choice switching and relate to prefrontal activity in schizophrenia. Biol.
Psychiatry Cogn. Neurosci. Neuroimaging 2020; 5: 173 –183.
105. Cole DM, Diaconescu AO, Pfeiffer UJ et al . Atypical processing of
uncertainty in individuals at risk for psychosis. Neuroimage Clin. 2020;
26: 102239.
106. Powers AR, Mathys C, Corlett PR. Pavlovian conditioning-induced hal-
lucinations result from overweighting of perceptual priors. Science
2017; 357: 596 –600.
107. Adams R, Perrinet L, Friston K. Smooth pursuit and visual occlusion:
Active inference and oculomotor control in schizophrenia. PLoS ONE
2012; 7: e47502.
108. Lawson R, Mathys C, Rees G. Adults with autism overestimate the vol-
atility of the sensory environment. Nat. Neurosci. 2017; 20: 1293 –1299.
109. Smith R, Schwartenbeck P, Stewart JL et al. Imprecise action selection
in substance use disorder: Evidence for active learning impairments
when solving the explore-exploit dilemma. Drug Alcohol Depend.
2020; 215: 108208.
110. Smith R, Kirlic N, Touthang J et al. Greater decision uncertainty char-
acterizes a transdiagnostic patient sample during approach-avoidance
conﬂict: A computational modeling approach. J. Psychiatry Neurosci.
2020. https://doi.org/10.31234/osf.io/t2dhn
111. Smith R, Kuplicki R, Feinstein J, Forthman KL, Stewart JL,
Paulus MP, et al. An active inference model reveals a failure to adapt
interoceptive precision estimates across depression, anxiety, eating, andsubstance use disorders. medRxiv . 2020. https://doi.org/10.1101/2020.
06.03.20121343
112. Smith R, Kuplicki R, Teed A, Upshaw V, Khalsa SS. Con ﬁrmatory evi-
dence that healthy individuals can adaptively adjust prior expectationsand interoceptive precision estimates. bioRxiv . 2020. https://doi.org/10.
1101/2020.08.31.275594
Psychiatry and Clinical Neurosciences 75: 3 –13, 2021 13PCNPsychiatry and
Clinical Neurosciences The predictive brain in psychiatry
 14401819, 2021, 1, Downloaded from https://onlinelibrary.wiley.com/doi/10.1111/pcn.13138, Wiley Online Library on [09/03/2023]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License