Behavioral/Cognitive
Bottom-Up and Top-Down Factors Differentially Influence
Stimulus Representations Across Large-Scale AttentionalNetworks
X
Nicole M. Long and X
Brice A. Kuhl
Department of Psychology, University of Oregon, Eugene, Oregon 97402
Visual attention is thought to be supported by three large-scale frontoparietal networks: the frontoparietal control network (FPCN), the
dorsal attention network (DAN), and the ventral attention network (VAN). The traditional view is that these networks support visualattention by biasing and evaluating sensory representations in visual cortical regions. However, recent evidence suggests that frontopa-rietal regions actively represent perceptual stimuli. Here, we assessed how perceptual stimuli are represented across large-scale fronto-parietal and visual networks. Specifically, we tested whether representations of stimulus features across these networks are differentiallysensitive to bottom-up and top-down factors. In a pair of pattern-based fMRI studies, male and female human subjects made perceptualdecisions about face images that varied along two independent dimensions: gender and affect. Across studies, we interrupted bottom-upvisual input using backward masks. Within studies, we manipulated which stimulus features were goal relevant (i.e., whether gender oraffect was relevant) and task switching (i.e., whether the goal on the current trial matched the goal on the prior trial). We found thatstimulus features could be reliably decoded from all four networks and, importantly, that subregions within each attentional networkmaintained coherent representations. Critically, the different attentional manipulations (interruption, goal relevance, and task switch-ing) differentially influenced feature representations across networks. Whereas visual interruption had a relatively greater influence onrepresentations in visual regions, goal relevance and task switching had a relatively greater influence on representations in frontoparietalnetworks. Therefore, large-scale brain networks can be dissociated according to how attention influences the feature representations thatthey maintain.
Key words: attention; cognitive control; decoding; parietal cortex; prefrontal cortex; resting-state networks
Introduction
Visual attention is thought to be supported by several frontopa-
rietal networks ( Posner and Petersen, 1990 ;Corbetta and Shul-man, 2002 ;Dosenbach et al., 2008 ). The idea that the brain is
comprised of multiple functional networks has been inspired andelaborated by resting-state analyses of human fMRI data (
Yeo et
al., 2011 ), which reveal three networks of particular importance
to attentional control: the frontoparietal control network(FPCN), the dorsal attention network (DAN), and the ventral
Received Sept. 20, 2017; revised Jan. 18, 2018; accepted Jan. 24, 2018.
Author contributions: N.M.L. and B.A.K. designed research; N.M.L. performed research; N.M.L. analyzed data;
N.M.L. and B.A.K. wrote the paper.
This work was supported by the Lewis Family Endowment to the University of Oregon, which supports the Robert
and Beverly Lewis Center for NeuroImaging and by the National Institute of Neurological Disorders and Stroke–National Institutes of Health (Grant 1RO1NS089729 to B.A.K.). We thank Rosalie Samide and Sarah Sweigart forassistance with data collection.
The authors declare no competing financial interests.Correspondence should be addressed to either Nicole Long or Brice Kuhl, Department of Psychology, 1227 Uni-
versity of Oregon Eugene, OR 97403. E-mail:
niclong@uoregon.edu orbkuhl@uoregon.edu .
DOI:10.1523/JNEUROSCI.2724-17.2018
Copyright © 2018 the authors 0270-6474/18/382495-10$15.00/0Significance Statement
Visual attention is supported by multiple frontoparietal attentional networks. However, it remains unclear how stimulus features
are represented within these networks and how they are influenced by attention. Here, we assessed feature representations in fourlarge-scale networks using a perceptual decision-making paradigm in which we manipulated top-down and bottom-up factors.We found that top-down manipulations such as goal relevance and task switching modulated feature representations in atten-tional networks, whereas bottom-up manipulations such as interruption of visual processing had a relatively stronger influence onfeature representations in visual regions. Together, these findings indicate that attentional networks actively represent stimulusfeatures and that representations within different large-scale networks are influenced by different forms of attention.The Journal of Neuroscience, March 7, 2018 •38(10):2495–2504 • 2495

attention network (VAN). Traditionally, these networks have
been thought to support visual attention by biasing and evaluat-ing sensory representations within visual cortical areas (
Desi-
mone and Duncan, 1995 ;Egner and Hirsch, 2005 ;Serences and
Yantis, 2006 ;Gazzaley and Nobre, 2012 ). However, recent evi-
dence from pattern-based fMRI studies has blurred the distinc-tion between sensory representations in visual cortical areas andcontrol processes in frontoparietal regions. Namely, there is ac-cumulating evidence that frontoparietal regions actively repre-sent stimulus features during visual attention and workingmemory (
Ester et al., 2015 ;Lee and Kuhl, 2016 ;Xu, 2017 ). These
findings suggest a potentially transformative approach for under-standing the functional role of frontoparietal networks in visualattention: that frontoparietal networks can be characterized –and dissociated from visual cortical regions – in terms of howthey represent stimuli in relation to bottom-up and top-downfactors.
Attention manipulations that may dissociate stimulus repre-
sentations in frontal and parietal cortices from those in visualcortex include robustness to interruption of visual processing,goal relevance, and task switching. For example, working mem-ory representations in the intraparietal sulcus (
Bettencourt and
Xu, 2016 ) and prefrontal cortex ( Miller et al., 1996 ) are more
robust to distraction than are representations in visual corticalareas. Likewise, multiple frontal and parietal regions preferen-tially represent goal-relevant stimulus information, as shown viaelectrophysiological recordings in monkeys (
Rainer et al., 1998 ;
Swaminathan and Freedman, 2012 ;Roy et al., 2014 ;Sarma et al.,
2016 ) and pattern-based fMRI in humans ( Kuhl et al., 2013 ;
Sreenivasan et al., 2014 ;Ester et al., 2015 ;Bracci et al., 2017 ).
Finally, dorsal frontal and parietal regions show increased uni-variate activation on trials when goals change (task switching)(
Braver et al., 2003 ;Monsell, 2003 ;Yeung et al., 2006 ;Ravizza and
Carter, 2008 ;Bode and Haynes, 2009 ;Esterman et al., 2009 ).
Collectively, these findings suggest that different forms of atten-tion potentially differentiate stimulus representations acrossfrontoparietal and visual regions. However, there has been lim-ited application of “representation-based” analyses to large-scalenetworks. Do frontoparietal networks actively and coherentlyrepresent stimulus information? Are representations in differentnetworks influenced by different forms of attention?
Here, we conducted a pair of pattern-based fMRI studies to
determine how various attention-related manipulations (inter-ruption of visual processing, goal relevance, and task switching)influence feature representations in frontoparietal attentionalnetworks (FPCN, DAN, and VAN) and, as a comparison, withina network of visual regions (VisN). In both studies, subjectsviewed faces that varied along two independent dimensions: gen-der (male vs female) and affect (happy vs grumpy). On each trial,subjects made a perceptual decision related to a cued face feature(e.g., “Male?”). Using pattern classification analyses, we firsttested for representation of stimulus features within each net-work and, importantly, tested whether frontoparietal regionswithin a common network maintained “coherent” representa-tions. Next, we determined how each attention manipulationinfluenced feature representations across networks. Visual inter-ruption was manipulated across studies: in Study 1, stimuli werefollowed by a visual mask; in Study 2, there was a longer stimulusduration and no mask. Goal relevance was manipulated by vary-ing the dimension (gender/affect) that was currently relevant.Finally, task switching was manipulated by alternating betweengoals on a trial-by-trial manner, resulting in trials in which goalsrepeated (stay trials) and trials in which goals changed (switchtrials). We predicted that frontoparietal networks would ac-
tively and coherently represent stimulus features and thatfrontoparietal representations would be relatively more sensitive
to top-down manipulations (goals, task switching), whereas rep-resentations in VisN would be relatively more sensitive tobottom-up manipulations (interruption).
Materials and Methods
Subjects
Thirty-two (19 female; mean age /H1100522 years) right-handed, native Eng-
lish speakers from the University of Oregon community participated inthe fMRI studies. Sixteen subjects participated in Experiment 1 and 16participated in Experiment 2. Four total subjects were excluded. In Ex-periment 1, one subject was excluded for poor task performance (65%accuracy, which was /H110224 SDs away from the average performance of 95%)
and one was excluded for excessive head motion. In Experiment 2, twosubjects were excluded for exiting the scanner before task completion(one subject complained of nausea and the other began coughing repeat-edly; each missing two of six runs). Therefore, for each experiment, therewas a final set of 14 subjects included for analyses. All subjects had nor-mal or corrected-to-normal vision. Informed consent was obtained inaccordance with the University of Oregon Institutional Review Board.The raw, de-identified data and the associated experimental and analysiscodes used in this study can be accessed via the Kuhl laboratory website(
http://kuhllab.com/publications/ ).
An additional 14 (5 female; mean age /H1100519) right-handed, native
English speakers from the University of Oregon community participatedin a follow-up behavioral study. All subjects had normal or corrected-to-normal vision. Informed consent was obtained in accordance with theUniversity of Oregon Institutional Review Board and subjects receivedcourse credit for participating.
Materials
Stimuli consisted of 88 face images drawn from various internet sources.From this pool, 16 faces were designated as “target” faces, 24 as “filler”faces, and 48 as “localizer” faces. Within each set (target, filler, localizer)gender and affect were balanced: 1/4 of the faces were “happy, males”; 1/4were “happy, females”; 1/4 were “grumpy, males”; and 1/4 were“grumpy, females.” Gender and affect were determined, with unanimousagreement, by two independent raters.
Experimental design and statistical analysis
Procedure and design . Each trial began with the presentation of one of
four “goal cues” or questions: “Male?,” “Female?,” “Happy?,” or“Grumpy?” The goal was presented for 1400 ms (
Fig. 1 A) and was im-
mediately followed by a face stimulus. In Experiment 1, the face waspresented for 100 ms and immediately followed by a visual mask com-posed of scrambled face parts for 500 ms. In Experiment 2, the face waspresented for 600 ms with no mask. After the mask (Experiment 1) orface (Experiment 2), there wa sa6s interstimulus interval (ISI) during
which a fixation cross was shown. On each trial, the subject’s task was torespond “Yes” or “No” via button box as to whether the face matched thegoal/question. Subjects could respond at any point after the onset of theface, including during the ISI.
Trials were organized into blocks. Each block contained 17 trials, with
the first trial in each block representing a “filler” face. The designation ofthe first trial as a filler face was particularly important for analyses of“stay” versus “switch” trials because the first trial cannot be designated aseither a stay or switch trial (see below). The stimuli for the remaining 16trials in each block were target faces. Each of the 16 target faces appearedexactly once per block. Within each block, only two of the four goalswere presented (either “Male?” or “Female?” or either “Happy?” or“Grumpy?”). The goals alternated in an A-A-B-B-A-A-B-B manner (
Fig.
1C). Therefore, there was a constant alternation between switch trials
(goal change) and stay trials (goal repeat) .A3sg e t ready screen at the
start of each block informed subjects which two goals would occur withinthat block.
Each of the six scan runs contained four blocks. The four blocks in each
run comprised each of the four possible combinations of goals (Male/2496 •J. Neurosci., March 7, 2018 •38(10):2495–2504 Long and Kuhl •Stimulus Features in Attentional Networks

Grumpy, Female/Grumpy, Male/Happy, and Female/Happy). Block or-
der was randomized across runs and across subjects. The order of the 16target faces was also randomized in each block. Across the six scan runs,there was a grand total of 408 trials (including filler trials). To familiarizesubjects with the task, before entering the scanner, subjects completed a24-trial practice round. Subjects practiced each goal combination (e.g.,“Male?/Happy?”) and the stimuli used were the 24 filler faces.
After the main experiment, subjects completed two localizer runs.
However, because data from the localizer scan are not reported here,details of the task are not included.
The design of the behavioral follow-up study was identical to Experi-
ment 1, with the exception of the ISI (3 s instead of 6 s) and the inclusionof a post-task questionnaire, in which subjects were asked increasinglyspecific questions as to whether they noticed the task switching structure.We first asked subjects if they noticed any patterns throughout the task.We then noted that there was a pattern to the goal cues and asked if theywere aware of such a pattern. Finally, we explicitly asked subjects if theynoticed the A-A-B-B-A-A-B-B structure of the goal cues.
fMRI data acquisition
Imaging data were collected on a Siemen s 3 T Skyra scanner at the Robert
and Beverly Lewis Center for NeuroImaging at the University of Oregon.Before the functional imaging, a whole-brain high-resolution anatomicalimage was collected for each subject using a T1-weighted protocol (gridsize 256 /H11003256; 176 sagittal slices; voxel size 1 /H110031/H110031 mm). Whole-brain
functional images were collected using a T2*-weighted multiband accel-erated EPI sequence (TR /H110052s ;T E /H1100525 ms; flip angle /H1100590°; 72 hori-
zontal slices; grid size 104 /H11003104; voxel size 2 /H110032/H110032 mm). For the main
experiment, six functional scans were collected, each consisting of 280volumes. For the localizer task, two functional scans were collected eachconsisting of 225 volumes.fMRI data preprocessing
Preprocessing of the functional data was conducted using FSL 5.0
(FMRIB Software Library, http://www.fmrib.ox.ac.uk/fsl ;Smith et al.,
2004 ) and custom scripts. Images were first corrected for head motion
using MCFLIRT ( Jenkinson et al., 2002 ). Motion-corrected images were
smoothed with a Gaussian kernel with 1.7 mm SD ( /H110114 mm FWHM).
Network selection
We assessed feature representations in four resting-state networks de-
fined from a large, independent sample of subjects ( Yeo et al., 2011 ): the
FPCN, DAN, VAN, and VisN ( Fig. 1 D). The resting-state networks were
generated for each subject using their high-resolution anatomical imageand the FreeSurfer cortical parcellation scheme (
http://surfer.nmr.mgh.
harvard.edu ). The networks were then coregistered to the functional
data.
Univariate analyses
Univariate data analyses were conducted under the assumptions of thegeneral linear model (GLM) using SPM12 (
http://www.fil.ion.ucl.ac.uk/
spm). To test for univariate effects of switch versus stay trials, we defined
a model with separate regressors for switch and stay trials. The model alsoincluded regressors for scan run and six motion parameters for each run.Switch versus stay trials were contrasted using paired-samples ttests
resulting in subject-specific statistical parametric maps. These tvalues
were then averaged within network, resulting in a single mean tstatistic
per network and subject. For each network, one-sample ttests were then
applied across subjects to test for effects of switch versus stay trials at thegroup level.
Pattern classification analyses
For pattern classification analyses, functional data were detrended, high-pass filtered (0.01 Hz), and z-scored within scan (mean response of each
Figure 1. Experimental design. A, In a given trial, a goal cue was presented for 1400 ms. There were one of four possible goal cues (“Male?,” “Female?,” “Happy?,” or “Grumpy?”). After th e goal,
a face was presented for 100 ms. In Experiment 1, the face was followed by a mask image for 500 ms. In Experiment 2, the face was presented for an additional 500 ms. A fixation cross was then
presented for 6000 ms. Subjects responded “Yes” or “No” as to whether the face matched the goal. B, Faces varied along two dimensions: gender and affect. Note that faces shown here were not
those used in the experiment. Permission was given for these faces to be published. C, Each block followed the same general structure. At the start of each block, subjects were cued as to which goals
would be relevant for that block. Only two goals were relevant in each block (one from each dimension) and these goals alternated in a fixed AABBAABB sch edule. This enforced a constant alternation
between switch and stay trials. D, Four independently defined resting-state networks of a priori interest ( Yeo et al., 2011 ).Long and Kuhl •Stimulus Features in Attentional Networks J. Neurosci., March 7, 2018 •38(10):2495–2504 • 2497

voxel within each scan /H110050). Next, data were temporally compressed via
a weighted averaged of TRs 3, 4, and 5 (40%, 40%, 20%, respectively)relative to trial onset (representing 4–10 s after the goal was presented).TRs 3 and 4 were given greater weight because the hemodynamic re-sponse tends to peak at these TRs. The temporally compressed data re-sulted in a single spatial pattern of activity for each trial. Before patternclassification analyses were performed, an additional round of z-scoring
was applied across voxels to the trial-specific spatial patterns. This finalround of z-scoring resulted in each trial-specific spatial volume having a
mean activation equal to 0. Therefore, mean univariate activity wasmatched precisely across all conditions and trial types (
Kuhl and Chun,
2014 ;Long et al., 2016 ). Pattern classification analyses were performed
using penalized (L2) logistic regression (penalty parameter /H110051) imple-
mented via the Liblinear toolbox ( Fan et al., 2008 ) and custom MATLAB
(RRID:SCR 001622) code. Classifier performance was assessed in twoways. “Classification accuracy” represented a binary coding of whetherthe classifier successfully guessed the queried feature of the face. We used
classification accuracy for general assessment of classifier performance(i.e., whether features could be decoded). “Classifier evidence” was acontinuous value reflecting the logit-transformed probability that theclassifier assigned the correct feature each trial. Classifier evidence wasused as a trial-specific, continuous measure of feature information,which was used to assess trial-level correlations in feature representationswithin and between networks (see below).
For each subject, four separate classifiers were trained to decode stim-
ulus features. A given classifier was trained to discriminate either malefrom female faces (gender classifier) or happy from grumpy faces (affectclassifier). Additionally, separate gender classifiers were applied for trialsin which the goal was either “Male?” or “Female?” (i.e., trials in whichgender was relevant) versus trials in which the goal was either “Happy?”or “Grumpy?” (i.e., trials in which affect was relevant). Likewise, separateaffect classifiers were applied for trials in which affect was the relevantdimension versus trials in which gender was the relevant dimension.Goal-relevant feature representations were indexed by performance ofthe gender classifier on gender-relevant trials and performance of theaffect classifier on affect-relevant trials. Goal-irrelevant feature represen-tations were indexed by performance of the gender classifier on affect-relevant trials and performance of the affect classifier on gender-relevanttrials. All classification analyses were performed using leave-one-run-outcross-validation. A critical element of our design and implementation ofclassification analyses is that we deliberately orthogonalized feature in-formation from behavioral responses. In other words, there was no con-sistent mapping between feature information and motor response. As anexample, during trials in which gender was relevant, 50% of the time, afemale face would require a “Yes” response (i.e., on “Female?” trials) and,50% of the time, a female face would require a “No” response (i.e., on“Male?” trials). Therefore, successful decoding of goal-relevant featureinformation cannot be attributed to decoding of the planned or executedmotor responses. A second critical element of our design is that, acrosstrials, goals and features were not always matched. In fact, they wereindependent. That is, when presented with a goal cue of “Male?,” thesubsequently presented stimulus was equally likely to be a male or femaleface. This design feature critically allowed us to deconfound goal andfeature information. In other words, decoding of stimulus features can-not be driven exclusively by goal information.
To decode top-down goals, an additional four classifiers were applied.
The four classifiers corresponded to the four different possible combina-tions of goals in a given block: “Male?” versus “Grumpy?,” “Male?” versus
“Happy?,” “Female?” versus “Grumpy?,” and “Female?” versus “Happy?”
Classification was performed using leave-one-run-out cross-validation.Classification accuracy was averaged across all four classifiers to providea single measure of goal decoding accuracy. Because goal decoding couldpotentially be driven by low-level information such as visual word formor subvocal articulation, we also tested whether goal classifiers general-ized to different goals corresponding to the same dimensions. For exam-ple, a classifier trained to discriminate between “Male?” versus “Happy?”faces can also be thought of as a classifier that is discriminating betweenthe gender versus affect dimensions. If so, then a classifier trained on“Male?” versus “Happy?” may successfully transfer to the discriminationof “Female?” versus “Grumpy?” Successful transfer would suggest that
the goal representation is, at least in part, a representation of the relevantdimension as opposed to the specific word cue per se. Therefore, for eachof the four goal classifiers described above, we tested for transfer to the“complementary” pair of goals; i.e., goal pairs that corresponded to dis-crimination between the same dimensions. This dimension decodinganalysis was again performed using leave-one-run-out cross-validationso as to match the goal decoding analyses in terms of statistical power.Classification accuracy was averaged across all four transfer tests to pro-vide a single aggregate value of dimension decoding accuracy.
Representational coherence analysis
To assess the coherence of representations within and between networks,we decomposed each of the three attentional networks into separatefrontal and parietal ROIs: frontal-FPCN, parietal-FPCN, frontal-DAN,parietal-DAN, frontal-VAN, and parietal-VAN. None of the voxels fromthe frontal ROIs were contiguous with voxels from the parietal ROIs.These ROIs were generated using the average subject brain in Free Surfer.The ROIs were then projected from this volume space to surface spaceand then converted from average surface space to subject space. Becausethe number of voxels in these regions varied both within and acrosssubjects and differences in ROI size are likely to influence classifier per-formance, classification analyses were performed by randomly subsam-pling 500 voxels from each of the six frontal and parietal ROIs. Thisprocess was repeated for 100 iterations for each ROI and subject, witheach iteration involving a different random sample of 500 voxels. Classi-fication of goal-relevant and goal-irrelevant features was performed us-ing the same approach described above. Here, however, classifierevidence (a continuous value reflecting the strength of classifier informa-tion) was the critical dependent measure. For each subject, trial-by-trialmeasures of classifier evidence were correlated within network (e.g., acorrelation between classifier evidence from frontal-FPCN and parietal-FPCN) and between network (e.g., frontal-FPCN and parietal-DAN).The correlation analyses were separately performed for relevant and ir-relevant feature evidence. In total, we obtained 50,400
/H9267values: 100 iter-
ations/H110039 correlations /H1100328 subjects /H110032 relevance conditions. All /H9267
values were Fisher- ztransformed before averaging across iterations and
goal relevance. Finally, z-/H9267values were averaged across the three “within”
network correlations (e.g., correlations between frontal-FPCN andparietal-FPCN) and the six “between” network correlations (e.g., corre-lations between frontal-FPCN and parietal-DAN), resulting in two z-
/H9267
values for each subject, mean within network correlation, and mean
between network correlation.
Statistical analyses
One-sample ttests were used to compare representational coherence
measures ( z-/H9267values) to zero. Paired-sample ttests were used to compare
classification accuracy across subjects to chance decoding accuracy, asdetermined by permutation procedures. Namely, for each subject andnetwork, we shuffled the condition labels of interest (e.g., “male” and“female” for the gender feature classifier) and then calculated classifica-tion accuracy. We repeated this procedure 1000 times for each networkand subject and then averaged the 1000 shuffled accuracy values for eachnetwork and subject. These mean values were used as network- andsubject-specific empirically derived measures of chance accuracy. Pairedsamples ttests compared the true (unshuffled) accuracy values to the
shuffled accuracy values. For these paired-sample ttests, we report un-
corrected p-values; however, all of the p-values exceeded the threshold
for significance after Bonferroni correction; that is, after adjusting for thefact that we tested effects across four networks (i.e., a threshold of p/H11005
0.0125). Mixed-effects ANOVAs were used to compare conditionsand/or networks; experiment was always included as a factor when datafrom both experiments were included.
Results
Large-scale networks represent stimulus features
Motivated by recent evidence that activity patterns in frontopa-rietal regions represent stimulus features (
Swaminathan and
Freedman, 2012 ;Ester et al., 2015 ;Lee and Kuhl, 2016 ;Bracci et2498 •J. Neurosci., March 7, 2018 •38(10):2495–2504 Long and Kuhl •Stimulus Features in Attentional Networks

al., 2017 ), we first tested for representations of face features (gen-
der, affect) within each of the three attentional networks (FPCN,DAN, VAN) and, for comparison, within VisN. Importantly, andas described in the Materials and Methods, our procedure delib-erately deconfounded feature information from behavioral re-sponses, so decoding accuracy cannot be explained by decodingof response preparation or execution. Averaging across the gen-der and affect classifiers (producing a single value per subjectreflecting feature decoding), accuracy was above chance in eachof the four networks (FPCN, t
(27)/H110055.82, p/H110210.001; DAN, t(27)/H11005
5.37, p/H110210.001; VAN, t(27)/H110055.42, p/H110210.001; VisN, t(27)/H110054.34,
p/H110210.001; Figure 2 A), confirming the sensitivity of these large-
scale networks to feature information. There were no significantdifferences in decoding accuracy for the gender versus affect clas-sifiers for any of the four networks ( t/H110211,p/H110220.35). A mixed-
effects ANOVA with factors of network (FPCN, DAN, VAN,VisN) and experiment (1, 2) did not reveal a main effect of net-work ( F
(3,78)/H110050.49, p/H110050.69), indicating that overall feature
decoding was comparable across networks. The effects of exper-
iment are considered below.
Representational coherence within networks
The preceding results demonstrate that activity patterns inresting-state networks represent stimulus features. However, theuse of large-scale networks as ROIs is predicated on the notionthat individual components (brain regions) within these net-works are acting together in a functionally relevant way to sup-port behavior. To test for coherence of representations within theattentional networks, we divided each of the three attentionalnetworks into frontal and parietal subregions (see Materials andMethods and ROIs from a sample subject in
Fig. 2 B) and corre-
lated trial-by-trial feature evidence within and between each net-work (
Fig. 2 C). Correlations were significantly /H110220 both within
networks (M /H110050.15, SD /H110050.03; t(27)/H1100524.7, p/H110210.001) and
between networks (M /H110050.14, SD /H110050.03; t(27)/H1100527.4, p/H110210.001;
Fig. 2 D) .A2/H110032 mixed-effects ANOVA with factors of network
pairing (within, between) and experiment (1, 2) revealed a maineffect of network pairing ( F
(1,26)/H1100523.9, p/H110210.001), with stronger
correlations within networks than between networks. This
main effect of network pairing did not interact with experi-ment ( F
(1,26)/H110050.03, p/H110050.86). Therefore, although feature rep -
resentations were present across all of the attentional networks,there was greater representational coherence within networksthan between networks, validating the use of these networks aslarge-scale ROIs for pattern-based analyses.
Robustness of feature representations to visual interruption
We next tested the relative sensitivity of feature representations ineach network to the interruption of visual processing by compar-ing decoding accuracy across experiments. Sensitivity to visual
interruption would be reflected by relatively lower decoding ac-curacy in Experiment 1 (100 ms stimulus /H11001500 ms visual mask)
than in Experiment 2 (600 ms stimulus /H11001no visual mask;
Fig. 3 )
mixed-effects ANOVA with factors of experiment (1, 2) and net-work (FPCN, DAN, VAN, VisN) revealed a main effect of exper-iment ( F
(1,26)/H1100526.5, p/H110210.001), with lower decoding accuracy in
Experiment 1 than Experiment 2, consistent with a disruptive
influence of interruption. Relative sensitivity to visual interrup-tion markedly varied across networks, as reflected by a significantexperiment by network interaction ( F
(3,78)/H110056.2,p/H110210.001).
Post hoc independent sample ttests revealed no reliable differ-
ences between experiments in FPCN ( t(26)/H110051.1,p/H110050.29), a
trend in DAN ( t(26)/H110052.0,p/H110050.06), and reliably greater feature
decoding in Experiment 2 than Experiment 1 in VAN ( t(26)/H110053.2,
p/H110050.003) and VisN ( t(26)/H110055.8,p/H110210.001). Therefore, the
experimental manipulation of including a brief visual mask (Ex-
periment 1) versus extended stimulus presentation (Experiment2), the only difference between the two experiments, robustlydiminished feature representations in VisN and VAN, but hadrelatively less influence on feature representations in DAN andFPCN.
Goal relevance influences feature representations
We next tested the relative sensitivity of feature representations ineach network to trial-specific behavioral goals; that is, whethergoal-relevant feature information was stronger than goal-irrelevant feature information (
Kuhl et al., 2013 ;Roy et al., 2014 ;
Sarma et al., 2016 ;Bracci et al., 2017 ). For example, on trials in
which gender was the relevant dimension (“Male?” or “Female?”
Figure 2. Feature decoding across networks. A, Feature decoding averaged across experiments and goal relevance. Feature decoding was reliably above chance in all networks. B–D, Represen-
tational coherence within and between networks. B, Each attentional network was divided into discontiguous frontal and parietal subregions (here shown for a single subject). C, Correlations were
computed for trial-level measures of goal-relevant feature evidence for each pair of frontal and parietal subregions. Within-network correlation s (dark gray) corresponded to correlations between
pairs of subregions from the same network (e.g., frontal-FPCN and parietal-FPCN). Between-network correlations (light gray) corresponded to corr elations between pairs of subregions from
different networks (e.g., frontal-FPCN and parietal-DAN). This analysis was then repeated for goal-irrelevant feature evidence and Fisher Z-transformed /H9267values were then averaged across the
goal-relevant and goal-irrelevant correlation analyses. D, Within-network correlations were reliably stronger than between-network correlations. *** p/H110210.001.
Figure 3. Feature decoding as a function of interruption. Interruption of visual processing
was manipulated across experiments. In Experiment 1 (clear circles), stimuli were followed by avisual mask. In Experiment 2 (filled circles), there was a longer stimulus duration and no mask.There was a significant network-by-experiment interaction ( p/H110210.001). Significant differ-
ences between experiments were observed in VAN and VisN. Error bars indicate SEM. /H11011p/H11021
0.10, ** p/H110210.01, *** p/H110210.001.Long and Kuhl •Stimulus Features in Attentional Networks J. Neurosci., March 7, 2018 •38(10):2495–2504 • 2499

trials), goal-relevant feature information was indexed by accu-
racy of the gender classifier and goal-irrelevant feature informa-tion was indexed by accuracy of the affect classifier. To be clear,for this analysis, decoding accuracy refers only to the featureinformation in the actual face image. Therefore, if gender was therelevant dimension and the face image was a female face, then theclassifier was accurate if it guessed “Female” regardless of whetherthe current goal was “Male?” or “Female?” This approach en-sured that feature information was not confounded with goalinformation. Separate classifiers were trained/tested for relevantand irrelevant feature representations. That is, one set of classifi-ers was specifically trained and tested on goal-relevant featureinformation and a separate set was trained and tested on goal-irrelevant feature information. Separate classifiers were used forgoal-relevant and goal-irrelevant feature decoding so that therewas no assumption that goal-relevant and goal-irrelevant featurerepresentations are encoded in a common (generalizable) way.
A mixed-effects ANOVA with factors of experiment, goal rel-
evance (relevant, irrelevant), and network (FPCN, DAN, VAN,VisN) revealed a marginally significant main effect of relevance(F
(1,26)/H110053.93, p/H110050.06), reflecting a trend for stronger decoding
of goal-relevant than goal-irrelevant feature information ( Fig. 4 ).
The effect of relevance did not vary by experiment ( F(1,26)/H110050.07,
p/H110050.80). More critically, there was a significant interaction
between network and goal relevance ( F(3,78)/H110053.12, p/H110050.03),
indicating that the sensitivity of feature representations to top-
down goals varied across the networks. This interaction betweennetwork and relevance did not vary by experiment ( F
(3,78)/H110051.24,
p/H110050.30).
For each network, we ran follow-up mixed-effects ANOVAs
with factors of goal relevance (relevant, irrelevant) and experi-ment to test for effects of goal relevance within each network. Asignificant main effect of goal relevance (relevant /H11022irrelevant)
was observed in VAN ( F
(1,26)/H1100513.9, p/H110210.001), with a similar
trend in FPCN ( F(1,26)/H110053.7,p/H110050.07). There was no effect of
relevance in DAN ( F(1,26)/H110050.03, p/H110050.87) or VisN ( F(1,26)/H11005
0.12, p/H110050.73). None of the main effects of relevance interacted
with experiment ( F/H110212.5,p/H11022.1).
Task switches influence feature representations
In the preceding section, we considered whether goal-relevantfeatures were more strongly represented than goal-irrelevant fea-tures. However, goal cues (and, therefore, the relevant featuredimension) changed every two trials, creating both switch (goalchange) and stay (goal repeat) trials. To measure the influence ofgoal cue switches, we first probed the behavioral data for effects of
task switching. Reaction times (RTs) were compared as a func-tion of trial type (switch, stay) and experiment in a mixed-effectsANOVA. As expected, RTs were significantly greater for switchtrials (M /H110051423 ms, SD /H11005259 ms) than stay trials (M /H110051398 ms,
SD/H11005269 ms; F
(1,26)/H1100512.7, p/H110050.001; Fig. 5 A). This effect did
not interact with experiment ( F(1,26)/H110053.2,p/H110050.08). Accuracy
did not significantly differ across switch and stay trials (switch,
M/H1100596.92%, SD /H110053.17%; stay, M /H1100597.52%, SD /H110052.17%;
t(27)/H11005/H11002 1.5,p/H110050.13). There was a trend toward an interaction
between switch/stay and experiment ( F(1,26)/H110054.03, p/H110050.06),
reflecting a relatively greater effect of accuracy (stay /H11022switch) in
Experiment 2.
To determine whether the predictable nature of goal cues (i.e.,
the A-A-B-B-A-A-B-B alternation) was detected by subjectsand/or influenced switch costs (
Rogers and Monsell, 1995 ;Mon-
sell, 2003 ), we ran an independent behavioral study in which 14
subjects completed an experiment virtually identical to Experi-ment 1 (see Materials and Methods). Critically, however, thisbehavioral experiment also included a postexperiment question-naire to assess whether subjects became aware of the alternatingpattern of goal cues. Across all subjects, RTs were significantlygreater for switch trials (M /H110051298 ms, SD /H11005227 ms) than stay
trials (M /H110051257 ms, SD /H11005204 ms; t
(13)/H110052.58, p/H110050.02),
consistent with the data from Experiments 1 and 2. Of the 14
subjects, four were able to explicitly describe the task structure(i.e., they were aware of the pattern of alternation). Among thesefour subjects, switch costs were numerically greater (M /H1100559 ms)
relative to subjects who were unaware of the task structure (M /H11005
33 ms). These data indicate that, despite the highly structuredtask alternation, most subjects did not become aware of thisstructure. In addition, at least in this small sample of subjects,there was no evidence that awareness of the structure reducedswitch costs. Therefore, it is unlikely that explicit awareness of thetask structure had a major influence on fMRI-based effects of taskswitching.
Prior univariate fMRI studies of task switching have consis-
tently reported increased activation during switch versus stay tri-als in dorsal frontoparietal regions (overlapping with FPCN andDAN), whereas more ventral regions (overlapping with VAN) aregenerally insensitive to switch effects (
Kimberg et al., 2000 ;Rush-
worth et al., 2002 ;Braver et al., 2003 ;Brass and Von Cramon,
2004 ;Corbetta et al., 2008 ). In light of these prior studies, and as
a comparison point for our decoding analyses, we tested for uni-variate effects of task switching in each of the four resting-statenetworks. Consistent with prior findings, we found reliablygreater activation for switch than stay trials in FPCN ( t
(27)/H110054.0,
p/H110210.001) and DAN ( t(27)/H110052.5,p/H110050.02) and no effect in VAN
(t(27)/H110051.2,p/H110050.23) or VisN ( t(27)/H110050.23, p/H110050.82; Fig. 5 B).Post
hocindependent-samples ttests within each network did not
reveal any between-experiment differences in switch effects inFPCN, DAN, or VAN ( t/H110211.5,p/H11022.1). In VisN, there was a
reliable difference between experiment ( t
(26)/H11005/H11002 2.3,p/H110050.03),
although neither experiment alone showed a reliable difference
between switch and stay trials. In Experiment 1, activation wasrelatively greater for stay than switch trials ( t
(13)/H11005/H11002 1.7,p/H11005
0.12), whereas in Experiment 2, activation was relatively greater
for switch than stay trials ( t(13)/H110051.6,p/H110050.14).
Next, we considered the novel question of whether task
switches influenced the strength of feature representations. Forthis analysis, we used the same classifiers described above andthen back-sorted trial-specific accuracy values as a function oftrial type (switch vs stay). Decoding accuracy was entered into a
Figure 4. Feature decoding as a function of goal relevance. Orange indicates goal-relevant
feature decoding (e.g., decoding whether a face was male vs female when the goal was “Male?”or “Female?”). Blue indicates goal-irrelevant feature decoding (e.g., decoding whether a facewas male vs female when the goal was “Happy?” or “Grumpy?”). There was a significant inter-action between network and goal relevance ( p/H110050.03). Goal-relevant feature decoding was
reliably greater than goal-irrelevant feature decoding in VAN, with a similar trend in FPCN./H11011p/H110210.10, *** p/H110210.001.2500 •J. Neurosci., March 7, 2018 •38(10):2495–2504 Long and Kuhl •Stimulus Features in Attentional Networks

mixed-effects ANOVA with factors of task switch (switch, stay),
relevance (relevant, irrelevant), network, and experiment. Themain effect of task switch was not significant ( F
(1,26)/H110050.09, p/H11005
0.77). However, there was a robust 3-way interaction between
the effects of task switch, relevance, and network ( F(3,78)/H110054.50,
p/H110050.006). Considering goal-relevant feature information alone,
a mixed-effects ANOVA with factors of task switch, network, andexperiment revealed a significant interaction between task switchand network ( F
(3,78)/H110054.87, p/H110050.004). For goal-irrelevant fea -
ture information, a similar mixed-effects ANOVA did not revealan interaction between task switch and network ( F
(3,78)/H110050.60,
p/H110050.62). Therefore, the influence of task switches on feature
representations varied across the networks, but only when con-sidering goal-relevant feature representations.
The interaction between task switch and network for goal-
relevant feature representations was driven by relatively strongerrepresentations on switch versus stay trials in DAN and VAN andan opposite pattern in FPCN. This interaction did not signifi-cantly vary by experiment ( F
(3,78)/H110052.25, p/H110050.09). Follow-up
mixed-effects ANOVAs with factors of task switch (switch, stay)
and experiment revealed that, within FPCN, there was a signifi-cant effect of task switch ( F
(1,26)/H110056.3,p/H110050.02), reflecting rela -
tively lower feature information on switch than stay trials. Incontrast, there were opposite trends (greater feature informationon switch than stay trials) in DAN ( F
(1,26)/H110054.2,p/H110050.05) and
VAN ( F(1,26)/H110054.2,p/H110050.05). In VisN, there was no effect of task
switch ( F(1,26)/H110051.1,p/H110050.31). The effect of task switch inter -
acted with experiment in FPCN ( F(1,26)/H110056.6,p/H110050.02), but not
in DAN, VAN, or VisN ( F/H110212.2,p/H11022.15). For FPCN, the inter-
action between experiment and task switch reflected a greaterdecoding advantage on stay versus switch trials in Experiment 2compared with Experiment 1. Collectively, these data indicatethat task switches had an effect on goal-relevant feature informa-tion, but this effect varied across networks and was most evidentin the attentional networks.
Network representations of task goals
Although our central aim was to assess feature representationsacross networks, a complementary question is how/whetherthese networks represent top-down behavioral goals. Previousresearch has revealed top-down goal effects within multiple fron-toparietal regions (
Esterman et al., 2009 ;Greenberg et al., 2010 ;
Liu and Hou, 2013 ;Waskom et al., 2014 ;Waskom and Wagner,
2017 ). Here, to test for goal representations, we trained and tested
four separate pairwise classifiers to distinguish each combinationof gender and affect goals. For example, one classifier was trainedto dissociate “Male?” versus “Grumpy?” goal cues. Averagingacross the pairwise classifiers, goal decod-
ing was significantly above chance in eachof the four networks (FPCN, t
(27)/H110058.8,
p/H110210.001; DAN, t(27)/H1100510.6, p/H110210.001;
VAN, t(27)/H110055.9,p/H110210.001; VisN, t(27)/H11005
10.8, p/H110210.001; Fig. 6 ). A mixed-effects
ANOVA with factors of experiment andnetwork revealed no main effect of exper-iment ( F
(1,26)/H110050.76, p/H110050.39), a main
effect of network ( F(3,78)/H110058.53, p/H11021
0.001), and no interaction between net-
work and experiment ( F(3,78)/H110050.31, p/H11005
0.81). Adding task switch (switch, stay) as
a factor ( Waskom et al., 2014 ) revealed no
main effect of switch on goal decoding(F
(1,26)/H110050.01, p/H110050.92), nor was there
an interaction between the factors of task switch and network
(F(3,78)/H110050.70, p/H110050.56).
Because goals were communicated to subjects via word
cues, successful goal decoding potentially reflects multiple in-fluences: (1) “true” abstract goal representations, (2) represen-
tations of the visual word form of each goal cue, and/or (3)subvocal rehearsal of the word cues. Therefore, as a complemen-tary measure, we also assessed “dimension” decoding; that is,decoding of the dimension (gender or affect) that was relevant oneach trial. Dimension decoding was assessed by testing for trans-fer of classifiers across goal cues but within dimensions. Forexample, a classifier trained to discriminate “Male?” versus“Grumpy?” goals would be tested on “Female?” versus “Happy?”goals. Successful transfer would occur if the representation of the“Male?” goal is similar to the representation of the “Female?” goaland, likewise, if “Grumpy?” is similar to “Happy?” Although thisanalysis does not entirely rule out effects of visual word form orsubvocal rehearsal, it at least reduces these concerns. One-samplettests revealed reliable dimension decoding in all four networks
(FPCN, t
(27)/H110057.9,p/H110210.001; DAN, t(27)/H110057.5,p/H110210.001; VAN,
t(27)/H110055.1,p/H110210.001; VisN, t(27)/H1100510.0, p/H110210.001). A mixed-
effects ANOVA with factors of experiment and network revealed
no main effect of experiment ( F(1,26)/H110051.09, p/H110050.31), a main
effect of network ( F(3,78)/H110055.53, p/H110050.002), and no reliable
interaction between network and experiment ( F(3,78)/H110050.17,
p/H110050.92).
Finally, to compare goal decoding and dimension decoding
directly, we ran a mixed-effects ANOVA with factors of goal level(goal decoding vs dimension decoding), network, and experi-ment. There was a significant main effect of goal level ( F
(1,26)/H11005
25.86, p/H110210.001), reflecting lower dimension decoding accuracy
than goal decoding accuracy, which is not surprising given thatdimension decoding requires transfer of the classifier to non-identical goal cues. There was a significant main effect of network
(F
(3,78)/H110058.32, p/H110210.001), reflecting (as with the separate
ANOVAs for goal decoding and dimension decoding) relatively
lower decoding accuracy in VAN than in the other networks ( Fig.
6). The interaction between goal level and network was also sig-
nificant ( F(3,78)/H110052.95, p/H110050.04), indicating that the “cost” of
transferring across goal cues (but within dimensions) varied
across networks. Namely, the difference between goal decodingand dimension decoding was most pronounced in VisN (
Fig. 6 ).
Discussion
Here, using pattern-based fMRI methods and a perceptualdecision-making task, we compared representations of stimulusfeatures across multiple resting-state networks. We specifically
Figure 5. Effects of task switching. A, Difference in RTs (ms) between switch and stay trials. RTs were significantly slower for
switch trials than stay trials. B, Univariate contrast of switch versus stay trials. Activation was significantly greater for switch than
stay trials in both FPCN and DAN. C, Goal-relevant feature decoding separated by switch and stay trials. There was a significant
interaction between switch/stay and network, reflecting greater goal-relevant feature decoding on stay than switch trials in FPCN;the opposite trends were true for DAN and VAN. /H11011p/H110210.10, * p/H110210.05, ** p/H110210.01, *** p/H110210.001.Long and Kuhl •Stimulus Features in Attentional Networks J. Neurosci., March 7, 2018 •38(10):2495–2504 • 2501

targeted networks that are thought to contribute to attention and
cognitive control (FPCN, DAN, and VAN; Dosenbach et al.,
2008 ;Cole et al., 2013 ;Sestieri et al., 2017 ) and, as an important
comparison, visual cortical networks. Although stimulus featureswere reliably decoded from each network, of critical interest washow feature representations in each network were influenced bythree attentional manipulations: (1) interruption of visual pro-cessing, (2) goal relevance, and (3) task switching. Whereasbottom-up manipulations (interruption) had a relatively greaterinfluence on feature representations within VisN, top-down ma-nipulations (goals and task switches) had a relatively greaterinfluence on representations in attentional networks. These
findings reveal an important dissociation between feature rep-resentations in higher-level attentional networks and featurerepresentations in visual cortex.
Whereas most decoding studies use spatially contiguous ROIs
or searchlight analyses, we decoded from large, spatially discon-tiguous networks identified from independent studies of resting-state connectivity (
Vincent et al., 2008 ;Yeo et al., 2011 ). We used
these resting-state networks because they have been linked spe-cifically to attentional processes (
Fox et al., 2006 ;Corbetta et al.,
2008 ;Gratton et al., 2017 ). That said, these networks have been
defined based on correlations in univariate responses during restand it was an open question whether regions within thesenetworks would exhibit correlated feature representations, parti-cularly after mean univariate responses were removed (see Mate-rials and Methods). When specifically considering correlationsbetween frontal and parietal regions from each attentional net-work, we found that decoded feature representations were morecoherent within networks than between networks. Beyond vali-dating our approach, this finding provides novel evidence thatbrain regions within attentional networks represent commonstimulus information.
The traditional view of frontoparietal regions is that they bias
and/or evaluate stimulus representations held in perceptual re-gions (
Kastner et al., 1999 ;Zanto et al., 2010 ;Liu et al., 2011 ;
Gazzaley and Nobre, 2012 ). However, our findings, along with
other recent evidence ( Kuhl et al., 2013 ;Bettencourt and Xu,
2016 ;Ester et al., 2016 ;Bracci et al., 2017 ), challenge this view by
demonstrating active stimulus representations within frontopa-rietal regions. This raises the critical question of how frontopari-etal representations differ from those in perceptual regions. Weshow that frontoparietal representations were sensitive to differ-ent forms of attention than representations in visual cortical ar-eas. The fact that frontoparietal representations were relatively
more sensitive to top-down factors helps to reconcile evidencethat frontoparietal regions represent stimulus information withthe putative role of these regions in top-down processing. Specif-ically, our results suggest a transformation of information fromperceptual regions to frontoparietal regions that selectively rep-resent and/or evaluate stimulus features. We next briefly considerthe pattern of results for each attentional manipulation.
Previous work has shown that visual distraction disrupts
working memory representations in visual cortex to a greaterdegree than representations in frontoparietal regions (
Miller et
al., 1996 ;Suzuki and Gottlieb, 2013 ;Woolgar et al., 2015 ;Betten-
court and Xu, 2016 ). Based on these findings, we predicted that
feature representations in the attentional networks would be rel-atively less influenced by the across-experiment manipulation ofvisual interruption. Indeed, the effect of interruption (Experi-ment 1 vs Experiment 2) significantly differed across networks,with feature representations in VisN most strongly “suffering”from the interruption in bottom-up visual input (
Fig. 3 ). Among
the attentional networks, VAN showed a significant effect of in-terruption and there was a trend for DAN, whereas feature rep-resentations in FPCN were not influenced by interruption. Thefact that VAN feature representations were influenced by inter-ruption is consistent with the idea that VAN is involved inbottom-up attentional capture (
Corbetta and Shulman, 2002 ).
One reason why frontoparietal regions may actively represent
stimulus features is so that behaviorally relevant decisions can bemade. Indeed, several recent studies have found that stimulusrepresentations in frontoparietal regions are biased by task de-mands (
Swaminathan and Freedman, 2012 ;Kuhl et al., 2013 ;
Ester et al., 2016 ;Sarma et al., 2016 ;Bracci et al., 2017 ). We
specifically designed our stimuli to be multidimensional so thatwe could test for flexible representation of individual features. Aswith visual interruption, we found that the influence of behav-ioral goals varied across networks (
Fig. 4 ). In VAN, there was
significantly greater representation of goal-relevant than goal-irrelevant features, with a similar trend in FPCN. At first pass, theeffect of goal relevance in VAN seems at odds with the putativerole of VAN in bottom-up attentional orienting (
Corbetta and
Shulman, 2002 ). For example, univariate responses in VAN in-
crease for oddball stimuli or targets that appear at invalid loca-tions (
Bledowski et al., 2004 ;Kincade et al., 2005 ). However,
more recent evidence suggests that VAN plays a role in compar-ing bottom-up input to top-down goals (
Vossel et al., 2014 ;Grat-
ton et al., 2017 ). In fact, a recent meta-analysis found greater
VAN responses to task-relevant than task-irrelevant oddballs(
Kim, 2014 ), suggesting that VAN /H11032s response to exogenous stim-
uli is moderated by top-down goals. Therefore, the present find-ing of preferential decoding of goal-relevant features in VAN isconsistent with the view that VAN plays a role in orienting atten-tion to task-relevant perceptual input.
VisN feature representations were unaffected by goals. Al-
though other studies have clearly found that top-down factorscan influence stimulus representations in early visual areas (
Jehee
et al., 2011 ;Sprague and Serences, 2013 ;Ester et al., 2016 ), the
present findings suggest that frontoparietal regions can imposetheir own attentional biases to favor goal-relevant features asopposed to simply inheriting biases imposed in visual corticalregions. Potentially, the lack of attentional bias in VisN in thepresent study reflects the fact that we used stimuli (faces) that areprocessed holistically. With different stimulus types and/or at-tentional manipulations, it is likely easier to gate processing atearlier stages.
Figure 6. Goal and dimension decoding. For goal decoding (teal), four different classifiers
were trained to dissociate each of the possible pairs of goals that appeared in a given block. Thegoal pairs always consisted of one goal from each dimension (e.g., “Male?” vs “Grumpy?” goals).For dimension decoding (lavender), the classifier training was identical to goal, but the classi-fiers were tested on different goal pairs corresponding to the same dimensions. For example, aclassifier trained to dissociate Male/Grumpy goals would be tested on Female/Happy goals. Allnetworks showed reliable goal and dimension decoding. * p/H110210.05, ** p/H110210.01, *** p/H11021
0.001.2502 •J. Neurosci., March 7, 2018 •38(10):2495–2504 Long and Kuhl •Stimulus Features in Attentional Networks

A large body of previous research indicates that switching
between tasks (goals) is associated with increased univariate ac-tivity in dorsal frontoparietal regions (
Corbetta et al., 2008 ). Our
finding of greater univariate activation for switch versus stay tri-als in FPCN and DAN, but not VAN or VisN, is consistent withthis literature. However, we are not aware of prior pattern-basedfMRI studies that have compared frontoparietal feature repre-sentations across switch versus stay trials, so our analysis of taskswitching effects on feature representations was necessarily moreexploratory. We found that the influence of task switching variedacross networks (
Fig. 5 ) and, in particular, that switching effects
were more apparent in the attentional networks than VisN. Giventhat task switching requires reconfiguration of top-down atten-tion, this finding is consistent with the argument that featurerepresentations in attentional networks are relatively more sen-sitive to top-down attention. Among the attentional networks,FPCN showed greater feature decoding on stay than switch trials,whereas DAN and VAN showed opposite trends. Although wedid not predict this pattern a priori, the tendency for featurerepresentations to be stronger on switch than stay trials (in DANand VAN) is reminiscent of recent evidence for greater decodingof top-down goals on switch than stay trials (
Waskom et al.,
2014 ). For FPCN, it is notable that switch trials were associated
with relatively greater univariate activity but relatively lower fea-ture decoding, raising the possibility that these measures reflectopposing processes. Given the exploratory nature of this analysis,we believe this question requires additional investigation.
Although our primary focus was on frontoparietal represen-
tations of stimulus features, several prior studies have reportedfrontoparietal representations of top-down goals (
Waskom et al.,
2014 ;Hanson and Chrysikou, 2017 ;Loose et al., 2017 ;Waskom
and Wagner, 2017 ;Qiao et al., 2017 ) Consistent with these find-
ings, we observed significant goal decoding in all four networks.One open question is whether the strength of goal representa-tions is influenced by task switches. Although there is some evi-dence that goal representations are relatively stronger on switchtrials than stay trials (
Waskom et al., 2014 ), others have failed to
observe switch-related effects in task representations ( Loose et
al., 2017 ). Like Loose et al. (2017) , we did not observe a significant
difference in goal decoding as a function of task switching; how-ever, we did find task-switching effects in the decoding of goal-relevant features. Therefore, additional research will be needed tobetter understand how and when task switching influences thestrength of top-down goals and/or goal-relevant feature repre-sentations.
Given that classifiers trained on one pair of goals (e.g., “Male”
vs “Grumpy” goals) reliably transferred to nonidentical goals thatshared the same dimensions (e.g., “Female” vs “Happy” goals),this suggests that goal representations reflected, at least in part,information about or attention to the goal-relevant stimulus di-mension (gender or affect). The fact that the “transfer cost” (goalvs dimension decoding) was relatively greatest in VisN is consis-tent with the idea that goal decoding in VisN was more closelyrelated to low-level properties of the goals (e.g., the visual wordform of the cue). Considering goal-decoding performance acrossnetworks also provides a useful comparison point for the featuredecoding results. For example, comparing overall goal decodingversus decoding of goal-relevant features across the three atten-tional networks (a 2 /H110033 ANOVA) revealed a highly significant
interaction ( F
(2,52)/H110057.40, p/H110050.001), reflecting a dissociation
between the networks that best represented goal-relevant features
(VAN) versus the goals themselves (FPCN/DAN). Therefore,theoretical accounts of how these networks contribute to attentionwill benefit from considering, not only how feature representations
vary across networks, but also the hierarchical organization of fea-ture and goal representations (
Koechlin and Summerfield, 2007 ;
Badre, 2008 ).
In summary, we show that resting-state networks implicated
in attentional control actively and coherently represent stimulusfeatures and that network-based feature representations can bedissociated in terms of their sensitivity to various forms of atten-tion (interruption of visual processing, goal relevance, and taskswitching). Whereas feature representations in visual cortical ar-eas are sensitive to low-level manipulations (visual interruption),feature representations in attentional networks are sensitive tohigher-level manipulations (goal relevance and task switching).At a broad level, these findings indicate that multiple networksactively represent stimulus features, with the nature of these fea-ture representations providing insight into each network’s func-tional role.
References
Badre D (2008) Cognitive control, hierarchy, and the rostro-caudal organi-
zation of the frontal lobes. Trends Cogn Sci 12:193–200. CrossRef
Medline
Bettencourt KC, Xu Y (2016) Decoding the content of visual short-term
memory under distraction in occipital and parietal areas. Nat Neurosci19:150–157.
CrossRef Medline
Bledowski C, Prvulovic D, Goebel R, Zanella FE, Linden DE (2004) Atten-
tional systems in target and distractor processing: a combined ERP andfMRI study. Neuroimage 22:530–540.
CrossRef Medline
Bode S, Haynes JD (2009) Decoding sequential stages of task preparation in
the human brain. Neuroimage 45:606–613. CrossRef Medline
Bracci S, Daniels N, Op de Beeck H (2017) Task context overrules object-
and category-related representational content in the human parietal cor-tex. Cereb Cortex 27:310–321.
CrossRef Medline
Brass M, von Cramon DY (2004) Decomposing components of task prepa-
ration with functional magnetic resonance imaging. J Cogn Neurosci16:609–620.
CrossRef Medline
Braver TS, Reynolds JR, Donaldson DI (2003) Neural mechanisms of tran-
sient and sustained cognitive control during task switching. Neuron 39:713–726.
CrossRef Medline
Cole MW, Reynolds JR, Power JD, Repovs G, Anticevic A, Braver TS (2013)
Multi-task connectivity reveals exible hubs for adaptive task control. NatNeurosci 16:1348–1355.
CrossRef Medline
Corbetta M, Shulman GL (2002) Control of goal-directed and stimulus-
driven attention in the brain. Nat Rev Neurosci 3:201–215. CrossRef
Medline
Corbetta M, Patel G, Shulman GL (2008) The reorienting system of the
human brain: from environment to theory of mind. Neuron 58:306–324.
CrossRef Medline
Desimone R, Duncan J (1995) Neural mechanisms of selective visual atten-
tion. Annu Rev Neurosci 18:193–222. CrossRef Medline
Dosenbach NU, Fair DA, Cohen AL, Schlaggar BL, Petersen SE (2008) A
dual-networks architecture of top-down control. Trends Cogn Sci 12:99–105.
CrossRef Medline
Egner T, Hirsch J (2005) Cognitive control mechanisms resolve conict
through cortical amplification of task-relevant information. Nat Neurosci8:1784–1790.
CrossRef Medline
Ester EF, Sprague TC, Serences JT (2015) Parietal and frontal cortex encode
stimulus-specific mnemonic representations during visual workingmemory. Neuron 87:893–905.
CrossRef Medline
Ester EF, Sutterer DW, Serences JT, Awh E (2016) Feature-selective atten-
tional modulations in human frontoparietal cortex. J Neurosci 36:8188–8199.
CrossRef Medline
Esterman M, Chiu YC, Tamber-Rosenau BJ, Yantis S (2009) Decoding cog-
nitive control in human parietal cortex. Proc Natl Acad Sci U S A 106:17974–17979.
CrossRef Medline
Fan RE, Chang KW, Hsieh CJ, Wang XR, Lin CJ (2008) Liblinear: a library
for large linear classification. The Journal of Machine Learning Research9:1871–1874.
Fox MD, Corbetta M, Snyder AZ, Vincent JL, Raichle ME (2006) Spontane-Long and Kuhl •Stimulus Features in Attentional Networks J. Neurosci., March 7, 2018
•38(10):2495–2504 • 2503

ous neuronal activity distinguishes human dorsal and ventral attention
systems. Proc Natl Acad Sci U S A 103:10046–10051. CrossRef Medline
Gazzaley A, Nobre AC (2012) Top-down modulation: bridging selective at-
tention and working memory. Trends Cogn Sci 16:129–135. CrossRef
Medline
Gratton C, Neta M, Sun H, Ploran EJ, Schlaggar BL, Wheeler ME, Petersen SE,
**Nelson SM (2017) Distinct stages of moment-to-moment processingin the cinguloopercular and frontoparietal networks. Cereb Cortex 27:2403–2417.
CrossRef Medline
Greenberg AS, Esterman M, Wilson D, Serences JT, Yantis S (2010) Control
of spatial and feature-based attention in frontoparietal cortex. J Neurosci30:14330–14339.
CrossRef Medline
Hanson GK, Chrysikou EG (2017) Attention to distinct goal-relevant fea-
tures differentially guides semantic knowledge retrieval. J Cogn Neurosci29:1178–1193.
CrossRef Medline
Jehee JF, Brady DK, Tong F (2011) Attention improves encoding of task-
relevant features in the human visual cortex. J Neurosci 31:8210–8219.
CrossRef Medline
Jenkinson M, Bannister P, Brady M, Smith S (2002) Improved optimization
for the robust and accurate linear registration and motion correction ofbrain images. Neuroimage 17:825–841.
CrossRef Medline
Kastner S, Pinsk MA, De Weerd P, Desimone R, Ungerleider LG (1999)
Increased activity in human visual cortex during directed attention in theabsence of visual stimulation. Neuron 22:751–761.
CrossRef Medline
Kim H (2014) Involvement of the dorsal and ventral attention networks in
oddball stimulus processing: a meta-analysis. Hum Brain Mapp 35:2265–2284.
CrossRef Medline
Kimberg DY, Aguirre GK, D’Esposito M (2000) Modulation of task-related
neural activity in task-switching: an fMRI study. Brain Res Cogn BrainRes 10:189–196.
CrossRef Medline
Kincade JM, Abrams RA, Astafiev SV, Shulman GL, Corbetta M (2005) An
event-related functional magnetic resonance imaging study of voluntaryand stimulus-driven orienting of attention. J Neurosci 25:4593–4604.
CrossRef Medline
Koechlin E, Summerfield C (2007) An information theoretical approach to
prefrontal executive function. Trends Cogn Sci 11:229–235. CrossRef
Medline
Kuhl BA, Chun MM (2014) Successful remembering elicits event-specific
activity patterns in lateral parietal cortex. J Neurosci 34:8051–8060.
CrossRef Medline
Kuhl BA, Johnson MK, Chun MM (2013) Dissociable neural mechanisms
for goal-directed versus incidental memory reactivation. J Neurosci 33:16099–16109.
CrossRef Medline
Lee H, Kuhl BA (2016) Reconstructing perceived and retrieved faces from
activity patterns in lateral parietal cortex. J Neurosci 36:6069–6082.
CrossRef Medline
Liu T, Hou Y (2013) A hierarchy of attentional priority signals in human
frontoparietal cortex. J Neurosci 33:16606–16616. CrossRef Medline
Liu T, Hospadaruk L, Zhu DC, Gardner JL (2011) Feature-specific atten-
tional priority signals in human cortex. J Neurosci 31:4484–4495.
CrossRef Medline
Long NM, Lee H, Kuhl BA (2016) Hippocampal mismatch signals are mod-
ulated by the strength of neural predictions and their similarity to out-comes. J Neurosci 36:12677–12687.
CrossRef Medline
Loose LS, Wisniewski D, Rusconi M, Goschke T, Haynes JD (2017) Switch
independent task representations in frontal and parietal cortex. J Neuro-sci 37:8033–8042.
CrossRef Medline
Miller EK, Erickson CA, Desimone R (1996) Neural mechanisms of visual
working memory in prefontal cortex of the macaque. J Neurosci 16:5154–5167.
Medline
Monsell S (2003) Task switching. Trends Cogn Sci 7:134–140. CrossRef
Medline
Posner MI, Petersen SE (1990) The attention system of the human brain.
Annu Rev Neurosci 13:25–42. CrossRef Medline
Qiao L, Zhang L, Chen A, Egner T (2017) Dynamic trial-by-trial recoding of
task-set representations in the frontoparietal cortex mediates behavioralexibility. J Neurosci 37:11037–11050.
Medline
Rainer G, Asaad WF, Miller EK (1998) Selective representation of relevantinformation by neurons in the primate prefrontal cortex. Nature 393:
577–579. CrossRef Medline
Ravizza SM, Carter CS (2008) Shifting set about task switching: behavioral
and neural evidence for distinct forms of cognitive exibility. Neuropsy-chologia 46:2924–2935.
CrossRef Medline
Rogers RD, Monsell S (1995) Costs of a predictible switch between simple
cognitive tasks. Journal of Experimental Psychology General 124:207.
CrossRef
Roy JE, Buschman TJ, Miller EK (2014) PFC neurons reect categorical de-
cisions about ambiguous stimuli. J Cogn Neurosci 26:1283–1291.
CrossRef Medline
Rushworth MF, Hadland KA, Paus T, Sipila PK (2002) Role of the human
medial frontal cortex in task switching: a combined fMRI and TMS study.J Neurophysiol 87:2577–2592.
CrossRef Medline
Sarma A, Masse NY, Wang XJ, Freedman DJ (2016) Task-specific versus
generalized mnemonic representations in parietal and prefrontal cortices.Nat Neurosci 19:143–149.
CrossRef Medline
Serences JT, Yantis S (2006) Selective visual attention and perceptual coher-
ence. Trends Cogn Sci 10:38–45. CrossRef Medline
Sestieri C, Shulman GL, Corbetta M (2017) The contribution of the human
posterior parietal cortex to episodic memory. Nat Rev Neurosci 18:183–192.
CrossRef Medline
Smith SM, Jenkinson M, Woolrich MW, Beckmann CF, Behrens TE,
Johansen-Berg H, Bannister PR, De Luca M, Drobnjak I, Flitney DE,Niazy RK, Saunders J, Vickers J, Zhang Y, De Stefano N, Brady JM, Mat-thews PM (2004) Advances in functional and structural MR image anal-ysis and implementation as FSL. Neuroimage 23:S208–S219.
CrossRef
Medline
Sprague TC, Serences JT (2013) Attention modulates spatial priority maps
in the human occipital, parietal and frontal cortices. Nat Neurosci 16:1879–1887.
CrossRef Medline
Sreenivasan KK, Vytlacil J, D’Esposito M (2014) Distributed and dynamic
storage of working memory stimulus information in extrastriate cortex.J Cogn Neurosci 26:1141–1153.
CrossRef Medline
Suzuki M, Gottlieb J (2013) Distinct neural mechanisms of distractor sup-
pression in the frontal and parietal lobe. Nat Neurosci 16:98–104.
CrossRef Medline
Swaminathan SK, Freedman DJ (2012) Preferential encoding of visual cat-
egories in parietal cortex compared with prefrontal cortex. Nat Neurosci15:315–320.
CrossRef Medline
Vincent JL, Kahn I, Snyder AZ, Raichle ME, Buckner RL (2008) Evidence
for a frontoparietal control system revealed by intrinsic functional con-nectivity. J Neurophysiol 100:3328–3342.
CrossRef Medline
Vossel S, Geng JJ, Fink GR (2014) Dorsal and ventral attention systems
distinct neural circuits but collaborative roles. Neuroscientist 20:150–159.
CrossRef Medline
Waskom ML, Kumaran D, Gordon AM, Rissman J, Wagner AD (2014)
Frontoparietal representations of task context support the exible controlof goal-directed cognition. J Neurosci 34:10743–10755.
CrossRef Medline
Waskom ML, Wagner AD (2017) Distributed representation of context by
intrinsic subnetworks in prefrontal cortex. Proc Natl Acad Sci U S A 114:2030–2035.
CrossRef Medline
Woolgar A, Williams MA, Rich AN (2015) Attention enhances multi-voxel
representation of novel objects in frontal, parietal and visual cortices.Neuroimage 109:429–437.
CrossRef Medline
Xu Y (2017) Reevaluating the sensory account of visual working memory
storage. Trends Cogn Sci 21:794–815. CrossRef Medline
Yeo BT, Krienen FM, Sepulcre J, Sabuncu MR, Lashkari D, Hollinshead M,
Roffman JL, Smoller JW, Zo ¨llei L, Polimeni JR, Fischl B, Liu H, Buckner
RL (2011) The organization of the human cerebral cortex estimated by
intrinsic functional connectivity. J Neurophysiol 106:1125–1165. CrossRef
Medline
Yeung N, Nystrom LE, Aronson JA, Cohen JD (2006) Between-task compe-
tition and cognitive control in task switching. J Neurosci 26:1429–1438.
CrossRef Medline
Zanto TP, Rubens MT, Bollinger J, Gazzaley A (2010) Top-down modula-
tion of visual feature processing: the role of the inferior frontal junction.Neuroimage 53:736–745.
CrossRef Medline2504 •J. Neurosci., March 7, 2018 •38(10):2495–2504 Long and Kuhl •Stimulus Features in Attentional Networks